{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core.schema import TextNode\n",
    "from typing import Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Pydantic Models for Structured Output\n",
    "\n",
    "In this section, we define several Pydantic models to structure the output data. These models ensure that the extracted and generated data adheres to a predefined schema, facilitating validation and consistency.\n",
    "\n",
    "- `KnowledgeStatement`: Represents a knowledge statement with an ID and text.\n",
    "- `AbilityStatement`: Represents an ability statement with an ID and text.\n",
    "- `Topic`: Represents a topic with a name, subtopics, knowledge statements, and ability statements.\n",
    "- `LearningUnit`: Represents a learning unit with a name, topics, and a learning outcome.\n",
    "- `AssessmentMethod`: Represents an assessment method with a code and duration.\n",
    "- `FacilitatorGuideExtraction`: Represents the structured data extracted from the facilitator guide, including course title, proficiency level, learning units, and assessments.\n",
    "- `KnowledgeStatementContent`: Represents the content retrieved for a knowledge statement, including the knowledge ID, statement, topic name, and retrieved content.\n",
    "- `WSQ`: Represents a workplace scenario question, including the knowledge ID, statement, scenario, question, and answer.\n",
    "- `CaseStudyQuestion`: Represents a case study question with a question, answer, and associated abilities.\n",
    "- `CaseStudy`: Represents a case study with a scenario and a list of case study questions.\n",
    "\n",
    "These models are used to structure and validate the data throughout the extraction and generation processes, ensuring that the output is consistent and reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Define Pydantic models for structured output\n",
    "class KnowledgeStatement(BaseModel):\n",
    "    id: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "class AbilityStatement(BaseModel):\n",
    "    id: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "class Topic(BaseModel):\n",
    "    name: str\n",
    "    subtopics: List[str]\n",
    "    tsc_knowledges: List[KnowledgeStatement]\n",
    "    tsc_abilities: List[AbilityStatement]\n",
    "\n",
    "\n",
    "class LearningUnit(BaseModel):\n",
    "    name: str\n",
    "    topics: List[Topic]\n",
    "    learning_outcome: str\n",
    "\n",
    "\n",
    "class AssessmentMethod(BaseModel):\n",
    "    code: str\n",
    "    duration: str\n",
    "\n",
    "class FacilitatorGuideExtraction(BaseModel):\n",
    "    course_title: str\n",
    "    tsc_proficiency_level: str\n",
    "    learning_units: List[LearningUnit]\n",
    "    assessments: List[AssessmentMethod]  # New field for assessments\n",
    "\n",
    "# Define a Pydantic model for the Knowledge Statement and its Retrieved Content\n",
    "class KnowledgeStatementContent(BaseModel):\n",
    "    knowledge_id: str = Field(..., description=\"The ID of the Knowledge Statement, e.g., K1, K2.\")\n",
    "    knowledge_statement: str = Field(..., description=\"The text of the Knowledge Statement.\")\n",
    "    topic_name: str = Field(..., description=\"The name of the topic associated with this Knowledge Statement.\")\n",
    "    retrieved_content: str = Field(..., description=\"The content retrieved for this Knowledge Statement.\")\n",
    "\n",
    "# Define the WSQ model for structured output\n",
    "class WSQ(BaseModel):\n",
    "    knowledge_id: str = Field(..., description=\"The ID of the Knowledge Statement, e.g., K1, K2.\")\n",
    "    knowledge_statement: str = Field(..., description=\"The text of the Knowledge Statement.\")\n",
    "    scenario: str = Field(..., description=\"The realistic workplace scenario.\")\n",
    "    question: str = Field(..., description=\"The question based on the scenario.\")\n",
    "    answer: str = Field(..., description=\"The concise answer to the question.\")\n",
    "\n",
    "class LearningOutcomeContent(BaseModel):\n",
    "    ability_id: List[str]\n",
    "    retrieved_content: str = Field(..., description=\"The content retrieved for this Knowledge Statement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up LlamaParse, LlamaIndex and OpenAI Models\n",
    "\n",
    "In this section, we initialize the `Settings` for LlamaIndex with the OpenAI embedding and language models. We use the `OpenAIEmbedding` model for embeddings and the `OpenAI` model for language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI \n",
    "from llama_index.core.schema import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('TERTIARY_INFOTECH_API_KEY') \n",
    "LLAMA_API_KEY = os.getenv('LLAMA_CLOUD_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\", api_key=OPENAI_API_KEY)\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\", api_key=OPENAI_API_KEY)\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 90655fac-68db-4358-a78d-d3240b3713ea\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import LlamaParseJsonNodeParser\n",
    "from llama_index.core import VectorStoreIndex\n",
    "slides_parser = LlamaParse(\n",
    "    api_key=LLAMA_API_KEY,\n",
    "    result_type=\"text\",\n",
    "    fast_mode=True,\n",
    "    num_workers=8,\n",
    "    verbose=True,\n",
    ")\n",
    "file_path = \"../input/WSQ- Learner Guide Slides - Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini - v5.pdf\"\n",
    "md_json_objs = slides_parser.get_json_result(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_json_list = md_json_objs[0][\"pages\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 6c7a9703-a68c-4060-af5b-b6b94f943507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, ?it/s]\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.1490642624376317 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.44660132977111155 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 27\u001b[0m\n\u001b[0;32m     14\u001b[0m     documents\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     15\u001b[0m         Document(\n\u001b[0;32m     16\u001b[0m             text\u001b[38;5;241m=\u001b[39mpage\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     17\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mpage,\n\u001b[0;32m     18\u001b[0m         )\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     21\u001b[0m node_parser \u001b[38;5;241m=\u001b[39m LlamaParseJsonNodeParser(\n\u001b[0;32m     22\u001b[0m     llm\u001b[38;5;241m=\u001b[39mOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     23\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     24\u001b[0m     include_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[43mnode_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nodes_from_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m base_nodes, objects \u001b[38;5;241m=\u001b[39m node_parser\u001b[38;5;241m.\u001b[39mget_nodes_and_objects(nodes)\n\u001b[0;32m     30\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex(nodes\u001b[38;5;241m=\u001b[39mbase_nodes \u001b[38;5;241m+\u001b[39m objects)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\node_parser\\interface.py:165\u001b[0m, in \u001b[0;36mNodeParser.get_nodes_from_documents\u001b[1;34m(self, documents, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m doc_id_to_document \u001b[38;5;241m=\u001b[39m {doc\u001b[38;5;241m.\u001b[39mid_: doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents}\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    163\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mNODE_PARSING, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mDOCUMENTS: documents}\n\u001b[0;32m    164\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m--> 165\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postprocess_parsed_nodes(nodes, doc_id_to_document)\n\u001b[0;32m    168\u001b[0m     event\u001b[38;5;241m.\u001b[39mon_end({EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes})\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\node_parser\\relational\\base_element.py:127\u001b[0m, in \u001b[0;36mBaseElementNodeParser._parse_nodes\u001b[1;34m(self, nodes, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m nodes_with_progress \u001b[38;5;241m=\u001b[39m get_tqdm_iterable(nodes, show_progress, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes_with_progress:\n\u001b[1;32m--> 127\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nodes_from_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     all_nodes\u001b[38;5;241m.\u001b[39mextend(nodes)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_nodes\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\node_parser\\relational\\llama_parse_json_element.py:33\u001b[0m, in \u001b[0;36mLlamaParseJsonNodeParser.get_nodes_from_node\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     31\u001b[0m table_elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_table_elements(elements)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# extract summaries over table elements\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_table_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_elements\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# convert into nodes\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# will return a list of Nodes and Index Nodes\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_nodes_from_elements(\n\u001b[0;32m     37\u001b[0m     elements, node, ref_doc_text\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39mget_content()\n\u001b[0;32m     38\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\node_parser\\relational\\base_element.py:216\u001b[0m, in \u001b[0;36mBaseElementNodeParser.extract_table_summaries\u001b[1;34m(self, elements)\u001b[0m\n\u001b[0;32m    211\u001b[0m summary_jobs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    212\u001b[0m     _get_table_output(table_context, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummary_query_str)\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m table_context \u001b[38;5;129;01min\u001b[39;00m table_context_list\n\u001b[0;32m    214\u001b[0m ]\n\u001b[0;32m    215\u001b[0m summary_co \u001b[38;5;241m=\u001b[39m run_jobs(summary_jobs, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers)\n\u001b[1;32m--> 216\u001b[0m summary_outputs \u001b[38;5;241m=\u001b[39m \u001b[43masyncio_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_co\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element, summary_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(elements, summary_outputs):\n\u001b[0;32m    218\u001b[0m     element\u001b[38;5;241m.\u001b[39mtable_output \u001b[38;5;241m=\u001b[39m summary_output\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\async_utils.py:33\u001b[0m, in \u001b[0;36masyncio_run\u001b[1;34m(coro)\u001b[0m\n\u001b[0;32m     30\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# If we're here, there's an existing loop but it's not running\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# If we can't get the event loop, we're likely in a different thread, or its already running\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\asyncio\\futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\asyncio\\tasks.py:279\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\async_utils.py:148\u001b[0m, in \u001b[0;36mrun_jobs\u001b[1;34m(jobs, show_progress, workers, desc)\u001b[0m\n\u001b[0;32m    146\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tqdm_asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mpool_jobs, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 148\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mpool_jobs)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\asyncio\\tasks.py:349\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    351\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\asyncio\\tasks.py:277\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\async_utils.py:139\u001b[0m, in \u001b[0;36mrun_jobs.<locals>.worker\u001b[1;34m(job)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;129m@dispatcher\u001b[39m\u001b[38;5;241m.\u001b[39mspan\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mworker\u001b[39m(job: Coroutine) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m job\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\node_parser\\relational\\base_element.py:199\u001b[0m, in \u001b[0;36mBaseElementNodeParser.extract_table_summaries.<locals>._get_table_output\u001b[1;34m(table_context, summary_query_str)\u001b[0m\n\u001b[0;32m    197\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_query_engine(llm\u001b[38;5;241m=\u001b[39mllm, output_cls\u001b[38;5;241m=\u001b[39mTableOutput)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m query_engine\u001b[38;5;241m.\u001b[39maquery(summary_query_str)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, PydanticResponse):\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\base\\base_query_engine.py:64\u001b[0m, in \u001b[0;36mBaseQueryEngine.aquery\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     63\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[1;32m---> 64\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aquery(str_or_query_bundle)\n\u001b[0;32m     65\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m     66\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:195\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._aquery\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    191\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[0;32m    192\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[0;32m    193\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maretrieve(query_bundle)\n\u001b[1;32m--> 195\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_synthesizer\u001b[38;5;241m.\u001b[39masynthesize(\n\u001b[0;32m    196\u001b[0m         query\u001b[38;5;241m=\u001b[39mquery_bundle,\n\u001b[0;32m    197\u001b[0m         nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    200\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\base.py:306\u001b[0m, in \u001b[0;36mBaseSynthesizer.asynthesize\u001b[1;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    303\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE,\n\u001b[0;32m    304\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    305\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m--> 306\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maget_response(\n\u001b[0;32m    307\u001b[0m         query_str\u001b[38;5;241m=\u001b[39mquery\u001b[38;5;241m.\u001b[39mquery_str,\n\u001b[0;32m    308\u001b[0m         text_chunks\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    309\u001b[0m             n\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39mMetadataMode\u001b[38;5;241m.\u001b[39mLLM) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes\n\u001b[0;32m    310\u001b[0m         ],\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[0;32m    312\u001b[0m     )\n\u001b[0;32m    314\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    315\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\compact_and_refine.py:23\u001b[0m, in \u001b[0;36mCompactAndRefine.aget_response\u001b[1;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;129m@dispatcher\u001b[39m\u001b[38;5;241m.\u001b[39mspan\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maget_response\u001b[39m(\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs: Any,\n\u001b[0;32m     21\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RESPONSE_TEXT_TYPE:\n\u001b[0;32m     22\u001b[0m     compact_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39maget_response(\n\u001b[0;32m     24\u001b[0m         query_str\u001b[38;5;241m=\u001b[39mquery_str,\n\u001b[0;32m     25\u001b[0m         text_chunks\u001b[38;5;241m=\u001b[39mcompact_texts,\n\u001b[0;32m     26\u001b[0m         prev_response\u001b[38;5;241m=\u001b[39mprev_response,\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[0;32m     28\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:366\u001b[0m, in \u001b[0;36mRefine.aget_response\u001b[1;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prev_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;66;03m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;66;03m# is an answer, then return it\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agive_response_single(\n\u001b[0;32m    367\u001b[0m             query_str, text_chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs\n\u001b[0;32m    368\u001b[0m         )\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arefine_response_single(\n\u001b[0;32m    371\u001b[0m             prev_response, query_str, text_chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs\n\u001b[0;32m    372\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:487\u001b[0m, in \u001b[0;36mRefine._agive_response_single\u001b[1;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 487\u001b[0m         structured_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m program\u001b[38;5;241m.\u001b[39macall(\n\u001b[0;32m    488\u001b[0m             context_str\u001b[38;5;241m=\u001b[39mcur_text_chunk,\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m         structured_response \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m    492\u001b[0m             StructuredRefineResponse, structured_response\n\u001b[0;32m    493\u001b[0m         )\n\u001b[0;32m    494\u001b[0m         query_satisfied \u001b[38;5;241m=\u001b[39m structured_response\u001b[38;5;241m.\u001b[39mquery_satisfied\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:93\u001b[0m, in \u001b[0;36mDefaultRefineProgram.acall\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macall\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StructuredRefineResponse:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m         answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mastructured_predict(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls,\n\u001b[0;32m     95\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prompt,\n\u001b[0;32m     96\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m     97\u001b[0m         )\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(answer, BaseModel):\n\u001b[0;32m     99\u001b[0m             answer \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mmodel_dump_json()\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:947\u001b[0m, in \u001b[0;36mOpenAI.astructured_predict\u001b[1;34m(self, llm_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    942\u001b[0m llm_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m llm_kwargs \u001b[38;5;28;01melse\u001b[39;00m llm_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    944\u001b[0m )\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# by default structured prediction uses function calling to extract structured outputs\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;66;03m# here we force tool_choice to be required\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mastructured_predict(\u001b[38;5;241m*\u001b[39margs, llm_kwargs\u001b[38;5;241m=\u001b[39mllm_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\llms\\llm.py:431\u001b[0m, in \u001b[0;36mLLM.astructured_predict\u001b[1;34m(self, output_cls, prompt, llm_kwargs, **prompt_args)\u001b[0m\n\u001b[0;32m    418\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    419\u001b[0m     LLMStructuredPredictStartEvent(\n\u001b[0;32m    420\u001b[0m         output_cls\u001b[38;5;241m=\u001b[39moutput_cls, template\u001b[38;5;241m=\u001b[39mprompt, template_args\u001b[38;5;241m=\u001b[39mprompt_args\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m )\n\u001b[0;32m    424\u001b[0m program \u001b[38;5;241m=\u001b[39m get_program_for_llm(\n\u001b[0;32m    425\u001b[0m     output_cls,\n\u001b[0;32m    426\u001b[0m     prompt,\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    428\u001b[0m     pydantic_program_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_program_mode,\n\u001b[0;32m    429\u001b[0m )\n\u001b[1;32m--> 431\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m program\u001b[38;5;241m.\u001b[39macall(llm_kwargs\u001b[38;5;241m=\u001b[39mllm_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[0;32m    432\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(LLMStructuredPredictEndEvent(output\u001b[38;5;241m=\u001b[39mresult))\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\program\\function_program.py:223\u001b[0m, in \u001b[0;36mFunctionCallingProgram.acall\u001b[1;34m(self, llm_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m llm_kwargs \u001b[38;5;241m=\u001b[39m llm_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    221\u001b[0m tool \u001b[38;5;241m=\u001b[39m get_function_tool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls)\n\u001b[1;32m--> 223\u001b[0m agent_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mapredict_and_call(\n\u001b[0;32m    224\u001b[0m     [tool],\n\u001b[0;32m    225\u001b[0m     chat_history\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prompt\u001b[38;5;241m.\u001b[39mformat_messages(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    226\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose,\n\u001b[0;32m    227\u001b[0m     allow_parallel_tool_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_parallel_tool_calls,\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mllm_kwargs,\n\u001b[0;32m    229\u001b[0m )\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse_tool_outputs(\n\u001b[0;32m    231\u001b[0m     agent_response,\n\u001b[0;32m    232\u001b[0m     allow_parallel_tool_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_parallel_tool_calls,\n\u001b[0;32m    233\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\llms\\function_calling.py:239\u001b[0m, in \u001b[0;36mFunctionCallingLLM.apredict_and_call\u001b[1;34m(self, tools, user_msg, chat_history, verbose, allow_parallel_tool_calls, error_on_no_tool_call, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_function_calling_model:\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapredict_and_call(\n\u001b[0;32m    232\u001b[0m         tools,\n\u001b[0;32m    233\u001b[0m         user_msg\u001b[38;5;241m=\u001b[39muser_msg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    237\u001b[0m     )\n\u001b[1;32m--> 239\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39machat_with_tools(\n\u001b[0;32m    240\u001b[0m     tools,\n\u001b[0;32m    241\u001b[0m     user_msg\u001b[38;5;241m=\u001b[39muser_msg,\n\u001b[0;32m    242\u001b[0m     chat_history\u001b[38;5;241m=\u001b[39mchat_history,\n\u001b[0;32m    243\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    244\u001b[0m     allow_parallel_tool_calls\u001b[38;5;241m=\u001b[39mallow_parallel_tool_calls,\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    246\u001b[0m )\n\u001b[0;32m    248\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_tool_calls_from_response(\n\u001b[0;32m    249\u001b[0m     response, error_on_no_tool_call\u001b[38;5;241m=\u001b[39merror_on_no_tool_call\n\u001b[0;32m    250\u001b[0m )\n\u001b[0;32m    251\u001b[0m tool_tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    252\u001b[0m     acall_tool_with_selection(tool_call, tools, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tool_call \u001b[38;5;129;01min\u001b[39;00m tool_calls\n\u001b[0;32m    254\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\llms\\function_calling.py:74\u001b[0m, in \u001b[0;36mFunctionCallingLLM.achat_with_tools\u001b[1;34m(self, tools, user_msg, chat_history, verbose, allow_parallel_tool_calls, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Async chat with function calling.\"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m chat_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat_with_tools(\n\u001b[0;32m     67\u001b[0m     tools,\n\u001b[0;32m     68\u001b[0m     user_msg\u001b[38;5;241m=\u001b[39muser_msg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39machat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_kwargs)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_chat_with_tools_response(\n\u001b[0;32m     76\u001b[0m     response,\n\u001b[0;32m     77\u001b[0m     tools,\n\u001b[0;32m     78\u001b[0m     allow_parallel_tool_calls\u001b[38;5;241m=\u001b[39mallow_parallel_tool_calls,\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     80\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:357\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    350\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    351\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:75\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_async_llm_chat\u001b[1;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[0;32m     67\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m     68\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m     },\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m f(_self, messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     77\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[0;32m     78\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m     79\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[0;32m     80\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[0;32m     81\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:627\u001b[0m, in \u001b[0;36mOpenAI.achat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     achat_fn \u001b[38;5;241m=\u001b[39m acompletion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acomplete)\n\u001b[1;32m--> 627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m achat_fn(messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:189\u001b[0m, in \u001b[0;36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    188\u001b[0m async_wrapped\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m copy(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:111\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:153\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\_utils.py:99\u001b[0m, in \u001b[0;36mwrap_to_async_func.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:114\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    116\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:674\u001b[0m, in \u001b[0;36mOpenAI._achat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(messages, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse_client:\n\u001b[1;32m--> 674\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m aclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    675\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessage_dicts, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    676\u001b[0m     )\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aclient:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:1339\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1304\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1306\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1336\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1337\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m AsyncStream[ChatCompletionChunk]:\n\u001b[0;32m   1338\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1340\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1341\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[0;32m   1342\u001b[0m             {\n\u001b[0;32m   1343\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1344\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1345\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1346\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1347\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1348\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1349\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1350\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1351\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1352\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1353\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1354\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1355\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1356\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1357\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1358\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1359\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1360\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1361\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1362\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1363\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1364\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1366\u001b[0m             },\n\u001b[0;32m   1367\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m   1368\u001b[0m         ),\n\u001b[0;32m   1369\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1370\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1371\u001b[0m         ),\n\u001b[0;32m   1372\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1373\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1374\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[0;32m   1375\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1816\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1803\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1804\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1812\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[0;32m   1813\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1814\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1815\u001b[0m     )\n\u001b[1;32m-> 1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1510\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1503\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1511\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1512\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1513\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1514\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1515\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m   1516\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1596\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maclose()\n\u001b[1;32m-> 1596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1597\u001b[0m         input_options,\n\u001b[0;32m   1598\u001b[0m         cast_to,\n\u001b[0;32m   1599\u001b[0m         retries,\n\u001b[0;32m   1600\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1601\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1602\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1603\u001b[0m     )\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1643\u001b[0m, in \u001b[0;36mAsyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1639\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1644\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1645\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1646\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m   1647\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1648\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1649\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1596\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maclose()\n\u001b[1;32m-> 1596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1597\u001b[0m         input_options,\n\u001b[0;32m   1598\u001b[0m         cast_to,\n\u001b[0;32m   1599\u001b[0m         retries,\n\u001b[0;32m   1600\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1601\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1602\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1603\u001b[0m     )\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1643\u001b[0m, in \u001b[0;36mAsyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1639\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1644\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1645\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1646\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m   1647\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1648\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1649\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1596\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maclose()\n\u001b[1;32m-> 1596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1597\u001b[0m         input_options,\n\u001b[0;32m   1598\u001b[0m         cast_to,\n\u001b[0;32m   1599\u001b[0m         retries,\n\u001b[0;32m   1600\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1601\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1602\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1603\u001b[0m     )\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1643\u001b[0m, in \u001b[0;36mAsyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1639\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1644\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1645\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1646\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m   1647\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1648\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1649\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1611\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1608\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maread()\n\u001b[0;32m   1610\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1614\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1615\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1620\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "slides_parser = LlamaParse(\n",
    "    api_key=LLAMA_API_KEY,\n",
    "    # Use \"markdown\" or \"json\" because we're calling get_json_result()\n",
    "    result_type=\"markdown\",\n",
    "    num_workers=8,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "json_objs = slides_parser.get_json_result(file_path)\n",
    "json_list = json_objs[0][\"pages\"]\n",
    "\n",
    "documents = []\n",
    "for page in json_list:\n",
    "    documents.append(\n",
    "        Document(\n",
    "            text=page.get(\"text\", \"\"),\n",
    "            metadata=page,\n",
    "        )\n",
    "    )\n",
    "\n",
    "node_parser = LlamaParseJsonNodeParser(\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    "    num_workers=8,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
    "\n",
    "index = VectorStoreIndex(nodes=base_nodes + objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "099d364a-d12e-4ee8-8d7a-b3758d70aa88 Develop Ar {'page': 1, 'text': ' Develop Artificial Intelligence and Large\\nLanguage Model (LLM) Applications withGoogle Gemini\\n                         Semini\\n  WS     SINGAPORE\\n         WorkforCE SKILL8\\n         QUALIFICATIONS                                                      Version: 5.0\\n                                                                     Learner Guide Slides\\n  T      Umfmtech                                      Website:www.tertiarycourses.com.sg\\n                                                       Email: enquiry@tertiaryinfotech.comCourse Code: TGS-2024042961\\n                                                                      Tel: +65 6100 0613\\n                     This material belongs to Tertiary Infotech Pte Ltd (UEN: 20120096W). All Rights Reserved', 'images': [{'name': 'img_p0_3.png', 'height': 137, 'width': 300, 'x': 15.348425687999999, 'y': 219.125947956912, 'original_width': 300, 'original_height': 137, 'ocr': [{'x': 106, 'y': 34, 'w': 116, 'h': 24, 'confidence': '0.9842973394927044', 'text': 'SINGAPORE'}, {'x': 21, 'y': 47, 'w': 64, 'h': 40, 'confidence': '0.9812295739401005', 'text': 'WS'}, {'x': 106, 'y': 54, 'w': 194, 'h': 26, 'confidence': '0.4937106920834399', 'text': 'WorkforCE SKILL8'}, {'x': 106, 'y': 75, 'w': 159, 'h': 24, 'confidence': '0.6521510474818355', 'text': 'QUALIFICATIONS'}]}, {'name': 'img_p0_4.png', 'height': 80, 'width': 350, 'x': 82.51181366399999, 'y': 311.43105327288, 'original_width': 350, 'original_height': 80, 'ocr': [{'x': 2, 'y': 6, 'w': 348, 'h': 74, 'confidence': '0.37336243117196827', 'text': 'Umfmtech'}]}, {'name': 'img_p0_5.png', 'height': 400, 'width': 400, 'x': 12.000000384, 'y': 306.91363186847997, 'original_width': 400, 'original_height': 400, 'ocr': [{'x': 86, 'y': 40, 'w': 246, 'h': 306, 'confidence': '0.9111111366910905', 'text': 'T'}]}, {'name': 'img_p0_6.png', 'height': 757, 'width': 2048, 'x': 166.36319429999998, 'y': 99.26771971199997, 'original_width': 2048, 'original_height': 757, 'ocr': [{'x': 252, 'y': 280, 'w': 1796, 'h': 477, 'confidence': '0.71662359604208', 'text': 'Semini'}]}], 'charts': [], 'items': [], 'status': 'OK', 'links': [{'url': 'http://www.tertiarycourses.com.sg/', 'text': 'Email: enquiry@tertiaryinfotech.com'}, {'url': 'mailto:enquiry@tertiaryinfotech.com', 'text': ''}], 'width': 720, 'height': 405, 'triggeredAutoMode': False, 'structuredData': None, 'noStructuredContent': False, 'noTextContent': False}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import BaseNode, TextNode, Document\n",
    "\n",
    "documents = []\n",
    "for _, page in enumerate(md_json_list):\n",
    "    documents.append(\n",
    "        Document(\n",
    "            text=page.get(\"text\"),\n",
    "            metadata=page,\n",
    "        )\n",
    "    )\n",
    "\n",
    "for doc in documents:\n",
    "    print(doc.id_, doc.text.strip()[:10], doc.metadata)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Develop Artificial Intelligence and Large\n",
      "Language Model (LLM) Applications withGoogle Gemini\n",
      "                         Semini\n",
      "  WS     SINGAPORE\n",
      "         WorkforCE SKILL8\n",
      "         QUALIFICATIONS                                                      Version: 5.0\n",
      "                                                                     Learner Guide Slides\n",
      "  T      Umfmtech                                      Website:www.tertiarycourses.com.sg\n",
      "                                                       Email: enquiry@tertiaryinfotech.comCourse Code: TGS-2024042961\n",
      "                                                                      Tel: +65 6100 0613\n",
      "                     This material belongs to Tertiary Infotech Pte Ltd (UEN: 20120096W). All Rights Reserved\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import LlamaParseJsonNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "node_parser = LlamaParseJsonNodeParser(\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"), num_workers=16, include_metadata=True\n",
    ")\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "\n",
    "recursive_index = VectorStoreIndex(nodes=base_nodes + objects)\n",
    "recursive_query_engine = recursive_index.as_query_engine(\n",
    "    similarity_top_k=5, verbose=True\n",
    ")\n",
    "res = recursive_query_engine.query(\n",
    "    \"what is MultiModal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Response\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['page', 'text', 'images', 'charts', 'items', 'status', 'links', 'width', 'height', 'triggeredAutoMode', 'structuredData', 'noStructuredContent', 'noTextContent'])\n"
     ]
    }
   ],
   "source": [
    "print(md_json_list[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'img_p0_3.png', 'height': 137, 'width': 300, 'x': 15.348425687999999, 'y': 219.125947956912, 'original_width': 300, 'original_height': 137, 'ocr': [{'x': 106, 'y': 34, 'w': 116, 'h': 24, 'confidence': '0.9842973394927044', 'text': 'SINGAPORE'}, {'x': 21, 'y': 47, 'w': 64, 'h': 40, 'confidence': '0.9812295739401005', 'text': 'WS'}, {'x': 106, 'y': 54, 'w': 194, 'h': 26, 'confidence': '0.4937106920834399', 'text': 'WorkforCE SKILL8'}, {'x': 106, 'y': 75, 'w': 159, 'h': 24, 'confidence': '0.6521510474818355', 'text': 'QUALIFICATIONS'}]}, {'name': 'img_p0_4.png', 'height': 80, 'width': 350, 'x': 82.51181366399999, 'y': 311.43105327288, 'original_width': 350, 'original_height': 80, 'ocr': [{'x': 2, 'y': 6, 'w': 348, 'h': 74, 'confidence': '0.37336243117196827', 'text': 'Umfmtech'}]}, {'name': 'img_p0_5.png', 'height': 400, 'width': 400, 'x': 12.000000384, 'y': 306.91363186847997, 'original_width': 400, 'original_height': 400, 'ocr': [{'x': 86, 'y': 40, 'w': 246, 'h': 306, 'confidence': '0.9111111366910905', 'text': 'T'}]}, {'name': 'img_p0_6.png', 'height': 757, 'width': 2048, 'x': 166.36319429999998, 'y': 99.26771971199997, 'original_width': 2048, 'original_height': 757, 'ocr': [{'x': 252, 'y': 280, 'w': 1796, 'h': 477, 'confidence': '0.71662359604208', 'text': 'Semini'}]}]\n"
     ]
    }
   ],
   "source": [
    "print(md_json_list[0]['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Image for page 1: [{'name': 'img_p0_3.png', 'height': 137, 'width': 300, 'x': 15.348425687999999, 'y': 219.125947956912, 'original_width': 300, 'original_height': 137, 'ocr': [{'x': 106, 'y': 34, 'w': 116, 'h': 24, 'confidence': '0.9842973394927044', 'text': 'SINGAPORE'}, {'x': 21, 'y': 47, 'w': 64, 'h': 40, 'confidence': '0.9812295739401005', 'text': 'WS'}, {'x': 106, 'y': 54, 'w': 194, 'h': 26, 'confidence': '0.4937106920834399', 'text': 'WorkforCE SKILL8'}, {'x': 106, 'y': 75, 'w': 159, 'h': 24, 'confidence': '0.6521510474818355', 'text': 'QUALIFICATIONS'}]}, {'name': 'img_p0_4.png', 'height': 80, 'width': 350, 'x': 82.51181366399999, 'y': 311.43105327288, 'original_width': 350, 'original_height': 80, 'ocr': [{'x': 2, 'y': 6, 'w': 348, 'h': 74, 'confidence': '0.37336243117196827', 'text': 'Umfmtech'}]}, {'name': 'img_p0_5.png', 'height': 400, 'width': 400, 'x': 12.000000384, 'y': 306.91363186847997, 'original_width': 400, 'original_height': 400, 'ocr': [{'x': 86, 'y': 40, 'w': 246, 'h': 306, 'confidence': '0.9111111366910905', 'text': 'T'}]}, {'name': 'img_p0_6.png', 'height': 757, 'width': 2048, 'x': 166.36319429999998, 'y': 99.26771971199997, 'original_width': 2048, 'original_height': 757, 'ocr': [{'x': 252, 'y': 280, 'w': 1796, 'h': 477, 'confidence': '0.71662359604208', 'text': 'Semini'}]}]\n",
      "> Image for page 2: [{'name': 'img_p1_1.png', 'height': 1170, 'width': 2048, 'x': 52.811025312, 'y': 54.01181275199997, 'original_width': 2048, 'original_height': 1170}]\n",
      "> Image for page 3: []\n",
      "> Image for page 4: []\n",
      "> Image for page 5: []\n",
      "> Image for page 6: []\n",
      "> Image for page 7: []\n",
      "> Image for page 8: []\n",
      "> Image for page 9: []\n",
      "> Image for page 10: []\n",
      "> Image for page 11: []\n",
      "> Image for page 12: []\n",
      "> Image for page 13: []\n",
      "> Image for page 14: [{'name': 'img_p13_1.png', 'height': 979, 'width': 1514, 'x': 0.000908464596, 'y': 0, 'original_width': 1514, 'original_height': 979}]\n",
      "> Image for page 15: []\n",
      "> Image for page 16: []\n",
      "> Image for page 17: [{'name': 'img_p16_1.png', 'height': 675, 'width': 1080, 'x': 414.38977703999996, 'y': 94.51966837896, 'original_width': 1080, 'original_height': 675, 'ocr': [{'x': 461, 'y': 9, 'w': 34, 'h': 14, 'confidence': '0.31633598002576946', 'text': 'p'}, {'x': 469, 'y': 325, 'w': 176, 'h': 88, 'confidence': '0.9999035072511238', 'text': 'LLM'}, {'x': 477, 'y': 411, 'w': 160, 'h': 20, 'confidence': '0.7295448038690834', 'text': 'LARGE LANGUAGE MODEL'}]}]\n",
      "> Image for page 18: [{'name': 'img_p17_7.png', 'height': 225, 'width': 225, 'x': 330.19067985743993, 'y': 69.48004159343999, 'original_width': 225, 'original_height': 225}, {'name': 'img_p17_8.png', 'height': 1080, 'width': 1440, 'x': 465.50788891199994, 'y': 47.435040888, 'original_width': 1440, 'original_height': 1080, 'ocr': [{'x': 224, 'y': 724, 'w': 1021, 'h': 295, 'confidence': '0.8471885352531827', 'text': 'Gemini'}]}, {'name': 'img_p17_9.png', 'height': 196, 'width': 196, 'x': 336.30316036799996, 'y': 218.85456802696797, 'original_width': 196, 'original_height': 196, 'ocr': [{'x': 29, 'y': 39, 'w': 148, 'h': 116, 'confidence': '0.704104051834786', 'text': 'AI'}]}, {'name': 'img_p17_10.png', 'height': 965, 'width': 1716, 'x': 46.42716684, 'y': 256.5256971852, 'original_width': 1716, 'original_height': 965, 'ocr': [{'x': 801, 'y': 93, 'w': 162, 'h': 214, 'confidence': '0.9777440428918318', 'text': '2'}]}, {'name': 'img_p17_11.png', 'height': 154, 'width': 640, 'x': 474.36910966799996, 'y': 215.21275885531196, 'original_width': 640, 'original_height': 154, 'ocr': [{'x': 152, 'y': 4, 'w': 488, 'h': 140, 'confidence': '0.737468342497628', 'text': 'perplexity'}]}, {'name': 'img_p17_12.png', 'height': 273, 'width': 300, 'x': 531.566946144, 'y': 270.732347246112, 'original_width': 300, 'original_height': 273}]\n",
      "> Image for page 19: [{'name': 'img_p18_1.png', 'height': 1528, 'width': 1500, 'x': 411.37796591999995, 'y': 63.844490232, 'original_width': 1500, 'original_height': 1528, 'ocr': [{'x': 1156, 'y': 506, 'w': 70, 'h': 52, 'confidence': '0.13519363268927975', 'text': 'S'}, {'x': 1218, 'y': 556, 'w': 26, 'h': 28, 'confidence': '0.24411216735360597', 'text': 'X'}]}]\n",
      "> Image for page 20: [{'name': 'img_p19_1.png', 'height': 1342, 'width': 1328, 'x': 399.377965536, 'y': 63.844490232, 'original_width': 1328, 'original_height': 1342}]\n",
      "> Image for page 21: [{'name': 'img_p20_1.png', 'height': 1376, 'width': 1364, 'x': 411.37796591999995, 'y': 63.844490232, 'original_width': 1364, 'original_height': 1376}]\n",
      "> Image for page 22: [{'name': 'img_p21_1.png', 'height': 1360, 'width': 1360, 'x': 411.37796591999995, 'y': 63.844490232, 'original_width': 1360, 'original_height': 1360, 'ocr': [{'x': 110, 'y': 652, 'w': 156, 'h': 96, 'confidence': '0.22191019356250763', 'text': '3='}, {'x': 234, 'y': 850, 'w': 242, 'h': 282, 'confidence': '0.1635471143675069', 'text': '5'}]}]\n",
      "> Image for page 23: [{'name': 'img_p22_1.png', 'height': 1348, 'width': 1386, 'x': 426.44686404, 'y': 64.47244300799997, 'original_width': 1386, 'original_height': 1348}]\n",
      "> Image for page 24: [{'name': 'img_p23_1.png', 'height': 1348, 'width': 1332, 'x': 390.0079849211999, 'y': 61.34055314400001, 'original_width': 1332, 'original_height': 1348}]\n",
      "> Image for page 25: [{'name': 'img_p24_1.png', 'height': 1366, 'width': 1362, 'x': 393.21261100799995, 'y': 63.844490232, 'original_width': 1362, 'original_height': 1366, 'ocr': [{'x': 201, 'y': 139, 'w': 158, 'h': 206, 'confidence': '0.41043231325831186', 'text': '5'}, {'x': 1101, 'y': 263, 'w': 74, 'h': 14, 'confidence': '0.15612041595650245', 'text': 'Monfintngt'}, {'x': 1104, 'y': 222, 'w': 72, 'h': 30, 'confidence': '0.30002206563949585', 'text': 'SOz,'}]}]\n",
      "> Image for page 26: []\n",
      "> Image for page 27: []\n",
      "> Image for page 28: []\n",
      "> Image for page 29: []\n",
      "> Image for page 30: [{'name': 'img_p29_1.png', 'height': 730, 'width': 1260, 'x': 70.687010136, 'y': 55.722442727999976, 'original_width': 1260, 'original_height': 730, 'ocr': [{'x': 209, 'y': 53, 'w': 562, 'h': 36, 'confidence': '0.9774665115371466', 'text': 'MEASURING MASSIVE MULTITASK'}, {'x': 208, 'y': 94, 'w': 479, 'h': 42, 'confidence': '0.9783598135091871', 'text': 'LANGUAGE UNDERSTANDING'}, {'x': 226, 'y': 169, 'w': 150, 'h': 32, 'confidence': '0.8782486746571847', 'text': 'Dan Hendrycks'}, {'x': 488, 'y': 172, 'w': 124, 'h': 24, 'confidence': '0.8070041376239995', 'text': 'Collin Burns'}, {'x': 722, 'y': 172, 'w': 134, 'h': 24, 'confidence': '0.999892210907869', 'text': 'Steven Basart'}, {'x': 946, 'y': 172, 'w': 100, 'h': 26, 'confidence': '0.9999214369960628', 'text': 'Andy Zou'}, {'x': 240, 'y': 193, 'w': 118, 'h': 29, 'confidence': '0.8905486415690537', 'text': 'UC Berkeley'}, {'x': 456, 'y': 194, 'w': 186, 'h': 28, 'confidence': '0.9998385817714036', 'text': 'Columbia University'}, {'x': 742, 'y': 192, 'w': 97, 'h': 33, 'confidence': '0.9927831063030906', 'text': 'UChicago'}, {'x': 937, 'y': 197, 'w': 34, 'h': 20, 'confidence': '0.9999266652712032', 'text': 'UC'}, {'x': 970, 'y': 192, 'w': 85, 'h': 32, 'confidence': '0.9999913177335946', 'text': 'Berkeley'}, {'x': 222, 'y': 256, 'w': 158, 'h': 24, 'confidence': '0.9929381407094979', 'text': 'Mantas Mazeika'}, {'x': 580, 'y': 256, 'w': 60, 'h': 24, 'confidence': '0.5380927850282905', 'text': 'Dawn'}, {'x': 892, 'y': 256, 'w': 164, 'h': 26, 'confidence': '0.8531513014125494', 'text': 'Jacob Steinhardt'}, {'x': 272, 'y': 280, 'w': 58, 'h': 24, 'confidence': '0.9975999260699647', 'text': 'UIUC'}, {'x': 576, 'y': 278, 'w': 120, 'h': 30, 'confidence': '0.9998407973056239', 'text': 'UC Berkeley'}, {'x': 914, 'y': 276, 'w': 119, 'h': 32, 'confidence': '0.9995364503250415', 'text': 'UC Berkeley'}, {'x': 578, 'y': 354, 'w': 122, 'h': 24, 'confidence': '0.9998471285402867', 'text': 'ABSTRACT'}, {'x': 11, 'y': 337, 'w': 42, 'h': 96, 'confidence': '0.5027054987497195', 'text': '8'}, {'x': 286, 'y': 404, 'w': 706, 'h': 28, 'confidence': '0.5533352512252948', 'text': \"We propose a new test to measure a text model's multitask accuracy: The test\"}, {'x': 284, 'y': 428, 'w': 138, 'h': 24, 'confidence': '0.9998990685732367', 'text': 'covers 57 tasks'}, {'x': 417, 'y': 422, 'w': 578, 'h': 36, 'confidence': '0.7214543594248272', 'text': 'including elementary mathematics, US history, computer science,'}, {'x': 13, 'y': 431, 'w': 42, 'h': 72, 'confidence': '0.6765308449954013', 'text': '8'}, {'x': 284, 'y': 452, 'w': 706, 'h': 26, 'confidence': '0.8026631439794186', 'text': 'law, and more. To attain high accuracy on this test, models must possess extensive'}, {'x': 282, 'y': 471, 'w': 420, 'h': 33, 'confidence': '0.8772414495520997', 'text': 'world knowledge and problem solving ability:'}, {'x': 710, 'y': 476, 'w': 282, 'h': 24, 'confidence': '0.8981023988405832', 'text': 'We find that while most recent'}, {'x': 284, 'y': 498, 'w': 706, 'h': 29, 'confidence': '0.6353108321998405', 'text': 'models have near random-chance accuracy, the very largest GPT-3 model improves'}, {'x': 11, 'y': 501, 'w': 42, 'h': 50, 'confidence': '0.304228345197771', 'text': '~'}, {'x': 286, 'y': 523, 'w': 383, 'h': 27, 'confidence': '0.8589873562188864', 'text': 'over random chance by almost 20 percentage'}, {'x': 726, 'y': 523, 'w': 264, 'h': 27, 'confidence': '0.6888758506605901', 'text': 'on average. However; 0n every'}, {'x': 286, 'y': 546, 'w': 212, 'h': 24, 'confidence': '0.934389620091214', 'text': 'one of the 57 tasks, the'}, {'x': 540, 'y': 546, 'w': 450, 'h': 26, 'confidence': '0.8227110967039315', 'text': 'models still need substantial improvements before'}, {'x': 333, 'y': 577, 'w': 32, 'h': 14, 'confidence': '0.7950514696543666', 'text': 'can'}, {'x': 364, 'y': 568, 'w': 256, 'h': 28, 'confidence': '0.9611896679049057', 'text': 'reach expert-level accuracy:'}, {'x': 628, 'y': 567, 'w': 362, 'h': 29, 'confidence': '0.8234862488574435', 'text': 'Models also have lopsided performance'}, {'x': 322, 'y': 593, 'w': 413, 'h': 29, 'confidence': '0.9526730598532366', 'text': 'frequently do not know when they are wrong:'}, {'x': 743, 'y': 593, 'w': 69, 'h': 27, 'confidence': '0.5692297436843116', 'text': 'Worse,'}, {'x': 854, 'y': 592, 'w': 140, 'h': 26, 'confidence': '0.6978583224234147', 'text': 'still have near-'}, {'x': 11, 'y': 568, 'w': 44, 'h': 140, 'confidence': '0.15265248468015002', 'text': '5'}, {'x': 284, 'y': 612, 'w': 706, 'h': 32, 'confidence': '0.4452503024381666', 'text': 'random accuracy 0n some socially important subjects such as morality and law.'}, {'x': 286, 'y': 638, 'w': 704, 'h': 31, 'confidence': '0.500652905257468', 'text': \"By comprehensively evaluating the breadth and depth of a model's academic and\"}, {'x': 283, 'y': 660, 'w': 251, 'h': 32, 'confidence': '0.9270701070233175', 'text': 'professional understanding,'}, {'x': 534, 'y': 664, 'w': 456, 'h': 28, 'confidence': '0.9615952397478285', 'text': 'our test can be used to analyze models across many'}, {'x': 284, 'y': 684, 'w': 392, 'h': 32, 'confidence': '0.7774381812981987', 'text': 'tasks and to identify important shortcomings'}, {'x': 640, 'y': 253, 'w': 50, 'h': 32, 'confidence': '0.9999560117721558', 'text': 'Song'}, {'x': 666, 'y': 525, 'w': 60, 'h': 20, 'confidence': '0.9992064467283659', 'text': 'points'}, {'x': 499, 'y': 544, 'w': 38, 'h': 26, 'confidence': '0.999990701675415', 'text': 'best'}, {'x': 285, 'y': 567, 'w': 39, 'h': 30, 'confidence': '0.9998348355293274', 'text': 'they'}, {'x': 282, 'y': 596, 'w': 42, 'h': 18, 'confidence': '0.9999772876144699', 'text': 'and'}, {'x': 810, 'y': 590, 'w': 43, 'h': 31, 'confidence': '0.9999682307243347', 'text': 'they'}]}]\n",
      "> Image for page 31: [{'name': 'img_p30_1.png', 'height': 1319, 'width': 2048, 'x': 117.564964392, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 1319, 'ocr': [{'x': 676, 'y': 6, 'w': 112, 'h': 26, 'confidence': '0.9903030664452335', 'text': 'Averaget'}, {'x': 60, 'y': 22, 'w': 60, 'h': 24, 'confidence': '0.9999973773956299', 'text': 'Rank'}, {'x': 142, 'y': 20, 'w': 72, 'h': 24, 'confidence': '0.9829354378015133', 'text': 'Model'}, {'x': 794, 'y': 22, 'w': 66, 'h': 24, 'confidence': '0.9999828335137793', 'text': 'Paper'}, {'x': 1472, 'y': 20, 'w': 62, 'h': 24, 'confidence': '0.9998743534088135', 'text': 'Code'}, {'x': 1555, 'y': 23, 'w': 74, 'h': 20, 'confidence': '0.9999926999457116', 'text': 'Result'}, {'x': 1656, 'y': 20, 'w': 54, 'h': 24, 'confidence': '0.9999732375144958', 'text': 'Year'}, {'x': 1860, 'y': 22, 'w': 26, 'h': 24, 'confidence': '0.19116164740374675', 'text': 'C'}, {'x': 704, 'y': 36, 'w': 40, 'h': 26, 'confidence': '0.9992618828532058', 'text': '(%)'}, {'x': 150, 'y': 114, 'w': 216, 'h': 30, 'confidence': '0.9492730482826613', 'text': 'Claude 3.5 Sonnet'}, {'x': 706, 'y': 134, 'w': 54, 'h': 26, 'confidence': '0.9627129755523981', 'text': '88.7'}, {'x': 802, 'y': 131, 'w': 498, 'h': 31, 'confidence': '0.7659349611585665', 'text': 'Claude 3.5 Sonnet Model Card Addendum'}, {'x': 1660, 'y': 132, 'w': 68, 'h': 28, 'confidence': '0.9999998211860657', 'text': '2024'}, {'x': 152, 'y': 154, 'w': 86, 'h': 28, 'confidence': '0.6574069799770528', 'text': '(5-shot)'}, {'x': 93, 'y': 233, 'w': 14, 'h': 22, 'confidence': '0.9999983310706426', 'text': '2'}, {'x': 150, 'y': 228, 'w': 92, 'h': 28, 'confidence': '0.9459246215372504', 'text': 'GPT-4o'}, {'x': 706, 'y': 228, 'w': 54, 'h': 30, 'confidence': '0.961969751581404', 'text': '88.7'}, {'x': 1660, 'y': 226, 'w': 68, 'h': 30, 'confidence': '0.9999991059303284', 'text': '2024'}, {'x': 150, 'y': 308, 'w': 186, 'h': 30, 'confidence': '0.8256581830987889', 'text': 'Llama 3.1 405B'}, {'x': 93, 'y': 331, 'w': 14, 'h': 22, 'confidence': '0.9999969005608733', 'text': '3'}, {'x': 706, 'y': 328, 'w': 56, 'h': 28, 'confidence': '0.9999281167984009', 'text': '88.6'}, {'x': 802, 'y': 325, 'w': 337, 'h': 31, 'confidence': '0.9968136971501516', 'text': 'The Llama 3 Herd of Models'}, {'x': 1588, 'y': 328, 'w': 32, 'h': 28, 'confidence': '0.3123698081425097', 'text': 'J'}, {'x': 1660, 'y': 326, 'w': 68, 'h': 30, 'confidence': '0.9999992847442627', 'text': '2024'}, {'x': 1773, 'y': 327, 'w': 161, 'h': 27, 'confidence': '0.7154160335904874', 'text': 'chain-of-thought'}, {'x': 152, 'y': 348, 'w': 64, 'h': 30, 'confidence': '0.8657096705776016', 'text': '(CoT)'}, {'x': 146, 'y': 426, 'w': 282, 'h': 39, 'confidence': '0.9998083776959631', 'text': 'Tencent Hunyuan Large'}, {'x': 706, 'y': 428, 'w': 56, 'h': 28, 'confidence': '0.5398993400664164', 'text': '88.4'}, {'x': 1660, 'y': 426, 'w': 68, 'h': 30, 'confidence': '0.9999995231628418', 'text': '2024'}, {'x': 150, 'y': 508, 'w': 176, 'h': 32, 'confidence': '0.9912185703872081', 'text': 'Claude 3 Opus'}, {'x': 93, 'y': 531, 'w': 14, 'h': 22, 'confidence': '0.9999957084701805', 'text': '5'}, {'x': 706, 'y': 528, 'w': 56, 'h': 28, 'confidence': '0.9999706745147705', 'text': '88.2'}, {'x': 801, 'y': 525, 'w': 334, 'h': 36, 'confidence': '0.7171920196357213', 'text': 'The Claude 3 Model Family:'}, {'x': 1206, 'y': 526, 'w': 170, 'h': 30, 'confidence': '0.8564390223353424', 'text': 'Sonnet; Haiku'}, {'x': 1588, 'y': 528, 'w': 30, 'h': 26, 'confidence': '0.14667125232117328', 'text': '9'}, {'x': 1660, 'y': 526, 'w': 68, 'h': 30, 'confidence': '0.9999991655349731', 'text': '2024'}, {'x': 1811, 'y': 530, 'w': 86, 'h': 20, 'confidence': '0.18333667364314374', 'text': 'Teweshot'}, {'x': 152, 'y': 548, 'w': 140, 'h': 30, 'confidence': '0.6167370813915825', 'text': '(S-shot; CoT)'}, {'x': 150, 'y': 628, 'w': 176, 'h': 32, 'confidence': '0.8564350819166965', 'text': 'Claude 3 Opus'}, {'x': 706, 'y': 646, 'w': 58, 'h': 30, 'confidence': '0.9048791797405775', 'text': '86.8'}, {'x': 801, 'y': 642, 'w': 576, 'h': 37, 'confidence': '0.8175158846949896', 'text': 'The Claude 3 Model Family: Opus; Sonnet; Haiku'}, {'x': 1660, 'y': 644, 'w': 68, 'h': 30, 'confidence': '0.999999463558197', 'text': '2024'}, {'x': 152, 'y': 668, 'w': 88, 'h': 26, 'confidence': '0.6544273708507413', 'text': '(S-shot)'}, {'x': 148, 'y': 742, 'w': 88, 'h': 28, 'confidence': '0.674303656204583', 'text': 'Leeroo'}, {'x': 801, 'y': 735, 'w': 628, 'h': 42, 'confidence': '0.6634662125259431', 'text': 'Routoo: Learning to Route to Large Language Models'}, {'x': 698, 'y': 760, 'w': 72, 'h': 30, 'confidence': '0.9999833666349927', 'text': '86.64'}, {'x': 1660, 'y': 758, 'w': 68, 'h': 30, 'confidence': '0.9999993443489075', 'text': '2024'}, {'x': 152, 'y': 782, 'w': 88, 'h': 26, 'confidence': '0.6398427030659463', 'text': '(5-shot)'}, {'x': 800, 'y': 774, 'w': 131, 'h': 39, 'confidence': '0.9997869152278177', 'text': 'Effectively'}, {'x': 150, 'y': 860, 'w': 80, 'h': 30, 'confidence': '0.9997300236541287', 'text': 'GPT-4'}, {'x': 706, 'y': 880, 'w': 58, 'h': 30, 'confidence': '0.8931255619442013', 'text': '86.4'}, {'x': 801, 'y': 877, 'w': 286, 'h': 36, 'confidence': '0.5111315189629766', 'text': 'GPT-4 Technical Report'}, {'x': 1660, 'y': 878, 'w': 68, 'h': 30, 'confidence': '0.9999997615814209', 'text': '2023'}, {'x': 1811, 'y': 883, 'w': 86, 'h': 20, 'confidence': '0.45520561477354443', 'text': 'Tew-shot'}, {'x': 152, 'y': 900, 'w': 110, 'h': 28, 'confidence': '0.9999232843101918', 'text': '(few-shot)'}, {'x': 149, 'y': 984, 'w': 171, 'h': 32, 'confidence': '0.8787388905456798', 'text': 'Llama 3.1 70B'}, {'x': 706, 'y': 1006, 'w': 56, 'h': 26, 'confidence': '0.9991450453783421', 'text': '86.0'}, {'x': 800, 'y': 1003, 'w': 340, 'h': 29, 'confidence': '0.997063125856483', 'text': 'The Llama 3 Herd of Models'}, {'x': 1588, 'y': 1004, 'w': 30, 'h': 26, 'confidence': '0.5569509411893456', 'text': '2'}, {'x': 1660, 'y': 1002, 'w': 68, 'h': 30, 'confidence': '0.9999994039535522', 'text': '2024'}, {'x': 1774, 'y': 1006, 'w': 160, 'h': 24, 'confidence': '0.9989161279942672', 'text': 'chain-of-thought'}, {'x': 152, 'y': 1026, 'w': 62, 'h': 26, 'confidence': '0.9987565659050163', 'text': '(CoT)'}, {'x': 150, 'y': 1110, 'w': 156, 'h': 30, 'confidence': '0.9772715108488358', 'text': 'Gemini Ultra'}, {'x': 82, 'y': 1130, 'w': 34, 'h': 30, 'confidence': '0.9999807810911719', 'text': '10'}, {'x': 706, 'y': 1130, 'w': 54, 'h': 26, 'confidence': '0.3363557010776378', 'text': '83.7'}, {'x': 1820, 'y': 1130, 'w': 68, 'h': 24, 'confidence': '0.9970162477324064', 'text': '5-shot'}, {'x': 152, 'y': 1150, 'w': 86, 'h': 28, 'confidence': '0.6895417853586955', 'text': '(S-shot)'}, {'x': 150, 'y': 1234, 'w': 56, 'h': 30, 'confidence': '0.9771660957096563', 'text': 'GaC'}, {'x': 801, 'y': 1229, 'w': 648, 'h': 40, 'confidence': '0.7812638083224933', 'text': 'Breaking the Ceiling of the LLM Community by Treating'}, {'x': 84, 'y': 1256, 'w': 28, 'h': 26, 'confidence': '0.9997007704898443', 'text': '11'}, {'x': 698, 'y': 1254, 'w': 72, 'h': 30, 'confidence': '0.9999779287970416', 'text': '83.54'}, {'x': 1586, 'y': 1254, 'w': 34, 'h': 30, 'confidence': '0.1247032054103423', 'text': '7'}, {'x': 1660, 'y': 1252, 'w': 68, 'h': 30, 'confidence': '0.9999995231628418', 'text': '2024'}, {'x': 1809, 'y': 1257, 'w': 90, 'h': 20, 'confidence': '0.7549548130687126', 'text': 'Ensemble'}, {'x': 152, 'y': 1276, 'w': 472, 'h': 28, 'confidence': '0.8564820491705056', 'text': '(Qwen2-72B-Instruct + Llama-3-7OB-Instruct)'}, {'x': 801, 'y': 1267, 'w': 608, 'h': 40, 'confidence': '0.8412410561109533', 'text': 'Token Generation as a Classification for Ensembling'}, {'x': 1802, 'y': 17, 'w': 52, 'h': 33, 'confidence': '0.9793174197002368', 'text': 'Tags'}, {'x': 1133, 'y': 523, 'w': 70, 'h': 40, 'confidence': '0.7416995951801476', 'text': 'Opus;'}]}]\n",
      "> Image for page 32: [{'name': 'img_p31_1.png', 'height': 952, 'width': 2048, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 952, 'ocr': [{'x': 236, 'y': 34, 'w': 64, 'h': 24, 'confidence': '0.9999956284136424', 'text': 'Rank'}, {'x': 960, 'y': 34, 'w': 76, 'h': 24, 'confidence': '0.9991532562535722', 'text': 'Arena'}, {'x': 1892, 'y': 32, 'w': 134, 'h': 30, 'confidence': '0.9998875427418058', 'text': 'Knowledge'}, {'x': 22, 'y': 50, 'w': 78, 'h': 26, 'confidence': '0.905791816679787', 'text': 'Rank*'}, {'x': 110, 'y': 50, 'w': 60, 'h': 30, 'confidence': '0.9862316011677612', 'text': '(UB)'}, {'x': 448, 'y': 50, 'w': 76, 'h': 26, 'confidence': '0.9999736638236573', 'text': 'Model'}, {'x': 1128, 'y': 50, 'w': 92, 'h': 28, 'confidence': '0.765299574090206', 'text': '958 CI'}, {'x': 1298, 'y': 50, 'w': 76, 'h': 26, 'confidence': '0.9999143271587139', 'text': 'Votes'}, {'x': 1466, 'y': 50, 'w': 178, 'h': 30, 'confidence': '0.7310932556854446', 'text': 'Organization'}, {'x': 1664, 'y': 50, 'w': 106, 'h': 26, 'confidence': '0.9999968460170529', 'text': 'License'}, {'x': 236, 'y': 64, 'w': 165, 'h': 38, 'confidence': '0.8338218617927088', 'text': '(Stylectrl)'}, {'x': 960, 'y': 68, 'w': 78, 'h': 26, 'confidence': '0.9997642509894332', 'text': 'Score'}, {'x': 1890, 'y': 68, 'w': 94, 'h': 28, 'confidence': '0.9981578162805341', 'text': 'Cutoff'}, {'x': 25, 'y': 133, 'w': 14, 'h': 22, 'confidence': '0.9999949932161059', 'text': '1'}, {'x': 239, 'y': 133, 'w': 16, 'h': 22, 'confidence': '1.0', 'text': '2'}, {'x': 446, 'y': 125, 'w': 237, 'h': 39, 'confidence': '0.508743412280927', 'text': 'Gemini_Exp.1124'}, {'x': 960, 'y': 128, 'w': 62, 'h': 28, 'confidence': '0.9999996423721313', 'text': '1365'}, {'x': 1128, 'y': 130, 'w': 78, 'h': 28, 'confidence': '0.7780569785169686', 'text': '+8/-6'}, {'x': 1298, 'y': 130, 'w': 62, 'h': 26, 'confidence': '0.999999463558197', 'text': '5625'}, {'x': 1466, 'y': 130, 'w': 92, 'h': 30, 'confidence': '0.9999916292700755', 'text': 'Google'}, {'x': 1662, 'y': 125, 'w': 165, 'h': 36, 'confidence': '0.9244165330748428', 'text': 'Proprietary'}, {'x': 1892, 'y': 128, 'w': 104, 'h': 28, 'confidence': '0.9999935118030164', 'text': 'Unknown'}, {'x': 25, 'y': 197, 'w': 16, 'h': 22, 'confidence': '0.9999953508431112', 'text': '1'}, {'x': 239, 'y': 197, 'w': 16, 'h': 22, 'confidence': '0.9999966621426779', 'text': '1'}, {'x': 448, 'y': 192, 'w': 458, 'h': 32, 'confidence': '0.670136540853315', 'text': 'ChatGPI_4o_latest_(2024-11.20).'}, {'x': 959, 'y': 190, 'w': 63, 'h': 30, 'confidence': '0.9999985694885254', 'text': '1361'}, {'x': 1128, 'y': 194, 'w': 78, 'h': 26, 'confidence': '0.9995942325357136', 'text': '+4/-5'}, {'x': 1297, 'y': 191, 'w': 77, 'h': 29, 'confidence': '0.9999985605754728', 'text': '10658'}, {'x': 1465, 'y': 194, 'w': 92, 'h': 28, 'confidence': '0.9998791095578342', 'text': 'OpenAI'}, {'x': 1662, 'y': 188, 'w': 165, 'h': 37, 'confidence': '0.999685646346659', 'text': 'Proprietary'}, {'x': 1892, 'y': 192, 'w': 104, 'h': 28, 'confidence': '0.999988240132959', 'text': 'Unknown'}, {'x': 23, 'y': 255, 'w': 18, 'h': 26, 'confidence': '0.9999995231628986', 'text': '3'}, {'x': 237, 'y': 257, 'w': 20, 'h': 26, 'confidence': '0.9999978542339392', 'text': '5'}, {'x': 447, 'y': 253, 'w': 236, 'h': 36, 'confidence': '0.9525194815944317', 'text': 'Gemini-Exp-1114'}, {'x': 960, 'y': 256, 'w': 62, 'h': 26, 'confidence': '0.8698764271870464', 'text': '1344'}, {'x': 1128, 'y': 256, 'w': 78, 'h': 28, 'confidence': '0.9995411843734872', 'text': '+4/-5'}, {'x': 1298, 'y': 256, 'w': 78, 'h': 28, 'confidence': '0.9999992536317571', 'text': '12778'}, {'x': 1466, 'y': 256, 'w': 92, 'h': 30, 'confidence': '0.9999886119100786', 'text': 'Google'}, {'x': 1664, 'y': 255, 'w': 162, 'h': 30, 'confidence': '0.9990733286360215', 'text': 'Proprietary'}, {'x': 1892, 'y': 256, 'w': 104, 'h': 26, 'confidence': '0.9999391726196678', 'text': 'Unknown'}, {'x': 23, 'y': 319, 'w': 20, 'h': 28, 'confidence': '0.4581064264209545', 'text': '4'}, {'x': 237, 'y': 319, 'w': 20, 'h': 28, 'confidence': '1.0', 'text': '2'}, {'x': 447, 'y': 317, 'w': 162, 'h': 38, 'confidence': '0.5000764182598714', 'text': '01-preview'}, {'x': 960, 'y': 320, 'w': 62, 'h': 26, 'confidence': '0.8848074839140889', 'text': '1334'}, {'x': 1128, 'y': 320, 'w': 78, 'h': 26, 'confidence': '0.9996698855711057', 'text': '+4/-4'}, {'x': 1298, 'y': 320, 'w': 76, 'h': 26, 'confidence': '0.8484994527216255', 'text': '27835'}, {'x': 1465, 'y': 319, 'w': 92, 'h': 28, 'confidence': '0.9997609899988991', 'text': 'OpenAI'}, {'x': 1664, 'y': 319, 'w': 164, 'h': 30, 'confidence': '0.9999663929670168', 'text': 'Proprietary'}, {'x': 1892, 'y': 320, 'w': 104, 'h': 28, 'confidence': '0.9545085785053636', 'text': '2023/10'}, {'x': 23, 'y': 383, 'w': 20, 'h': 26, 'confidence': '0.9999964237245109', 'text': '5'}, {'x': 237, 'y': 385, 'w': 20, 'h': 24, 'confidence': '1.0', 'text': '8'}, {'x': 447, 'y': 381, 'w': 114, 'h': 36, 'confidence': '0.39605182074747564', 'text': 'ol-mini'}, {'x': 960, 'y': 384, 'w': 64, 'h': 28, 'confidence': '0.9999988675117493', 'text': '1308'}, {'x': 1128, 'y': 384, 'w': 78, 'h': 28, 'confidence': '0.9998336648802844', 'text': '+3/-4'}, {'x': 1298, 'y': 384, 'w': 76, 'h': 26, 'confidence': '0.7877320087607864', 'text': '31992'}, {'x': 1467, 'y': 384, 'w': 90, 'h': 28, 'confidence': '0.9998868478125571', 'text': 'OpenAI'}, {'x': 1664, 'y': 384, 'w': 164, 'h': 30, 'confidence': '0.9330299013368674', 'text': 'Proprietary'}, {'x': 1890, 'y': 384, 'w': 108, 'h': 28, 'confidence': '0.9999994593174372', 'text': '2023/10'}, {'x': 23, 'y': 445, 'w': 20, 'h': 28, 'confidence': '0.9999790192750879', 'text': '5'}, {'x': 237, 'y': 447, 'w': 20, 'h': 24, 'confidence': '0.9999890327754315', 'text': '5'}, {'x': 446, 'y': 443, 'w': 281, 'h': 38, 'confidence': '0.3647096356279543', 'text': 'Gemini-1..5.-Pro-002'}, {'x': 960, 'y': 446, 'w': 62, 'h': 28, 'confidence': '0.9999901056289673', 'text': '1301'}, {'x': 1128, 'y': 448, 'w': 78, 'h': 26, 'confidence': '0.8994764741631751', 'text': '+5/-3'}, {'x': 1298, 'y': 446, 'w': 76, 'h': 28, 'confidence': '0.9999998933759693', 'text': '27336'}, {'x': 1466, 'y': 448, 'w': 92, 'h': 30, 'confidence': '0.9999927486127799', 'text': 'Google'}, {'x': 1662, 'y': 443, 'w': 167, 'h': 36, 'confidence': '0.9999462283903213', 'text': 'Proprietary'}, {'x': 1892, 'y': 446, 'w': 104, 'h': 28, 'confidence': '0.9999874741630587', 'text': 'Unknown'}, {'x': 25, 'y': 513, 'w': 16, 'h': 22, 'confidence': '0.9999979734431044', 'text': '6'}, {'x': 237, 'y': 511, 'w': 20, 'h': 24, 'confidence': '0.9999967813517721', 'text': '5'}, {'x': 448, 'y': 510, 'w': 130, 'h': 32, 'confidence': '0.764085040447277', 'text': 'Gemini-1.'}, {'x': 584, 'y': 510, 'w': 218, 'h': 32, 'confidence': '0.6240257985268316', 'text': '5-Pro-Exp-0827'}, {'x': 960, 'y': 510, 'w': 62, 'h': 26, 'confidence': '0.671123751573017', 'text': '1299'}, {'x': 1128, 'y': 510, 'w': 78, 'h': 28, 'confidence': '0.9988879176289412', 'text': '+4/-4'}, {'x': 1298, 'y': 510, 'w': 76, 'h': 26, 'confidence': '0.9999998933759693', 'text': '32345'}, {'x': 1466, 'y': 510, 'w': 92, 'h': 30, 'confidence': '0.9999896825864407', 'text': 'Google'}, {'x': 1664, 'y': 510, 'w': 164, 'h': 30, 'confidence': '0.9999594198638218', 'text': 'Proprietary'}, {'x': 1892, 'y': 510, 'w': 106, 'h': 30, 'confidence': '0.9129869600838263', 'text': '2023/11'}, {'x': 23, 'y': 575, 'w': 18, 'h': 24, 'confidence': '0.9681372754227339', 'text': '8'}, {'x': 238, 'y': 574, 'w': 34, 'h': 28, 'confidence': '0.9997687059305996', 'text': '11'}, {'x': 448, 'y': 574, 'w': 188, 'h': 32, 'confidence': '0.6273661888526629', 'text': 'Grok-2-08-13'}, {'x': 960, 'y': 574, 'w': 64, 'h': 28, 'confidence': '0.999999463558197', 'text': '1289'}, {'x': 1128, 'y': 574, 'w': 78, 'h': 26, 'confidence': '0.9998842055120782', 'text': '+4/-3'}, {'x': 1298, 'y': 574, 'w': 76, 'h': 26, 'confidence': '0.5952178032977268', 'text': '52102'}, {'x': 1468, 'y': 574, 'w': 48, 'h': 26, 'confidence': '0.9933468570345417', 'text': 'XAI'}, {'x': 1663, 'y': 571, 'w': 163, 'h': 33, 'confidence': '0.9998736193192403', 'text': 'Proprietary'}, {'x': 1890, 'y': 574, 'w': 94, 'h': 30, 'confidence': '0.8979646881540112', 'text': '2024/3'}, {'x': 23, 'y': 639, 'w': 18, 'h': 24, 'confidence': '0.9764755111210727', 'text': '8'}, {'x': 238, 'y': 638, 'w': 34, 'h': 28, 'confidence': '0.9999924135756967', 'text': '13'}, {'x': 445, 'y': 635, 'w': 194, 'h': 38, 'confidence': '0.736082825735324', 'text': 'Yi_Lightning'}, {'x': 960, 'y': 638, 'w': 62, 'h': 26, 'confidence': '0.999999463558197', 'text': '1287'}, {'x': 1128, 'y': 638, 'w': 78, 'h': 28, 'confidence': '0.9997993845121944', 'text': '+4/-3'}, {'x': 1298, 'y': 638, 'w': 78, 'h': 28, 'confidence': '1.0', 'text': '29336'}, {'x': 1466, 'y': 638, 'w': 34, 'h': 26, 'confidence': '0.9999983141264758', 'text': '01'}, {'x': 1510, 'y': 638, 'w': 34, 'h': 26, 'confidence': '0.9997013604940551', 'text': 'AI'}, {'x': 1663, 'y': 635, 'w': 165, 'h': 33, 'confidence': '0.9998639138833857', 'text': 'Proprietary'}, {'x': 1892, 'y': 638, 'w': 104, 'h': 26, 'confidence': '0.9999730558707686', 'text': 'Unknown'}, {'x': 23, 'y': 703, 'w': 18, 'h': 24, 'confidence': '0.9999997615814351', 'text': '8'}, {'x': 241, 'y': 705, 'w': 16, 'h': 22, 'confidence': '0.9999959468882622', 'text': '5'}, {'x': 447, 'y': 697, 'w': 266, 'h': 39, 'confidence': '0.35903272706334094', 'text': 'GPT_4q-2024-05.13'}, {'x': 960, 'y': 702, 'w': 64, 'h': 28, 'confidence': '0.999996542930603', 'text': '1285'}, {'x': 1128, 'y': 702, 'w': 78, 'h': 26, 'confidence': '0.9996024429753473', 'text': '+2/-2'}, {'x': 1298, 'y': 702, 'w': 92, 'h': 26, 'confidence': '0.8445607131256958', 'text': '111745'}, {'x': 1465, 'y': 701, 'w': 92, 'h': 28, 'confidence': '0.9999118632105854', 'text': 'OpenAI'}, {'x': 1663, 'y': 699, 'w': 165, 'h': 33, 'confidence': '0.9997970165811049', 'text': 'Proprietary'}, {'x': 1892, 'y': 700, 'w': 106, 'h': 30, 'confidence': '0.546271966783937', 'text': '2023/10'}, {'x': 237, 'y': 767, 'w': 18, 'h': 22, 'confidence': '0.9999997615814351', 'text': '3'}, {'x': 448, 'y': 764, 'w': 428, 'h': 32, 'confidence': '0.696017628341365', 'text': 'Claude_3.5_Sonnet_(20241022).'}, {'x': 960, 'y': 764, 'w': 64, 'h': 28, 'confidence': '0.9999990463256836', 'text': '1282'}, {'x': 1128, 'y': 764, 'w': 78, 'h': 28, 'confidence': '0.9998223091905136', 'text': '+4/-3'}, {'x': 1298, 'y': 764, 'w': 78, 'h': 30, 'confidence': '0.6311591526867325', 'text': '29454'}, {'x': 1467, 'y': 762, 'w': 133, 'h': 33, 'confidence': '0.9999831119460119', 'text': 'Anthropic'}, {'x': 1664, 'y': 764, 'w': 164, 'h': 30, 'confidence': '0.9999529225362371', 'text': 'Proprietary'}, {'x': 1892, 'y': 764, 'w': 90, 'h': 28, 'confidence': '0.9697038264503715', 'text': '2024/4'}, {'x': 22, 'y': 828, 'w': 32, 'h': 26, 'confidence': '0.9999912334667646', 'text': '11'}, {'x': 238, 'y': 828, 'w': 34, 'h': 28, 'confidence': '0.9999942680334141', 'text': '18'}, {'x': 448, 'y': 828, 'w': 278, 'h': 32, 'confidence': '0.32260770676253303', 'text': 'Athene_V2-Chat_-ZZB'}, {'x': 960, 'y': 828, 'w': 62, 'h': 26, 'confidence': '0.999948073938262', 'text': '1274'}, {'x': 1128, 'y': 828, 'w': 78, 'h': 28, 'confidence': '0.9998859648324375', 'text': '+8/-6'}, {'x': 1298, 'y': 828, 'w': 62, 'h': 26, 'confidence': '0.9068390644496761', 'text': '4354'}, {'x': 1468, 'y': 828, 'w': 134, 'h': 26, 'confidence': '0.998245820785189', 'text': 'NexusFlow'}, {'x': 1664, 'y': 828, 'w': 136, 'h': 26, 'confidence': '0.9980584094903507', 'text': 'NexusFlow'}, {'x': 1892, 'y': 828, 'w': 104, 'h': 26, 'confidence': '0.9999657565847045', 'text': 'Unknown'}, {'x': 22, 'y': 892, 'w': 34, 'h': 26, 'confidence': '0.9999994942378553', 'text': '12'}, {'x': 238, 'y': 892, 'w': 34, 'h': 28, 'confidence': '0.8332510557177583', 'text': '19'}, {'x': 448, 'y': 892, 'w': 158, 'h': 32, 'confidence': '0.8514826997663053', 'text': 'GLM-4-Plus'}, {'x': 960, 'y': 892, 'w': 62, 'h': 26, 'confidence': '0.999624355213582', 'text': '1274'}, {'x': 1128, 'y': 892, 'w': 78, 'h': 28, 'confidence': '0.9997391936079925', 'text': '+5/-4'}, {'x': 1298, 'y': 892, 'w': 78, 'h': 28, 'confidence': '0.7067348062983198', 'text': '28133'}, {'x': 1468, 'y': 892, 'w': 78, 'h': 32, 'confidence': '0.9994590257095666', 'text': 'Zhipu'}, {'x': 1554, 'y': 892, 'w': 32, 'h': 26, 'confidence': '0.999394993461038', 'text': 'AI'}, {'x': 1664, 'y': 892, 'w': 164, 'h': 30, 'confidence': '0.7906438217728394', 'text': 'Proprietary'}, {'x': 1892, 'y': 892, 'w': 104, 'h': 26, 'confidence': '0.999965531297824', 'text': 'Unknown'}]}]\n",
      "> Image for page 33: [{'name': 'img_p32_1.png', 'height': 442, 'width': 498, 'x': 244.45768498799998, 'y': 162.08467054103994, 'original_width': 498, 'original_height': 442, 'ocr': [{'x': 32, 'y': 276, 'w': 433, 'h': 137, 'confidence': '0.9998212091540735', 'text': 'Gemini'}]}]\n",
      "> Image for page 34: [{'name': 'img_p33_2.png', 'height': 180, 'width': 320, 'x': 0, 'y': 0, 'original_width': 320, 'original_height': 180, 'ocr': [{'x': 4, 'y': 70, 'w': 48, 'h': 32, 'confidence': '0.9999041954974118', 'text': 'Go'}, {'x': 271, 'y': 71, 'w': 48, 'h': 38, 'confidence': '0.9999135556532298', 'text': 'gle'}]}]\n",
      "> Image for page 35: []\n",
      "> Image for page 36: [{'name': 'img_p35_1.png', 'height': 926, 'width': 1040, 'x': 401.66930419199997, 'y': 56.62204905599998, 'original_width': 1040, 'original_height': 926, 'ocr': [{'x': 924, 'y': 20, 'w': 48, 'h': 28, 'confidence': '0.8370497226715088', 'text': '1.0'}, {'x': 8, 'y': 850, 'w': 135, 'h': 63, 'confidence': '0.9999803811557654', 'text': 'Ultra'}]}]\n",
      "> Image for page 37: [{'name': 'img_p36_1.png', 'height': 876, 'width': 1042, 'x': 371.41186227888, 'y': 57.28149789600002, 'original_width': 1042, 'original_height': 876, 'ocr': [{'x': 940, 'y': 10, 'w': 46, 'h': 26, 'confidence': '0.9790836652188847', 'text': '1.5'}, {'x': 20, 'y': 806, 'w': 94, 'h': 52, 'confidence': '0.9999654496712286', 'text': 'Pro'}]}]\n",
      "> Image for page 38: [{'name': 'img_p37_1.png', 'height': 916, 'width': 1008, 'x': 360.00001152, 'y': 57.09449001599995, 'original_width': 1008, 'original_height': 916, 'ocr': [{'x': 918, 'y': 0, 'w': 50, 'h': 28, 'confidence': '0.9169446229934692', 'text': '1.0'}, {'x': 7, 'y': 849, 'w': 143, 'h': 57, 'confidence': '0.9970120805803488', 'text': 'Nano'}]}]\n",
      "> Image for page 39: [{'name': 'img_p38_1.png', 'height': 924, 'width': 1032, 'x': 345.00985355999995, 'y': 57.09449001599995, 'original_width': 1032, 'original_height': 924, 'ocr': [{'x': 938, 'y': 20, 'w': 48, 'h': 32, 'confidence': '0.9952774509289581', 'text': '1.5'}, {'x': 0, 'y': 855, 'w': 133, 'h': 60, 'confidence': '0.9999193918498422', 'text': 'Flash'}]}]\n",
      "> Image for page 40: [{'name': 'img_p39_1.png', 'height': 944, 'width': 1660, 'x': 64.659450888, 'y': 50.433072479999964, 'original_width': 1660, 'original_height': 944, 'ocr': [{'x': 669, 'y': 3, 'w': 126, 'h': 42, 'confidence': '0.9999867786099642', 'text': 'Model'}, {'x': 791, 'y': 0, 'w': 245, 'h': 61, 'confidence': '0.999986682197848', 'text': 'capabilities'}, {'x': 759, 'y': 403, 'w': 182, 'h': 36, 'confidence': '0.9919216348985642', 'text': 'use case'}, {'x': 87, 'y': 875, 'w': 98, 'h': 38, 'confidence': '0.9983130693435669', 'text': 'Cost'}, {'x': 1438, 'y': 869, 'w': 167, 'h': 54, 'confidence': '0.9999748581609756', 'text': 'Latency'}]}]\n",
      "> Image for page 41: [{'name': 'img_p40_1.png', 'height': 841, 'width': 2048, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 841, 'ocr': [{'x': 32, 'y': 50, 'w': 124, 'h': 148, 'confidence': '0.1667802753657488', 'text': '5)'}, {'x': 992, 'y': 402, 'w': 194, 'h': 66, 'confidence': '0.9999907237043121', 'text': 'Model'}, {'x': 1770, 'y': 410, 'w': 156, 'h': 54, 'confidence': '0.9996558624136116', 'text': 'Output'}, {'x': 85, 'y': 503, 'w': 64, 'h': 38, 'confidence': '0.8335651217141262', 'text': 'PDF'}, {'x': 67, 'y': 621, 'w': 96, 'h': 86, 'confidence': '0.5053685304083297', 'text': 'TT'}, {'x': 59, 'y': 743, 'w': 101, 'h': 68, 'confidence': '0.8102087378501892', 'text': '< >'}]}]\n",
      "> Image for page 42: [{'name': 'img_p41_1.png', 'height': 962, 'width': 2048, 'x': 39.31102488, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 962, 'ocr': [{'x': 214, 'y': 56, 'w': 252, 'h': 55, 'confidence': '0.8526811336118088', 'text': 'Model Input'}, {'x': 1513, 'y': 53, 'w': 344, 'h': 61, 'confidence': '0.9209889825540928', 'text': 'Model Response'}, {'x': 799, 'y': 137, 'w': 435, 'h': 42, 'confidence': '0.7303935414627082', 'text': 'interleaved: a mix of text,'}, {'x': 862, 'y': 177, 'w': 304, 'h': 49, 'confidence': '0.49301221907280823', 'text': 'image, audio etc.'}, {'x': 1362, 'y': 458, 'w': 24, 'h': 28, 'confidence': '0.9998940257493736', 'text': 'A'}, {'x': 1386, 'y': 452, 'w': 252, 'h': 49, 'confidence': '0.9998550485251485', 'text': 'good outfit for'}, {'x': 1719, 'y': 453, 'w': 256, 'h': 38, 'confidence': '0.8419126860710486', 'text': 'cat would be a'}, {'x': 127, 'y': 495, 'w': 444, 'h': 40, 'confidence': '0.842561162095485', 'text': 'What do you think would be a'}, {'x': 1367, 'y': 493, 'w': 596, 'h': 38, 'confidence': '0.4617273581755997', 'text': 'small t-shirt or & cat-sized sweater.'}, {'x': 172, 'y': 529, 'w': 349, 'h': 45, 'confidence': '0.9629512625486631', 'text': 'good outfit for my cat?'}, {'x': 934, 'y': 508, 'w': 168, 'h': 54, 'confidence': '0.9999745168185059', 'text': 'Model'}, {'x': 1379, 'y': 535, 'w': 252, 'h': 36, 'confidence': '0.9564915595033675', 'text': 'You could also'}, {'x': 1695, 'y': 535, 'w': 262, 'h': 42, 'confidence': '0.7432531614241386', 'text': 'your cat a cute'}, {'x': 1423, 'y': 575, 'w': 490, 'h': 36, 'confidence': '0.6330404609735623', 'text': 'bow tie or a collar with a bell:'}, {'x': 1633, 'y': 460, 'w': 86, 'h': 32, 'confidence': '0.9981035590171814', 'text': 'your'}, {'x': 1627, 'y': 540, 'w': 68, 'h': 34, 'confidence': '0.9999986234898187', 'text': 'get'}]}]\n",
      "> Image for page 43: [{'name': 'img_p42_1.png', 'height': 1012, 'width': 1792, 'x': 66.62204937599999, 'y': 51.76574968800003, 'original_width': 1792, 'original_height': 1012, 'ocr': [{'x': 57, 'y': 79, 'w': 130, 'h': 36, 'confidence': '0.9999372678093793', 'text': 'Prompt'}, {'x': 918, 'y': 78, 'w': 167, 'h': 40, 'confidence': '0.9999761869131482', 'text': 'Response'}, {'x': 56, 'y': 137, 'w': 564, 'h': 29, 'confidence': '0.9105666113416148', 'text': \"Here's a solution toa Physics problem by a student:\"}, {'x': 920, 'y': 141, 'w': 788, 'h': 28, 'confidence': '0.7528046488108364', 'text': 'The student did not get the correct answer: The student made a mistake'}, {'x': 918, 'y': 164, 'w': 762, 'h': 30, 'confidence': '0.8431996300937298', 'text': 'in the calculation of the potential energy at the start of the slope: The'}, {'x': 919, 'y': 188, 'w': 793, 'h': 30, 'confidence': '0.8083753404198563', 'text': 'potential energy at the start of the slope is given by mgh, where m is the'}, {'x': 77, 'y': 207, 'w': 742, 'h': 20, 'confidence': '0.614010158014864', 'text': \"23.A skier slides down the frictionless slope as shown What Is the skier'$ speed at the bottom?\"}, {'x': 920, 'y': 212, 'w': 788, 'h': 28, 'confidence': '0.616506723634413', 'text': 'mass of the skier; g is the acceleration due to gravity; and h is the height'}, {'x': 225, 'y': 235, 'w': 42, 'h': 18, 'confidence': '0.5511101136741168', 'text': 'Start'}, {'x': 918, 'y': 236, 'w': 776, 'h': 29, 'confidence': '0.5612165362733292', 'text': 'of the slope: The student used the length of the slope, L, instead of the'}, {'x': 920, 'y': 260, 'w': 560, 'h': 28, 'confidence': '0.5697305455787284', 'text': 'height, H,in the calculation of the potential energy:'}, {'x': 199, 'y': 291, 'w': 70, 'h': 20, 'confidence': '0.8825756391293004', 'text': 'H-40m'}, {'x': 918, 'y': 308, 'w': 256, 'h': 24, 'confidence': '0.9574766420141954', 'text': 'The correct solution is:'}, {'x': 615, 'y': 343, 'w': 52, 'h': 18, 'confidence': '0.9999443732842316', 'text': 'Finish'}, {'x': 918, 'y': 356, 'w': 768, 'h': 26, 'confidence': '0.6604273036272393', 'text': 'The conservation of energy means that the total energy of the skier is'}, {'x': 91, 'y': 379, 'w': 72, 'h': 16, 'confidence': '0.7153985687443346', 'text': 'Solution:'}, {'x': 395, 'y': 373, 'w': 66, 'h': 16, 'confidence': '0.24506272888732672', 'text': 'L-BO m'}, {'x': 918, 'y': 380, 'w': 596, 'h': 26, 'confidence': '0.6830898903195615', 'text': 'the same at the beginning and at the end of the slope:'}, {'x': 560, 'y': 404, 'w': 106, 'h': 24, 'confidence': '0.4624076783657074', 'text': 'Mean'}, {'x': 686, 'y': 400, 'w': 129, 'h': 29, 'confidence': '0.37115114504412494', 'text': 'tuatic'}, {'x': 117, 'y': 410, 'w': 250, 'h': 45, 'confidence': '0.22887431554614154', 'text': 'Te coneeuason'}, {'x': 382, 'y': 405, 'w': 175, 'h': 50, 'confidence': '0.27274009999273596', 'text': '3 mneay'}, {'x': 920, 'y': 426, 'w': 748, 'h': 28, 'confidence': '0.6614368587304467', 'text': 'At the start of the slope, the skier has only potential energy; which is'}, {'x': 258, 'y': 452, 'w': 42, 'h': 24, 'confidence': '0.14285663142428623', 'text': 'Tle'}, {'x': 312, 'y': 448, 'w': 72, 'h': 26, 'confidence': '0.20060474589419922', 'text': 'ckiSz'}, {'x': 412, 'y': 446, 'w': 30, 'h': 30, 'confidence': '0.14729635494037385', 'text': '<'}, {'x': 464, 'y': 446, 'w': 72, 'h': 24, 'confidence': '0.1949797802251479', 'text': 'soe'}, {'x': 558, 'y': 434, 'w': 34, 'h': 32, 'confidence': '0.7440285262043886', 'text': 'a'}, {'x': 618, 'y': 440, 'w': 50, 'h': 26, 'confidence': '0.236263008796457', 'text': '#'}, {'x': 681, 'y': 429, 'w': 165, 'h': 56, 'confidence': '0.3029196564957284', 'text': 'benn f'}, {'x': 918, 'y': 452, 'w': 160, 'h': 26, 'confidence': '0.8414157209665507', 'text': 'given by mgh:'}, {'x': 188, 'y': 492, 'w': 32, 'h': 28, 'confidence': '0.5123298276718365', 'text': 'ot'}, {'x': 920, 'y': 496, 'w': 780, 'h': 29, 'confidence': '0.7394446996322849', 'text': 'At the end of the slope, the skier has only kinetic energy; which is given'}, {'x': 121, 'y': 527, 'w': 95, 'h': 31, 'confidence': '0.568855033558562', 'text': 'Stcuy ;'}, {'x': 230, 'y': 528, 'w': 44, 'h': 26, 'confidence': '0.6499725815376065', 'text': '6='}, {'x': 918, 'y': 522, 'w': 58, 'h': 32, 'confidence': '0.3367168691397783', 'text': 'by 2'}, {'x': 122, 'y': 574, 'w': 82, 'h': 32, 'confidence': '0.6298670562274354', 'text': 'End :'}, {'x': 222, 'y': 572, 'w': 46, 'h': 30, 'confidence': '0.5236625671386719', 'text': '6 ='}, {'x': 917, 'y': 566, 'w': 273, 'h': 28, 'confidence': '0.9440425455629742', 'text': 'Therefore, we can write:'}, {'x': 273, 'y': 573, 'w': 36, 'h': 48, 'confidence': '0.9971861396139481', 'text': '1'}, {'x': 399, 'y': 613, 'w': 22, 'h': 20, 'confidence': '0.17532564819105906', 'text': '2.'}, {'x': 1244, 'y': 612, 'w': 54, 'h': 24, 'confidence': '0.9999435632907281', 'text': 'mgh'}, {'x': 1322, 'y': 600, 'w': 76, 'h': 48, 'confidence': '0.2856525778770447', 'text': \"zmv'\"}, {'x': 305, 'y': 621, 'w': 96, 'h': 49, 'confidence': '0.485494464635849', 'text': 'hzmv'}, {'x': 623, 'y': 677, 'w': 24, 'h': 16, 'confidence': '0.4374122995071481', 'text': '='}, {'x': 664, 'y': 657, 'w': 177, 'h': 48, 'confidence': '0.8428742192977258', 'text': '39.6m s-1'}, {'x': 919, 'y': 660, 'w': 533, 'h': 30, 'confidence': '0.7300391482474846', 'text': 'Canceling out the mass m on both sides, we get:'}, {'x': 419, 'y': 673, 'w': 184, 'h': 36, 'confidence': '0.5678873139668877', 'text': '2n 9 B1* 80'}, {'x': 208, 'y': 674, 'w': 152, 'h': 54, 'confidence': '0.16953258788252804', 'text': 'v=N2J1'}, {'x': 1266, 'y': 714, 'w': 54, 'h': 26, 'confidence': '0.9996640086174011', 'text': 'gh ='}, {'x': 1321, 'y': 703, 'w': 54, 'h': 44, 'confidence': '0.16025822014498073', 'text': 'zv'}, {'x': 56, 'y': 767, 'w': 508, 'h': 29, 'confidence': '0.8033049508326249', 'text': 'Try to reason about the question step by step:'}, {'x': 917, 'y': 756, 'w': 237, 'h': 28, 'confidence': '0.6375627137322147', 'text': 'Solving for V, we get:'}, {'x': 56, 'y': 815, 'w': 778, 'h': 28, 'confidence': '0.8910450979054069', 'text': 'Did the student get the correct answer? If the solution is wrong; please'}, {'x': 1271, 'y': 809, 'w': 34, 'h': 18, 'confidence': '0.8194088339805603', 'text': 'V ='}, {'x': 1301, 'y': 801, 'w': 67, 'h': 30, 'confidence': '0.7313894885648536', 'text': 'Vzgh'}, {'x': 56, 'y': 838, 'w': 496, 'h': 28, 'confidence': '0.8978380513410406', 'text': 'explain what is wrong and solve the problem:'}, {'x': 917, 'y': 848, 'w': 418, 'h': 33, 'confidence': '0.668380433336712', 'text': 'Substituting the given values, we get:'}, {'x': 58, 'y': 886, 'w': 766, 'h': 24, 'confidence': '0.8642296167520925', 'text': 'Make sure to use LaTeX for math and round off the final answer to two'}, {'x': 56, 'y': 910, 'w': 174, 'h': 26, 'confidence': '0.9492180278759631', 'text': 'decimal places:'}, {'x': 1165, 'y': 909, 'w': 34, 'h': 16, 'confidence': '0.6047717338858417', 'text': 'V ='}, {'x': 1197, 'y': 902, 'w': 279, 'h': 26, 'confidence': '0.4248849117971446', 'text': 'V2x9.81x46 = 28.01 mls'}, {'x': 917, 'y': 945, 'w': 737, 'h': 30, 'confidence': '0.45259781252099096', 'text': \"Therefore, the skier's speed at the bottom of the slope is 28.01 mls:\"}, {'x': 115, 'y': 492, 'w': 58, 'h': 25, 'confidence': '0.7024372911720959', 'text': 'and'}, {'x': 978, 'y': 524, 'w': 50, 'h': 17, 'confidence': '0.98553210939953', 'text': 'mv?'}, {'x': 276, 'y': 527, 'w': 84, 'h': 37, 'confidence': '0.3057582777348758', 'text': 'm3 L'}, {'x': 299, 'y': 575, 'w': 75, 'h': 11, 'confidence': '0.9001057474795326', 'text': 'Mv2'}, {'x': 216, 'y': 632, 'w': 95, 'h': 34, 'confidence': '0.18410621583461761', 'text': '\"JL='}]}]\n",
      "> Image for page 44: [{'name': 'img_p43_2.png', 'height': 180, 'width': 320, 'x': 0, 'y': 0, 'original_width': 320, 'original_height': 180, 'ocr': [{'x': 31, 'y': 15, 'w': 84, 'h': 16, 'confidence': '0.9544790385334312', 'text': 'Gemini 1.5 Pro'}, {'x': 14, 'y': 76, 'w': 166, 'h': 28, 'confidence': '0.8606040221716865', 'text': '696,417 tokens'}, {'x': 225, 'y': 89, 'w': 80, 'h': 12, 'confidence': '0.2065351021420089', 'text': \"'10UO,UOO tokars\"}]}]\n",
      "> Image for page 45: [{'name': 'img_p44_1.png', 'height': 973, 'width': 2048, 'x': 300.466545048, 'y': 72.214581051024, 'original_width': 2048, 'original_height': 973, 'ocr': [{'x': 23, 'y': 21, 'w': 246, 'h': 42, 'confidence': '0.5294907717302331', 'text': 'Google Al Studio'}, {'x': 397, 'y': 21, 'w': 228, 'h': 40, 'confidence': '0.9948354814610291', 'text': 'Untitled prompt'}, {'x': 1935, 'y': 25, 'w': 91, 'h': 28, 'confidence': '0.9999890511597057', 'text': 'Compare'}, {'x': 442, 'y': 100, 'w': 214, 'h': 30, 'confidence': '0.9999488721620491', 'text': 'System Instructions'}, {'x': 25, 'y': 135, 'w': 26, 'h': 16, 'confidence': '0.26077127483423146', 'text': '07'}, {'x': 58, 'y': 128, 'w': 78, 'h': 26, 'confidence': '0.9406297822542475', 'text': 'Get API'}, {'x': 442, 'y': 148, 'w': 446, 'h': 28, 'confidence': '0.9242128455335249', 'text': 'Optional tone and style instructions for the model'}, {'x': 60, 'y': 186, 'w': 184, 'h': 26, 'confidence': '0.980611046996737', 'text': 'Create new prompt'}, {'x': 60, 'y': 236, 'w': 168, 'h': 24, 'confidence': '0.8659623182255681', 'text': 'New tuned model'}, {'x': 60, 'y': 286, 'w': 34, 'h': 26, 'confidence': '0.9990921778521354', 'text': 'My'}, {'x': 90, 'y': 332, 'w': 49, 'h': 29, 'confidence': '0.9999796152114868', 'text': 'Test'}, {'x': 60, 'y': 386, 'w': 72, 'h': 24, 'confidence': '0.990951941638618', 'text': 'View all'}, {'x': 59, 'y': 434, 'w': 145, 'h': 28, 'confidence': '0.9998452245621227', 'text': 'Prompt Gallery'}, {'x': 60, 'y': 520, 'w': 244, 'h': 26, 'confidence': '0.9995773193969877', 'text': 'Developer documentation'}, {'x': 390, 'y': 494, 'w': 240, 'h': 50, 'confidence': '0.9727870241586904', 'text': 'Get started'}, {'x': 59, 'y': 569, 'w': 159, 'h': 30, 'confidence': '0.9988433287727397', 'text': 'Developer forum'}, {'x': 392, 'y': 560, 'w': 294, 'h': 30, 'confidence': '0.8704814410463827', 'text': 'Try a sample prompt or add'}, {'x': 740, 'y': 558, 'w': 178, 'h': 30, 'confidence': '0.9995478263411922', 'text': 'own input below'}, {'x': 60, 'y': 620, 'w': 236, 'h': 28, 'confidence': '0.7870886730934418', 'text': 'Gemini API for Enterprise'}, {'x': 485, 'y': 645, 'w': 229, 'h': 44, 'confidence': '0.9443951088199037', 'text': 'Guided learning'}, {'x': 1043, 'y': 647, 'w': 227, 'h': 43, 'confidence': '0.9998671800203467', 'text': 'Homework help'}, {'x': 1599, 'y': 649, 'w': 236, 'h': 40, 'confidence': '0.9871025109896144', 'text': 'Teach a concept'}, {'x': 484, 'y': 700, 'w': 190, 'h': 26, 'confidence': '0.8147461532370764', 'text': 'Discuss a topic with'}, {'x': 670, 'y': 696, 'w': 168, 'h': 32, 'confidence': '0.9995737911648136', 'text': 'guided questions'}, {'x': 1042, 'y': 700, 'w': 340, 'h': 28, 'confidence': '0.9348328353827564', 'text': 'Get feedback as you work through a'}, {'x': 1601, 'y': 703, 'w': 58, 'h': 20, 'confidence': '0.8911917548960964', 'text': 'Learn'}, {'x': 1657, 'y': 696, 'w': 297, 'h': 33, 'confidence': '0.9787778249181615', 'text': 'together with a friendly Al tutor'}, {'x': 1040, 'y': 725, 'w': 84, 'h': 31, 'confidence': '0.9999705326627166', 'text': 'problem'}, {'x': 22, 'y': 916, 'w': 302, 'h': 24, 'confidence': '0.9473228648440127', 'text': 'This experimental model for feedback and'}, {'x': 22, 'y': 944, 'w': 92, 'h': 24, 'confidence': '0.9782503200511595', 'text': 'testing only:'}, {'x': 1896, 'y': 38, 'w': 34, 'h': 0, 'confidence': '0.4233731160000679', 'text': 'JR'}, {'x': 132, 'y': 125, 'w': 38, 'h': 32, 'confidence': '0.9998543666302052', 'text': 'key'}, {'x': 91, 'y': 281, 'w': 64, 'h': 34, 'confidence': '0.8367729091055801', 'text': 'library'}, {'x': 682, 'y': 563, 'w': 59, 'h': 21, 'confidence': '0.9954994916915894', 'text': 'your'}]}]\n",
      "> Image for page 46: [{'name': 'img_p45_1.png', 'height': 866, 'width': 2048, 'x': 17.311024176, 'y': 59.55118300799995, 'original_width': 2048, 'original_height': 866, 'ocr': [{'x': 20, 'y': 8, 'w': 207, 'h': 38, 'confidence': '0.7352211541608319', 'text': 'Google Al Studio'}, {'x': 332, 'y': 10, 'w': 54, 'h': 28, 'confidence': '0.9999909400939941', 'text': 'Test'}, {'x': 1606, 'y': 16, 'w': 73, 'h': 20, 'confidence': '0.9896808824036781', 'text': 'Compare'}, {'x': 1735, 'y': 17, 'w': 74, 'h': 16, 'confidence': '0.8817636398427185', 'text': 'Get code'}, {'x': 1865, 'y': 15, 'w': 90, 'h': 18, 'confidence': '0.6096425008900779', 'text': 'Learn More'}, {'x': 368, 'y': 76, 'w': 178, 'h': 26, 'confidence': '0.9997949626644084', 'text': 'System Instructions'}, {'x': 1727, 'y': 77, 'w': 38, 'h': 20, 'confidence': '0.9999922227208102', 'text': 'Run'}, {'x': 1761, 'y': 70, 'w': 80, 'h': 33, 'confidence': '0.999987861677114', 'text': 'settings'}, {'x': 1977, 'y': 79, 'w': 46, 'h': 18, 'confidence': '0.9999979741431879', 'text': 'Reset'}, {'x': 52, 'y': 98, 'w': 94, 'h': 24, 'confidence': '0.757165735221434', 'text': 'Get API key'}, {'x': 370, 'y': 114, 'w': 218, 'h': 24, 'confidence': '0.9446634646602599', 'text': 'You are a horticulturist with a'}, {'x': 586, 'y': 113, 'w': 942, 'h': 27, 'confidence': '0.6887708469607209', 'text': 'background in natural lawns and native plants, and you help people plan low water gardens: Take into account location; weather;'}, {'x': 1559, 'y': 117, 'w': 116, 'h': 20, 'confidence': '0.8585716389474667', 'text': 'what plants are'}, {'x': 53, 'y': 147, 'w': 152, 'h': 20, 'confidence': '0.8892233100782632', 'text': 'Create new prompt'}, {'x': 370, 'y': 138, 'w': 464, 'h': 24, 'confidence': '0.5781557283411176', 'text': 'native to the area. You are knowledgeable, casual, and friendly:'}, {'x': 1759, 'y': 133, 'w': 52, 'h': 18, 'confidence': '0.9999692922237101', 'text': 'Model'}, {'x': 1778, 'y': 172, 'w': 196, 'h': 27, 'confidence': '0.8408997633962951', 'text': 'LearnLM 1.5 Pro Experim~'}, {'x': 55, 'y': 187, 'w': 136, 'h': 20, 'confidence': '0.9931177899319196', 'text': 'New tuned model'}, {'x': 345, 'y': 199, 'w': 38, 'h': 16, 'confidence': '0.9999818801879883', 'text': 'User'}, {'x': 52, 'y': 226, 'w': 83, 'h': 26, 'confidence': '0.8346180966571016', 'text': 'My library'}, {'x': 342, 'y': 232, 'w': 286, 'h': 26, 'confidence': '0.9739335937454073', 'text': 'How to grow strawberries in Singa[ore'}, {'x': 1759, 'y': 247, 'w': 100, 'h': 20, 'confidence': '0.9997931636668663', 'text': 'Token Count'}, {'x': 83, 'y': 273, 'w': 34, 'h': 18, 'confidence': '0.9999968409538269', 'text': 'Test'}, {'x': 1761, 'y': 275, 'w': 88, 'h': 20, 'confidence': '0.4351376252799348', 'text': '751 /32,767'}, {'x': 343, 'y': 283, 'w': 52, 'h': 20, 'confidence': '0.9999901372714848', 'text': 'Model'}, {'x': 405, 'y': 283, 'w': 42, 'h': 20, 'confidence': '0.8109891485753256', 'text': '14.25'}, {'x': 55, 'y': 311, 'w': 58, 'h': 20, 'confidence': '0.9353173839099975', 'text': 'View all'}, {'x': 342, 'y': 319, 'w': 424, 'h': 26, 'confidence': '0.7773759529105406', 'text': \"Alright, let's talk about growing strawberries in Singapore\"}, {'x': 771, 'y': 321, 'w': 66, 'h': 20, 'confidence': '0.8624832630700263', 'text': 'It can be'}, {'x': 848, 'y': 318, 'w': 775, 'h': 27, 'confidence': '0.556475345419389', 'text': 'bit tricky, as our tropical climate isn*t ideal for these cool-season fruits. Strawberries prefer temperatures'}, {'x': 1757, 'y': 329, 'w': 105, 'h': 26, 'confidence': '0.8009608590485607', 'text': 'Temperature'}, {'x': 344, 'y': 345, 'w': 173, 'h': 21, 'confidence': '0.386672585341263', 'text': 'between 1O*C and 21*C ,'}, {'x': 553, 'y': 345, 'w': 796, 'h': 21, 'confidence': '0.6743112379494625', 'text': \"we're consistently warmer than that. But don't despair; it's not impossiblel Here's what you need to consider:\"}, {'x': 55, 'y': 357, 'w': 60, 'h': 18, 'confidence': '0.9699059602438329', 'text': 'Prompt'}, {'x': 342, 'y': 401, 'w': 240, 'h': 28, 'confidence': '0.8189805399183282', 'text': 'Understanding the Challenges:'}, {'x': 51, 'y': 420, 'w': 205, 'h': 26, 'confidence': '0.7642788861236971', 'text': 'Developer documentation'}, {'x': 1759, 'y': 445, 'w': 44, 'h': 20, 'confidence': '0.9999585231508025', 'text': 'Tools'}, {'x': 51, 'y': 462, 'w': 135, 'h': 26, 'confidence': '0.9999309281052959', 'text': 'Developer forum'}, {'x': 369, 'y': 465, 'w': 74, 'h': 20, 'confidence': '0.998682104360664', 'text': 'Heat and'}, {'x': 441, 'y': 459, 'w': 82, 'h': 30, 'confidence': '0.9998275761981743', 'text': 'Humidity:'}, {'x': 563, 'y': 467, 'w': 48, 'h': 18, 'confidence': '0.8266376708178993', 'text': \"pore's\"}, {'x': 608, 'y': 462, 'w': 78, 'h': 26, 'confidence': '0.9844535626443697', 'text': 'high heat'}, {'x': 715, 'y': 465, 'w': 148, 'h': 20, 'confidence': '0.9963781665978239', 'text': 'humidity can stress'}, {'x': 861, 'y': 462, 'w': 285, 'h': 26, 'confidence': '0.9969752357552918', 'text': 'strawberry plants, leading to diseases'}, {'x': 1178, 'y': 462, 'w': 158, 'h': 24, 'confidence': '0.8415808658834595', 'text': 'poor fruit production:'}, {'x': 368, 'y': 490, 'w': 788, 'h': 24, 'confidence': '0.6142546684066363', 'text': 'Sunlight: While strawberries need ample sunlight (around 6-8 hours) , intense tropical sun can scorch them:'}, {'x': 1758, 'y': 486, 'w': 144, 'h': 24, 'confidence': '0.997447925506002', 'text': 'Structured output'}, {'x': 52, 'y': 506, 'w': 198, 'h': 24, 'confidence': '0.9088751981852506', 'text': 'Gemini API for Enterprise'}, {'x': 370, 'y': 516, 'w': 512, 'h': 24, 'confidence': '0.8095124455126061', 'text': 'Rainfall: Our monsoon seasons can lead to overwatering and root rot:'}, {'x': 1843, 'y': 527, 'w': 36, 'h': 18, 'confidence': '0.9993382096290588', 'text': 'Edit'}, {'x': 1877, 'y': 527, 'w': 64, 'h': 20, 'confidence': '0.7485042241644797', 'text': 'schema'}, {'x': 342, 'y': 574, 'w': 134, 'h': 27, 'confidence': '0.9998681208582507', 'text': 'Tips for Success:'}, {'x': 1759, 'y': 589, 'w': 124, 'h': 20, 'confidence': '0.7184464431618212', 'text': 'Code execution'}, {'x': 370, 'y': 634, 'w': 990, 'h': 26, 'confidence': '0.8345723922844183', 'text': 'Choose the Right Variety: Opt for varieties specifically bred for warmer climates. Alpine strawberries or everbearing varieties might be'}, {'x': 1372, 'y': 634, 'w': 298, 'h': 26, 'confidence': '0.7151704964357317', 'text': 'better bet than June-bearing types. Ask'}, {'x': 369, 'y': 656, 'w': 1303, 'h': 27, 'confidence': '0.7530304657876093', 'text': 'your local nursery for recommendations on varieties that have shown some success in Singapore. They might even carry seeds or seedlings started in local conditions, giving you'}, {'x': 371, 'y': 683, 'w': 94, 'h': 18, 'confidence': '0.8263461302802756', 'text': 'a head start:'}, {'x': 1758, 'y': 687, 'w': 127, 'h': 27, 'confidence': '0.9976791683226252', 'text': 'Function calling'}, {'x': 371, 'y': 709, 'w': 212, 'h': 20, 'confidence': '0.7119238313605277', 'text': 'Create a Cool Environment:'}, {'x': 396, 'y': 732, 'w': 794, 'h': 26, 'confidence': '0.7874574727177371', 'text': 'Potting: Growing strawberries in pots allows for better control over the environment: Use terracotta pots, as'}, {'x': 1224, 'y': 733, 'w': 186, 'h': 25, 'confidence': '0.9352605528593739', 'text': 'help keep the soil cooler:'}, {'x': 1843, 'y': 729, 'w': 112, 'h': 20, 'confidence': '0.863632233370293', 'text': 'Edit functions'}, {'x': 25, 'y': 753, 'w': 246, 'h': 16, 'confidence': '0.8533934377732699', 'text': 'This experimental model for feedback and'}, {'x': 396, 'y': 760, 'w': 402, 'h': 24, 'confidence': '0.9883869537224169', 'text': 'Placement: Place your pots in a location that receives'}, {'x': 794, 'y': 756, 'w': 69, 'h': 30, 'confidence': '0.9999633234855269', 'text': 'morning'}, {'x': 863, 'y': 767, 'w': 30, 'h': 14, 'confidence': '0.9995601490931104', 'text': 'sun'}, {'x': 888, 'y': 760, 'w': 162, 'h': 24, 'confidence': '0.7448486228529193', 'text': 'and afternoon shade.'}, {'x': 1065, 'y': 758, 'w': 609, 'h': 28, 'confidence': '0.763897257775527', 'text': 'balcony or a sheltered patio would work well: You could even consider using shade'}, {'x': 25, 'y': 777, 'w': 72, 'h': 16, 'confidence': '0.9788011294541611', 'text': 'testing only:'}, {'x': 396, 'y': 784, 'w': 304, 'h': 24, 'confidence': '0.5811817874554575', 'text': 'cloth during the hottest parts of the day:'}, {'x': 1758, 'y': 796, 'w': 148, 'h': 24, 'confidence': '0.9999805560419197', 'text': 'Advanced settings'}, {'x': 394, 'y': 806, 'w': 708, 'h': 30, 'confidence': '0.8240779964155168', 'text': 'Cooling Techniques: Consider placing the pots on a tray filled with pebbles and water to create'}, {'x': 1112, 'y': 810, 'w': 534, 'h': 24, 'confidence': '0.6808667007338941', 'text': 'humid microclimate around the plants. Just make sure the bottom of the'}, {'x': 52, 'y': 834, 'w': 70, 'h': 24, 'confidence': '0.9999833097902971', 'text': 'Settings'}, {'x': 398, 'y': 834, 'w': 358, 'h': 24, 'confidence': '0.9289430297767263', 'text': \"pot isn't directly sitting in water to avoid root rot:\"}, {'x': 1526, 'y': 120, 'w': 34, 'h': 14, 'confidence': '0.9999881620207366', 'text': 'and'}, {'x': 518, 'y': 348, 'w': 34, 'h': 14, 'confidence': '0.999686919297231', 'text': 'and'}, {'x': 113, 'y': 349, 'w': 56, 'h': 29, 'confidence': '0.9999971614154921', 'text': 'Gallery'}, {'x': 519, 'y': 460, 'w': 44, 'h': 29, 'confidence': '0.6299500692852278', 'text': 'Singaf'}, {'x': 682, 'y': 468, 'w': 34, 'h': 14, 'confidence': '0.9999059161134095', 'text': 'and'}, {'x': 1142, 'y': 468, 'w': 34, 'h': 14, 'confidence': '0.9999612513354031', 'text': 'and'}, {'x': 1187, 'y': 732, 'w': 36, 'h': 26, 'confidence': '0.9999746680259705', 'text': 'they'}]}]\n",
      "> Image for page 47: [{'name': 'img_p46_1.png', 'height': 942, 'width': 2048, 'x': 47.970473975999994, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 942, 'ocr': [{'x': 19, 'y': 173, 'w': 57, 'h': 247, 'confidence': '0.2735608619631513', 'text': '1'}, {'x': 240, 'y': 815, 'w': 714, 'h': 102, 'confidence': '0.9996679103196419', 'text': 'Low Temperature'}, {'x': 1244, 'y': 813, 'w': 748, 'h': 104, 'confidence': '0.8522956957167519', 'text': 'High Temperature'}]}]\n",
      "> Image for page 48: [{'name': 'img_p47_1.png', 'height': 1147, 'width': 2048, 'x': 426.70243491431995, 'y': 60.425198784, 'original_width': 2048, 'original_height': 1147, 'ocr': [{'x': 127, 'y': 1, 'w': 645, 'h': 146, 'confidence': '0.9681131796971212', 'text': 'Wishing you'}, {'x': 123, 'y': 236, 'w': 253, 'h': 102, 'confidence': '0.99998256695316', 'text': 'happy'}, {'x': 128, 'y': 430, 'w': 370, 'h': 76, 'confidence': '0.5345780244571822', 'text': 'wondertul'}, {'x': 1240, 'y': 336, 'w': 684, 'h': 173, 'confidence': '0.9156271395432763', 'text': 'Top k = 3'}, {'x': 1247, 'y': 508, 'w': 743, 'h': 65, 'confidence': '0.9920449654576309', 'text': 'next token is selected from'}, {'x': 1244, 'y': 563, 'w': 787, 'h': 87, 'confidence': '0.9153187288939376', 'text': 'among the 3 most probable'}, {'x': 128, 'y': 618, 'w': 227, 'h': 92, 'confidence': '0.999910275403631', 'text': 'merry'}, {'x': 122, 'y': 804, 'w': 173, 'h': 86, 'confidence': '0.9994817380481021', 'text': 'very'}, {'x': 123, 'y': 995, 'w': 280, 'h': 90, 'confidence': '0.9999855945480354', 'text': 'speedy'}]}, {'name': 'img_p47_2.png', 'height': 1086, 'width': 2048, 'x': 426.70276956, 'y': 229.02363921852, 'original_width': 2048, 'original_height': 1086, 'ocr': [{'x': 117, 'y': 0, 'w': 631, 'h': 120, 'confidence': '0.99709098525428', 'text': 'Wishing you'}, {'x': 764, 'y': 16, 'w': 80, 'h': 74, 'confidence': '0.6219573153403282', 'text': 'a'}, {'x': 109, 'y': 210, 'w': 250, 'h': 100, 'confidence': '0.9999473275654446', 'text': 'happy'}, {'x': 116, 'y': 400, 'w': 364, 'h': 74, 'confidence': '0.9714643699154883', 'text': 'wonderful'}, {'x': 1123, 'y': 497, 'w': 635, 'h': 169, 'confidence': '0.9643996632324496', 'text': 'Top k=1'}, {'x': 114, 'y': 582, 'w': 223, 'h': 92, 'confidence': '0.9998765284735074', 'text': 'merry'}, {'x': 1127, 'y': 667, 'w': 908, 'h': 60, 'confidence': '0.955349539534917', 'text': 'selects the token that is the most'}, {'x': 1124, 'y': 720, 'w': 911, 'h': 84, 'confidence': '0.9831364590534832', 'text': 'probable among all the tokens in'}, {'x': 110, 'y': 766, 'w': 168, 'h': 84, 'confidence': '0.9995787739753723', 'text': 'very'}, {'x': 1125, 'y': 782, 'w': 645, 'h': 84, 'confidence': '0.6492106079319323', 'text': 'the models vocabulary'}, {'x': 110, 'y': 951, 'w': 275, 'h': 92, 'confidence': '0.9998181764151552', 'text': 'speedy'}]}]\n",
      "> Image for page 49: [{'name': 'img_p48_1.png', 'height': 969, 'width': 2048, 'x': 397.03938278399994, 'y': 57.09449001599998, 'original_width': 2048, 'original_height': 969, 'ocr': [{'x': 96, 'y': 0, 'w': 662, 'h': 141, 'confidence': '0.9815828863240192', 'text': 'Wishing you'}, {'x': 776, 'y': 34, 'w': 146, 'h': 76, 'confidence': '0.30667688234717216', 'text': 'a.'}, {'x': 59, 'y': 286, 'w': 197, 'h': 81, 'confidence': '0.999964813997035', 'text': 'happy'}, {'x': 882, 'y': 290, 'w': 110, 'h': 52, 'confidence': '0.99154057841958', 'text': '30%'}, {'x': 64, 'y': 433, 'w': 283, 'h': 66, 'confidence': '0.6484006268037361', 'text': 'wonderful'}, {'x': 726, 'y': 438, 'w': 104, 'h': 48, 'confidence': '0.941985547542572', 'text': '20%'}, {'x': 1110, 'y': 370, 'w': 583, 'h': 183, 'confidence': '0.5354261335010614', 'text': 'Top p ='}, {'x': 1727, 'y': 374, 'w': 229, 'h': 137, 'confidence': '0.9998051575091346', 'text': '0.5'}, {'x': 1121, 'y': 547, 'w': 820, 'h': 63, 'confidence': '0.9028160755764557', 'text': 'Tokens are selected from the'}, {'x': 67, 'y': 580, 'w': 171, 'h': 66, 'confidence': '0.9516816347945012', 'text': 'merry'}, {'x': 572, 'y': 580, 'w': 94, 'h': 50, 'confidence': '0.9981144070625305', 'text': '10%'}, {'x': 1125, 'y': 615, 'w': 374, 'h': 60, 'confidence': '0.9970661171894709', 'text': 'most to least'}, {'x': 1494, 'y': 599, 'w': 517, 'h': 91, 'confidence': '0.9356876703924418', 'text': 'probable until the'}, {'x': 524, 'y': 710, 'w': 76, 'h': 48, 'confidence': '0.996208723484471', 'text': '8%'}, {'x': 1119, 'y': 679, 'w': 348, 'h': 62, 'confidence': '0.9137233414633867', 'text': 'sum of their'}, {'x': 1465, 'y': 666, 'w': 569, 'h': 88, 'confidence': '0.9994707285426448', 'text': 'probabilities equals'}, {'x': 66, 'y': 722, 'w': 124, 'h': 56, 'confidence': '0.9017458074599554', 'text': 'very'}, {'x': 1116, 'y': 743, 'w': 428, 'h': 76, 'confidence': '0.8793507109149982', 'text': 'the topP value:'}, {'x': 59, 'y': 855, 'w': 215, 'h': 75, 'confidence': '0.9999696803627581', 'text': 'speedy'}, {'x': 476, 'y': 864, 'w': 74, 'h': 50, 'confidence': '0.619647867497512', 'text': '4%'}]}]\n",
      "> Image for page 50: [{'name': 'img_p49_1.png', 'height': 1438, 'width': 566, 'x': 572.67527423112, 'y': 51.95866308000001, 'original_width': 566, 'original_height': 1438, 'ocr': [{'x': 20, 'y': 5, 'w': 195, 'h': 50, 'confidence': '0.9516130725756736', 'text': 'Run settings'}, {'x': 450, 'y': 14, 'w': 82, 'h': 30, 'confidence': '0.9999983473273739', 'text': 'Reset'}, {'x': 78, 'y': 110, 'w': 86, 'h': 32, 'confidence': '0.9999895508386168', 'text': 'Model'}, {'x': 107, 'y': 185, 'w': 336, 'h': 38, 'confidence': '0.7076530072407956', 'text': 'LearnLM 1.5 Pro Experimo'}, {'x': 24, 'y': 312, 'w': 38, 'h': 30, 'confidence': '0.1787623325408725', 'text': '0.'}, {'x': 76, 'y': 310, 'w': 172, 'h': 32, 'confidence': '0.9999773906310806', 'text': 'Token Count'}, {'x': 80, 'y': 358, 'w': 160, 'h': 32, 'confidence': '0.5629466563599267', 'text': '502 / 32,767'}, {'x': 25, 'y': 452, 'w': 226, 'h': 42, 'confidence': '0.5180015728187627', 'text': '87   Temperature'}, {'x': 76, 'y': 654, 'w': 76, 'h': 32, 'confidence': '0.9999254694751994', 'text': 'Tools'}, {'x': 73, 'y': 725, 'w': 248, 'h': 38, 'confidence': '0.6111166455122625', 'text': 'Structured output'}, {'x': 223, 'y': 791, 'w': 170, 'h': 36, 'confidence': '0.9844008065954797', 'text': 'Edit schema'}, {'x': 76, 'y': 902, 'w': 212, 'h': 32, 'confidence': '0.9971757973925804', 'text': 'Code execution'}, {'x': 74, 'y': 1076, 'w': 217, 'h': 41, 'confidence': '0.9985993045711156', 'text': 'Function calling'}, {'x': 223, 'y': 1143, 'w': 190, 'h': 36, 'confidence': '0.7713373744320771', 'text': 'Edit functions'}, {'x': 75, 'y': 1261, 'w': 254, 'h': 38, 'confidence': '0.9780079704761299', 'text': 'Advanced settings'}, {'x': 73, 'y': 1328, 'w': 208, 'h': 44, 'confidence': '0.896807254548634', 'text': 'Safety settings'}, {'x': 75, 'y': 1393, 'w': 263, 'h': 43, 'confidence': '0.5759365299411874', 'text': 'Edit safety settings'}]}]\n",
      "> Image for page 51: [{'name': 'img_p50_1.png', 'height': 772, 'width': 800, 'x': 185.95571461199998, 'y': 58.273623912000005, 'original_width': 800, 'original_height': 772, 'ocr': [{'x': 31, 'y': 28, 'w': 706, 'h': 43, 'confidence': '0.8908027328444555', 'text': 'Adjust how likely you are to see responses that could'}, {'x': 30, 'y': 72, 'w': 590, 'h': 32, 'confidence': '0.8545859983518891', 'text': 'be harmful: Content is blocked based on the'}, {'x': 29, 'y': 111, 'w': 384, 'h': 38, 'confidence': '0.8181415633818164', 'text': 'probability that it is harmful:'}, {'x': 516, 'y': 214, 'w': 130, 'h': 30, 'confidence': '0.850413894419225', 'text': 'Block none'}, {'x': 32, 'y': 228, 'w': 164, 'h': 30, 'confidence': '0.9999942323053734', 'text': 'Harassment'}, {'x': 516, 'y': 352, 'w': 128, 'h': 30, 'confidence': '0.8911620100806785', 'text': 'Block none'}, {'x': 32, 'y': 366, 'w': 68, 'h': 30, 'confidence': '0.5874914362048194', 'text': 'Hate'}, {'x': 516, 'y': 490, 'w': 128, 'h': 30, 'confidence': '0.9968298305110518', 'text': 'Block none'}, {'x': 28, 'y': 500, 'w': 225, 'h': 39, 'confidence': '0.9992981935227271', 'text': 'Sexually Explicit'}, {'x': 514, 'y': 628, 'w': 132, 'h': 30, 'confidence': '0.9995982484256097', 'text': 'Block none'}, {'x': 30, 'y': 640, 'w': 263, 'h': 40, 'confidence': '0.9835594953099492', 'text': 'Dangerous Content'}]}]\n",
      "> Image for page 52: [{'name': 'img_p51_1.png', 'height': 870, 'width': 2048, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 870, 'ocr': [{'x': 394, 'y': 32, 'w': 298, 'h': 56, 'confidence': '0.9999578383308085', 'text': 'Temperature'}, {'x': 1056, 'y': 32, 'w': 146, 'h': 54, 'confidence': '0.9988236953234816', 'text': 'Top-K'}, {'x': 1666, 'y': 32, 'w': 142, 'h': 54, 'confidence': '0.9981296612609991', 'text': 'Top-P'}, {'x': 266, 'y': 178, 'w': 554, 'h': 32, 'confidence': '0.7804435400472147', 'text': 'Controls the randomness of the models'}, {'x': 856, 'y': 178, 'w': 546, 'h': 32, 'confidence': '0.8939482235521959', 'text': 'Limits the number of tokens considered'}, {'x': 1500, 'y': 175, 'w': 473, 'h': 41, 'confidence': '0.7530276507169176', 'text': 'Specifies a cumulative probability'}, {'x': 32, 'y': 196, 'w': 184, 'h': 32, 'confidence': '0.9118276266846085', 'text': 'How it works'}, {'x': 493, 'y': 217, 'w': 102, 'h': 36, 'confidence': '0.9999251596242191', 'text': 'output'}, {'x': 1094, 'y': 208, 'w': 165, 'h': 49, 'confidence': '0.9999951747404573', 'text': 'generation'}, {'x': 1668, 'y': 216, 'w': 138, 'h': 30, 'confidence': '0.9998153110778264', 'text': 'threshold'}, {'x': 283, 'y': 376, 'w': 522, 'h': 43, 'confidence': '0.801729028357488', 'text': 'More varied and surprising outputs at'}, {'x': 355, 'y': 415, 'w': 376, 'h': 40, 'confidence': '0.9309821928425295', 'text': 'higher temperatures; more'}, {'x': 870, 'y': 416, 'w': 519, 'h': 39, 'confidence': '0.9807383498979119', 'text': 'Encourages the model to explore less'}, {'x': 1452, 'y': 415, 'w': 569, 'h': 40, 'confidence': '0.8988543846501363', 'text': 'Allows for more fine-grained control over'}, {'x': 7, 'y': 435, 'w': 234, 'h': 38, 'confidence': '0.9884829522715345', 'text': 'Effect on output'}, {'x': 281, 'y': 449, 'w': 526, 'h': 42, 'confidence': '0.9329541874252306', 'text': 'conservative and predictable outputs'}, {'x': 925, 'y': 449, 'w': 408, 'h': 42, 'confidence': '0.9502989307580085', 'text': 'common words and phrases'}, {'x': 1576, 'y': 454, 'w': 54, 'h': 30, 'confidence': '0.9999998623489704', 'text': 'the'}, {'x': 1625, 'y': 447, 'w': 274, 'h': 45, 'confidence': '0.9860275254715094', 'text': 'diversity of outputs'}, {'x': 385, 'y': 491, 'w': 316, 'h': 38, 'confidence': '0.9988378289487865', 'text': 'at lower temperatures'}, {'x': 311, 'y': 660, 'w': 466, 'h': 42, 'confidence': '0.973715617763536', 'text': 'When you want to generate more'}, {'x': 1453, 'y': 660, 'w': 572, 'h': 42, 'confidence': '0.8056216732472644', 'text': 'When you want to generate very creative'}, {'x': 868, 'y': 679, 'w': 523, 'h': 42, 'confidence': '0.6324659601596879', 'text': 'When you want to generate a diverse'}, {'x': 305, 'y': 699, 'w': 476, 'h': 40, 'confidence': '0.6601546838159725', 'text': 'creative and surprising outputs, or'}, {'x': 1446, 'y': 704, 'w': 34, 'h': 26, 'confidence': '0.9914991500815675', 'text': 'or'}, {'x': 1480, 'y': 696, 'w': 549, 'h': 43, 'confidence': '0.8288680242213387', 'text': 'surprising outputs; or when you need to'}, {'x': 36, 'y': 720, 'w': 176, 'h': 30, 'confidence': '0.826672589409871', 'text': 'When to use'}, {'x': 901, 'y': 714, 'w': 456, 'h': 43, 'confidence': '0.8261093292859969', 'text': 'set of outputs without sacrificing'}, {'x': 265, 'y': 733, 'w': 556, 'h': 43, 'confidence': '0.8486892753887066', 'text': 'when you want to encourage the model'}, {'x': 1439, 'y': 737, 'w': 596, 'h': 38, 'confidence': '0.9074105989809323', 'text': 'ensure that the outputs are consistent with'}, {'x': 1052, 'y': 758, 'w': 154, 'h': 30, 'confidence': '0.9992502637914242', 'text': 'coherence'}, {'x': 363, 'y': 775, 'w': 252, 'h': 36, 'confidence': '0.8103442000380602', 'text': 'to explore diverse'}, {'x': 608, 'y': 767, 'w': 117, 'h': 49, 'confidence': '0.9972501635486121', 'text': 'options'}, {'x': 1580, 'y': 780, 'w': 24, 'h': 24, 'confidence': '0.9997459811374121', 'text': 'a'}, {'x': 1602, 'y': 768, 'w': 294, 'h': 48, 'confidence': '0.9984696242195352', 'text': 'specific style or tone'}, {'x': 1004, 'y': 206, 'w': 92, 'h': 50, 'confidence': '0.999995473967752', 'text': 'during'}]}]\n",
      "> Image for page 53: []\n",
      "> Image for page 54: []\n",
      "> Image for page 55: [{'name': 'img_p54_1.png', 'height': 1402, 'width': 1886, 'x': 128.852366328, 'y': 51.118111871999986, 'original_width': 1886, 'original_height': 1402, 'ocr': [{'x': 54, 'y': 28, 'w': 224, 'h': 77, 'confidence': '0.9866244756140855', 'text': 'API keys'}, {'x': 53, 'y': 123, 'w': 1732, 'h': 42, 'confidence': '0.7166902112540421', 'text': 'Cloud projects are subject to the Google Cloud Platform Terms of Service, and use of Gemini API and Google Al Studio is subject to the'}, {'x': 55, 'y': 165, 'w': 520, 'h': 36, 'confidence': '0.8688848689345972', 'text': 'Gemini API Additional Terms of Service:'}, {'x': 55, 'y': 232, 'w': 1788, 'h': 43, 'confidence': '0.6735262187963152', 'text': \"Remember to use API keys securely: Don't share or embed them in public code. Use of Gemini API from a billing-enabled project is subject to\"}, {'x': 53, 'y': 275, 'w': 310, 'h': 39, 'confidence': '0.7452702869499224', 'text': 'pay-as-you-go pricing:'}, {'x': 50, 'y': 370, 'w': 748, 'h': 53, 'confidence': '0.7557958702945053', 'text': 'Quickly test the API by running a cURL command'}, {'x': 55, 'y': 445, 'w': 275, 'h': 45, 'confidence': '0.8419602216120389', 'text': 'API quickstart guide'}, {'x': 85, 'y': 551, 'w': 73, 'h': 38, 'confidence': '0.9710819125175476', 'text': 'curl'}, {'x': 118, 'y': 600, 'w': 36, 'h': 26, 'confidence': '0.6704490944454953', 'text': '~H'}, {'x': 162, 'y': 592, 'w': 511, 'h': 44, 'confidence': '0.895454457889382', 'text': '\"Content-Type: application/json\"'}, {'x': 117, 'y': 641, 'w': 792, 'h': 38, 'confidence': '0.18203231363883662', 'text': '~d \"{I \"contents| \" : [{| \"parts|\" : [{| \"text| \": | \"Explain'}, {'x': 978, 'y': 644, 'w': 38, 'h': 28, 'confidence': '0.9973269986083082', 'text': 'AI'}, {'x': 1025, 'y': 640, 'w': 209, 'h': 36, 'confidence': '0.8237557709308168', 'text': 'works| \"}]}]}\"'}, {'x': 118, 'y': 688, 'w': 36, 'h': 26, 'confidence': '0.8508471891293847', 'text': '~X'}, {'x': 163, 'y': 681, 'w': 1606, 'h': 45, 'confidence': '0.5436068595931449', 'text': 'POST \"https:/ /generativelanguage.googleapis. com/vlbeta/models/gemini-1.5-flash-latest:generateContent?'}, {'x': 85, 'y': 728, 'w': 273, 'h': 39, 'confidence': '0.7804813766298494', 'text': 'key-YOUR_API_KEY\"'}, {'x': 138, 'y': 818, 'w': 210, 'h': 24, 'confidence': '0.9317999929715353', 'text': 'Use code with caution_'}, {'x': 134, 'y': 948, 'w': 148, 'h': 32, 'confidence': '0.9733497122718692', 'text': 'Create API'}, {'x': 53, 'y': 1061, 'w': 1324, 'h': 42, 'confidence': '0.8007138989871528', 'text': 'Your API keys are listed below: You can also view and manage your project and API keys in Google Cloud.'}, {'x': 123, 'y': 1155, 'w': 182, 'h': 36, 'confidence': '0.7808550971449781', 'text': 'Project number'}, {'x': 390, 'y': 1158, 'w': 154, 'h': 32, 'confidence': '0.9998764054654314', 'text': 'Project name'}, {'x': 880, 'y': 1158, 'w': 44, 'h': 28, 'confidence': '0.9831172525541894', 'text': 'API'}, {'x': 1184, 'y': 1156, 'w': 98, 'h': 30, 'confidence': '0.9999956294799149', 'text': 'Created'}, {'x': 1514, 'y': 1156, 'w': 56, 'h': 26, 'confidence': '0.9999314546585083', 'text': 'Plan'}, {'x': 1443, 'y': 1241, 'w': 199, 'h': 41, 'confidence': '0.9178220394820387', 'text': 'Free of charge'}, {'x': 190, 'y': 1284, 'w': 72, 'h': 32, 'confidence': '0.9999960064888', 'text': '0529'}, {'x': 389, 'y': 1281, 'w': 146, 'h': 36, 'confidence': '0.9955450559026939', 'text': 'Gemini API'}, {'x': 886, 'y': 1283, 'w': 90, 'h': 32, 'confidence': '0.36467683279092883', 'text': 'LL2CM'}, {'x': 1158, 'y': 1284, 'w': 152, 'h': 32, 'confidence': '0.7640000841861445', 'text': 'Dec 1, 2024'}, {'x': 1453, 'y': 1283, 'w': 180, 'h': 38, 'confidence': '0.944389139085895', 'text': 'Set up Billing'}, {'x': 1431, 'y': 1323, 'w': 224, 'h': 38, 'confidence': '0.9999331809608147', 'text': 'View usage data'}, {'x': 917, 'y': 639, 'w': 49, 'h': 36, 'confidence': '0.9999055719901783', 'text': 'how'}, {'x': 281, 'y': 943, 'w': 50, 'h': 44, 'confidence': '0.9995891229835373', 'text': 'key'}, {'x': 924, 'y': 1155, 'w': 40, 'h': 35, 'confidence': '0.9993265867233276', 'text': 'key'}]}]\n",
      "> Image for page 56: []\n",
      "> Image for page 57: [{'name': 'img_p56_1.png', 'height': 976, 'width': 980, 'x': 165.36811552799998, 'y': 51.12008037600003, 'original_width': 980, 'original_height': 976, 'ocr': [{'x': 17, 'y': 25, 'w': 48, 'h': 42, 'confidence': '0.6639789238477221', 'text': 'F'}, {'x': 92, 'y': 30, 'w': 123, 'h': 40, 'confidence': '0.9999949536257429', 'text': 'Secrets'}, {'x': 86, 'y': 111, 'w': 830, 'h': 50, 'confidence': '0.86239085812629', 'text': 'Configure your code by storing environment variables, file paths or'}, {'x': 87, 'y': 149, 'w': 782, 'h': 42, 'confidence': '0.6674521485831029', 'text': 'keys. Values stored here are private, visible only to you and the'}, {'x': 89, 'y': 187, 'w': 332, 'h': 38, 'confidence': '0.6671366280542794', 'text': 'notebooks that you select '}, {'x': 13, 'y': 199, 'w': 56, 'h': 44, 'confidence': '0.999540672645683', 'text': '{x}'}, {'x': 89, 'y': 249, 'w': 456, 'h': 39, 'confidence': '0.8042385956252456', 'text': 'Secret name cannot contain spaces.'}, {'x': 92, 'y': 316, 'w': 130, 'h': 32, 'confidence': '0.9999673781188508', 'text': 'Notebook'}, {'x': 236, 'y': 334, 'w': 80, 'h': 30, 'confidence': '0.9244961565774065', 'text': 'Name'}, {'x': 464, 'y': 334, 'w': 80, 'h': 30, 'confidence': '0.9998246007155615', 'text': 'Value'}, {'x': 694, 'y': 334, 'w': 102, 'h': 30, 'confidence': '0.9999967559032072', 'text': 'Actions'}, {'x': 90, 'y': 354, 'w': 94, 'h': 26, 'confidence': '0.9988912764897486', 'text': 'access'}, {'x': 246, 'y': 414, 'w': 206, 'h': 30, 'confidence': '0.5782016754853824', 'text': 'GOOGLE_API_k'}, {'x': 158, 'y': 512, 'w': 200, 'h': 32, 'confidence': '0.9203490866883626', 'text': 'Add new secret'}, {'x': 121, 'y': 581, 'w': 214, 'h': 42, 'confidence': '0.9998562828741404', 'text': 'Gemini API keys'}, {'x': 89, 'y': 660, 'w': 482, 'h': 43, 'confidence': '0.9618224581774456', 'text': 'Access your secret keys in Python via:'}, {'x': 129, 'y': 793, 'w': 294, 'h': 42, 'confidence': '0.7348091041573488', 'text': 'from google.colab'}, {'x': 433, 'y': 795, 'w': 108, 'h': 38, 'confidence': '0.9993486906808217', 'text': 'import'}, {'x': 552, 'y': 796, 'w': 140, 'h': 32, 'confidence': '0.9941998380389856', 'text': 'userdata'}, {'x': 129, 'y': 825, 'w': 227, 'h': 43, 'confidence': '0.9606911552724546', 'text': 'userdata.get ('}, {'x': 366, 'y': 830, 'w': 176, 'h': 32, 'confidence': '0.9999291653391591', 'text': 'secretName'}, {'x': 553, 'y': 833, 'w': 14, 'h': 26, 'confidence': '0.9817124423825909', 'text': ')'}]}]\n",
      "> Image for page 58: [{'name': 'img_p57_1.png', 'height': 853, 'width': 2048, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 853, 'ocr': [{'x': 32, 'y': 12, 'w': 44, 'h': 28, 'confidence': '0.9999116285613665', 'text': 'pip'}, {'x': 84, 'y': 10, 'w': 342, 'h': 30, 'confidence': '0.9567871165904522', 'text': 'install google-generativeai'}, {'x': 20, 'y': 88, 'w': 418, 'h': 28, 'confidence': '0.6584448539407658', 'text': 'from google.colab import userdata'}, {'x': 20, 'y': 116, 'w': 80, 'h': 26, 'confidence': '0.9987326770747486', 'text': 'import'}, {'x': 108, 'y': 116, 'w': 242, 'h': 28, 'confidence': '0.5915311885767007', 'text': 'goog Le. generativeai'}, {'x': 358, 'y': 115, 'w': 105, 'h': 29, 'confidence': '0.9834248105645519', 'text': 'as genai'}, {'x': 19, 'y': 142, 'w': 691, 'h': 31, 'confidence': '0.7380126205616577', 'text': \"genai.configure(api_key-userdata.get ( 'GOOGLE_API_KEY'  \"}, {'x': 3, 'y': 227, 'w': 177, 'h': 41, 'confidence': '0.9993019712288936', 'text': 'Gemini API'}, {'x': 3, 'y': 337, 'w': 214, 'h': 36, 'confidence': '0.9219487544786154', 'text': 'Text Generation'}, {'x': 22, 'y': 434, 'w': 78, 'h': 26, 'confidence': '0.762807375407243', 'text': 'import'}, {'x': 108, 'y': 432, 'w': 242, 'h': 30, 'confidence': '0.882016815156542', 'text': 'goog Le.generativeai'}, {'x': 358, 'y': 433, 'w': 104, 'h': 29, 'confidence': '0.9866422777025338', 'text': 'as genai'}, {'x': 20, 'y': 488, 'w': 68, 'h': 26, 'confidence': '0.9999379978996776', 'text': 'model'}, {'x': 119, 'y': 488, 'w': 517, 'h': 30, 'confidence': '0.7308855960734018', 'text': 'genai.GenerativeModel (\"gemini-1.5-flash\" )'}, {'x': 22, 'y': 520, 'w': 104, 'h': 26, 'confidence': '0.8769583301458993', 'text': 'response'}, {'x': 158, 'y': 516, 'w': 182, 'h': 30, 'confidence': '0.7466993819744433', 'text': 'model.generate_'}, {'x': 346, 'y': 516, 'w': 180, 'h': 26, 'confidence': '0.8766828430578596', 'text': 'content (\"Write'}, {'x': 555, 'y': 516, 'w': 145, 'h': 28, 'confidence': '0.9983356452870668', 'text': 'story about'}, {'x': 732, 'y': 516, 'w': 190, 'h': 28, 'confidence': '0.9446554847604732', 'text': 'magic backpack.'}, {'x': 20, 'y': 546, 'w': 68, 'h': 26, 'confidence': '0.9975577064762652', 'text': 'print'}, {'x': 98, 'y': 546, 'w': 176, 'h': 26, 'confidence': '0.9565037087442018', 'text': 'response.text)'}, {'x': 20, 'y': 598, 'w': 180, 'h': 26, 'confidence': '0.9997359698173337', 'text': 'Elara clutched'}, {'x': 206, 'y': 600, 'w': 44, 'h': 24, 'confidence': '0.9999978664093272', 'text': 'the'}, {'x': 257, 'y': 603, 'w': 54, 'h': 20, 'confidence': '0.9991685748100281', 'text': 'worn'}, {'x': 319, 'y': 597, 'w': 181, 'h': 30, 'confidence': '0.9734801984469118', 'text': 'leather straps'}, {'x': 506, 'y': 600, 'w': 30, 'h': 24, 'confidence': '0.9718963187919584', 'text': 'of'}, {'x': 544, 'y': 600, 'w': 42, 'h': 24, 'confidence': '0.9999993117448777', 'text': 'the'}, {'x': 594, 'y': 600, 'w': 114, 'h': 26, 'confidence': '0.9999909400734736', 'text': 'backpack,'}, {'x': 718, 'y': 598, 'w': 118, 'h': 26, 'confidence': '0.8794841327961211', 'text': 'its faded'}, {'x': 844, 'y': 600, 'w': 80, 'h': 24, 'confidence': '0.6234247209740659', 'text': 'emb Lem'}, {'x': 980, 'y': 595, 'w': 192, 'h': 33, 'confidence': '0.9784822134682991', 'text': 'swirling nebula'}, {'x': 1204, 'y': 598, 'w': 182, 'h': 30, 'confidence': '0.9698217401480062', 'text': 'barely visible'}, {'x': 1392, 'y': 600, 'w': 94, 'h': 24, 'confidence': '0.6767100017460637', 'text': 'beneath'}, {'x': 1492, 'y': 596, 'w': 121, 'h': 32, 'confidence': '0.8966011286243485', 'text': 'the grime_'}, {'x': 1642, 'y': 598, 'w': 44, 'h': 26, 'confidence': '0.999909150872559', 'text': 'She'}, {'x': 1718, 'y': 598, 'w': 66, 'h': 26, 'confidence': '0.9999878981639524', 'text': 'found'}, {'x': 1792, 'y': 600, 'w': 30, 'h': 24, 'confidence': '0.9993312793157817', 'text': 'it'}, {'x': 1828, 'y': 599, 'w': 118, 'h': 24, 'confidence': '0.999996940292561', 'text': 'abandoned'}, {'x': 1956, 'y': 600, 'w': 28, 'h': 24, 'confidence': '0.9932054594587486', 'text': 'in'}, {'x': 1992, 'y': 600, 'w': 42, 'h': 24, 'confidence': '0.9999988299663297', 'text': 'the'}, {'x': 20, 'y': 652, 'w': 54, 'h': 24, 'confidence': '0.9999531507492065', 'text': 'That'}, {'x': 82, 'y': 652, 'w': 78, 'h': 28, 'confidence': '0.999992067273776', 'text': 'night,'}, {'x': 170, 'y': 652, 'w': 66, 'h': 24, 'confidence': '0.9995160730169915', 'text': 'Elara'}, {'x': 244, 'y': 652, 'w': 80, 'h': 24, 'confidence': '0.9999986373241087', 'text': 'needed'}, {'x': 356, 'y': 650, 'w': 140, 'h': 30, 'confidence': '0.8745062403373844', 'text': 'new pencil.'}, {'x': 518, 'y': 652, 'w': 44, 'h': 24, 'confidence': '0.5227917432785034', 'text': 'She'}, {'x': 570, 'y': 652, 'w': 92, 'h': 24, 'confidence': '0.9999987384072065', 'text': 'reached'}, {'x': 668, 'y': 652, 'w': 56, 'h': 24, 'confidence': '0.9998785853385925', 'text': 'into'}, {'x': 730, 'y': 652, 'w': 166, 'h': 28, 'confidence': '0.9964018896304486', 'text': 'the backpack,'}, {'x': 906, 'y': 652, 'w': 118, 'h': 28, 'confidence': '0.9994684238328009', 'text': 'expecting'}, {'x': 1030, 'y': 652, 'w': 44, 'h': 24, 'confidence': '0.9999966963759913', 'text': 'the'}, {'x': 1081, 'y': 655, 'w': 66, 'h': 20, 'confidence': '0.9917970476579216', 'text': 'usual'}, {'x': 1156, 'y': 652, 'w': 80, 'h': 28, 'confidence': '0.9960906136521276', 'text': 'jumble'}, {'x': 1242, 'y': 652, 'w': 129, 'h': 27, 'confidence': '0.6913773868211299', 'text': 'of crayons'}, {'x': 1380, 'y': 652, 'w': 42, 'h': 24, 'confidence': '0.999997040503424', 'text': 'and'}, {'x': 1430, 'y': 652, 'w': 230, 'h': 28, 'confidence': '0.9965473355756621', 'text': 'half-eaten granola'}, {'x': 1668, 'y': 652, 'w': 64, 'h': 24, 'confidence': '0.42818766661505464', 'text': 'bars.'}, {'x': 1754, 'y': 652, 'w': 104, 'h': 26, 'confidence': '0.5744187496319719', 'text': 'Instead ,'}, {'x': 1866, 'y': 652, 'w': 144, 'h': 28, 'confidence': '0.9913299413269575', 'text': 'her fingers'}, {'x': 20, 'y': 706, 'w': 54, 'h': 24, 'confidence': '0.999737024307251', 'text': 'Over'}, {'x': 82, 'y': 706, 'w': 42, 'h': 24, 'confidence': '0.9999995870469189', 'text': 'the'}, {'x': 132, 'y': 706, 'w': 54, 'h': 24, 'confidence': '0.9999966621398926', 'text': 'next'}, {'x': 194, 'y': 704, 'w': 115, 'h': 31, 'confidence': '0.9985365964984563', 'text': 'few days,'}, {'x': 320, 'y': 706, 'w': 156, 'h': 26, 'confidence': '0.9992926208774433', 'text': 'the backpack'}, {'x': 506, 'y': 706, 'w': 68, 'h': 28, 'confidence': '0.997718578119344', 'text': 'magic'}, {'x': 580, 'y': 704, 'w': 228, 'h': 26, 'confidence': '0.9669044879408143', 'text': 'became undeniable.'}, {'x': 844, 'y': 702, 'w': 230, 'h': 32, 'confidence': '0.9719794306982963', 'text': 'sudden craving for'}, {'x': 1080, 'y': 706, 'w': 42, 'h': 24, 'confidence': '0.9999431503407694', 'text': 'hot'}, {'x': 1129, 'y': 703, 'w': 118, 'h': 26, 'confidence': '0.9999761579999791', 'text': 'chocolate'}, {'x': 1256, 'y': 706, 'w': 104, 'h': 24, 'confidence': '0.9999615196206361', 'text': 'resulted'}, {'x': 1368, 'y': 706, 'w': 30, 'h': 24, 'confidence': '0.9996055282900668', 'text': 'in'}, {'x': 1428, 'y': 699, 'w': 108, 'h': 36, 'confidence': '0.9999415416133441', 'text': 'steaming'}, {'x': 1542, 'y': 701, 'w': 306, 'h': 33, 'confidence': '0.7529754204149266', 'text': 'mug materializing Within'}, {'x': 1854, 'y': 706, 'w': 42, 'h': 24, 'confidence': '0.9991523930937961', 'text': 'its'}, {'x': 1904, 'y': 706, 'w': 90, 'h': 26, 'confidence': '0.9989152459214773', 'text': 'depths.'}, {'x': 20, 'y': 758, 'w': 42, 'h': 24, 'confidence': '0.9999896761798278', 'text': 'But'}, {'x': 70, 'y': 758, 'w': 42, 'h': 24, 'confidence': '0.9999995182214076', 'text': 'the'}, {'x': 120, 'y': 758, 'w': 106, 'h': 28, 'confidence': '0.664854454758003', 'text': 'backpack'}, {'x': 256, 'y': 758, 'w': 68, 'h': 28, 'confidence': '0.7685476979685809', 'text': 'magic'}, {'x': 331, 'y': 761, 'w': 56, 'h': 20, 'confidence': '0.9996203184127808', 'text': 'wasn'}, {'x': 418, 'y': 758, 'w': 94, 'h': 24, 'confidence': '0.9994261867512596', 'text': 'without'}, {'x': 518, 'y': 756, 'w': 132, 'h': 28, 'confidence': '0.9974134629620224', 'text': 'its quirks'}, {'x': 680, 'y': 758, 'w': 30, 'h': 24, 'confidence': '0.9999684743028646', 'text': 'It'}, {'x': 718, 'y': 756, 'w': 190, 'h': 28, 'confidence': '0.7882166819901012', 'text': 'was capricious.'}, {'x': 930, 'y': 758, 'w': 44, 'h': 24, 'confidence': '0.9998150681311999', 'text': 'One'}, {'x': 1067, 'y': 757, 'w': 93, 'h': 28, 'confidence': '0.9999972064724094', 'text': 'request'}, {'x': 1168, 'y': 758, 'w': 42, 'h': 24, 'confidence': '0.9999639355170521', 'text': 'for'}, {'x': 1242, 'y': 760, 'w': 68, 'h': 26, 'confidence': '0.9999683859161217', 'text': 'sunny'}, {'x': 1318, 'y': 758, 'w': 116, 'h': 24, 'confidence': '0.9999852974669141', 'text': 'afternoon'}, {'x': 1442, 'y': 758, 'w': 94, 'h': 28, 'confidence': '0.9993472823575935', 'text': 'yielded'}, {'x': 1566, 'y': 757, 'w': 246, 'h': 30, 'confidence': '0.9982492310631194', 'text': 'torrential downpour_'}, {'x': 1866, 'y': 758, 'w': 82, 'h': 24, 'confidence': '0.9951366581775336', 'text': 'desire'}, {'x': 1954, 'y': 758, 'w': 44, 'h': 24, 'confidence': '0.9998871684074402', 'text': 'for'}, {'x': 2004, 'y': 758, 'w': 30, 'h': 24, 'confidence': '0.33091847935501695', 'text': 'si'}, {'x': 20, 'y': 810, 'w': 54, 'h': 26, 'confidence': '0.9996105432510376', 'text': 'This'}, {'x': 82, 'y': 812, 'w': 92, 'h': 24, 'confidence': '0.9999945481131689', 'text': 'erratic'}, {'x': 182, 'y': 812, 'w': 80, 'h': 24, 'confidence': '0.9999974693158696', 'text': 'nature'}, {'x': 270, 'y': 810, 'w': 42, 'h': 26, 'confidence': '0.5491244885885267', 'text': 'led'}, {'x': 318, 'y': 812, 'w': 68, 'h': 24, 'confidence': '0.9994969862036447', 'text': 'Elara'}, {'x': 394, 'y': 812, 'w': 30, 'h': 24, 'confidence': '0.9999209334277391', 'text': 'to'}, {'x': 432, 'y': 812, 'w': 140, 'h': 24, 'confidence': '0.9999875636872922', 'text': 'understand:'}, {'x': 582, 'y': 809, 'w': 154, 'h': 30, 'confidence': '0.999581256542941', 'text': 'the backpack'}, {'x': 743, 'y': 815, 'w': 56, 'h': 20, 'confidence': '0.9993918538093567', 'text': 'wasn'}, {'x': 854, 'y': 810, 'w': 280, 'h': 30, 'confidence': '0.8022121456749864', 'text': 'genie granting wishes ,'}, {'x': 1142, 'y': 812, 'w': 44, 'h': 24, 'confidence': '0.7364469170570374', 'text': 'but'}, {'x': 1217, 'y': 810, 'w': 130, 'h': 26, 'confidence': '0.9999892562395729', 'text': 'reflection'}, {'x': 1354, 'y': 812, 'w': 32, 'h': 24, 'confidence': '0.9095095066160677', 'text': 'of'}, {'x': 1392, 'y': 812, 'w': 44, 'h': 24, 'confidence': '0.9999291100557716', 'text': 'her'}, {'x': 1443, 'y': 815, 'w': 42, 'h': 20, 'confidence': '0.9539913128774402', 'text': 'own'}, {'x': 1494, 'y': 812, 'w': 66, 'h': 24, 'confidence': '0.9992429355541232', 'text': 'inner'}, {'x': 1566, 'y': 812, 'w': 72, 'h': 24, 'confidence': '0.9983807059695635', 'text': 'world'}, {'x': 1666, 'y': 812, 'w': 44, 'h': 24, 'confidence': '0.9999832065931312', 'text': 'Her'}, {'x': 1716, 'y': 812, 'w': 118, 'h': 24, 'confidence': '0.7578209015669817', 'text': 'anxieties'}, {'x': 1842, 'y': 810, 'w': 130, 'h': 26, 'confidence': '0.9998154241818246', 'text': 'manifested'}, {'x': 1979, 'y': 815, 'w': 30, 'h': 20, 'confidence': '0.9997229378609758', 'text': 'as'}, {'x': 981, 'y': 754, 'w': 50, 'h': 35, 'confidence': '0.793387591720998', 'text': 'day ,'}]}]\n",
      "> Image for page 59: [{'name': 'img_p58_1.png', 'height': 1052, 'width': 2048, 'x': 62.916340596, 'y': 45.094489632000034, 'original_width': 2048, 'original_height': 1052, 'ocr': [{'x': 48, 'y': 54, 'w': 176, 'h': 30, 'confidence': '0.9997510862838432', 'text': 'Model variant'}, {'x': 565, 'y': 53, 'w': 106, 'h': 36, 'confidence': '0.9997109396069397', 'text': 'Input(s)'}, {'x': 952, 'y': 52, 'w': 95, 'h': 38, 'confidence': '0.9997695558408254', 'text': 'Output'}, {'x': 1214, 'y': 50, 'w': 179, 'h': 39, 'confidence': '0.9997324600572198', 'text': 'Optimized for'}, {'x': 48, 'y': 158, 'w': 210, 'h': 30, 'confidence': '0.6521446076864439', 'text': 'Gemini 1.5 Flash'}, {'x': 566, 'y': 154, 'w': 331, 'h': 39, 'confidence': '0.7817659692255974', 'text': 'Audio, images, videos, and'}, {'x': 954, 'y': 158, 'w': 60, 'h': 30, 'confidence': '0.9999799728393555', 'text': 'Text'}, {'x': 1215, 'y': 153, 'w': 716, 'h': 40, 'confidence': '0.8057173883491627', 'text': 'Fast and versatile performance across a diverse variety of'}, {'x': 46, 'y': 191, 'w': 273, 'h': 42, 'confidence': '0.9785093133678554', 'text': 'gemini-1.5-flash'}, {'x': 564, 'y': 198, 'w': 54, 'h': 28, 'confidence': '0.9999978542327881', 'text': 'text'}, {'x': 1214, 'y': 198, 'w': 76, 'h': 30, 'confidence': '0.7087436567680568', 'text': 'tasks'}, {'x': 48, 'y': 300, 'w': 250, 'h': 32, 'confidence': '0.8578613021475157', 'text': 'Gemini 1.5 Flash-8B'}, {'x': 566, 'y': 298, 'w': 331, 'h': 39, 'confidence': '0.9437609598566088', 'text': 'Audio, images, videos, and'}, {'x': 954, 'y': 302, 'w': 60, 'h': 30, 'confidence': '0.9838336269999713', 'text': 'Text'}, {'x': 1215, 'y': 299, 'w': 508, 'h': 38, 'confidence': '0.8919082105978836', 'text': 'High volume and lower intelligence tasks'}, {'x': 46, 'y': 334, 'w': 323, 'h': 43, 'confidence': '0.7280272291693299', 'text': 'gemini-1.5-flash-8b'}, {'x': 564, 'y': 342, 'w': 54, 'h': 26, 'confidence': '0.9021209215043101', 'text': 'text'}, {'x': 48, 'y': 444, 'w': 186, 'h': 32, 'confidence': '0.9730371641591782', 'text': 'Gemini 1.5 Pro'}, {'x': 565, 'y': 439, 'w': 333, 'h': 41, 'confidence': '0.8946299984844478', 'text': 'Audio, images, videos, and'}, {'x': 952, 'y': 443, 'w': 63, 'h': 33, 'confidence': '0.999991238117218', 'text': 'Text'}, {'x': 1214, 'y': 441, 'w': 651, 'h': 40, 'confidence': '0.8419551849279165', 'text': 'Complex reasoning tasks requiring more intelligence'}, {'x': 46, 'y': 481, 'w': 241, 'h': 40, 'confidence': '0.957110992053179', 'text': 'gemini-1.5-pro'}, {'x': 564, 'y': 486, 'w': 54, 'h': 26, 'confidence': '0.9163008860099912', 'text': 'text'}, {'x': 47, 'y': 587, 'w': 380, 'h': 36, 'confidence': '0.8385063938535263', 'text': 'Gemini 1.0 Pro (Deprecated on'}, {'x': 568, 'y': 588, 'w': 58, 'h': 30, 'confidence': '0.5385751966486627', 'text': 'Text'}, {'x': 954, 'y': 588, 'w': 60, 'h': 30, 'confidence': '0.9544021701476992', 'text': 'Text'}, {'x': 1217, 'y': 585, 'w': 710, 'h': 42, 'confidence': '0.7612636760374324', 'text': 'Natural language tasks, multi-turn text and code chat, and'}, {'x': 47, 'y': 625, 'w': 148, 'h': 38, 'confidence': '0.5708869358656381', 'text': '2/15/2025)'}, {'x': 1215, 'y': 625, 'w': 206, 'h': 38, 'confidence': '0.9988801169113416', 'text': 'code generation'}, {'x': 45, 'y': 660, 'w': 243, 'h': 45, 'confidence': '0.7361927006677292', 'text': 'gemini-1.0-pro'}, {'x': 47, 'y': 765, 'w': 206, 'h': 42, 'confidence': '0.7323759225647534', 'text': 'Text Embedding'}, {'x': 568, 'y': 772, 'w': 58, 'h': 30, 'confidence': '0.9999911502008884', 'text': 'Text'}, {'x': 954, 'y': 772, 'w': 58, 'h': 28, 'confidence': '0.9999879598617554', 'text': 'Text'}, {'x': 1216, 'y': 768, 'w': 510, 'h': 40, 'confidence': '0.9803306132203141', 'text': 'Measuring the relatedness of text strings'}, {'x': 46, 'y': 804, 'w': 307, 'h': 41, 'confidence': '0.9542921258139085', 'text': 'text-embedding-004'}, {'x': 952, 'y': 805, 'w': 161, 'h': 40, 'confidence': '0.9999977004639368', 'text': 'embeddings'}, {'x': 48, 'y': 914, 'w': 60, 'h': 32, 'confidence': '0.9999801782778809', 'text': 'AQA'}, {'x': 568, 'y': 914, 'w': 58, 'h': 30, 'confidence': '0.9477846285950032', 'text': 'Text'}, {'x': 954, 'y': 914, 'w': 58, 'h': 28, 'confidence': '0.9999826550483704', 'text': 'Text'}, {'x': 1213, 'y': 907, 'w': 606, 'h': 44, 'confidence': '0.9128466372369253', 'text': 'Providing source-grounded answers to questions'}, {'x': 48, 'y': 958, 'w': 54, 'h': 28, 'confidence': '0.9999786641207165', 'text': 'aqa'}]}]\n",
      "> Image for page 60: [{'name': 'img_p59_1.png', 'height': 478, 'width': 1476, 'x': 12.000000384, 'y': 57.09447033095998, 'original_width': 1476, 'original_height': 478, 'ocr': [{'x': 16, 'y': 20, 'w': 24, 'h': 28, 'confidence': '0.9999982118614561', 'text': '#'}, {'x': 50, 'y': 18, 'w': 58, 'h': 32, 'confidence': '0.9999838948467685', 'text': 'Set'}, {'x': 120, 'y': 24, 'w': 40, 'h': 30, 'confidence': '0.9998355469580109', 'text': 'up'}, {'x': 170, 'y': 18, 'w': 56, 'h': 32, 'confidence': '0.9999921538953669', 'text': 'the'}, {'x': 236, 'y': 18, 'w': 92, 'h': 32, 'confidence': '0.9999826202652845', 'text': 'model'}, {'x': 15, 'y': 51, 'w': 296, 'h': 44, 'confidence': '0.8722086090745509', 'text': 'generation_config'}, {'x': 321, 'y': 63, 'w': 22, 'h': 20, 'confidence': '0.9881747964619194', 'text': '='}, {'x': 354, 'y': 56, 'w': 28, 'h': 32, 'confidence': '0.998892018311043', 'text': '{'}, {'x': 51, 'y': 92, 'w': 238, 'h': 40, 'confidence': '0.8587806033216042', 'text': '\"temperature\" :'}, {'x': 306, 'y': 96, 'w': 32, 'h': 32, 'confidence': '0.9999455467059719', 'text': '1,'}, {'x': 48, 'y': 130, 'w': 129, 'h': 42, 'confidence': '0.9679454789856394', 'text': '\"top_p\"'}, {'x': 201, 'y': 128, 'w': 91, 'h': 41, 'confidence': '0.8321806265620223', 'text': '0.95 ,'}, {'x': 48, 'y': 168, 'w': 129, 'h': 42, 'confidence': '0.9599516572135426', 'text': '\"top_k\"'}, {'x': 135, 'y': 207, 'w': 244, 'h': 40, 'confidence': '0.9921521570268148', 'text': 'output_tokens\"'}, {'x': 403, 'y': 207, 'w': 90, 'h': 38, 'confidence': '0.9992904760578374', 'text': '8186 ,'}, {'x': 21, 'y': 251, 'w': 16, 'h': 24, 'confidence': '0.9846109760407593', 'text': '}'}, {'x': 18, 'y': 321, 'w': 89, 'h': 32, 'confidence': '0.9998863913342878', 'text': 'model'}, {'x': 149, 'y': 318, 'w': 1306, 'h': 43, 'confidence': '0.7085694607289135', 'text': 'genai.GenerativeModel ( \"gemini-1.5-flash\" ,generation_config-generation_config)'}, {'x': 19, 'y': 363, 'w': 140, 'h': 36, 'confidence': '0.9999831412017317', 'text': 'response'}, {'x': 201, 'y': 359, 'w': 466, 'h': 39, 'confidence': '0.9232144901478576', 'text': 'model.generate_content ( \"How'}, {'x': 675, 'y': 361, 'w': 126, 'h': 36, 'confidence': '0.7004456172442974', 'text': 'to grow'}, {'x': 810, 'y': 359, 'w': 208, 'h': 32, 'confidence': '0.9980646917062255', 'text': 'strawberries'}, {'x': 1029, 'y': 357, 'w': 222, 'h': 45, 'confidence': '0.7633011835605024', 'text': 'in Singapore.'}, {'x': 1267, 'y': 365, 'w': 16, 'h': 24, 'confidence': '0.958469772420333', 'text': ')'}, {'x': 13, 'y': 391, 'w': 99, 'h': 48, 'confidence': '0.9999930694352156', 'text': 'print'}, {'x': 121, 'y': 399, 'w': 238, 'h': 38, 'confidence': '0.9867134155156361', 'text': 'response.text)'}, {'x': 204, 'y': 166, 'w': 50, 'h': 42, 'confidence': '0.5400440844863786', 'text': '64 ,'}, {'x': 51, 'y': 203, 'w': 86, 'h': 42, 'confidence': '0.9988825597605469', 'text': '\"max_'}]}]\n",
      "> Image for page 61: [{'name': 'img_p60_1.png', 'height': 728, 'width': 1510, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 1510, 'original_height': 728, 'ocr': [{'x': 58, 'y': 10, 'w': 106, 'h': 32, 'confidence': '0.5598331035819732', 'text': 'Create'}, {'x': 176, 'y': 10, 'w': 56, 'h': 32, 'confidence': '0.9999950445645353', 'text': 'the'}, {'x': 242, 'y': 9, 'w': 92, 'h': 32, 'confidence': '0.730324820479049', 'text': 'model'}, {'x': 23, 'y': 47, 'w': 293, 'h': 40, 'confidence': '0.9759501200527522', 'text': 'generation_config'}, {'x': 327, 'y': 55, 'w': 22, 'h': 20, 'confidence': '0.9892946052873732', 'text': '='}, {'x': 360, 'y': 48, 'w': 26, 'h': 30, 'confidence': '0.9997799517581285', 'text': '{'}, {'x': 55, 'y': 84, 'w': 241, 'h': 40, 'confidence': '0.9827588154509297', 'text': '\"temperature\" :'}, {'x': 310, 'y': 88, 'w': 34, 'h': 32, 'confidence': '0.9998674085893339', 'text': '1,'}, {'x': 54, 'y': 122, 'w': 141, 'h': 42, 'confidence': '0.7784918599932725', 'text': '\"top_p\":'}, {'x': 207, 'y': 123, 'w': 82, 'h': 36, 'confidence': '0.6219650690489947', 'text': '0.95_'}, {'x': 55, 'y': 161, 'w': 128, 'h': 40, 'confidence': '0.708370505057357', 'text': '\"top_k\"'}, {'x': 140, 'y': 197, 'w': 245, 'h': 42, 'confidence': '0.9942933210757661', 'text': 'output_tokens\"'}, {'x': 409, 'y': 199, 'w': 90, 'h': 38, 'confidence': '0.9992652624645174', 'text': '8186 ,'}, {'x': 24, 'y': 313, 'w': 89, 'h': 32, 'confidence': '0.9998765817862992', 'text': 'model'}, {'x': 155, 'y': 310, 'w': 380, 'h': 43, 'confidence': '0.9849171176747075', 'text': 'genai.GenerativeModel('}, {'x': 56, 'y': 347, 'w': 195, 'h': 45, 'confidence': '0.8313574049733508', 'text': 'model_name='}, {'x': 258, 'y': 350, 'w': 496, 'h': 38, 'confidence': '0.6017991797599119', 'text': 'learnlm-1.5-pro-experimental\"'}, {'x': 57, 'y': 385, 'w': 613, 'h': 45, 'confidence': '0.9724449154159877', 'text': 'generation_config-generation_config,'}, {'x': 55, 'y': 424, 'w': 398, 'h': 45, 'confidence': '0.8869396545038815', 'text': 'system_instruction-\"You'}, {'x': 462, 'y': 432, 'w': 54, 'h': 26, 'confidence': '0.9999965587250227', 'text': 'are'}, {'x': 529, 'y': 433, 'w': 20, 'h': 24, 'confidence': '0.9999738933359801', 'text': 'a'}, {'x': 563, 'y': 428, 'w': 240, 'h': 32, 'confidence': '0.9999208569761537', 'text': 'horticulturist'}, {'x': 814, 'y': 428, 'w': 76, 'h': 32, 'confidence': '0.9996790885925293', 'text': 'with'}, {'x': 901, 'y': 433, 'w': 18, 'h': 24, 'confidence': '0.9999454028906172', 'text': 'a'}, {'x': 933, 'y': 427, 'w': 176, 'h': 38, 'confidence': '0.9999872959672763', 'text': 'background'}, {'x': 1120, 'y': 428, 'w': 40, 'h': 32, 'confidence': '0.9982297016144589', 'text': 'in'}, {'x': 1170, 'y': 428, 'w': 124, 'h': 32, 'confidence': '0.8932886615966846', 'text': 'natural'}, {'x': 1306, 'y': 428, 'w': 88, 'h': 32, 'confidence': '0.380854330583716', 'text': 'lawns'}, {'x': 1406, 'y': 428, 'w': 56, 'h': 32, 'confidence': '0.9999974534563641', 'text': 'and'}, {'x': 1474, 'y': 432, 'w': 36, 'h': 28, 'confidence': '0.9999854172215584', 'text': 'na'}, {'x': 22, 'y': 539, 'w': 211, 'h': 44, 'confidence': '0.9600255987523868', 'text': 'chat_session'}, {'x': 274, 'y': 537, 'w': 309, 'h': 44, 'confidence': '0.8908181607715827', 'text': 'model.start_chat( )'}, {'x': 26, 'y': 622, 'w': 138, 'h': 32, 'confidence': '0.9999934434783277', 'text': 'response'}, {'x': 208, 'y': 615, 'w': 513, 'h': 45, 'confidence': '0.7088115093042906', 'text': 'chat_session.send_message( \"How'}, {'x': 731, 'y': 616, 'w': 344, 'h': 38, 'confidence': '0.939759965991689', 'text': 'to grow strawberries'}, {'x': 1085, 'y': 617, 'w': 258, 'h': 40, 'confidence': '0.7134955258990393', 'text': 'in Singapore?\" )'}, {'x': 21, 'y': 690, 'w': 95, 'h': 38, 'confidence': '0.9999993602557958', 'text': 'print'}, {'x': 126, 'y': 696, 'w': 224, 'h': 32, 'confidence': '0.9782933065919491', 'text': 'response.text'}, {'x': 209, 'y': 158, 'w': 51, 'h': 42, 'confidence': '0.9428540468215942', 'text': '64 ,'}, {'x': 57, 'y': 195, 'w': 86, 'h': 42, 'confidence': '0.999140833302893', 'text': '\"max_'}]}]\n",
      "> Image for page 62: [{'name': 'img_p61_1.png', 'height': 402, 'width': 1746, 'x': 8.681102639999999, 'y': 60.57206689893599, 'original_width': 1746, 'original_height': 402, 'ocr': [{'x': 0, 'y': 11, 'w': 67, 'h': 36, 'confidence': '0.9995631575584412', 'text': '[50]'}, {'x': 80, 'y': 13, 'w': 108, 'h': 37, 'confidence': '0.9289402426631547', 'text': 'import'}, {'x': 199, 'y': 12, 'w': 161, 'h': 42, 'confidence': '0.9590261001097059', 'text': 'PIL. Image'}, {'x': 81, 'y': 89, 'w': 90, 'h': 32, 'confidence': '0.8935668022332622', 'text': 'model'}, {'x': 212, 'y': 83, 'w': 702, 'h': 48, 'confidence': '0.5965949550226535', 'text': 'genai.GenerativeModel ( \"gemini-1.5-flash\")'}, {'x': 81, 'y': 127, 'w': 92, 'h': 39, 'confidence': '0.9973858682268665', 'text': 'image'}, {'x': 215, 'y': 124, 'w': 584, 'h': 45, 'confidence': '0.5035436096372252', 'text': \"PIL. Image.open ( ' [content/panda-png\"}, {'x': 807, 'y': 131, 'w': 16, 'h': 26, 'confidence': '0.8888641699481106', 'text': ')'}, {'x': 84, 'y': 170, 'w': 138, 'h': 32, 'confidence': '0.9996832358314545', 'text': 'response'}, {'x': 267, 'y': 161, 'w': 496, 'h': 44, 'confidence': '0.731147313914338', 'text': 'model.generate_content ( [\"Tell'}, {'x': 772, 'y': 170, 'w': 40, 'h': 28, 'confidence': '0.9946740203336241', 'text': 'me'}, {'x': 822, 'y': 166, 'w': 92, 'h': 32, 'confidence': '0.999878768879644', 'text': 'about'}, {'x': 922, 'y': 157, 'w': 231, 'h': 49, 'confidence': '0.5786331579160306', 'text': 'this picture\" _'}, {'x': 1176, 'y': 164, 'w': 123, 'h': 42, 'confidence': '0.966715244293059', 'text': 'image] )'}, {'x': 79, 'y': 200, 'w': 344, 'h': 43, 'confidence': '0.9875164409867397', 'text': 'print(response.text)'}, {'x': 9, 'y': 275, 'w': 44, 'h': 40, 'confidence': '0.7217195199837114', 'text': '3'}, {'x': 80, 'y': 278, 'w': 56, 'h': 32, 'confidence': '0.9999721945435649', 'text': 'The'}, {'x': 148, 'y': 276, 'w': 91, 'h': 40, 'confidence': '0.9994002719126898', 'text': 'image'}, {'x': 250, 'y': 278, 'w': 38, 'h': 32, 'confidence': '0.9801656409376154', 'text': 'is'}, {'x': 299, 'y': 283, 'w': 20, 'h': 24, 'confidence': '0.9999444492425624', 'text': 'a'}, {'x': 333, 'y': 275, 'w': 261, 'h': 39, 'confidence': '0.8373615221578048', 'text': 'screenshot from'}, {'x': 603, 'y': 283, 'w': 18, 'h': 24, 'confidence': '0.9999378929244962', 'text': 'a'}, {'x': 634, 'y': 274, 'w': 106, 'h': 36, 'confidence': '0.8310911834824574', 'text': 'video .'}, {'x': 773, 'y': 281, 'w': 16, 'h': 24, 'confidence': '0.9989096515869598', 'text': 'A'}, {'x': 804, 'y': 282, 'w': 56, 'h': 28, 'confidence': '0.999932482474758', 'text': 'man'}, {'x': 870, 'y': 278, 'w': 76, 'h': 32, 'confidence': '0.9964456346439675', 'text': 'with'}, {'x': 956, 'y': 278, 'w': 90, 'h': 32, 'confidence': '0.8043021549946422', 'text': 'short'}, {'x': 1058, 'y': 278, 'w': 74, 'h': 32, 'confidence': '0.9981831981833849', 'text': 'dark'}, {'x': 1142, 'y': 278, 'w': 74, 'h': 32, 'confidence': '0.9995981454849243', 'text': 'hair'}, {'x': 1227, 'y': 273, 'w': 175, 'h': 42, 'confidence': '0.990960922179671', 'text': 'is sitting'}, {'x': 1412, 'y': 278, 'w': 38, 'h': 32, 'confidence': '0.999974741078583', 'text': 'at'}, {'x': 1463, 'y': 283, 'w': 18, 'h': 24, 'confidence': '0.9999096413997819', 'text': 'a'}, {'x': 1496, 'y': 278, 'w': 86, 'h': 32, 'confidence': '0.9945377149974536', 'text': 'desk.'}, {'x': 1596, 'y': 278, 'w': 42, 'h': 32, 'confidence': '0.9999989041821146', 'text': 'He'}, {'x': 1647, 'y': 281, 'w': 20, 'h': 26, 'confidence': '0.3897978278683354', 'text': '5'}, {'x': 1680, 'y': 282, 'w': 56, 'h': 26, 'confidence': '0.9997953157238583', 'text': 'wea'}]}, {'name': 'img_p61_2.png', 'height': 790, 'width': 1022, 'x': 242.86418099999997, 'y': 198.35041973303996, 'original_width': 1022, 'original_height': 790, 'ocr': [{'x': 0, 'y': 189, 'w': 174, 'h': 32, 'confidence': '0.782162301448732', 'text': 'Srouping customers'}, {'x': 16, 'y': 365, 'w': 56, 'h': 21, 'confidence': '0.30674186032283235', 'text': 'Lpcaled'}, {'x': 2, 'y': 385, 'w': 36, 'h': 13, 'confidence': '0.12899948120089857', 'text': 'min'}]}]\n",
      "> Image for page 63: []\n",
      "> Image for page 64: [{'name': 'img_p63_1.png', 'height': 1451, 'width': 2048, 'x': 313.91939980919994, 'y': 57.90555303407996, 'original_width': 2048, 'original_height': 1451, 'ocr': [{'x': 83, 'y': 356, 'w': 262, 'h': 42, 'confidence': '0.9593021927530268', 'text': 'Vertex Al Studio'}, {'x': 764, 'y': 353, 'w': 229, 'h': 42, 'confidence': '0.7305049435506517', 'text': 'Model Garden'}, {'x': 1443, 'y': 353, 'w': 271, 'h': 48, 'confidence': '0.999981524731614', 'text': 'Colab Enterprise'}, {'x': 85, 'y': 403, 'w': 498, 'h': 36, 'confidence': '0.6241186640510284', 'text': 'Prompt, test and tune generative Al models'}, {'x': 764, 'y': 405, 'w': 461, 'h': 36, 'confidence': '0.7855551423666571', 'text': 'Browse, customize, and deploy machine'}, {'x': 1447, 'y': 402, 'w': 502, 'h': 38, 'confidence': '0.9798103876427648', 'text': 'A new notebook experience with enterprise-'}, {'x': 84, 'y': 438, 'w': 136, 'h': 30, 'confidence': '0.8514718792005175', 'text': 'like Gemini:'}, {'x': 761, 'y': 433, 'w': 470, 'h': 40, 'confidence': '0.8482984248511998', 'text': 'learning models. Choose from Google or'}, {'x': 1445, 'y': 433, 'w': 502, 'h': 41, 'confidence': '0.7440940242383539', 'text': 'grade privacy and security: Start coding in a'}, {'x': 763, 'y': 466, 'w': 334, 'h': 40, 'confidence': '0.6043232107992412', 'text': 'popular open-source models'}, {'x': 1446, 'y': 470, 'w': 158, 'h': 30, 'confidence': '0.6179717188015119', 'text': 'couple clicks.'}, {'x': 84, 'y': 582, 'w': 94, 'h': 32, 'confidence': '0.9816050754967168', 'text': 'Try now'}, {'x': 766, 'y': 582, 'w': 94, 'h': 32, 'confidence': '0.9999278631009462', 'text': 'Try now'}, {'x': 1447, 'y': 578, 'w': 264, 'h': 38, 'confidence': '0.8684476455284583', 'text': 'Go to Colab Enterprise'}, {'x': 210, 'y': 755, 'w': 214, 'h': 49, 'confidence': '0.9330489033192526', 'text': 'Prepare Data'}, {'x': 892, 'y': 753, 'w': 326, 'h': 50, 'confidence': '0.7452291534546608', 'text': 'Model Development'}, {'x': 1572, 'y': 753, 'w': 220, 'h': 52, 'confidence': '0.8357093681827844', 'text': 'Deploy & Use'}, {'x': 86, 'y': 896, 'w': 122, 'h': 32, 'confidence': '0.9999985670067253', 'text': 'Datasets'}, {'x': 711, 'y': 895, 'w': 38, 'h': 36, 'confidence': '0.31180553995001503', 'text': 'P'}, {'x': 768, 'y': 896, 'w': 188, 'h': 32, 'confidence': '0.6893992766590081', 'text': 'Model Garden'}, {'x': 1447, 'y': 895, 'w': 204, 'h': 38, 'confidence': '0.9998012677234898', 'text': 'Model Registry'}, {'x': 83, 'y': 934, 'w': 366, 'h': 39, 'confidence': '0.8386048160759919', 'text': 'Store and manage training data.'}, {'x': 765, 'y': 937, 'w': 478, 'h': 36, 'confidence': '0.9037258501956136', 'text': 'Tune and deploy a Google or open-source'}, {'x': 1449, 'y': 939, 'w': 381, 'h': 33, 'confidence': '0.7321499665324765', 'text': 'Manage your models in Vertex Al.'}, {'x': 768, 'y': 970, 'w': 78, 'h': 28, 'confidence': '0.6266883845432324', 'text': 'model:'}, {'x': 85, 'y': 987, 'w': 179, 'h': 42, 'confidence': '0.6181022528772256', 'text': 'Data labeling'}, {'x': 1390, 'y': 1010, 'w': 44, 'h': 32, 'confidence': '0.8120776414871216', 'text': '(Q))'}, {'x': 1448, 'y': 1008, 'w': 230, 'h': 32, 'confidence': '0.9050182758369784', 'text': 'Online Prediction'}, {'x': 86, 'y': 1034, 'w': 262, 'h': 28, 'confidence': '0.7729100310419785', 'text': 'Use human labelers on'}, {'x': 345, 'y': 1030, 'w': 156, 'h': 39, 'confidence': '0.9999942140126358', 'text': 'training data'}, {'x': 765, 'y': 1035, 'w': 115, 'h': 42, 'confidence': '0.9999940994339976', 'text': 'Training'}, {'x': 1447, 'y': 1047, 'w': 410, 'h': 38, 'confidence': '0.772770988297455', 'text': 'Deploy models for online prediction:'}, {'x': 766, 'y': 1082, 'w': 298, 'h': 30, 'confidence': '0.8615315391998332', 'text': 'Train a model in Vertex Al.'}, {'x': 86, 'y': 1104, 'w': 180, 'h': 32, 'confidence': '0.9768831470293025', 'text': 'Feature Store'}, {'x': 1448, 'y': 1120, 'w': 238, 'h': 32, 'confidence': '0.8551330725606008', 'text': 'Batch Predictions'}, {'x': 83, 'y': 1144, 'w': 365, 'h': 37, 'confidence': '0.6870174046441831', 'text': 'Organize and store ML features.'}, {'x': 767, 'y': 1151, 'w': 170, 'h': 38, 'confidence': '0.9999963697573911', 'text': 'Experiments'}, {'x': 1449, 'y': 1159, 'w': 434, 'h': 38, 'confidence': '0.8847092269087267', 'text': 'Make a bulk prediction request from a'}, {'x': 766, 'y': 1194, 'w': 382, 'h': 32, 'confidence': '0.554366103337381', 'text': 'Track; visualize; and compare ML'}, {'x': 1448, 'y': 1194, 'w': 78, 'h': 28, 'confidence': '0.8699566255160558', 'text': 'model.'}, {'x': 764, 'y': 1221, 'w': 149, 'h': 39, 'confidence': '0.9996530065043412', 'text': 'experiments_'}, {'x': 1391, 'y': 1265, 'w': 44, 'h': 38, 'confidence': '0.5978829066548883', 'text': '%'}, {'x': 1448, 'y': 1264, 'w': 190, 'h': 32, 'confidence': '0.9974292680592601', 'text': 'Vector Search'}, {'x': 709, 'y': 1295, 'w': 42, 'h': 36, 'confidence': '0.9969559267337083', 'text': '@'}, {'x': 767, 'y': 1293, 'w': 132, 'h': 36, 'confidence': '0.7135646345977724', 'text': 'Metadata'}, {'x': 1447, 'y': 1305, 'w': 452, 'h': 36, 'confidence': '0.8385619347034352', 'text': 'Vector database to match semantically'}, {'x': 766, 'y': 1337, 'w': 460, 'h': 33, 'confidence': '0.8083788691616158', 'text': 'Track metadata and artifacts in your ML'}, {'x': 1448, 'y': 1338, 'w': 152, 'h': 30, 'confidence': '0.8686636768621115', 'text': 'similar items_'}, {'x': 763, 'y': 1367, 'w': 95, 'h': 37, 'confidence': '0.8655111217171232', 'text': 'system:'}]}]\n",
      "> Image for page 65: [{'name': 'img_p64_1.png', 'height': 1004, 'width': 2048, 'x': 12.000000384, 'y': 53.77362376799999, 'original_width': 2048, 'original_height': 1004, 'ocr': [{'x': 723, 'y': 68, 'w': 638, 'h': 92, 'confidence': '0.6330681554931465', 'text': 'Vertex AI Studio'}, {'x': 671, 'y': 196, 'w': 738, 'h': 45, 'confidence': '0.4147618376553455', 'text': 'Test; tune and deploy enterprise-ready generative Al'}, {'x': 694, 'y': 283, 'w': 159, 'h': 25, 'confidence': '0.7861831672427375', 'text': 'TRY A TUTORIAL'}, {'x': 944, 'y': 281, 'w': 196, 'h': 25, 'confidence': '0.5010879860317697', 'text': 'DOCUMENTATIONG'}, {'x': 1230, 'y': 282, 'w': 174, 'h': 26, 'confidence': '0.9350818105090617', 'text': 'API REFERENCEC'}, {'x': 1113, 'y': 434, 'w': 197, 'h': 32, 'confidence': '0.6778478723483626', 'text': 'Translate text'}, {'x': 376, 'y': 459, 'w': 424, 'h': 44, 'confidence': '0.3938611742282509', 'text': 'Generate with Gemini'}, {'x': 1113, 'y': 513, 'w': 244, 'h': 41, 'confidence': '0.7453338611101866', 'text': 'Generate images'}, {'x': 394, 'y': 564, 'w': 166, 'h': 26, 'confidence': '0.9964899685188809', 'text': 'OPEN FREEFORM'}, {'x': 654, 'y': 564, 'w': 116, 'h': 26, 'confidence': '0.4967581495036845', 'text': 'OPEN CHAT'}, {'x': 1112, 'y': 591, 'w': 418, 'h': 45, 'confidence': '0.7571330891772791', 'text': 'Convert or synthesize speech'}, {'x': 369, 'y': 805, 'w': 304, 'h': 38, 'confidence': '0.9515146552996993', 'text': 'Prompt management'}, {'x': 876, 'y': 810, 'w': 26, 'h': 28, 'confidence': '0.9895809713050454', 'text': 'F'}, {'x': 928, 'y': 809, 'w': 107, 'h': 49, 'confidence': '0.9999925052774333', 'text': 'Tuning'}, {'x': 1495, 'y': 803, 'w': 152, 'h': 36, 'confidence': '0.9690037002015495', 'text': 'Evaluation'}, {'x': 368, 'y': 850, 'w': 334, 'h': 24, 'confidence': '0.8867225552535595', 'text': 'Saved prompts and tools to make them'}, {'x': 1494, 'y': 848, 'w': 322, 'h': 26, 'confidence': '0.9645258579721226', 'text': 'Understand how a model performs on'}, {'x': 932, 'y': 862, 'w': 270, 'h': 26, 'confidence': '0.9810573949972762', 'text': 'Customize a model to your task'}, {'x': 368, 'y': 874, 'w': 58, 'h': 24, 'confidence': '0.5635501641799656', 'text': 'better:'}, {'x': 1494, 'y': 874, 'w': 86, 'h': 26, 'confidence': '0.9911842714619754', 'text': 'your data'}]}]\n",
      "> Image for page 66: [{'name': 'img_p65_1.png', 'height': 1272, 'width': 2048, 'x': 85.27165627199999, 'y': 55.09645845599999, 'original_width': 2048, 'original_height': 1272, 'ocr': [{'x': 15, 'y': 41, 'w': 140, 'h': 36, 'confidence': '0.9851761676002645', 'text': 'Features'}, {'x': 415, 'y': 38, 'w': 337, 'h': 45, 'confidence': '0.6748944532783698', 'text': 'Google Al Gemini API'}, {'x': 1031, 'y': 39, 'w': 540, 'h': 44, 'confidence': '0.8042368270174596', 'text': 'Google Cloud Vertex Al Gemini API'}, {'x': 15, 'y': 139, 'w': 338, 'h': 38, 'confidence': '0.933953989463779', 'text': 'Latest Gemini models'}, {'x': 415, 'y': 141, 'w': 432, 'h': 36, 'confidence': '0.8504804265154216', 'text': 'Gemini Pro and Gemini Ultra'}, {'x': 1031, 'y': 141, 'w': 432, 'h': 36, 'confidence': '0.7797224428883158', 'text': 'Gemini Pro and Gemini Ultra'}, {'x': 13, 'y': 227, 'w': 122, 'h': 42, 'confidence': '0.9386585474247744', 'text': 'Sign up'}, {'x': 415, 'y': 227, 'w': 246, 'h': 42, 'confidence': '0.8516995159314528', 'text': 'Google account'}, {'x': 1031, 'y': 225, 'w': 868, 'h': 44, 'confidence': '0.7693743168195811', 'text': 'Google Cloud account (with terms agreement and billing)'}, {'x': 14, 'y': 313, 'w': 229, 'h': 42, 'confidence': '0.7768307297170807', 'text': 'Authentication'}, {'x': 417, 'y': 315, 'w': 58, 'h': 36, 'confidence': '0.9983789223023588', 'text': 'API'}, {'x': 1031, 'y': 315, 'w': 460, 'h': 42, 'confidence': '0.7651665151047119', 'text': 'Google Cloud service account'}, {'x': 15, 'y': 401, 'w': 218, 'h': 38, 'confidence': '0.9999315745207443', 'text': 'User interface'}, {'x': 415, 'y': 401, 'w': 260, 'h': 44, 'confidence': '0.8941189823605252', 'text': 'Google Al Studio'}, {'x': 1033, 'y': 401, 'w': 248, 'h': 38, 'confidence': '0.6738600197990798', 'text': 'Vertex Al Studio'}, {'x': 11, 'y': 447, 'w': 179, 'h': 49, 'confidence': '0.9999794925534954', 'text': 'playground'}, {'x': 15, 'y': 539, 'w': 164, 'h': 36, 'confidence': '0.6875401640986242', 'text': 'API & SDK'}, {'x': 415, 'y': 538, 'w': 377, 'h': 43, 'confidence': '0.9362168732608113', 'text': 'Python; Nodejs, Android'}, {'x': 1030, 'y': 536, 'w': 606, 'h': 50, 'confidence': '0.7101634821440621', 'text': 'SDK supports Python; Node js, Java, Go'}, {'x': 415, 'y': 585, 'w': 354, 'h': 42, 'confidence': '0.5471702997570483', 'text': '(Kotlin/ Java), Swift; Go'}, {'x': 15, 'y': 675, 'w': 132, 'h': 36, 'confidence': '0.9999098257259573', 'text': 'Free tier'}, {'x': 415, 'y': 675, 'w': 64, 'h': 36, 'confidence': '0.9999709556890053', 'text': 'Yes'}, {'x': 1028, 'y': 668, 'w': 608, 'h': 50, 'confidence': '0.8228147268708129', 'text': 'S300 Google Cloud credit for new users'}, {'x': 15, 'y': 760, 'w': 300, 'h': 44, 'confidence': '0.9616763482778683', 'text': 'Quota (Request per'}, {'x': 415, 'y': 761, 'w': 392, 'h': 43, 'confidence': '0.767426762818002', 'text': '60 (can request increase)'}, {'x': 1030, 'y': 759, 'w': 537, 'h': 44, 'confidence': '0.9132910634773478', 'text': 'Increase upon request (default: 60)'}, {'x': 15, 'y': 811, 'w': 124, 'h': 40, 'confidence': '0.9999974768138993', 'text': 'minute)'}, {'x': 15, 'y': 899, 'w': 288, 'h': 43, 'confidence': '0.6455545727335763', 'text': 'Enterprise support'}, {'x': 417, 'y': 899, 'w': 50, 'h': 36, 'confidence': '0.9998626040385861', 'text': 'No'}, {'x': 1033, 'y': 899, 'w': 412, 'h': 42, 'confidence': '0.9222309107321887', 'text': 'Data privacy commitments'}, {'x': 1030, 'y': 944, 'w': 326, 'h': 49, 'confidence': '0.9845545267628621', 'text': 'Customer encryption'}, {'x': 1031, 'y': 989, 'w': 311, 'h': 50, 'confidence': '0.8054180129866787', 'text': 'Virtual private cloud'}, {'x': 1033, 'y': 1040, 'w': 231, 'h': 45, 'confidence': '0.9996576747944396', 'text': 'Data residency'}, {'x': 1033, 'y': 1093, 'w': 322, 'h': 43, 'confidence': '0.7669983820747206', 'text': 'Access transparency'}, {'x': 12, 'y': 1172, 'w': 120, 'h': 53, 'confidence': '0.9989364118307471', 'text': 'MLOps'}, {'x': 417, 'y': 1179, 'w': 50, 'h': 36, 'confidence': '0.9999192475932576', 'text': 'No'}, {'x': 1031, 'y': 1179, 'w': 62, 'h': 36, 'confidence': '0.9999837279319763', 'text': 'Full'}, {'x': 1091, 'y': 1172, 'w': 863, 'h': 53, 'confidence': '0.8764821200682944', 'text': 'MLOps on Vertex Al (Examples: model evaluation, Model'}, {'x': 1031, 'y': 1223, 'w': 425, 'h': 49, 'confidence': '0.730526866221285', 'text': 'Monitoring; Model Registry)'}, {'x': 478, 'y': 313, 'w': 54, 'h': 46, 'confidence': '0.9996563621129042', 'text': 'key'}, {'x': 1357, 'y': 943, 'w': 53, 'h': 48, 'confidence': '0.9997803810115533', 'text': 'key'}]}]\n",
      "> Image for page 67: [{'name': 'img_p66_1.png', 'height': 825, 'width': 2048, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 825, 'ocr': [{'x': 0, 'y': 15, 'w': 169, 'h': 44, 'confidence': '0.9761647982372778', 'text': 'Google Cloud'}, {'x': 223, 'y': 29, 'w': 74, 'h': 16, 'confidence': '0.994975807452969', 'text': 'Overview'}, {'x': 321, 'y': 27, 'w': 70, 'h': 18, 'confidence': '0.999949136723018', 'text': 'Solutions'}, {'x': 413, 'y': 25, 'w': 72, 'h': 20, 'confidence': '0.6318390571083167', 'text': 'Products'}, {'x': 505, 'y': 23, 'w': 59, 'h': 27, 'confidence': '0.9999822925969936', 'text': 'Pricing'}, {'x': 587, 'y': 29, 'w': 80, 'h': 16, 'confidence': '0.9873913671589784', 'text': 'Resources'}, {'x': 691, 'y': 27, 'w': 86, 'h': 18, 'confidence': '0.9656750054783607', 'text': 'Contact Us'}, {'x': 1487, 'y': 29, 'w': 42, 'h': 16, 'confidence': '0.9999619722366333', 'text': 'Docs'}, {'x': 1543, 'y': 29, 'w': 64, 'h': 18, 'confidence': '0.7579787216147922', 'text': 'Support'}, {'x': 1677, 'y': 23, 'w': 63, 'h': 26, 'confidence': '0.9324567818490082', 'text': 'English'}, {'x': 1812, 'y': 24, 'w': 56, 'h': 24, 'confidence': '0.9994779720889172', 'text': 'Sign in'}, {'x': 1916, 'y': 24, 'w': 82, 'h': 24, 'confidence': '0.9507122279007311', 'text': 'Start free'}, {'x': 721, 'y': 145, 'w': 586, 'h': 73, 'confidence': '0.9471449753907791', 'text': 'Google Cloud console'}, {'x': 552, 'y': 238, 'w': 616, 'h': 30, 'confidence': '0.6100273832813244', 'text': 'Build a free proof of concept with $300 in free credit and'}, {'x': 1206, 'y': 238, 'w': 266, 'h': 30, 'confidence': '0.9559710219285724', 'text': 'over 150 products in the'}, {'x': 886, 'y': 270, 'w': 247, 'h': 36, 'confidence': '0.8468057911243223', 'text': 'Google Cloud console.'}, {'x': 828, 'y': 345, 'w': 175, 'h': 26, 'confidence': '0.6075683511271924', 'text': 'Get started for free'}, {'x': 1071, 'y': 345, 'w': 125, 'h': 26, 'confidence': '0.9998536575904681', 'text': 'Contact sales'}, {'x': 679, 'y': 526, 'w': 742, 'h': 44, 'confidence': '0.6441031811879345', 'text': 'build on our intuitive cloud management console'}, {'x': 257, 'y': 626, 'w': 375, 'h': 32, 'confidence': '0.8452376641023528', 'text': 'Organized, user-friendly interface'}, {'x': 783, 'y': 627, 'w': 337, 'h': 31, 'confidence': '0.8515068151382852', 'text': 'Customizable IAM permissions'}, {'x': 1310, 'y': 628, 'w': 174, 'h': 28, 'confidence': '0.9177418585110672', 'text': 'Global VPCs for'}, {'x': 1480, 'y': 624, 'w': 189, 'h': 39, 'confidence': '0.9701761088979548', 'text': 'simplifying scale'}, {'x': 258, 'y': 676, 'w': 428, 'h': 32, 'confidence': '0.825028763738607', 'text': 'Get up and running quickly with our easy-to-'}, {'x': 782, 'y': 679, 'w': 424, 'h': 29, 'confidence': '0.7606473588489423', 'text': 'Provide granular access by resources; roles;'}, {'x': 1308, 'y': 679, 'w': 454, 'h': 29, 'confidence': '0.8629540374520539', 'text': 'Create customized network configurations with'}, {'x': 256, 'y': 712, 'w': 454, 'h': 30, 'confidence': '0.4339905358323266', 'text': 'use, intuitive console UI. Plus, get free usage of'}, {'x': 781, 'y': 707, 'w': 396, 'h': 36, 'confidence': '0.8170866022357741', 'text': 'and service accounts, reducing potential'}, {'x': 1308, 'y': 712, 'w': 452, 'h': 30, 'confidence': '0.9610160067311196', 'text': 'global VPCs backed by a full suite of integrated'}, {'x': 258, 'y': 742, 'w': 366, 'h': 30, 'confidence': '0.4429195976112014', 'text': 'over 20_products up to monthly limits.'}, {'x': 782, 'y': 742, 'w': 410, 'h': 32, 'confidence': '0.7060046985250479', 'text': 'security risks through tailored permissions:'}, {'x': 1308, 'y': 743, 'w': 167, 'h': 29, 'confidence': '0.9998169796037706', 'text': 'security features_'}, {'x': 1169, 'y': 237, 'w': 33, 'h': 34, 'confidence': '0.9999849272273436', 'text': 'try'}, {'x': 609, 'y': 522, 'w': 67, 'h': 48, 'confidence': '0.999901580161855', 'text': 'Why'}]}]\n",
      "> Image for page 68: [{'name': 'img_p67_1.png', 'height': 1110, 'width': 1320, 'x': 155.61319395599998, 'y': 55.094489952, 'original_width': 1320, 'original_height': 1110, 'ocr': [{'x': 26, 'y': 22, 'w': 26, 'h': 32, 'confidence': '0.6111634969711304', 'text': '1 .'}, {'x': 65, 'y': 9, 'w': 140, 'h': 60, 'confidence': '0.9986360931969546', 'text': 'Log in'}, {'x': 22, 'y': 98, 'w': 1196, 'h': 48, 'confidence': '0.8325269366935112', 'text': 'Go to Google Cloud and sign in with your Gmail account: You will need to create'}, {'x': 23, 'y': 139, 'w': 688, 'h': 44, 'confidence': '0.5185268749305789', 'text': \"a Gmail account if you don't already have one:\"}, {'x': 24, 'y': 242, 'w': 28, 'h': 32, 'confidence': '0.9857535051874694', 'text': '2.'}, {'x': 66, 'y': 218, 'w': 296, 'h': 73, 'confidence': '0.9860613325293797', 'text': 'Set up billing'}, {'x': 22, 'y': 316, 'w': 1196, 'h': 50, 'confidence': '0.6277093863460168', 'text': 'If this is your first time on Google Cloud, youIl be asked to set up billing: A cloud'}, {'x': 20, 'y': 352, 'w': 1204, 'h': 51, 'confidence': '0.7942231085909242', 'text': 'billing account is used to define who pays for a given set of resources, and it can'}, {'x': 25, 'y': 393, 'w': 374, 'h': 38, 'confidence': '0.981471789313378', 'text': 'be linked to one or more'}, {'x': 398, 'y': 389, 'w': 798, 'h': 52, 'confidence': '0.986718981675344', 'text': 'projects. Project usage is charged to the linked Cloud'}, {'x': 23, 'y': 431, 'w': 657, 'h': 44, 'confidence': '0.7329182810807703', 'text': 'Billing account (more about Projects below):'}, {'x': 23, 'y': 493, 'w': 1070, 'h': 44, 'confidence': '0.7081525179980629', 'text': 'In order to run the notebooks for this course, you need to activate your'}, {'x': 1087, 'y': 487, 'w': 113, 'h': 53, 'confidence': '0.9036337946916507', 'text': 'billing:'}, {'x': 22, 'y': 526, 'w': 1120, 'h': 50, 'confidence': '0.6874132994368316', 'text': 'You can do it at this point by following the instructions provided on Google'}, {'x': 23, 'y': 567, 'w': 496, 'h': 45, 'confidence': '0.6745386071618712', 'text': 'Cloud or later in the steps below:'}, {'x': 24, 'y': 627, 'w': 1190, 'h': 49, 'confidence': '0.8408416492169092', 'text': 'Running the colab notebooks in this course will result in you being billed for the'}, {'x': 24, 'y': 666, 'w': 1172, 'h': 48, 'confidence': '0.7297838163113731', 'text': 'API services: You will be responsible for the costs incurred: We have converted'}, {'x': 20, 'y': 704, 'w': 1180, 'h': 48, 'confidence': '0.7955104394276631', 'text': 'to markdown the costly examples (generally the large video examples) and the'}, {'x': 20, 'y': 740, 'w': 1131, 'h': 48, 'confidence': '0.830473773705104', 'text': 'total charges to your account should be less than one USD for a single pass'}, {'x': 19, 'y': 775, 'w': 967, 'h': 49, 'confidence': '0.6603127220048071', 'text': 'through the notebooks. The Vertex API costs are described here:'}, {'x': 61, 'y': 937, 'w': 728, 'h': 44, 'confidence': '0.873600733295073', 'text': \"Ifyou are a new user on Google Cloud, there's a\"}, {'x': 788, 'y': 931, 'w': 446, 'h': 52, 'confidence': '0.665035489888588', 'text': '90-day free trial with a S300'}, {'x': 23, 'y': 973, 'w': 1134, 'h': 38, 'confidence': '0.6642532115234331', 'text': 'credit which would be more than sufficient to run all the notebooks for this'}, {'x': 24, 'y': 1016, 'w': 110, 'h': 30, 'confidence': '0.8351897209675964', 'text': 'course:'}]}]\n",
      "> Image for page 69: [{'name': 'img_p68_1.png', 'height': 798, 'width': 1256, 'x': 99.649609488, 'y': 49.09055275199995, 'original_width': 1256, 'original_height': 798, 'ocr': [{'x': 29, 'y': 3, 'w': 384, 'h': 42, 'confidence': '0.7261112090367668', 'text': 'Give your Project a name:'}, {'x': 129, 'y': 66, 'w': 1048, 'h': 39, 'confidence': '0.5588789535634356', 'text': 'You can give anv name vou want; but it is recommended to use \"DLAI-'}, {'x': 126, 'y': 103, 'w': 1058, 'h': 43, 'confidence': '0.9423196790542433', 'text': 'shortcourse-on-gemini\" so thatyou can run the Google Colabs without'}, {'x': 124, 'y': 135, 'w': 460, 'h': 49, 'confidence': '0.8551802777192454', 'text': 'changing anything in the code'}, {'x': 29, 'y': 203, 'w': 1144, 'h': 38, 'confidence': '0.7263377451462778', 'text': 'Your Proiect ID will automaticallv displav under the text box (red) Save that'}, {'x': 28, 'y': 233, 'w': 1196, 'h': 51, 'confidence': '0.698104838394007', 'text': 'Project ID somewhere as it will be later used in running the Google Colabs.'}, {'x': 31, 'y': 277, 'w': 228, 'h': 40, 'confidence': '0.8959067151968152', 'text': 'Once created,'}, {'x': 339, 'y': 275, 'w': 484, 'h': 44, 'confidence': '0.9156170252999289', 'text': 'Project ID cannot be changed:'}, {'x': 84, 'y': 354, 'w': 160, 'h': 32, 'confidence': '0.9366923305988702', 'text': 'Project name'}, {'x': 83, 'y': 391, 'w': 368, 'h': 38, 'confidence': '0.9635429204527779', 'text': 'DLAI-shortcourse-on-gemini'}, {'x': 80, 'y': 462, 'w': 465, 'h': 39, 'confidence': '0.8891081730080959', 'text': 'Project ID: dlai-shortcourse-on-gemini.'}, {'x': 565, 'y': 465, 'w': 296, 'h': 36, 'confidence': '0.9100466500253839', 'text': 'cannot be changed later:'}, {'x': 871, 'y': 463, 'w': 68, 'h': 33, 'confidence': '0.9954394102096558', 'text': 'EDIT'}, {'x': 83, 'y': 539, 'w': 106, 'h': 28, 'confidence': '0.9999849113810817', 'text': 'Location'}, {'x': 83, 'y': 573, 'w': 252, 'h': 43, 'confidence': '0.4114402168470821', 'text': '@J No organization'}, {'x': 1036, 'y': 576, 'w': 120, 'h': 32, 'confidence': '0.974118508473972', 'text': 'BROWSE'}, {'x': 83, 'y': 639, 'w': 342, 'h': 37, 'confidence': '0.7735660499507855', 'text': 'Parent organization or folder'}, {'x': 88, 'y': 728, 'w': 110, 'h': 32, 'confidence': '0.632381401559443', 'text': 'CREATE'}, {'x': 270, 'y': 728, 'w': 116, 'h': 32, 'confidence': '0.9999775157944271', 'text': 'CANCEL'}, {'x': 255, 'y': 282, 'w': 86, 'h': 32, 'confidence': '0.9998037815093994', 'text': 'your'}]}]\n",
      "> Image for page 70: [{'name': 'img_p69_1.png', 'height': 1128, 'width': 1280, 'x': 169.41535975199997, 'y': 52.43110404000004, 'original_width': 1280, 'original_height': 1128, 'ocr': [{'x': 28, 'y': 6, 'w': 1102, 'h': 50, 'confidence': '0.8489031737004672', 'text': 'After your Project has been created, select it by clicking the arrow (in red)'}, {'x': 86, 'y': 148, 'w': 128, 'h': 26, 'confidence': '0.5171082490378288', 'text': 'Google Cloud'}, {'x': 287, 'y': 151, 'w': 108, 'h': 21, 'confidence': '0.9999221831085114', 'text': 'My First Project'}, {'x': 458, 'y': 148, 'w': 356, 'h': 24, 'confidence': '0.8344098414024868', 'text': 'Search (/) for resources, docs, products, and more'}, {'x': 1047, 'y': 151, 'w': 56, 'h': 20, 'confidence': '0.9774353949329995', 'text': 'Search'}, {'x': 340, 'y': 220, 'w': 138, 'h': 26, 'confidence': '0.8749879696559049', 'text': 'Select a project'}, {'x': 993, 'y': 223, 'w': 96, 'h': 18, 'confidence': '0.945241594961679', 'text': 'NEW PROJECT'}, {'x': 345, 'y': 269, 'w': 158, 'h': 16, 'confidence': '0.9465245666067186', 'text': 'Search projects and folders'}, {'x': 195, 'y': 317, 'w': 130, 'h': 40, 'confidence': '0.9999638402804896', 'text': 'Welcon'}, {'x': 343, 'y': 337, 'w': 54, 'h': 16, 'confidence': '0.9999574648485946', 'text': 'RECENT'}, {'x': 445, 'y': 337, 'w': 62, 'h': 16, 'confidence': '0.999772859957133', 'text': 'STARRED'}, {'x': 555, 'y': 337, 'w': 26, 'h': 14, 'confidence': '0.9998402576881874', 'text': 'ALL'}, {'x': 415, 'y': 373, 'w': 38, 'h': 14, 'confidence': '0.9995367527008057', 'text': 'Name'}, {'x': 134, 'y': 388, 'w': 184, 'h': 28, 'confidence': '0.9230491034308662', 'text': 'Youre working in My'}, {'x': 415, 'y': 403, 'w': 176, 'h': 16, 'confidence': '0.7579605830675586', 'text': 'DLAI-shortcourse-on-gemini'}, {'x': 802, 'y': 400, 'w': 169, 'h': 19, 'confidence': '0.7886541552085061', 'text': 'dlai-shortcourse-on-gemini'}, {'x': 137, 'y': 437, 'w': 100, 'h': 16, 'confidence': '0.9158212767195311', 'text': 'Project number:'}, {'x': 245, 'y': 437, 'w': 72, 'h': 16, 'confidence': '0.9999966449381574', 'text': '545378003'}, {'x': 355, 'y': 431, 'w': 44, 'h': 20, 'confidence': '0.18651094227218412', 'text': '08'}, {'x': 415, 'y': 434, 'w': 100, 'h': 18, 'confidence': '0.7897855597251493', 'text': 'My First Project'}, {'x': 802, 'y': 431, 'w': 151, 'h': 20, 'confidence': '0.8667845311304017', 'text': 'balmy-parser-433005-r3'}, {'x': 1120, 'y': 454, 'w': 120, 'h': 24, 'confidence': '0.9687075262808694', 'text': 'most advancd'}, {'x': 137, 'y': 477, 'w': 80, 'h': 16, 'confidence': '0.9999831516827768', 'text': 'Dashboard'}, {'x': 234, 'y': 476, 'w': 85, 'h': 18, 'confidence': '0.9706024280065995', 'text': 'Recommenc'}, {'x': 1118, 'y': 478, 'w': 120, 'h': 24, 'confidence': '0.7795620804021497', 'text': 'Gemini 1.5 Pr'}, {'x': 1115, 'y': 539, 'w': 38, 'h': 20, 'confidence': '0.38781824707984924', 'text': 'mini'}, {'x': 171, 'y': 561, 'w': 80, 'h': 18, 'confidence': '0.6887310890983932', 'text': 'Create a VM'}, {'x': 134, 'y': 638, 'w': 146, 'h': 26, 'confidence': '0.9956121045184829', 'text': 'Quick access'}, {'x': 153, 'y': 709, 'w': 144, 'h': 20, 'confidence': '0.8593979530885112', 'text': 'API APIs & Services'}, {'x': 1123, 'y': 707, 'w': 57, 'h': 26, 'confidence': '0.9999934786187397', 'text': 'Engine'}, {'x': 1035, 'y': 781, 'w': 54, 'h': 16, 'confidence': '0.9998552620215183', 'text': 'CANCEL'}, {'x': 158, 'y': 818, 'w': 132, 'h': 26, 'confidence': '0.9801205628543612', 'text': '3 Cloud Storage'}, {'x': 475, 'y': 825, 'w': 70, 'h': 18, 'confidence': '0.999392840436585', 'text': 'BigQuery'}, {'x': 767, 'y': 825, 'w': 96, 'h': 16, 'confidence': '0.9848389375531923', 'text': 'VPC network'}, {'x': 1057, 'y': 825, 'w': 86, 'h': 16, 'confidence': '0.9999818298115769', 'text': 'Kubernetes'}, {'x': 1141, 'y': 819, 'w': 55, 'h': 26, 'confidence': '0.9999877845690768', 'text': 'Engine'}, {'x': 30, 'y': 928, 'w': 1154, 'h': 48, 'confidence': '0.8889948532555937', 'text': 'Once vour Project has been selected, vou should see it being displayed in the'}, {'x': 29, 'y': 967, 'w': 942, 'h': 44, 'confidence': '0.6958612398828262', 'text': 'box. This would mean that this is your current selected Project.'}, {'x': 28, 'y': 1028, 'w': 1114, 'h': 48, 'confidence': '0.7844244250371113', 'text': 'You need to make sure you are inside the correct project for the next'}, {'x': 29, 'y': 1071, 'w': 102, 'h': 40, 'confidence': '0.5680462397210422', 'text': 'steps:'}]}]\n",
      "> Image for page 71: []\n",
      "> Image for page 72: [{'name': 'img_p71_1.png', 'height': 1338, 'width': 1276, 'x': 17.313976932, 'y': 51.76574968799997, 'original_width': 1276, 'original_height': 1338, 'ocr': [{'x': 20, 'y': 10, 'w': 26, 'h': 30, 'confidence': '0.9509331245897187', 'text': '4_'}, {'x': 65, 'y': 0, 'w': 257, 'h': 46, 'confidence': '0.6025362095882747', 'text': 'Enable APIs'}, {'x': 31, 'y': 90, 'w': 684, 'h': 38, 'confidence': '0.5972415573556523', 'text': 'You will now enable the APIs that are needed.'}, {'x': 32, 'y': 152, 'w': 747, 'h': 41, 'confidence': '0.5315179997299755', 'text': 'From the search bar, find Enabled APIs & services:'}, {'x': 93, 'y': 245, 'w': 175, 'h': 44, 'confidence': '0.7537530477708461', 'text': 'Aplgateway'}, {'x': 1077, 'y': 249, 'w': 106, 'h': 36, 'confidence': '0.9887230835124081', 'text': 'Search'}, {'x': 163, 'y': 325, 'w': 182, 'h': 40, 'confidence': '0.9999868807654372', 'text': 'api gateway'}, {'x': 30, 'y': 354, 'w': 36, 'h': 30, 'confidence': '0.35704556845447427', 'text': 'rs'}, {'x': 163, 'y': 401, 'w': 226, 'h': 40, 'confidence': '0.9999187812875105', 'text': 'apis & services'}, {'x': 93, 'y': 510, 'w': 209, 'h': 30, 'confidence': '0.9988483410484006', 'text': 'SEARCH RESULTS'}, {'x': 176, 'y': 575, 'w': 207, 'h': 36, 'confidence': '0.9133245607576351', 'text': 'APIs & Services'}, {'x': 97, 'y': 593, 'w': 52, 'h': 36, 'confidence': '0.9892080092478424', 'text': 'API'}, {'x': 176, 'y': 614, 'w': 392, 'h': 33, 'confidence': '0.9784451728163053', 'text': 'API management for cloud services'}, {'x': 1200, 'y': 630, 'w': 42, 'h': 26, 'confidence': '0.962937669032335', 'text': 'tke'}, {'x': 177, 'y': 675, 'w': 96, 'h': 38, 'confidence': '0.9999959119710741', 'text': 'Apigee'}, {'x': 177, 'y': 711, 'w': 193, 'h': 28, 'confidence': '0.7633444374095179', 'text': 'APLManagement'}, {'x': 30, 'y': 786, 'w': 38, 'h': 26, 'confidence': '0.130381472491909', 'text': 'Y ('}, {'x': 176, 'y': 774, 'w': 312, 'h': 30, 'confidence': '0.7075266375953532', 'text': 'Enabled APIs & services'}, {'x': 1200, 'y': 782, 'w': 42, 'h': 26, 'confidence': '0.9707030967347914', 'text': 'sil'}, {'x': 95, 'y': 789, 'w': 54, 'h': 36, 'confidence': '0.983300874932885', 'text': 'API'}, {'x': 32, 'y': 822, 'w': 34, 'h': 26, 'confidence': '0.9999657769305327', 'text': 'Ke'}, {'x': 176, 'y': 812, 'w': 176, 'h': 26, 'confidence': '0.9941300650012018', 'text': 'APIs & Services'}, {'x': 176, 'y': 870, 'w': 218, 'h': 32, 'confidence': '0.979803325874716', 'text': 'Cloud Vision API'}, {'x': 95, 'y': 884, 'w': 55, 'h': 39, 'confidence': '0.9672759029813748', 'text': 'API'}, {'x': 28, 'y': 914, 'w': 38, 'h': 26, 'confidence': '0.4968185132599921', 'text': 'Dul'}, {'x': 176, 'y': 907, 'w': 244, 'h': 32, 'confidence': '0.8728791755218352', 'text': 'Google Enterprise API'}, {'x': 178, 'y': 970, 'w': 64, 'h': 30, 'confidence': '0.9970307946205139', 'text': 'APIs'}, {'x': 28, 'y': 990, 'w': 36, 'h': 24, 'confidence': '0.9578412124970479', 'text': 'ior'}, {'x': 176, 'y': 1005, 'w': 144, 'h': 31, 'confidence': '0.8148126922472154', 'text': 'API Gateway'}, {'x': 35, 'y': 1033, 'w': 28, 'h': 20, 'confidence': '0.9941524245998015', 'text': 'za'}, {'x': 176, 'y': 1066, 'w': 242, 'h': 32, 'confidence': '0.8013340821470973', 'text': 'Translation API Go'}, {'x': 174, 'y': 1104, 'w': 208, 'h': 26, 'confidence': '0.9973817361008905', 'text': 'Interactive Tutorial'}, {'x': 177, 'y': 1162, 'w': 169, 'h': 39, 'confidence': '0.4787204637928588', 'text': 'API Gateway'}, {'x': 176, 'y': 1200, 'w': 530, 'h': 33, 'confidence': '0.7765135778218534', 'text': 'API development; deployment; and management'}, {'x': 34, 'y': 1274, 'w': 34, 'h': 28, 'confidence': '0.9999996628252286', 'text': '42'}, {'x': 177, 'y': 1261, 'w': 254, 'h': 38, 'confidence': '0.9756638329654141', 'text': 'API usage overview'}, {'x': 444, 'y': 1261, 'w': 229, 'h': 33, 'confidence': '0.9999629662001629', 'text': 'Cloud Translation'}, {'x': 175, 'y': 1296, 'w': 680, 'h': 38, 'confidence': '0.7272710095759007', 'text': 'Google provides client libraries for many popular languages to.'}]}, {'name': 'img_p71_2.png', 'height': 384, 'width': 1374, 'x': 343.738199976, 'y': 72.58660862198401, 'original_width': 1374, 'original_height': 384, 'ocr': [{'x': 86, 'y': 52, 'w': 205, 'h': 40, 'confidence': '0.8305151652789374', 'text': 'Next, click on'}, {'x': 319, 'y': 53, 'w': 424, 'h': 36, 'confidence': '0.7097023970466212', 'text': 'ENABLE APIS AND SERVICES.'}, {'x': 106, 'y': 184, 'w': 150, 'h': 24, 'confidence': '0.7196816223854994', 'text': 'APIs & Services'}, {'x': 349, 'y': 187, 'w': 204, 'h': 18, 'confidence': '0.9501673230543772', 'text': 'ENABLE APIS AND SERVICES'}, {'x': 185, 'y': 273, 'w': 604, 'h': 20, 'confidence': '0.8233249923851526', 'text': 'You dont have any APIs available to use yet: To get started, click \"Enable APIs and services\\\\\\''}, {'x': 794, 'y': 272, 'w': 153, 'h': 24, 'confidence': '0.743010562002871', 'text': 'or go to the API library'}]}]\n",
      "> Image for page 73: [{'name': 'img_p72_1.png', 'height': 1006, 'width': 1222, 'x': 155.986225464, 'y': 50.433072479999964, 'original_width': 1222, 'original_height': 1006, 'ocr': [{'x': 27, 'y': 9, 'w': 538, 'h': 36, 'confidence': '0.562058393931128', 'text': 'In the search bar; look for Vertex Al:'}, {'x': 263, 'y': 240, 'w': 419, 'h': 45, 'confidence': '0.9074385599700643', 'text': 'Welcome to the API Library'}, {'x': 262, 'y': 295, 'w': 696, 'h': 32, 'confidence': '0.6894951676514018', 'text': 'The API Library has documentation; links, and a smart search experience.'}, {'x': 333, 'y': 391, 'w': 78, 'h': 20, 'confidence': '0.9799894664005647', 'text': 'vertex ail'}, {'x': 284, 'y': 450, 'w': 106, 'h': 24, 'confidence': '0.8529485830956304', 'text': 'vertex ai api'}, {'x': 282, 'y': 494, 'w': 242, 'h': 26, 'confidence': '0.8075392597350216', 'text': 'vertex ai search for retail api'}, {'x': 91, 'y': 559, 'w': 75, 'h': 37, 'confidence': '0.6638900214901313', 'text': 'Maps'}, {'x': 1040, 'y': 568, 'w': 126, 'h': 26, 'confidence': '0.9049889851838577', 'text': 'VIEW ALL (23)'}, {'x': 500, 'y': 672, 'w': 36, 'h': 24, 'confidence': '0.24579762732830202', 'text': 'iDs'}, {'x': 124, 'y': 716, 'w': 216, 'h': 28, 'confidence': '0.9993245047883674', 'text': 'Maps SDK for Android'}, {'x': 488, 'y': 716, 'w': 176, 'h': 31, 'confidence': '0.9492717820845045', 'text': 'Maps SDK for iOS'}, {'x': 854, 'y': 718, 'w': 204, 'h': 26, 'confidence': '0.9179433975410446', 'text': 'Maps JavaScript API'}, {'x': 122, 'y': 750, 'w': 66, 'h': 24, 'confidence': '0.9243291131137843', 'text': 'Google'}, {'x': 488, 'y': 750, 'w': 66, 'h': 24, 'confidence': '0.5929990450018026', 'text': 'Google'}, {'x': 854, 'y': 750, 'w': 64, 'h': 24, 'confidence': '0.9743142575227913', 'text': 'Google'}, {'x': 124, 'y': 794, 'w': 280, 'h': 26, 'confidence': '0.6950883762797849', 'text': 'Maps for your native Android app.'}, {'x': 488, 'y': 794, 'w': 244, 'h': 28, 'confidence': '0.8489690351653324', 'text': 'Maps for your native iOS app_'}, {'x': 854, 'y': 796, 'w': 190, 'h': 26, 'confidence': '0.9998189762164219', 'text': 'Maps for your website'}]}]\n",
      "> Image for page 74: [{'name': 'img_p73_1.png', 'height': 750, 'width': 1236, 'x': 83.21358534, 'y': 52.43307254400003, 'original_width': 1236, 'original_height': 750, 'ocr': [{'x': 29, 'y': 17, 'w': 362, 'h': 36, 'confidence': '0.7043253147977315', 'text': 'And select Vertex Al API:'}, {'x': 52, 'y': 158, 'w': 84, 'h': 24, 'confidence': '0.6855763493685093', 'text': '3 results'}, {'x': 200, 'y': 214, 'w': 124, 'h': 24, 'confidence': '0.5402623796134682', 'text': 'Vertex Al API'}, {'x': 200, 'y': 243, 'w': 158, 'h': 26, 'confidence': '0.9994609195760383', 'text': 'Google Enterprise API'}, {'x': 203, 'y': 287, 'w': 38, 'h': 16, 'confidence': '0.7131329560001142', 'text': 'Train'}, {'x': 239, 'y': 283, 'w': 671, 'h': 25, 'confidence': '0.7692873680025969', 'text': 'high-quality custom machine learning models with minimal machine learning expertise and effort.'}, {'x': 200, 'y': 364, 'w': 274, 'h': 26, 'confidence': '0.5873000481367373', 'text': 'Vertex Al Search for Retail API'}, {'x': 201, 'y': 397, 'w': 156, 'h': 20, 'confidence': '0.9783835367087459', 'text': 'Google Enterprise API'}, {'x': 202, 'y': 432, 'w': 966, 'h': 24, 'confidence': '0.6475829777653239', 'text': 'Vertex Al Search for Retail API is made up of Retail Search; Browse and Recommendations. These discovery Al solutions help you implement'}, {'x': 202, 'y': 459, 'w': 603, 'h': 20, 'confidence': '0.7564520131468268', 'text': 'personalized search; browse and recommendations, based on machine learning models,'}, {'x': 808, 'y': 456, 'w': 316, 'h': 24, 'confidence': '0.7196859622995299', 'text': 'across your websites and mobile applications'}, {'x': 202, 'y': 540, 'w': 110, 'h': 26, 'confidence': '0.9953977179184065', 'text': 'AlloyDB API'}, {'x': 201, 'y': 571, 'w': 156, 'h': 20, 'confidence': '0.9642473617407173', 'text': 'Google Enterprise API'}, {'x': 199, 'y': 604, 'w': 923, 'h': 27, 'confidence': '0.7590202284059006', 'text': 'AlloyDB for PostgreSQL is an open source-compatible database service thats a powerful option for migrating; modernizing; or building'}, {'x': 203, 'y': 635, 'w': 88, 'h': 16, 'confidence': '0.7588800879701774', 'text': 'commercial-='}, {'x': 283, 'y': 628, 'w': 903, 'h': 27, 'confidence': '0.5941323586343791', 'text': 'Igrade applications. It offers full compatibility with standard PostgreSQL,and is more than 4x faster for transactional workloads and'}, {'x': 202, 'y': 654, 'w': 984, 'h': 24, 'confidence': '0.7888323324570171', 'text': 'up to 1OOx faster for analytical queries than standard PostgreSQL in our performance tests. AlloyDB for PostgreSQL offers a 99.99% availability_'}]}]\n",
      "> Image for page 75: [{'name': 'img_p74_1.png', 'height': 1020, 'width': 1326, 'x': 137.89764220799998, 'y': 50.433072479999964, 'original_width': 1326, 'original_height': 1020, 'ocr': [{'x': 57, 'y': 29, 'w': 310, 'h': 36, 'confidence': '0.6865675488894241', 'text': 'Enable Vertex Al API:'}, {'x': 129, 'y': 167, 'w': 153, 'h': 32, 'confidence': '0.9932796154971667', 'text': 'Google Cloud'}, {'x': 368, 'y': 170, 'w': 174, 'h': 24, 'confidence': '0.4780544978393924', 'text': 'DLAI-shortcourse-on-_'}, {'x': 126, 'y': 230, 'w': 158, 'h': 26, 'confidence': '0.9873343533271665', 'text': 'Product details'}, {'x': 287, 'y': 308, 'w': 190, 'h': 40, 'confidence': '0.9131445802500363', 'text': 'Vertex Al API'}, {'x': 290, 'y': 351, 'w': 164, 'h': 26, 'confidence': '0.9827975344783401', 'text': 'Google Enterprise API'}, {'x': 288, 'y': 404, 'w': 624, 'h': 30, 'confidence': '0.8185046556111145', 'text': 'Train high-quality custom machine learning models with minimal machine'}, {'x': 286, 'y': 432, 'w': 196, 'h': 28, 'confidence': '0.9954558759257437', 'text': 'learning expertise and'}, {'x': 302, 'y': 516, 'w': 68, 'h': 24, 'confidence': '0.9999762017788989', 'text': 'ENABLE'}, {'x': 409, 'y': 517, 'w': 106, 'h': 20, 'confidence': '0.9965599011608558', 'text': 'TRY THIS API'}, {'x': 157, 'y': 641, 'w': 86, 'h': 20, 'confidence': '0.9992761457853397', 'text': 'OVERVIEW'}, {'x': 299, 'y': 641, 'w': 138, 'h': 20, 'confidence': '0.7046517636044002', 'text': 'DOCUMENTATION'}, {'x': 493, 'y': 640, 'w': 161, 'h': 21, 'confidence': '0.9997805285622354', 'text': 'RELATED PRODUCTS'}, {'x': 54, 'y': 788, 'w': 1212, 'h': 51, 'confidence': '0.667985409842438', 'text': 'Ifyou didntt enable billing previously, clicking the ENABLE button will prompt you'}, {'x': 53, 'y': 831, 'w': 771, 'h': 36, 'confidence': '0.6611248564762424', 'text': 'to do so now. You cannot use Vertex Al API without'}, {'x': 820, 'y': 824, 'w': 247, 'h': 51, 'confidence': '0.9865877914466481', 'text': 'enabling billing:'}, {'x': 56, 'y': 947, 'w': 700, 'h': 50, 'confidence': '0.7666221178284218', 'text': 'Follow the steps to create your Billing Account'}, {'x': 532, 'y': 174, 'w': 62, 'h': 16, 'confidence': '0.8914684805172624', 'text': '~gemini'}]}]\n",
      "> Image for page 76: [{'name': 'img_p75_1.png', 'height': 992, 'width': 1200, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 1200, 'original_height': 992, 'ocr': [{'x': 24, 'y': 42, 'w': 28, 'h': 34, 'confidence': '0.9998559451110108', 'text': '5.'}, {'x': 67, 'y': 24, 'w': 776, 'h': 67, 'confidence': '0.8758318615733085', 'text': 'Test Vertex Al API (Mandatory Step)'}, {'x': 34, 'y': 117, 'w': 811, 'h': 52, 'confidence': '0.6943448226253773', 'text': 'Final steps! Test to see if your Vertex Al API is working:'}, {'x': 35, 'y': 187, 'w': 480, 'h': 36, 'confidence': '0.47378511170253307', 'text': 'In the search bar; find Vertex Al:'}, {'x': 83, 'y': 275, 'w': 308, 'h': 39, 'confidence': '0.8383530475246654', 'text': 'Vertex ai agent builder'}, {'x': 890, 'y': 276, 'w': 32, 'h': 32, 'confidence': '0.9964292986797432', 'text': 'X'}, {'x': 973, 'y': 269, 'w': 148, 'h': 40, 'confidence': '0.9994048131234552', 'text': 'Q Search'}, {'x': 88, 'y': 350, 'w': 30, 'h': 30, 'confidence': '0.6359209033512911', 'text': 'Q'}, {'x': 149, 'y': 346, 'w': 325, 'h': 42, 'confidence': '0.9310888364712223', 'text': 'vertex ai agent builder'}, {'x': 88, 'y': 428, 'w': 28, 'h': 28, 'confidence': '0.9964603569479245', 'text': 'Q'}, {'x': 149, 'y': 423, 'w': 488, 'h': 36, 'confidence': '0.5897887109682677', 'text': 'vertex ai search and conversation'}, {'x': 82, 'y': 532, 'w': 206, 'h': 28, 'confidence': '0.8545253123166963', 'text': 'SEARCH RESULTS'}, {'x': 164, 'y': 596, 'w': 120, 'h': 30, 'confidence': '0.8379905047875956', 'text': 'Vertex Al'}, {'x': 162, 'y': 632, 'w': 432, 'h': 32, 'confidence': '0.5368424028800672', 'text': 'One Al platform; every ML tool you need'}, {'x': 164, 'y': 692, 'w': 180, 'h': 30, 'confidence': '0.9868865594555325', 'text': 'Vector Search'}, {'x': 162, 'y': 730, 'w': 104, 'h': 26, 'confidence': '0.49353957001185433', 'text': 'Vertex Al'}, {'x': 35, 'y': 864, 'w': 722, 'h': 51, 'confidence': '0.5830928121734765', 'text': 'From the left hand menu, select Prompt Gallery:'}]}, {'name': 'img_p75_2.png', 'height': 1370, 'width': 808, 'x': 430.33723818024, 'y': 57.09449001599995, 'original_width': 808, 'original_height': 1370, 'ocr': [{'x': 45, 'y': 14, 'w': 724, 'h': 53, 'confidence': '0.7208982802954657', 'text': 'From the left hand menu; select Prompt Gallery:'}, {'x': 165, 'y': 177, 'w': 154, 'h': 38, 'confidence': '0.6948322283393099', 'text': 'Vertex Al'}, {'x': 166, 'y': 296, 'w': 132, 'h': 32, 'confidence': '0.9609740224507565', 'text': 'Dashboard'}, {'x': 170, 'y': 378, 'w': 168, 'h': 30, 'confidence': '0.7651269953032925', 'text': 'Model Garden'}, {'x': 88, 'y': 454, 'w': 36, 'h': 32, 'confidence': '0.8697898016289761', 'text': 'QU'}, {'x': 164, 'y': 458, 'w': 114, 'h': 32, 'confidence': '0.9999947150478472', 'text': 'Pipelines'}, {'x': 70, 'y': 538, 'w': 158, 'h': 30, 'confidence': '0.9997015571436823', 'text': 'NOTEBOOKS'}, {'x': 86, 'y': 620, 'w': 36, 'h': 24, 'confidence': '0.47705189791571895', 'text': 'cO'}, {'x': 166, 'y': 618, 'w': 196, 'h': 30, 'confidence': '0.8096522555029068', 'text': 'Colab Enterprise'}, {'x': 166, 'y': 698, 'w': 136, 'h': 30, 'confidence': '0.9999865293049157', 'text': 'Workbench'}, {'x': 70, 'y': 776, 'w': 226, 'h': 32, 'confidence': '0.6950146062229015', 'text': 'VERTEX Al STUDIO'}, {'x': 164, 'y': 858, 'w': 112, 'h': 28, 'confidence': '0.9999042404610015', 'text': 'Overview'}, {'x': 166, 'y': 936, 'w': 138, 'h': 32, 'confidence': '0.9999503519563577', 'text': 'Multimodal'}, {'x': 162, 'y': 1016, 'w': 127, 'h': 39, 'confidence': '0.9009023245768822', 'text': 'Language'}, {'x': 164, 'y': 1098, 'w': 78, 'h': 28, 'confidence': '0.9999331310550952', 'text': 'Vision'}, {'x': 163, 'y': 1177, 'w': 96, 'h': 36, 'confidence': '0.9999706537090577', 'text': 'Speech'}, {'x': 163, 'y': 1253, 'w': 185, 'h': 41, 'confidence': '0.6908929503531327', 'text': 'Prompt Gallery'}, {'x': 164, 'y': 1336, 'w': 180, 'h': 32, 'confidence': '0.8429748718774788', 'text': 'Saved prompts'}]}]\n",
      "> Image for page 77: [{'name': 'img_p76_1.png', 'height': 1130, 'width': 2048, 'x': 55.604332488, 'y': 53.76378124799999, 'original_width': 2048, 'original_height': 1130, 'ocr': [{'x': 15, 'y': 11, 'w': 938, 'h': 42, 'confidence': '0.5332733043218981', 'text': 'Then first select; Text (in red) and then click on Ad copy (in blue):'}, {'x': 116, 'y': 100, 'w': 344, 'h': 32, 'confidence': '0.9991964280075999', 'text': 'DLAI-shortcourse-on-gemini'}, {'x': 578, 'y': 98, 'w': 98, 'h': 32, 'confidence': '0.3841199117407095', 'text': 'Search'}, {'x': 711, 'y': 95, 'w': 520, 'h': 40, 'confidence': '0.5489596404529795', 'text': 'for resources, docs, products, and more'}, {'x': 1439, 'y': 93, 'w': 144, 'h': 38, 'confidence': '0.9482149088915838', 'text': 'Q Search'}, {'x': 161, 'y': 282, 'w': 318, 'h': 61, 'confidence': '0.9617632620250116', 'text': 'Prompt gallery'}, {'x': 165, 'y': 381, 'w': 870, 'h': 37, 'confidence': '0.7882378523876662', 'text': 'Browse prompts across media types and models to help you get started.'}, {'x': 230, 'y': 478, 'w': 296, 'h': 32, 'confidence': '0.9613105259957448', 'text': 'Search sample prompts'}, {'x': 1012, 'y': 478, 'w': 76, 'h': 28, 'confidence': '0.9999201915376383', 'text': 'Tasks'}, {'x': 1400, 'y': 478, 'w': 112, 'h': 28, 'confidence': '0.9999753861149948', 'text': 'Features'}, {'x': 1786, 'y': 476, 'w': 173, 'h': 37, 'confidence': '0.8308006549216228', 'text': 'Prompt types'}, {'x': 276, 'y': 590, 'w': 88, 'h': 32, 'confidence': '0.9999791549764923', 'text': 'Audio'}, {'x': 554, 'y': 590, 'w': 154, 'h': 32, 'confidence': '0.7562186606662145', 'text': 'Document'}, {'x': 893, 'y': 588, 'w': 101, 'h': 43, 'confidence': '0.9972391069510224', 'text': 'Image'}, {'x': 1164, 'y': 590, 'w': 68, 'h': 32, 'confidence': '0.9999743103981018', 'text': 'Text'}, {'x': 1422, 'y': 590, 'w': 88, 'h': 32, 'confidence': '0.9996215295510082', 'text': 'Video'}, {'x': 1868, 'y': 590, 'w': 160, 'h': 30, 'confidence': '0.6679286745327094', 'text': 'Clear AII Fili'}, {'x': 306, 'y': 776, 'w': 142, 'h': 48, 'confidence': '0.6645667487733726', 'text': 'Ad copy'}, {'x': 916, 'y': 774, 'w': 364, 'h': 53, 'confidence': '0.8387377194637308', 'text': 'Analyze financial news'}, {'x': 1527, 'y': 774, 'w': 347, 'h': 54, 'confidence': '0.7124678589981243', 'text': 'Analyze market share'}, {'x': 199, 'y': 897, 'w': 486, 'h': 38, 'confidence': '0.9701106943815662', 'text': 'Write ad copy for different topics from a'}, {'x': 809, 'y': 895, 'w': 494, 'h': 39, 'confidence': '0.8427841753962027', 'text': 'Provide an overall investment rating on a'}, {'x': 1421, 'y': 896, 'w': 502, 'h': 39, 'confidence': '0.9840671455161915', 'text': 'Analyze the competitive landscape of the'}, {'x': 197, 'y': 934, 'w': 246, 'h': 39, 'confidence': '0.8101247712680693', 'text': 'product description.'}, {'x': 810, 'y': 938, 'w': 394, 'h': 32, 'confidence': '0.8007906607527225', 'text': 'company based on recent news:'}, {'x': 1418, 'y': 931, 'w': 431, 'h': 42, 'confidence': '0.6515957193121871', 'text': 'streaming service market based on'}, {'x': 1419, 'y': 975, 'w': 171, 'h': 31, 'confidence': '0.9997515965930946', 'text': 'financial data_'}]}]\n",
      "> Image for page 78: [{'name': 'img_p77_1.png', 'height': 1259, 'width': 2048, 'x': 140.05905959999998, 'y': 52.740100112879986, 'original_width': 2048, 'original_height': 1259, 'ocr': [{'x': 35, 'y': 9, 'w': 878, 'h': 42, 'confidence': '0.8220200468707215', 'text': 'Run (in red) the text prompt (you might see a different prompt):'}, {'x': 120, 'y': 96, 'w': 326, 'h': 32, 'confidence': '0.7935038006631663', 'text': 'DLAI-shortcourse-on-gemini'}, {'x': 557, 'y': 96, 'w': 92, 'h': 30, 'confidence': '0.9791798863402329', 'text': 'Search'}, {'x': 685, 'y': 93, 'w': 492, 'h': 36, 'confidence': '0.5701623483373882', 'text': 'for resources; docs, products, and more'}, {'x': 1377, 'y': 91, 'w': 135, 'h': 36, 'confidence': '0.9997667059209586', 'text': 'Q Search'}, {'x': 245, 'y': 177, 'w': 130, 'h': 44, 'confidence': '0.9938904924242845', 'text': 'Ad copy'}, {'x': 782, 'y': 186, 'w': 118, 'h': 30, 'confidence': '0.7908208550393825', 'text': 'Freeform'}, {'x': 982, 'y': 182, 'w': 141, 'h': 36, 'confidence': '0.9999605681856605', 'text': 'Structured'}, {'x': 1200, 'y': 184, 'w': 206, 'h': 32, 'confidence': '0.6339162103931671', 'text': 'API reference ['}, {'x': 1536, 'y': 184, 'w': 66, 'h': 30, 'confidence': '0.9999825954437256', 'text': 'Save'}, {'x': 1694, 'y': 186, 'w': 118, 'h': 28, 'confidence': '0.8893190521223749', 'text': 'Get code'}, {'x': 1994, 'y': 186, 'w': 34, 'h': 28, 'confidence': '0.3282353737314594', 'text': '5'}, {'x': 1526, 'y': 284, 'w': 68, 'h': 26, 'confidence': '0.9998596816144797', 'text': 'Model'}, {'x': 203, 'y': 321, 'w': 279, 'h': 40, 'confidence': '0.9998738539379456', 'text': 'System instructions'}, {'x': 1336, 'y': 324, 'w': 56, 'h': 30, 'confidence': '0.9985606670379639', 'text': 'Edit'}, {'x': 1523, 'y': 314, 'w': 244, 'h': 37, 'confidence': '0.7525255468315474', 'text': 'gemini-1.5-flash-001'}, {'x': 1526, 'y': 392, 'w': 74, 'h': 28, 'confidence': '0.9999748390957192', 'text': 'Region'}, {'x': 1526, 'y': 426, 'w': 214, 'h': 28, 'confidence': '0.6905702580800369', 'text': 'us-centrall (lowa)'}, {'x': 202, 'y': 446, 'w': 113, 'h': 41, 'confidence': '0.9981340830147601', 'text': 'Prompt'}, {'x': 1225, 'y': 445, 'w': 174, 'h': 40, 'confidence': '0.5818639183182901', 'text': 'Clear Prompt'}, {'x': 1502, 'y': 504, 'w': 155, 'h': 36, 'confidence': '0.7114973928288272', 'text': 'Temperature'}, {'x': 204, 'y': 522, 'w': 1150, 'h': 48, 'confidence': '0.7654218173998206', 'text': 'For each of the following categories, create 3 one-sentence ad copies using the product'}, {'x': 203, 'y': 568, 'w': 278, 'h': 41, 'confidence': '0.7416952715731504', 'text': 'description provided.'}, {'x': 1783, 'y': 581, 'w': 18, 'h': 22, 'confidence': '1.0', 'text': '2'}, {'x': 1944, 'y': 570, 'w': 42, 'h': 28, 'confidence': '0.9980845565534255', 'text': '0.2'}, {'x': 205, 'y': 658, 'w': 156, 'h': 38, 'confidence': '0.7396239076540495', 'text': 'Categories:'}, {'x': 1502, 'y': 648, 'w': 215, 'h': 36, 'confidence': '0.9434827964398017', 'text': 'Output token limit'}, {'x': 217, 'y': 699, 'w': 117, 'h': 42, 'confidence': '0.999971424267591', 'text': 'Scarcity'}, {'x': 1782, 'y': 720, 'w': 66, 'h': 30, 'confidence': '0.6683684591109772', 'text': '8192'}, {'x': 1944, 'y': 714, 'w': 52, 'h': 28, 'confidence': '0.9999997246979434', 'text': '204'}, {'x': 220, 'y': 748, 'w': 190, 'h': 30, 'confidence': '0.9994148052891809', 'text': 'Loss-Aversion'}, {'x': 218, 'y': 790, 'w': 191, 'h': 42, 'confidence': '0.7279017011883301', 'text': 'Appeal to Ego'}, {'x': 1576, 'y': 790, 'w': 294, 'h': 32, 'confidence': '0.8902954948880639', 'text': 'Ground model responses'}, {'x': 218, 'y': 831, 'w': 147, 'h': 42, 'confidence': '0.9998380439613387', 'text': 'Exclusivity'}, {'x': 218, 'y': 875, 'w': 181, 'h': 42, 'confidence': '0.9999894008295064', 'text': 'Gain-Seeking'}, {'x': 1612, 'y': 906, 'w': 136, 'h': 28, 'confidence': '0.9967510819804832', 'text': 'Customize'}, {'x': 210, 'y': 976, 'w': 136, 'h': 30, 'confidence': '0.9913031230046049', 'text': '135 tokens'}, {'x': 1525, 'y': 995, 'w': 230, 'h': 37, 'confidence': '0.8666268539580705', 'text': 'Add stop sequence'}, {'x': 1523, 'y': 1055, 'w': 341, 'h': 27, 'confidence': '0.7999745776753331', 'text': 'Press Enter after each sequence'}, {'x': 202, 'y': 1106, 'w': 143, 'h': 41, 'confidence': '0.963144092412277', 'text': 'Response'}, {'x': 1276, 'y': 1106, 'w': 128, 'h': 30, 'confidence': '0.7649591451215945', 'text': 'Markdown'}, {'x': 1527, 'y': 1122, 'w': 198, 'h': 40, 'confidence': '0.7299327278241817', 'text': 'Safety Settings'}, {'x': 205, 'y': 1205, 'w': 760, 'h': 40, 'confidence': '0.889052453270459', 'text': 'The model will generate a response after you click Submit'}, {'x': 1542, 'y': 1230, 'w': 123, 'h': 20, 'confidence': '0.281372846680256', 'text': '44.nA'}]}]\n",
      "> Image for page 79: []\n",
      "> Image for page 80: [{'name': 'img_p79_1.png', 'height': 306, 'width': 1620, 'x': 12.000000384, 'y': 78.40945132799999, 'original_width': 1620, 'original_height': 306, 'ocr': [{'x': 21, 'y': 13, 'w': 179, 'h': 48, 'confidence': '0.9502467360778942', 'text': 'PROJECT_ID'}, {'x': 241, 'y': 18, 'w': 479, 'h': 38, 'confidence': '0.8359564690824316', 'text': '\"dlai-shortcourse-on-gemini\"'}, {'x': 781, 'y': 18, 'w': 380, 'h': 44, 'confidence': '0.9993986587976349', 'text': '@param {type:\"string\"}'}, {'x': 24, 'y': 58, 'w': 140, 'h': 32, 'confidence': '0.9998740619317729', 'text': 'LOCATION'}, {'x': 208, 'y': 58, 'w': 226, 'h': 32, 'confidence': '0.684926876833409', 'text': '\"us-centrall\"'}, {'x': 459, 'y': 56, 'w': 414, 'h': 44, 'confidence': '0.9981021429813818', 'text': '# @param {type:\"string\"}'}, {'x': 22, 'y': 170, 'w': 111, 'h': 40, 'confidence': '0.9985086637340603', 'text': 'import'}, {'x': 142, 'y': 172, 'w': 140, 'h': 32, 'confidence': '0.9944859882467921', 'text': 'vertexai'}, {'x': 22, 'y': 240, 'w': 563, 'h': 48, 'confidence': '0.8767423329807855', 'text': 'vertexai.init(project-PROJECT_ID ,'}, {'x': 597, 'y': 248, 'w': 294, 'h': 32, 'confidence': '0.9863776821661594', 'text': 'location-LOCATION'}]}]\n",
      "> Image for page 81: [{'name': 'img_p80_1.png', 'height': 495, 'width': 2048, 'x': 12.000000384, 'y': 57.09449001599998, 'original_width': 2048, 'original_height': 495, 'ocr': [{'x': 1801, 'y': 11, 'w': 26, 'h': 14, 'confidence': '0.39322690343433486', 'text': 'CJ'}, {'x': 1838, 'y': 4, 'w': 32, 'h': 24, 'confidence': '0.19596194229322705', 'text': 'A'}, {'x': 1916, 'y': 4, 'w': 32, 'h': 28, 'confidence': '0.9926378831378315', 'text': '0'}, {'x': 1956, 'y': 6, 'w': 26, 'h': 24, 'confidence': '0.1638201415189542', 'text': 'W'}, {'x': 20, 'y': 32, 'w': 550, 'h': 28, 'confidence': '0.7088907793097817', 'text': 'rom vertexai generative_models import GenerativeModel'}, {'x': 9, 'y': 97, 'w': 56, 'h': 20, 'confidence': '0.999887990716035', 'text': 'model'}, {'x': 90, 'y': 93, 'w': 378, 'h': 29, 'confidence': '0.8671383781766109', 'text': 'GenerativeModel ( \"gemini-1.0-pro-002\"'}, {'x': 12, 'y': 158, 'w': 1134, 'h': 28, 'confidence': '0.6123246894814831', 'text': 'Recheck your project name; and be sure it matches the name assigned when setting up the Google Cloud Project. Note that project'}, {'x': 13, 'y': 193, 'w': 190, 'h': 20, 'confidence': '0.6156127193908181', 'text': 'names are lowercase.'}, {'x': 12, 'y': 219, 'w': 782, 'h': 29, 'confidence': '0.6002842569935088', 'text': 'Ensure you completed Step 5 of the instructions on setting up Google Cloud and Vertex Al:'}, {'x': 6, 'y': 285, 'w': 78, 'h': 29, 'confidence': '0.9487006905700884', 'text': 'gemini('}, {'x': 91, 'y': 289, 'w': 78, 'h': 20, 'confidence': '0.901369141402822', 'text': \"'What is\"}, {'x': 193, 'y': 289, 'w': 192, 'h': 20, 'confidence': '0.869885652303509', 'text': 'multimodal model?\"'}, {'x': 399, 'y': 289, 'w': 126, 'h': 20, 'confidence': '0.9704211109640829', 'text': 'model-model)'}, {'x': 17, 'y': 333, 'w': 108, 'h': 20, 'confidence': '0.7660160843181781', 'text': '## What is'}, {'x': 132, 'y': 331, 'w': 364, 'h': 25, 'confidence': '0.6240924672654301', 'text': 'a Multimodal Model?inlnA multimodal'}, {'x': 503, 'y': 333, 'w': 86, 'h': 20, 'confidence': '0.847114553275755', 'text': 'model is'}, {'x': 594, 'y': 330, 'w': 344, 'h': 28, 'confidence': '0.7794805754524146', 'text': 'a type 0f artificial intelligence'}, {'x': 944, 'y': 332, 'w': 44, 'h': 24, 'confidence': '0.9999277591705322', 'text': '(AI)'}, {'x': 995, 'y': 333, 'w': 44, 'h': 20, 'confidence': '0.5830930502966587', 'text': 'that'}, {'x': 1048, 'y': 330, 'w': 658, 'h': 27, 'confidence': '0.8168601083678908', 'text': 'can process and understand information from multiple modalities ,'}, {'x': 1713, 'y': 335, 'w': 46, 'h': 20, 'confidence': '0.9999187588691711', 'text': 'such'}, {'x': 1767, 'y': 337, 'w': 22, 'h': 16, 'confidence': '0.9994914940020913', 'text': 'as'}, {'x': 1797, 'y': 337, 'w': 52, 'h': 18, 'confidence': '0.9994809383189068', 'text': 'text,'}, {'x': 1855, 'y': 331, 'w': 69, 'h': 28, 'confidence': '0.9996669106609389', 'text': 'images'}, {'x': 1941, 'y': 335, 'w': 62, 'h': 20, 'confidence': '0.773219008353784', 'text': 'audio ,'}, {'x': 9, 'y': 355, 'w': 94, 'h': 20, 'confidence': '0.8653348372319923', 'text': 'nd video.'}, {'x': 111, 'y': 355, 'w': 170, 'h': 20, 'confidence': '0.9661546264121733', 'text': 'This allows them'}, {'x': 286, 'y': 350, 'w': 457, 'h': 30, 'confidence': '0.906354368732401', 'text': 'to better understand the context and meaning'}, {'x': 748, 'y': 351, 'w': 242, 'h': 29, 'confidence': '0.8849437929254454', 'text': 'of information, leading'}, {'x': 994, 'y': 352, 'w': 242, 'h': 27, 'confidence': '0.9623621018108883', 'text': 'to improved performance'}, {'x': 1243, 'y': 361, 'w': 22, 'h': 14, 'confidence': '0.9859934987134619', 'text': 'on'}, {'x': 1272, 'y': 354, 'w': 108, 'h': 24, 'confidence': '0.9982946636743587', 'text': 'tasks such'}, {'x': 1386, 'y': 353, 'w': 189, 'h': 25, 'confidence': '0.4536675897773262', 'text': 'as: Ilnx *xMachine'}, {'x': 1580, 'y': 350, 'w': 324, 'h': 30, 'confidence': '0.5438057350536528', 'text': 'translation:** Translating text'}, {'x': 1911, 'y': 357, 'w': 44, 'h': 18, 'confidence': '0.9994911551475525', 'text': 'from'}, {'x': 1961, 'y': 359, 'w': 34, 'h': 16, 'confidence': '0.9996664101822296', 'text': 'one'}, {'x': 2003, 'y': 355, 'w': 22, 'h': 20, 'confidence': '0.49014193812304013', 'text': 'La'}, {'x': 8, 'y': 374, 'w': 188, 'h': 28, 'confidence': '0.9969396518501759', 'text': 'nguage to another,'}, {'x': 203, 'y': 374, 'w': 67, 'h': 26, 'confidence': '0.9999957173029362', 'text': 'taking'}, {'x': 277, 'y': 377, 'w': 236, 'h': 20, 'confidence': '0.6818495811130268', 'text': 'into account the visual'}, {'x': 523, 'y': 377, 'w': 148, 'h': 20, 'confidence': '0.9727402004608257', 'text': 'context of the'}, {'x': 679, 'y': 379, 'w': 84, 'h': 18, 'confidence': '0.9855860358473415', 'text': 'text.Inx'}, {'x': 767, 'y': 374, 'w': 571, 'h': 29, 'confidence': '0.5801636855151947', 'text': '#*Image captioning;** Generating descriptions of images'}, {'x': 1350, 'y': 372, 'w': 338, 'h': 30, 'confidence': '0.6148403693829875', 'text': 'taking into account the text and'}, {'x': 1695, 'y': 381, 'w': 64, 'h': 16, 'confidence': '0.28199099936027355', 'text': 'visua ['}, {'x': 1766, 'y': 376, 'w': 262, 'h': 24, 'confidence': '0.6442016447848068', 'text': 'cues Within the image. Inx'}, {'x': 7, 'y': 399, 'w': 108, 'h': 20, 'confidence': '0.7634244203671963', 'text': 'xxQuestion'}, {'x': 122, 'y': 398, 'w': 98, 'h': 24, 'confidence': '0.9999983708057125', 'text': 'answering'}, {'x': 225, 'y': 403, 'w': 24, 'h': 14, 'confidence': '0.7054077310974002', 'text': '**'}, {'x': 253, 'y': 396, 'w': 265, 'h': 26, 'confidence': '0.9792272792188094', 'text': 'Answering questions based'}, {'x': 525, 'y': 403, 'w': 22, 'h': 16, 'confidence': '0.9985459906485568', 'text': 'on'}, {'x': 574, 'y': 399, 'w': 309, 'h': 20, 'confidence': '0.8181459445803456', 'text': 'combination of text and visual'}, {'x': 892, 'y': 396, 'w': 386, 'h': 26, 'confidence': '0.5132374239529103', 'text': 'information. In* x*Video understanding:'}, {'x': 1283, 'y': 405, 'w': 24, 'h': 12, 'confidence': '0.22773212420846986', 'text': 'Xt'}, {'x': 1312, 'y': 398, 'w': 376, 'h': 24, 'confidence': '0.8349868761438275', 'text': 'Analyzing videos to identify objects'}, {'x': 1703, 'y': 399, 'w': 76, 'h': 20, 'confidence': '0.9999875192201169', 'text': 'actions'}, {'x': 1795, 'y': 399, 'w': 36, 'h': 20, 'confidence': '0.6008893251419067', 'text': 'and'}, {'x': 1839, 'y': 399, 'w': 186, 'h': 20, 'confidence': '0.65777782738537', 'text': 'events. Inlnln### H'}, {'x': 11, 'y': 427, 'w': 24, 'h': 14, 'confidence': '0.675533114977817', 'text': 'Ow'}, {'x': 38, 'y': 420, 'w': 591, 'h': 24, 'confidence': '0.8014375194931281', 'text': 'Do Multimodal Models Work?InlnMultimodal models typically'}, {'x': 635, 'y': 423, 'w': 36, 'h': 18, 'confidence': '0.9999803159285474', 'text': 'use'}, {'x': 678, 'y': 420, 'w': 188, 'h': 24, 'confidence': '0.9624162585724623', 'text': 'a technique called'}, {'x': 871, 'y': 421, 'w': 618, 'h': 20, 'confidence': '0.48355748225424344', 'text': 'xxfusionxx to combine information from different modalities.'}, {'x': 1497, 'y': 421, 'w': 46, 'h': 20, 'confidence': '0.9992700219154358', 'text': 'This'}, {'x': 1549, 'y': 421, 'w': 230, 'h': 20, 'confidence': '0.9066428567498254', 'text': 'can be done in several'}, {'x': 1787, 'y': 425, 'w': 52, 'h': 18, 'confidence': '0.9994010716495039', 'text': 'ways,'}, {'x': 1847, 'y': 421, 'w': 46, 'h': 20, 'confidence': '0.9999819397926331', 'text': 'such'}, {'x': 1899, 'y': 421, 'w': 86, 'h': 20, 'confidence': '0.6330867025798147', 'text': 'as: Inlnx'}, {'x': 1991, 'y': 423, 'w': 36, 'h': 18, 'confidence': '0.3247653236130271', 'text': '*XE'}, {'x': 8, 'y': 442, 'w': 212, 'h': 24, 'confidence': '0.8994232485995985', 'text': 'arly fusion:** Combi'}]}]\n",
      "> Image for page 82: [{'name': 'img_p81_1.png', 'height': 770, 'width': 744, 'x': 374.36812221599996, 'y': 57.76183255704001, 'original_width': 744, 'original_height': 770, 'ocr': [{'x': 14, 'y': 714, 'w': 108, 'h': 32, 'confidence': '0.9997894129563992', 'text': 'Please'}, {'x': 132, 'y': 714, 'w': 142, 'h': 32, 'confidence': '0.9999981455379533', 'text': 'describe'}, {'x': 284, 'y': 714, 'w': 72, 'h': 32, 'confidence': '0.9999038778916599', 'text': 'what'}, {'x': 370, 'y': 714, 'w': 38, 'h': 32, 'confidence': '0.9806430028088611', 'text': 'is'}, {'x': 420, 'y': 714, 'w': 38, 'h': 32, 'confidence': '0.9996265150597693', 'text': 'in'}, {'x': 470, 'y': 714, 'w': 72, 'h': 32, 'confidence': '0.9999967813491821', 'text': 'this'}, {'x': 555, 'y': 713, 'w': 106, 'h': 38, 'confidence': '0.998752468052578', 'text': 'image?'}]}, {'name': 'img_p81_2.png', 'height': 880, 'width': 1186, 'x': 15.996063503999999, 'y': 62.95668705398401, 'original_width': 1186, 'original_height': 880, 'ocr': [{'x': 19, 'y': 9, 'w': 532, 'h': 42, 'confidence': '0.929868945927867', 'text': 'from vertexai.generative_models'}, {'x': 561, 'y': 13, 'w': 108, 'h': 36, 'confidence': '0.9997670736951464', 'text': 'import'}, {'x': 685, 'y': 17, 'w': 14, 'h': 24, 'confidence': '0.9999902248621453', 'text': '('}, {'x': 86, 'y': 46, 'w': 275, 'h': 41, 'confidence': '0.9972764376735113', 'text': 'GenerativeModel,'}, {'x': 87, 'y': 87, 'w': 107, 'h': 42, 'confidence': '0.9954276739797031', 'text': 'Image ,'}, {'x': 90, 'y': 128, 'w': 74, 'h': 26, 'confidence': '0.9999701380729675', 'text': 'Part'}, {'x': 51, 'y': 161, 'w': 272, 'h': 36, 'confidence': '0.9905758217398378', 'text': 'GenerativeModel:'}, {'x': 335, 'y': 161, 'w': 276, 'h': 38, 'confidence': '0.8176160522814285', 'text': 'multimodal_model'}, {'x': 49, 'y': 215, 'w': 711, 'h': 42, 'confidence': '0.7664180625735966', 'text': 'vertexai . generative_models.GenerativeModel'}, {'x': 773, 'y': 217, 'w': 142, 'h': 36, 'confidence': '0.999982171817252', 'text': 'instance'}, {'x': 21, 'y': 262, 'w': 278, 'h': 41, 'confidence': '0.9836885873407023', 'text': 'multimodal_model'}, {'x': 341, 'y': 265, 'w': 748, 'h': 38, 'confidence': '0.5896702419371143', 'text': 'GenerativeModel (\"gemini-1.0-pro-vision-001\" )'}, {'x': 21, 'y': 366, 'w': 93, 'h': 42, 'confidence': '0.998283499015133', 'text': 'image'}, {'x': 155, 'y': 365, 'w': 780, 'h': 44, 'confidence': '0.607455773472833', 'text': 'Image. load_from_file( \"andrew_power_tools.png\" )'}, {'x': 20, 'y': 468, 'w': 145, 'h': 44, 'confidence': '0.8551355906100356', 'text': 'prompt_3'}, {'x': 206, 'y': 470, 'w': 126, 'h': 32, 'confidence': '0.7396940796953146', 'text': '\"Please'}, {'x': 342, 'y': 470, 'w': 142, 'h': 32, 'confidence': '0.9562339197061962', 'text': 'describe'}, {'x': 494, 'y': 470, 'w': 72, 'h': 32, 'confidence': '0.9707502371509485', 'text': 'what'}, {'x': 578, 'y': 470, 'w': 40, 'h': 32, 'confidence': '0.9917500636042734', 'text': 'is'}, {'x': 630, 'y': 470, 'w': 38, 'h': 32, 'confidence': '0.9990472770302872', 'text': 'in'}, {'x': 678, 'y': 470, 'w': 74, 'h': 32, 'confidence': '0.9309270064000851', 'text': 'this'}, {'x': 763, 'y': 469, 'w': 124, 'h': 38, 'confidence': '0.9982911969533073', 'text': 'image?\"'}, {'x': 23, 'y': 549, 'w': 20, 'h': 26, 'confidence': '0.45741172269621283', 'text': '#'}, {'x': 52, 'y': 544, 'w': 145, 'h': 43, 'confidence': '0.7321908633671135', 'text': 'prompt_3'}, {'x': 240, 'y': 546, 'w': 90, 'h': 32, 'confidence': '0.9999950846314297', 'text': '\"What'}, {'x': 341, 'y': 540, 'w': 378, 'h': 45, 'confidence': '0.9333900526644673', 'text': 'are likely professions'}, {'x': 730, 'y': 546, 'w': 40, 'h': 32, 'confidence': '0.9684234354898373', 'text': 'of'}, {'x': 779, 'y': 543, 'w': 229, 'h': 42, 'confidence': '0.6860189958617076', 'text': 'this person?\"'}, {'x': 21, 'y': 647, 'w': 244, 'h': 38, 'confidence': '0.9986564824294661', 'text': 'contents_image'}, {'x': 308, 'y': 643, 'w': 123, 'h': 48, 'confidence': '0.9997777715129864', 'text': '[image,'}, {'x': 442, 'y': 646, 'w': 157, 'h': 41, 'confidence': '0.9724739357061671', 'text': 'prompt_3]'}, {'x': 56, 'y': 749, 'w': 173, 'h': 33, 'confidence': '0.9742806949217206', 'text': 'from utils'}, {'x': 241, 'y': 745, 'w': 512, 'h': 44, 'confidence': '0.9811076979414086', 'text': 'import print_multimodal_prompt'}, {'x': 19, 'y': 822, 'w': 95, 'h': 42, 'confidence': '0.6512972670940568', 'text': 'print_'}, {'x': 121, 'y': 824, 'w': 294, 'h': 42, 'confidence': '0.99967529776438', 'text': 'multimodal_prompt'}, {'x': 425, 'y': 824, 'w': 258, 'h': 42, 'confidence': '0.9962030089052041', 'text': 'contents_image)'}]}, {'name': 'img_p81_3.png', 'height': 174, 'width': 2048, 'x': 11.332677528, 'y': 328.39769554809595, 'original_width': 2048, 'original_height': 174, 'ocr': [{'x': 37, 'y': 25, 'w': 329, 'h': 27, 'confidence': '0.8094009321138811', 'text': 'from utils import gemini_Vision'}, {'x': 15, 'y': 72, 'w': 307, 'h': 29, 'confidence': '0.9400503448245594', 'text': 'gemini_Vision(contents_image,'}, {'x': 329, 'y': 75, 'w': 242, 'h': 20, 'confidence': '0.8827469635472562', 'text': 'model-multimodal_model)'}, {'x': 36, 'y': 117, 'w': 162, 'h': 28, 'confidence': '0.8522447916037058', 'text': 'The image shows'}, {'x': 224, 'y': 116, 'w': 121, 'h': 28, 'confidence': '0.9044184424710033', 'text': 'man holding'}, {'x': 370, 'y': 119, 'w': 68, 'h': 26, 'confidence': '0.9999739144176095', 'text': 'hammer'}, {'x': 443, 'y': 121, 'w': 26, 'h': 18, 'confidence': '0.9986487866903827', 'text': 'in'}, {'x': 476, 'y': 118, 'w': 88, 'h': 24, 'confidence': '0.9986525262881419', 'text': 'one hand'}, {'x': 569, 'y': 123, 'w': 36, 'h': 18, 'confidence': '0.9999995870469189', 'text': 'and'}, {'x': 632, 'y': 118, 'w': 314, 'h': 26, 'confidence': '0.7589677636287747', 'text': 'power drill in the other hand.'}, {'x': 952, 'y': 115, 'w': 298, 'h': 29, 'confidence': '0.7411634397603958', 'text': 'He is Smiling and looking at'}, {'x': 1256, 'y': 118, 'w': 38, 'h': 24, 'confidence': '0.9999991052683532', 'text': 'the'}, {'x': 1301, 'y': 125, 'w': 72, 'h': 16, 'confidence': '0.9855584279917212', 'text': 'camera.'}, {'x': 1380, 'y': 115, 'w': 142, 'h': 29, 'confidence': '0.9440202629189721', 'text': 'He is wearing'}, {'x': 1546, 'y': 118, 'w': 112, 'h': 24, 'confidence': '0.9500464485330353', 'text': 'blue shirt'}, {'x': 1662, 'y': 118, 'w': 288, 'h': 24, 'confidence': '0.4546386386935889', 'text': 'and he has short black hair'}, {'x': 1962, 'y': 118, 'w': 86, 'h': 24, 'confidence': '0.982102259270544', 'text': 'The back'}, {'x': 17, 'y': 143, 'w': 86, 'h': 20, 'confidence': '0.7061271433240259', 'text': 'round is'}, {'x': 130, 'y': 144, 'w': 48, 'h': 24, 'confidence': '0.999991774559021', 'text': 'grey'}, {'x': 183, 'y': 143, 'w': 54, 'h': 20, 'confidence': '0.8822235770535877', 'text': 'wall.'}]}]\n",
      "> Image for page 83: [{'name': 'img_p82_1.png', 'height': 865, 'width': 2048, 'x': 19.984252608, 'y': 57.95275776, 'original_width': 2048, 'original_height': 865, 'ocr': [{'x': 12, 'y': 4, 'w': 90, 'h': 30, 'confidence': '0.9999873465649548', 'text': 'prompt'}, {'x': 10, 'y': 35, 'w': 94, 'h': 32, 'confidence': '0.9999860812194711', 'text': 'Answer'}, {'x': 113, 'y': 31, 'w': 661, 'h': 40, 'confidence': '0.9159195629401413', 'text': 'the following questions using the video only:'}, {'x': 54, 'y': 68, 'w': 66, 'h': 30, 'confidence': '0.9087140145237074', 'text': 'What'}, {'x': 128, 'y': 70, 'w': 34, 'h': 26, 'confidence': '0.9812232030816731', 'text': 'is'}, {'x': 172, 'y': 68, 'w': 224, 'h': 32, 'confidence': '0.9972707543762578', 'text': 'the main person'}, {'x': 405, 'y': 73, 'w': 18, 'h': 22, 'confidence': '0.5834975603029449', 'text': 'S'}, {'x': 432, 'y': 63, 'w': 167, 'h': 38, 'confidence': '0.9999449343976499', 'text': 'profession?'}, {'x': 54, 'y': 102, 'w': 64, 'h': 28, 'confidence': '0.9999933242797852', 'text': 'What'}, {'x': 128, 'y': 106, 'w': 48, 'h': 24, 'confidence': '0.9999982105368138', 'text': 'are'}, {'x': 186, 'y': 102, 'w': 251, 'h': 30, 'confidence': '0.7143796317942661', 'text': 'the main features'}, {'x': 448, 'y': 102, 'w': 34, 'h': 26, 'confidence': '0.971063838598238', 'text': 'of'}, {'x': 491, 'y': 99, 'w': 330, 'h': 36, 'confidence': '0.9594416261879961', 'text': 'the phone highlighted?'}, {'x': 53, 'y': 133, 'w': 156, 'h': 36, 'confidence': '0.8149455059780354', 'text': 'Which city'}, {'x': 214, 'y': 138, 'w': 50, 'h': 24, 'confidence': '0.9981337543205339', 'text': 'was'}, {'x': 274, 'y': 134, 'w': 64, 'h': 30, 'confidence': '0.9999902248382568', 'text': 'this'}, {'x': 348, 'y': 134, 'w': 180, 'h': 30, 'confidence': '0.9534473675362868', 'text': 'recorded in?'}, {'x': 12, 'y': 256, 'w': 78, 'h': 26, 'confidence': '0.9998229459724044', 'text': 'video'}, {'x': 127, 'y': 251, 'w': 354, 'h': 39, 'confidence': '0.9151240936880681', 'text': 'Part. from_uri(video_uri,'}, {'x': 490, 'y': 251, 'w': 327, 'h': 38, 'confidence': '0.8947545273200995', 'text': 'mime_type=\"video/mp4\" )'}, {'x': 12, 'y': 288, 'w': 210, 'h': 30, 'confidence': '0.9037423194722988', 'text': 'contents_video'}, {'x': 260, 'y': 286, 'w': 121, 'h': 37, 'confidence': '0.9993139203943292', 'text': '[prompt,'}, {'x': 390, 'y': 287, 'w': 90, 'h': 30, 'confidence': '0.9996700255803364', 'text': 'video]'}, {'x': 19, 'y': 373, 'w': 1670, 'h': 43, 'confidence': '0.8697757183556679', 'text': 'This cell is converted to markdown to prevent accidentally executing it The cost to run this cell is approximately 0.12 USD (as of August'}, {'x': 0, 'y': 424, 'w': 26, 'h': 34, 'confidence': '0.7085012240739623', 'text': '4).'}, {'x': 0, 'y': 479, 'w': 247, 'h': 38, 'confidence': '0.7356552587138401', 'text': 'thon responses_4 ='}, {'x': 248, 'y': 475, 'w': 833, 'h': 43, 'confidence': '0.6365841103764214', 'text': 'multimodal_model.generate_content(contents_video, stream-True)'}, {'x': 12, 'y': 580, 'w': 136, 'h': 26, 'confidence': '0.9999771929900265', 'text': 'responses_'}, {'x': 157, 'y': 579, 'w': 18, 'h': 22, 'confidence': '1.0', 'text': '4'}, {'x': 212, 'y': 571, 'w': 721, 'h': 38, 'confidence': '0.9275199348478391', 'text': 'multimodal_model.generate_content (contents_video,'}, {'x': 944, 'y': 575, 'w': 178, 'h': 28, 'confidence': '0.7471975463866461', 'text': 'stream-True)'}, {'x': 12, 'y': 664, 'w': 48, 'h': 26, 'confidence': '0.9999562959256643', 'text': 'for'}, {'x': 70, 'y': 668, 'w': 122, 'h': 26, 'confidence': '0.9999945163651631', 'text': 'response'}, {'x': 202, 'y': 664, 'w': 34, 'h': 30, 'confidence': '0.9993111371284906', 'text': 'in'}, {'x': 246, 'y': 668, 'w': 136, 'h': 26, 'confidence': '0.9999511059236931', 'text': 'responses_'}, {'x': 390, 'y': 666, 'w': 32, 'h': 24, 'confidence': '0.9972291274964237', 'text': '4:'}, {'x': 65, 'y': 692, 'w': 85, 'h': 40, 'confidence': '0.9999661468028405', 'text': 'print'}, {'x': 158, 'y': 698, 'w': 204, 'h': 30, 'confidence': '0.7131107968901246', 'text': 'response.text,'}, {'x': 376, 'y': 696, 'w': 64, 'h': 28, 'confidence': '0.9890533089637756', 'text': 'end='}, {'x': 437, 'y': 699, 'w': 30, 'h': 14, 'confidence': '0.35782429925115267', 'text': 'I'}, {'x': 54, 'y': 758, 'w': 50, 'h': 30, 'confidence': '0.9999295230049533', 'text': 'The'}, {'x': 110, 'y': 758, 'w': 168, 'h': 32, 'confidence': '0.7422430070562084', 'text': 'main person'}, {'x': 287, 'y': 763, 'w': 18, 'h': 22, 'confidence': '0.46270769238959986', 'text': '5'}, {'x': 314, 'y': 754, 'w': 153, 'h': 37, 'confidence': '0.7976401164674491', 'text': 'profession'}, {'x': 478, 'y': 760, 'w': 34, 'h': 28, 'confidence': '0.9789441360287366', 'text': 'is'}, {'x': 520, 'y': 760, 'w': 48, 'h': 26, 'confidence': '0.9999470045412716', 'text': 'not'}, {'x': 578, 'y': 758, 'w': 136, 'h': 28, 'confidence': '0.9998560297326687', 'text': 'mentioned'}, {'x': 726, 'y': 758, 'w': 92, 'h': 30, 'confidence': '0.964493658017945', 'text': 'in the'}, {'x': 826, 'y': 757, 'w': 90, 'h': 28, 'confidence': '0.9990405728548715', 'text': 'video.'}, {'x': 40, 'y': 788, 'w': 121, 'h': 31, 'confidence': '0.9095141247893446', 'text': 'The main'}, {'x': 170, 'y': 790, 'w': 120, 'h': 26, 'confidence': '0.9999967125435779', 'text': 'features'}, {'x': 302, 'y': 790, 'w': 32, 'h': 26, 'confidence': '0.9324416087636616', 'text': 'of'}, {'x': 346, 'y': 790, 'w': 48, 'h': 26, 'confidence': '0.9999996558724309', 'text': 'the'}, {'x': 403, 'y': 787, 'w': 256, 'h': 36, 'confidence': '0.7469366437800998', 'text': 'phone highlighted'}, {'x': 666, 'y': 792, 'w': 48, 'h': 24, 'confidence': '0.999999380570387', 'text': 'are'}, {'x': 724, 'y': 790, 'w': 50, 'h': 28, 'confidence': '0.9999983481878129', 'text': 'the'}, {'x': 782, 'y': 792, 'w': 92, 'h': 24, 'confidence': '0.9999904612599968', 'text': 'camera'}, {'x': 884, 'y': 790, 'w': 48, 'h': 26, 'confidence': '0.9999991052683532', 'text': 'and'}, {'x': 941, 'y': 783, 'w': 171, 'h': 40, 'confidence': '0.9290350716649481', 'text': 'the ability'}, {'x': 1118, 'y': 790, 'w': 34, 'h': 26, 'confidence': '0.9999642596595324', 'text': 'to'}, {'x': 1161, 'y': 783, 'w': 238, 'h': 39, 'confidence': '0.863941890185591', 'text': 'take good photos'}, {'x': 1410, 'y': 790, 'w': 48, 'h': 26, 'confidence': '0.9999985546643163', 'text': 'and'}, {'x': 1466, 'y': 788, 'w': 94, 'h': 28, 'confidence': '0.9997156783674909', 'text': 'videos'}, {'x': 1570, 'y': 790, 'w': 36, 'h': 28, 'confidence': '0.99914317782873', 'text': 'in'}, {'x': 1613, 'y': 787, 'w': 308, 'h': 36, 'confidence': '0.7485853466904149', 'text': 'low light conditions.'}, {'x': 38, 'y': 818, 'w': 50, 'h': 28, 'confidence': '0.9999002036698248', 'text': 'The'}, {'x': 96, 'y': 818, 'w': 78, 'h': 28, 'confidence': '0.9996874792034124', 'text': 'video'}, {'x': 184, 'y': 822, 'w': 48, 'h': 24, 'confidence': '0.9979482494720336', 'text': 'was'}, {'x': 244, 'y': 818, 'w': 122, 'h': 30, 'confidence': '0.9999656079266446', 'text': 'recorded'}, {'x': 376, 'y': 820, 'w': 124, 'h': 32, 'confidence': '0.6692479455175109', 'text': 'in Tokyo,'}, {'x': 519, 'y': 819, 'w': 91, 'h': 32, 'confidence': '0.8669224538444388', 'text': 'Japan .'}]}, {'name': 'img_p82_2.png', 'height': 556, 'width': 952, 'x': 469.25013312624, 'y': 49.75788348201601, 'original_width': 952, 'original_height': 556, 'ocr': [{'x': 106, 'y': 418, 'w': 140, 'h': 30, 'confidence': '0.48799617266047424', 'text': '0.00 / 0.57'}]}]\n",
      "> Image for page 84: [{'name': 'img_p83_1.png', 'height': 796, 'width': 952, 'x': 153.88386319199998, 'y': 51.09842683199997, 'original_width': 952, 'original_height': 796, 'ocr': [{'x': 8, 'y': 178, 'w': 166, 'h': 32, 'confidence': '0.4223141529273201', 'text': 'Grouping custorners'}, {'x': 8, 'y': 706, 'w': 90, 'h': 32, 'confidence': '0.9999846461257681', 'text': 'Write'}, {'x': 110, 'y': 708, 'w': 72, 'h': 30, 'confidence': '0.999925434589386', 'text': 'what'}, {'x': 193, 'y': 704, 'w': 210, 'h': 40, 'confidence': '0.990541660433486', 'text': 'is happening'}, {'x': 414, 'y': 708, 'w': 38, 'h': 30, 'confidence': '0.9995551268562354', 'text': 'in'}, {'x': 463, 'y': 701, 'w': 328, 'h': 45, 'confidence': '0.9356852820051926', 'text': 'the following image'}, {'x': 10, 'y': 742, 'w': 72, 'h': 32, 'confidence': '0.9999169111251831', 'text': 'from'}, {'x': 93, 'y': 749, 'w': 18, 'h': 22, 'confidence': '0.9998922377055806', 'text': 'a'}, {'x': 122, 'y': 736, 'w': 316, 'h': 48, 'confidence': '0.9992454476911212', 'text': 'unique perspective'}, {'x': 446, 'y': 742, 'w': 56, 'h': 32, 'confidence': '0.9999966963759913', 'text': 'and'}, {'x': 514, 'y': 742, 'w': 40, 'h': 32, 'confidence': '0.9999900533582403', 'text': 'do'}, {'x': 564, 'y': 744, 'w': 56, 'h': 30, 'confidence': '0.9999390896673935', 'text': 'not'}, {'x': 630, 'y': 742, 'w': 126, 'h': 32, 'confidence': '0.9999596287757131', 'text': 'mention'}, {'x': 765, 'y': 745, 'w': 90, 'h': 28, 'confidence': '0.9998559433814728', 'text': 'names'}]}]\n",
      "> Image for page 85: [{'name': 'img_p84_1.png', 'height': 648, 'width': 2048, 'x': 12.000000384, 'y': 57.09449001600004, 'original_width': 2048, 'original_height': 648, 'ocr': [{'x': 11, 'y': 3, 'w': 205, 'h': 27, 'confidence': '0.9854520126868296', 'text': 'generation_config_1'}, {'x': 240, 'y': 4, 'w': 182, 'h': 26, 'confidence': '0.9489752902864781', 'text': 'GenerationConfig ('}, {'x': 53, 'y': 27, 'w': 165, 'h': 25, 'confidence': '0.6126750453131635', 'text': 'temperature-0.0 _'}, {'x': 97, 'y': 53, 'w': 36, 'h': 20, 'confidence': '0.5104632420190662', 'text': 'k=l'}, {'x': 15, 'y': 141, 'w': 86, 'h': 20, 'confidence': '0.8466480419940096', 'text': 'response_'}, {'x': 106, 'y': 137, 'w': 100, 'h': 25, 'confidence': '0.9739718164770189', 'text': 'zero_temp'}, {'x': 228, 'y': 135, 'w': 258, 'h': 29, 'confidence': '0.829478745908198', 'text': 'gemini_Vision_parameters'}, {'x': 261, 'y': 160, 'w': 97, 'h': 26, 'confidence': '0.9059307090872073', 'text': 'contents,'}, {'x': 263, 'y': 191, 'w': 26, 'h': 14, 'confidence': '0.9969460583016169', 'text': 'mu'}, {'x': 282, 'y': 184, 'w': 160, 'h': 24, 'confidence': '0.9287862207854508', 'text': 'ltimodal_model,'}, {'x': 259, 'y': 206, 'w': 215, 'h': 28, 'confidence': '0.8212090862137132', 'text': 'generation_config_1)'}, {'x': 14, 'y': 270, 'w': 152, 'h': 24, 'confidence': '0.7531973269373365', 'text': 'print(response_'}, {'x': 170, 'y': 269, 'w': 106, 'h': 25, 'confidence': '0.8295801507064391', 'text': 'zero_temp)'}, {'x': 44, 'y': 314, 'w': 66, 'h': 24, 'confidence': '0.9365053197207112', 'text': 'man is'}, {'x': 116, 'y': 313, 'w': 212, 'h': 27, 'confidence': '0.6773714942782733', 'text': 'standing in front of'}, {'x': 352, 'y': 314, 'w': 122, 'h': 24, 'confidence': '0.8247585641135518', 'text': 'screen with'}, {'x': 480, 'y': 314, 'w': 98, 'h': 24, 'confidence': '0.9909288238906393', 'text': 'a stuffed'}, {'x': 582, 'y': 314, 'w': 140, 'h': 24, 'confidence': '0.9521548145903679', 'text': 'animal in his'}, {'x': 729, 'y': 321, 'w': 52, 'h': 16, 'confidence': '0.933491867254388', 'text': 'arms .'}, {'x': 788, 'y': 314, 'w': 100, 'h': 24, 'confidence': '0.617074679708675', 'text': 'He is smi'}, {'x': 934, 'y': 312, 'w': 192, 'h': 28, 'confidence': '0.764951762411231', 'text': 'and looking at the'}, {'x': 1133, 'y': 321, 'w': 72, 'h': 16, 'confidence': '0.9756369121360107', 'text': 'camera.'}, {'x': 1211, 'y': 313, 'w': 91, 'h': 26, 'confidence': '0.9798272884710169', 'text': 'There is'}, {'x': 1308, 'y': 314, 'w': 78, 'h': 24, 'confidence': '0.9775952602041769', 'text': 'a slide'}, {'x': 1392, 'y': 313, 'w': 450, 'h': 28, 'confidence': '0.5440914718488177', 'text': 'on the screen that says \"Grouping Customers'}, {'x': 1908, 'y': 312, 'w': 140, 'h': 27, 'confidence': '0.5323130686041292', 'text': 'man is wearin'}, {'x': 0, 'y': 380, 'w': 448, 'h': 28, 'confidence': '0.8108613978583643', 'text': 'Repeatable for low temperature and low topK'}, {'x': 15, 'y': 459, 'w': 96, 'h': 20, 'confidence': '0.9408306220263413', 'text': 'responses_'}, {'x': 119, 'y': 457, 'w': 96, 'h': 20, 'confidence': '0.9977926846604812', 'text': 'zero_temp'}, {'x': 239, 'y': 454, 'w': 257, 'h': 26, 'confidence': '0.629352260349866', 'text': 'gemini_vision_parameters'}, {'x': 261, 'y': 478, 'w': 97, 'h': 26, 'confidence': '0.9999712703548691', 'text': 'contents,'}, {'x': 260, 'y': 502, 'w': 182, 'h': 24, 'confidence': '0.949353587488547', 'text': 'multimodal_model,'}, {'x': 261, 'y': 525, 'w': 211, 'h': 25, 'confidence': '0.9202546039541837', 'text': 'generation_config_1)'}, {'x': 11, 'y': 570, 'w': 265, 'h': 28, 'confidence': '0.9766629430594396', 'text': 'print(response_zero_temp)'}, {'x': 45, 'y': 617, 'w': 64, 'h': 20, 'confidence': '0.9621949707851049', 'text': 'man is'}, {'x': 115, 'y': 613, 'w': 213, 'h': 29, 'confidence': '0.8322592334718603', 'text': 'standing in front of'}, {'x': 357, 'y': 617, 'w': 116, 'h': 20, 'confidence': '0.986843790389074', 'text': 'screen with'}, {'x': 497, 'y': 614, 'w': 81, 'h': 26, 'confidence': '0.99997706596505', 'text': 'stuffed'}, {'x': 585, 'y': 619, 'w': 64, 'h': 20, 'confidence': '0.9996274386027376', 'text': 'animal'}, {'x': 655, 'y': 617, 'w': 66, 'h': 20, 'confidence': '0.6856755134855737', 'text': 'in his'}, {'x': 729, 'y': 623, 'w': 44, 'h': 16, 'confidence': '0.9801181813170683', 'text': 'arms'}, {'x': 789, 'y': 617, 'w': 56, 'h': 20, 'confidence': '0.9905074759935871', 'text': 'He is'}, {'x': 853, 'y': 619, 'w': 34, 'h': 18, 'confidence': '0.9802278314952134', 'text': 'smi'}, {'x': 934, 'y': 612, 'w': 121, 'h': 30, 'confidence': '0.5401189617800726', 'text': 'and Looking'}, {'x': 1061, 'y': 617, 'w': 64, 'h': 20, 'confidence': '0.9991569612000943', 'text': 'at the'}, {'x': 1135, 'y': 621, 'w': 70, 'h': 18, 'confidence': '0.9935826947631009', 'text': 'camera.'}, {'x': 1215, 'y': 617, 'w': 86, 'h': 20, 'confidence': '0.5094507332856454', 'text': 'There is'}, {'x': 1329, 'y': 617, 'w': 56, 'h': 20, 'confidence': '0.9995217777265963', 'text': 'slide'}, {'x': 1393, 'y': 623, 'w': 22, 'h': 14, 'confidence': '0.9756496665745468', 'text': 'on'}, {'x': 1421, 'y': 617, 'w': 36, 'h': 20, 'confidence': '0.9999980728858172', 'text': 'the'}, {'x': 1464, 'y': 615, 'w': 378, 'h': 27, 'confidence': '0.9943033401449981', 'text': 'screen that says \"Grouping Customers'}, {'x': 1867, 'y': 617, 'w': 36, 'h': 20, 'confidence': '0.999968959757092', 'text': 'The'}, {'x': 1909, 'y': 623, 'w': 36, 'h': 14, 'confidence': '0.9962743735832948', 'text': 'man'}, {'x': 1950, 'y': 616, 'w': 98, 'h': 25, 'confidence': '0.7690599795216289', 'text': 'is wearin'}, {'x': 55, 'y': 50, 'w': 44, 'h': 27, 'confidence': '0.9609160653645561', 'text': 'top_'}, {'x': 882, 'y': 310, 'w': 46, 'h': 31, 'confidence': '0.996877908706665', 'text': 'ling'}, {'x': 1867, 'y': 312, 'w': 34, 'h': 26, 'confidence': '0.9993194843335114', 'text': 'The'}, {'x': 882, 'y': 612, 'w': 46, 'h': 31, 'confidence': '0.9949362277984619', 'text': 'ling'}]}]\n",
      "> Image for page 86: [{'name': 'img_p85_1.png', 'height': 349, 'width': 2048, 'x': 12.000000384, 'y': 65.75392926948001, 'original_width': 2048, 'original_height': 349, 'ocr': [{'x': 0, 'y': 4, 'w': 43, 'h': 28, 'confidence': '0.9999366998672485', 'text': '[63]'}, {'x': 50, 'y': 8, 'w': 202, 'h': 26, 'confidence': '0.763760666513328', 'text': 'generation_config_2'}, {'x': 276, 'y': 8, 'w': 174, 'h': 26, 'confidence': '0.9989436948391195', 'text': 'GenerationConfig'}, {'x': 91, 'y': 30, 'w': 141, 'h': 27, 'confidence': '0.6660624784650857', 'text': 'temperature-l'}, {'x': 90, 'y': 55, 'w': 92, 'h': 26, 'confidence': '0.811628090391257', 'text': 'top_k-40_'}, {'x': 0, 'y': 140, 'w': 42, 'h': 24, 'confidence': '0.9999772310256958', 'text': '[64]'}, {'x': 50, 'y': 140, 'w': 256, 'h': 26, 'confidence': '0.9596005997959148', 'text': 'responses_high_temp_topk'}, {'x': 327, 'y': 138, 'w': 263, 'h': 28, 'confidence': '0.9737690348256919', 'text': 'gemini_vision_parameters ('}, {'x': 340, 'y': 164, 'w': 96, 'h': 24, 'confidence': '0.9316335834501077', 'text': 'contents,'}, {'x': 340, 'y': 187, 'w': 180, 'h': 25, 'confidence': '0.9478968624105649', 'text': 'multimodal_model,'}, {'x': 339, 'y': 210, 'w': 211, 'h': 26, 'confidence': '0.9921272870591658', 'text': 'generation_config_2)'}, {'x': 49, 'y': 272, 'w': 325, 'h': 28, 'confidence': '0.7390084135153316', 'text': 'print (responses_high_temp_topk)'}, {'x': 4, 'y': 318, 'w': 34, 'h': 28, 'confidence': '0.17064824017651947', 'text': '5'}, {'x': 61, 'y': 321, 'w': 54, 'h': 18, 'confidence': '0.9234872931515838', 'text': 'A man'}, {'x': 119, 'y': 314, 'w': 82, 'h': 30, 'confidence': '0.999088906039058', 'text': 'wearing'}, {'x': 224, 'y': 318, 'w': 358, 'h': 26, 'confidence': '0.8448860632146655', 'text': 'blue shirt is standing in front of'}, {'x': 588, 'y': 318, 'w': 242, 'h': 26, 'confidence': '0.9469297151351632', 'text': 'a whiteboard explaining'}, {'x': 836, 'y': 318, 'w': 192, 'h': 24, 'confidence': '0.9942646788116639', 'text': 'something while ho'}, {'x': 1104, 'y': 316, 'w': 148, 'h': 26, 'confidence': '0.950868875545247', 'text': 'stuffed panda.'}, {'x': 1260, 'y': 318, 'w': 212, 'h': 24, 'confidence': '0.7445564738881563', 'text': 'The background shows'}, {'x': 1478, 'y': 317, 'w': 366, 'h': 27, 'confidence': '0.6812821258927615', 'text': 'a side about customer grouping and'}, {'x': 1852, 'y': 318, 'w': 190, 'h': 24, 'confidence': '0.5667404968181438', 'text': 'career development'}, {'x': 1022, 'y': 313, 'w': 54, 'h': 31, 'confidence': '0.9968649928199269', 'text': 'lding'}]}]\n",
      "> Image for page 87: [{'name': 'img_p86_1.png', 'height': 362, 'width': 2048, 'x': 12.000000384, 'y': 57.09448214198399, 'original_width': 2048, 'original_height': 362, 'ocr': [{'x': 9, 'y': 8, 'w': 185, 'h': 26, 'confidence': '0.9982132732845335', 'text': 'generation_config'}, {'x': 238, 'y': 8, 'w': 184, 'h': 26, 'confidence': '0.9945780208450551', 'text': 'GenerationConfig('}, {'x': 53, 'y': 35, 'w': 148, 'h': 20, 'confidence': '0.9602390681045924', 'text': 'temperature-1,'}, {'x': 95, 'y': 57, 'w': 48, 'h': 20, 'confidence': '0.6004612957581683', 'text': 'k=40 _'}, {'x': 52, 'y': 80, 'w': 112, 'h': 24, 'confidence': '0.5040360101234453', 'text': 'top_p=0.01 _'}, {'x': 11, 'y': 165, 'w': 255, 'h': 26, 'confidence': '0.9060784856326919', 'text': 'responses_high_temp_topp'}, {'x': 291, 'y': 164, 'w': 263, 'h': 26, 'confidence': '0.9094698584832349', 'text': 'gemini_vision_parameters ('}, {'x': 303, 'y': 191, 'w': 88, 'h': 20, 'confidence': '0.9999888732063521', 'text': 'contents'}, {'x': 302, 'y': 212, 'w': 180, 'h': 26, 'confidence': '0.9976319404179856', 'text': 'multimodal_model,'}, {'x': 301, 'y': 234, 'w': 213, 'h': 28, 'confidence': '0.9284823839988272', 'text': 'generation_config_4)'}, {'x': 9, 'y': 280, 'w': 329, 'h': 29, 'confidence': '0.9301868536719131', 'text': 'print(responses_high_temp_topp)'}, {'x': 43, 'y': 329, 'w': 64, 'h': 20, 'confidence': '0.9722595315386979', 'text': 'man is'}, {'x': 111, 'y': 324, 'w': 217, 'h': 30, 'confidence': '0.7257489212810098', 'text': 'standing in front of'}, {'x': 353, 'y': 329, 'w': 120, 'h': 20, 'confidence': '0.9936327375513809', 'text': 'screen with'}, {'x': 480, 'y': 326, 'w': 232, 'h': 26, 'confidence': '0.8355885815901515', 'text': 'a stuffed panda in his'}, {'x': 719, 'y': 333, 'w': 44, 'h': 16, 'confidence': '0.9997958540916443', 'text': 'arms'}, {'x': 779, 'y': 329, 'w': 26, 'h': 20, 'confidence': '0.9999667884449074', 'text': 'He'}, {'x': 813, 'y': 329, 'w': 66, 'h': 20, 'confidence': '0.9638205664699341', 'text': 'is smi'}, {'x': 925, 'y': 329, 'w': 36, 'h': 20, 'confidence': '0.9999980728858172', 'text': 'and'}, {'x': 968, 'y': 328, 'w': 152, 'h': 24, 'confidence': '0.8795986245827635', 'text': 'looking at the'}, {'x': 1127, 'y': 333, 'w': 72, 'h': 16, 'confidence': '0.8370164258537638', 'text': 'camera.'}, {'x': 1206, 'y': 326, 'w': 90, 'h': 24, 'confidence': '0.9234290805720636', 'text': 'There is'}, {'x': 1302, 'y': 326, 'w': 78, 'h': 24, 'confidence': '0.7796790078711232', 'text': 'a slide'}, {'x': 1385, 'y': 329, 'w': 66, 'h': 20, 'confidence': '0.703597286344475', 'text': 'on the'}, {'x': 1457, 'y': 329, 'w': 118, 'h': 20, 'confidence': '0.9969497223454734', 'text': 'screen that'}, {'x': 1582, 'y': 325, 'w': 256, 'h': 29, 'confidence': '0.655547560793323', 'text': 'says \"Grouping Customers\"'}, {'x': 1862, 'y': 326, 'w': 38, 'h': 24, 'confidence': '0.9998900176366916', 'text': 'The'}, {'x': 1907, 'y': 329, 'w': 64, 'h': 20, 'confidence': '0.8206428289786911', 'text': 'man is'}, {'x': 1977, 'y': 329, 'w': 70, 'h': 20, 'confidence': '0.8353222364486438', 'text': 'wearinc'}, {'x': 53, 'y': 54, 'w': 34, 'h': 26, 'confidence': '0.9994083642959595', 'text': 'top_'}, {'x': 874, 'y': 322, 'w': 46, 'h': 33, 'confidence': '0.9169509410858154', 'text': 'ling'}]}]\n",
      "> Image for page 88: [{'name': 'img_p87_1.png', 'height': 734, 'width': 1698, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 1698, 'original_height': 734, 'ocr': [{'x': 47, 'y': 35, 'w': 386, 'h': 44, 'confidence': '0.8501956710791627', 'text': 'The range for max_output_'}, {'x': 442, 'y': 38, 'w': 150, 'h': 32, 'confidence': '0.8757485695848628', 'text': 'tokens is'}, {'x': 603, 'y': 43, 'w': 14, 'h': 24, 'confidence': '0.9999878406894283', 'text': '1'}, {'x': 650, 'y': 36, 'w': 176, 'h': 36, 'confidence': '0.97789453403663', 'text': 'inclusive)'}, {'x': 842, 'y': 40, 'w': 40, 'h': 30, 'confidence': '0.9999484969395875', 'text': 'to'}, {'x': 894, 'y': 38, 'w': 74, 'h': 32, 'confidence': '0.9999216198921204', 'text': '2049'}, {'x': 981, 'y': 37, 'w': 194, 'h': 36, 'confidence': '0.9990706573353916', 'text': '(exclusive)'}, {'x': 49, 'y': 87, 'w': 360, 'h': 40, 'confidence': '0.630162292904167', 'text': 'When using max_output'}, {'x': 418, 'y': 90, 'w': 112, 'h': 32, 'confidence': '0.9999959606381071', 'text': 'tokens'}, {'x': 541, 'y': 85, 'w': 1086, 'h': 44, 'confidence': '0.868788250372886', 'text': 'the number of words returned by the model are 1 less than what you specify:'}, {'x': 47, 'y': 139, 'w': 338, 'h': 42, 'confidence': '0.9904143467089794', 'text': 'So setting max_output'}, {'x': 396, 'y': 142, 'w': 152, 'h': 32, 'confidence': '0.9957658280497108', 'text': 'tokens to'}, {'x': 559, 'y': 145, 'w': 16, 'h': 26, 'confidence': '0.9999954700521272', 'text': '1'}, {'x': 586, 'y': 133, 'w': 830, 'h': 49, 'confidence': '0.5891900776739607', 'text': 'will throw an error; since there would be no generated text '}, {'x': 0, 'y': 246, 'w': 28, 'h': 34, 'confidence': '0.9977025061323188', 'text': '3]'}, {'x': 43, 'y': 247, 'w': 328, 'h': 40, 'confidence': '0.8960060843959365', 'text': 'generation_config_5'}, {'x': 411, 'y': 240, 'w': 295, 'h': 48, 'confidence': '0.7600085665397247', 'text': 'GenerationConfig ('}, {'x': 109, 'y': 283, 'w': 360, 'h': 42, 'confidence': '0.6425173546246857', 'text': 'max_output_tokens-10 ,'}, {'x': 45, 'y': 427, 'w': 342, 'h': 36, 'confidence': '0.9283974972326421', 'text': 'responses_max_output'}, {'x': 428, 'y': 423, 'w': 415, 'h': 43, 'confidence': '0.9884192327529563', 'text': 'gemini_vision_parameters'}, {'x': 448, 'y': 466, 'w': 154, 'h': 32, 'confidence': '0.9997160630527185', 'text': 'contents,'}, {'x': 447, 'y': 501, 'w': 292, 'h': 36, 'confidence': '0.8546401104186356', 'text': 'multimodal_model,'}, {'x': 447, 'y': 539, 'w': 342, 'h': 40, 'confidence': '0.9911580503535641', 'text': 'generation_config_5)'}, {'x': 41, 'y': 612, 'w': 264, 'h': 44, 'confidence': '0.9996489305187606', 'text': 'print(responses'}, {'x': 380, 'y': 613, 'w': 124, 'h': 44, 'confidence': '0.9997992883637341', 'text': 'output)'}, {'x': 59, 'y': 691, 'w': 18, 'h': 24, 'confidence': '0.9995931800787936', 'text': 'A'}, {'x': 92, 'y': 692, 'w': 56, 'h': 28, 'confidence': '0.9999311748019089', 'text': 'man'}, {'x': 161, 'y': 683, 'w': 190, 'h': 42, 'confidence': '0.9842505882387452', 'text': 'is standing'}, {'x': 364, 'y': 690, 'w': 38, 'h': 30, 'confidence': '0.9992877925664699', 'text': 'in'}, {'x': 412, 'y': 688, 'w': 90, 'h': 32, 'confidence': '0.9999924830025506', 'text': 'front'}, {'x': 514, 'y': 688, 'w': 40, 'h': 32, 'confidence': '0.9679358843571725', 'text': 'of'}, {'x': 565, 'y': 695, 'w': 18, 'h': 22, 'confidence': '0.9999724628436901', 'text': 'a'}, {'x': 597, 'y': 687, 'w': 160, 'h': 38, 'confidence': '0.9848481655510329', 'text': 'projector'}, {'x': 313, 'y': 615, 'w': 70, 'h': 38, 'confidence': '0.6767450643057689', 'text': 'max_S'}]}]\n",
      "> Image for page 89: [{'name': 'img_p88_1.png', 'height': 734, 'width': 1794, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 1794, 'original_height': 734, 'ocr': [{'x': 21, 'y': 15, 'w': 494, 'h': 44, 'confidence': '0.8947044997701714', 'text': 'The range for stop_sequences is'}, {'x': 525, 'y': 21, 'w': 14, 'h': 26, 'confidence': '0.9999930858731574', 'text': '1'}, {'x': 557, 'y': 17, 'w': 192, 'h': 36, 'confidence': '0.9998343658412894', 'text': '(inclusive)'}, {'x': 764, 'y': 20, 'w': 40, 'h': 30, 'confidence': '0.9999551560476914', 'text': 'to'}, {'x': 816, 'y': 18, 'w': 38, 'h': 32, 'confidence': '0.9999983141264758', 'text': '17'}, {'x': 869, 'y': 16, 'w': 192, 'h': 36, 'confidence': '0.7642980764637949', 'text': '(exclusive)'}, {'x': 19, 'y': 62, 'w': 1305, 'h': 50, 'confidence': '0.8158201807622028', 'text': 'Multiple (no more than 16) words, numbers, space or special characters can be passed as a'}, {'x': 1336, 'y': 70, 'w': 76, 'h': 32, 'confidence': '0.9989761710166931', 'text': 'list'}, {'x': 20, 'y': 114, 'w': 1206, 'h': 49, 'confidence': '0.51714275056773', 'text': 'The model response stops just before the first time it encounters any stop sequence.'}, {'x': 17, 'y': 227, 'w': 328, 'h': 40, 'confidence': '0.9883060766756783', 'text': 'generation_config_6'}, {'x': 385, 'y': 220, 'w': 283, 'h': 48, 'confidence': '0.712666138462547', 'text': 'GenerationConfig '}, {'x': 84, 'y': 262, 'w': 407, 'h': 42, 'confidence': '0.8907022563341114', 'text': 'stop_sequences= [\"panda\" ]'}, {'x': 19, 'y': 405, 'w': 242, 'h': 40, 'confidence': '0.8426699259854411', 'text': 'responses_stop'}, {'x': 303, 'y': 405, 'w': 414, 'h': 40, 'confidence': '0.9983405159323999', 'text': 'gemini_vision_parameters'}, {'x': 356, 'y': 446, 'w': 142, 'h': 32, 'confidence': '0.7983365738251222', 'text': 'contents _'}, {'x': 353, 'y': 481, 'w': 292, 'h': 38, 'confidence': '0.9946581039829545', 'text': 'multimodal_model,'}, {'x': 353, 'y': 519, 'w': 344, 'h': 40, 'confidence': '0.9990923920077714', 'text': 'generation_config_6)'}, {'x': 13, 'y': 592, 'w': 362, 'h': 44, 'confidence': '0.9088968412899792', 'text': 'print(responses_stop)'}, {'x': 37, 'y': 673, 'w': 14, 'h': 22, 'confidence': '0.9969722335967077', 'text': 'A'}, {'x': 66, 'y': 672, 'w': 56, 'h': 28, 'confidence': '0.9998973818619565', 'text': 'man'}, {'x': 135, 'y': 663, 'w': 190, 'h': 42, 'confidence': '0.9790429661078525', 'text': 'is standing'}, {'x': 338, 'y': 670, 'w': 38, 'h': 30, 'confidence': '0.9994747220964011', 'text': 'in'}, {'x': 388, 'y': 668, 'w': 88, 'h': 32, 'confidence': '0.9999933893075612', 'text': 'front'}, {'x': 488, 'y': 668, 'w': 40, 'h': 32, 'confidence': '0.9670213459823459', 'text': 'of'}, {'x': 539, 'y': 673, 'w': 18, 'h': 24, 'confidence': '0.9998633908200105', 'text': 'a'}, {'x': 571, 'y': 667, 'w': 160, 'h': 38, 'confidence': '0.9998928986736324', 'text': 'projector'}, {'x': 741, 'y': 667, 'w': 226, 'h': 40, 'confidence': '0.9990776961235166', 'text': 'screen giving'}, {'x': 977, 'y': 675, 'w': 18, 'h': 22, 'confidence': '0.999964475947209', 'text': 'a'}, {'x': 1008, 'y': 665, 'w': 225, 'h': 40, 'confidence': '0.9997219777234558', 'text': 'presentation.'}, {'x': 1246, 'y': 670, 'w': 40, 'h': 30, 'confidence': '0.9999960381985386', 'text': 'He'}, {'x': 1298, 'y': 670, 'w': 38, 'h': 30, 'confidence': '0.9880349323226271', 'text': 'is'}, {'x': 1344, 'y': 660, 'w': 131, 'h': 48, 'confidence': '0.9992094212431049', 'text': 'holding'}, {'x': 1483, 'y': 675, 'w': 18, 'h': 22, 'confidence': '0.9999570851161934', 'text': 'a'}, {'x': 1516, 'y': 668, 'w': 124, 'h': 32, 'confidence': '0.9999636388873799', 'text': 'stuffed'}]}]\n",
      "> Image for page 90: [{'name': 'img_p89_1.png', 'height': 964, 'width': 1540, 'x': 330.57644758631994, 'y': 50.60236382400001, 'original_width': 1540, 'original_height': 964, 'ocr': [{'x': 625, 'y': 849, 'w': 435, 'h': 86, 'confidence': '0.876639415994439', 'text': '[image, prompt]'}]}]\n",
      "> Image for page 91: [{'name': 'img_p90_1.png', 'height': 900, 'width': 1636, 'x': 75.948821328, 'y': 49.102363776000004, 'original_width': 1636, 'original_height': 900, 'ocr': [{'x': 70, 'y': 204, 'w': 24, 'h': 30, 'confidence': '0.9692844779682588', 'text': 'I'}, {'x': 104, 'y': 204, 'w': 78, 'h': 32, 'confidence': '0.999982476234436', 'text': 'have'}, {'x': 191, 'y': 202, 'w': 200, 'h': 41, 'confidence': '0.8899033421416455', 'text': 'an image of'}, {'x': 401, 'y': 209, 'w': 20, 'h': 24, 'confidence': '0.9999190585303417', 'text': 'a'}, {'x': 503, 'y': 203, 'w': 148, 'h': 40, 'confidence': '0.999998103391072', 'text': 'engaging'}, {'x': 662, 'y': 204, 'w': 40, 'h': 32, 'confidence': '0.9997950881722089', 'text': 'in'}, {'x': 713, 'y': 209, 'w': 20, 'h': 24, 'confidence': '0.9999653103975881', 'text': 'a'}, {'x': 745, 'y': 196, 'w': 601, 'h': 49, 'confidence': '0.9905689627314406', 'text': 'recreational activity, likely with'}, {'x': 1355, 'y': 209, 'w': 20, 'h': 24, 'confidence': '0.9999710323524234', 'text': 'a'}, {'x': 1388, 'y': 204, 'w': 108, 'h': 32, 'confidence': '0.7190819001528563', 'text': 'human .'}, {'x': 70, 'y': 244, 'w': 60, 'h': 32, 'confidence': '0.9269662499427795', 'text': 'Can'}, {'x': 139, 'y': 239, 'w': 148, 'h': 42, 'confidence': '0.9903439059327747', 'text': 'you tell'}, {'x': 296, 'y': 248, 'w': 42, 'h': 28, 'confidence': '0.9992386599487848', 'text': 'me'}, {'x': 348, 'y': 244, 'w': 76, 'h': 32, 'confidence': '0.9994325041770935', 'text': 'what'}, {'x': 437, 'y': 241, 'w': 146, 'h': 40, 'confidence': '0.9831222194681143', 'text': 'is going'}, {'x': 592, 'y': 244, 'w': 58, 'h': 32, 'confidence': '0.9941548091628145', 'text': 'on?'}, {'x': 659, 'y': 241, 'w': 200, 'h': 36, 'confidence': '0.680890080868764', 'text': 'Or describe'}, {'x': 868, 'y': 244, 'w': 76, 'h': 32, 'confidence': '0.99974125623703', 'text': 'what'}, {'x': 956, 'y': 244, 'w': 42, 'h': 32, 'confidence': '0.9998902513704756', 'text': 'he'}, {'x': 1009, 'y': 241, 'w': 40, 'h': 36, 'confidence': '0.9886085968239988', 'text': 'is'}, {'x': 1059, 'y': 243, 'w': 112, 'h': 38, 'confidence': '0.9998272921775772', 'text': 'doing?'}, {'x': 69, 'y': 279, 'w': 96, 'h': 38, 'confidence': '0.9999992536317571', 'text': 'Maybe'}, {'x': 174, 'y': 286, 'w': 60, 'h': 32, 'confidence': '0.9961996668170775', 'text': 'you'}, {'x': 244, 'y': 284, 'w': 58, 'h': 26, 'confidence': '0.9999823118634976', 'text': 'can'}, {'x': 313, 'y': 276, 'w': 219, 'h': 43, 'confidence': '0.898916255995825', 'text': 'also provide'}, {'x': 538, 'y': 284, 'w': 24, 'h': 26, 'confidence': '0.9999723436360455', 'text': 'a'}, {'x': 571, 'y': 276, 'w': 115, 'h': 41, 'confidence': '0.9999094343544691', 'text': 'quote?'}, {'x': 76, 'y': 679, 'w': 173, 'h': 57, 'confidence': '0.9999159227275952', 'text': 'Gemini,'}, {'x': 265, 'y': 685, 'w': 102, 'h': 44, 'confidence': '0.9999961256980896', 'text': 'this'}, {'x': 473, 'y': 678, 'w': 155, 'h': 60, 'confidence': '0.6507373876946396', 'text': 'having'}, {'x': 642, 'y': 694, 'w': 30, 'h': 34, 'confidence': '0.9999723436360455', 'text': 'a'}, {'x': 686, 'y': 684, 'w': 316, 'h': 52, 'confidence': '0.990561532936429', 'text': 'blast playing'}, {'x': 1013, 'y': 679, 'w': 296, 'h': 65, 'confidence': '0.9992201372107973', 'text': 'fetch caught'}, {'x': 1319, 'y': 693, 'w': 58, 'h': 42, 'confidence': '0.9936019663143628', 'text': 'my'}, {'x': 1391, 'y': 695, 'w': 82, 'h': 40, 'confidence': '0.9999764617108438', 'text': 'eye'}, {'x': 80, 'y': 740, 'w': 173, 'h': 51, 'confidence': '0.9584858345540886', 'text': 'Can you'}, {'x': 265, 'y': 739, 'w': 104, 'h': 42, 'confidence': '0.9895942807197571', 'text': 'tell'}, {'x': 384, 'y': 748, 'w': 54, 'h': 32, 'confidence': '0.9999576005336721', 'text': 'me'}, {'x': 454, 'y': 748, 'w': 30, 'h': 32, 'confidence': '0.9998883040148634', 'text': 'a'}, {'x': 499, 'y': 739, 'w': 80, 'h': 42, 'confidence': '0.999991672117281', 'text': 'bit'}, {'x': 591, 'y': 739, 'w': 128, 'h': 42, 'confidence': '0.9999939757401635', 'text': 'about'}, {'x': 733, 'y': 735, 'w': 248, 'h': 61, 'confidence': '0.9459531918677193', 'text': 'this happy'}, {'x': 993, 'y': 741, 'w': 170, 'h': 40, 'confidence': '0.9999474632366392', 'text': 'moment?'}, {'x': 436, 'y': 199, 'w': 54, 'h': 46, 'confidence': '0.9999799029765554', 'text': 'dog'}, {'x': 384, 'y': 680, 'w': 74, 'h': 59, 'confidence': '0.9999874049413062', 'text': 'dog'}]}]\n",
      "> Image for page 92: [{'name': 'img_p91_1.png', 'height': 884, 'width': 1958, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 1958, 'original_height': 884, 'ocr': [{'x': 719, 'y': 199, 'w': 194, 'h': 44, 'confidence': '0.9999405300642736', 'text': 'Describe'}, {'x': 926, 'y': 196, 'w': 245, 'h': 56, 'confidence': '0.9912989295719187', 'text': 'this image'}, {'x': 82, 'y': 534, 'w': 90, 'h': 32, 'confidence': '0.9993094213188873', 'text': 'Role:'}, {'x': 182, 'y': 534, 'w': 58, 'h': 32, 'confidence': '0.9999589801055311', 'text': 'You'}, {'x': 250, 'y': 540, 'w': 56, 'h': 24, 'confidence': '0.9999960769466525', 'text': 'are'}, {'x': 316, 'y': 540, 'w': 40, 'h': 24, 'confidence': '0.9999968811346347', 'text': 'an'}, {'x': 366, 'y': 534, 'w': 126, 'h': 32, 'confidence': '0.7014783082719338', 'text': 'AI that'}, {'x': 501, 'y': 532, 'w': 363, 'h': 42, 'confidence': '0.9798508615228271', 'text': 'does image understand'}, {'x': 81, 'y': 607, 'w': 124, 'h': 38, 'confidence': '0.9438557926397177', 'text': 'Gemini ,'}, {'x': 216, 'y': 608, 'w': 74, 'h': 32, 'confidence': '0.999992847442627', 'text': 'this'}, {'x': 368, 'y': 608, 'w': 58, 'h': 32, 'confidence': '0.9999263570618102', 'text': 'hav'}, {'x': 487, 'y': 615, 'w': 20, 'h': 22, 'confidence': '0.9811627643563631', 'text': 'a'}, {'x': 518, 'y': 605, 'w': 345, 'h': 42, 'confidence': '0.9692841297281692', 'text': 'blast playing fetch,'}, {'x': 873, 'y': 607, 'w': 160, 'h': 38, 'confidence': '0.9187206541394501', 'text': 'caught my'}, {'x': 1042, 'y': 614, 'w': 68, 'h': 28, 'confidence': '0.9995916485786438', 'text': 'eye.'}, {'x': 79, 'y': 643, 'w': 314, 'h': 40, 'confidence': '0.737835847099946', 'text': 'Please provide The'}, {'x': 402, 'y': 646, 'w': 90, 'h': 32, 'confidence': '0.9999875782913994', 'text': 'breed'}, {'x': 502, 'y': 646, 'w': 42, 'h': 32, 'confidence': '0.9453746578908009', 'text': 'of'}, {'x': 622, 'y': 646, 'w': 38, 'h': 30, 'confidence': '0.9998443973813265', 'text': 'in'}, {'x': 671, 'y': 644, 'w': 173, 'h': 42, 'confidence': '0.7096239124587138', 'text': 'the image ,'}, {'x': 856, 'y': 646, 'w': 58, 'h': 32, 'confidence': '0.9999986234898187', 'text': 'and'}, {'x': 923, 'y': 645, 'w': 228, 'h': 38, 'confidence': '0.9124064604010822', 'text': 'a description'}, {'x': 1160, 'y': 646, 'w': 40, 'h': 32, 'confidence': '0.9533741973260168', 'text': 'of'}, {'x': 1209, 'y': 641, 'w': 296, 'h': 42, 'confidence': '0.799906004007011', 'text': 'the setting where'}, {'x': 1514, 'y': 646, 'w': 58, 'h': 32, 'confidence': '0.9999990364428464', 'text': 'the'}, {'x': 1650, 'y': 646, 'w': 38, 'h': 32, 'confidence': '0.9959769288709825', 'text': 'is'}, {'x': 81, 'y': 681, 'w': 128, 'h': 38, 'confidence': '0.6890785101691359', 'text': 'playing'}, {'x': 81, 'y': 757, 'w': 120, 'h': 30, 'confidence': '0.7034949984893246', 'text': 'Answer :'}, {'x': 859, 'y': 531, 'w': 63, 'h': 43, 'confidence': '0.9985729455947876', 'text': 'ing.'}, {'x': 420, 'y': 604, 'w': 54, 'h': 43, 'confidence': '0.9999668950005018', 'text': 'ing'}, {'x': 300, 'y': 605, 'w': 56, 'h': 43, 'confidence': '0.9999827936409793', 'text': 'dog'}, {'x': 556, 'y': 641, 'w': 52, 'h': 46, 'confidence': '0.9999671014761352', 'text': 'dog'}, {'x': 1580, 'y': 642, 'w': 56, 'h': 43, 'confidence': '0.9999903644340618', 'text': 'dog'}]}]\n",
      "> Image for page 93: []\n",
      "> Image for page 94: [{'name': 'img_p93_1.png', 'height': 996, 'width': 1500, 'x': 120.57677551199998, 'y': 45.094489632000034, 'original_width': 1500, 'original_height': 996, 'ocr': [{'x': 66, 'y': 147, 'w': 102, 'h': 33, 'confidence': '0.9136867094069104', 'text': 'I have'}, {'x': 176, 'y': 152, 'w': 38, 'h': 24, 'confidence': '0.9999838156485313', 'text': 'an'}, {'x': 221, 'y': 146, 'w': 136, 'h': 39, 'confidence': '0.8439659375765697', 'text': 'image of'}, {'x': 365, 'y': 153, 'w': 20, 'h': 22, 'confidence': '0.9998810326675454', 'text': 'a'}, {'x': 457, 'y': 147, 'w': 136, 'h': 38, 'confidence': '0.9999992413566076', 'text': 'engaging'}, {'x': 602, 'y': 148, 'w': 36, 'h': 28, 'confidence': '0.9999330714605809', 'text': 'in'}, {'x': 649, 'y': 153, 'w': 18, 'h': 22, 'confidence': '0.999439675642666', 'text': 'a'}, {'x': 679, 'y': 145, 'w': 352, 'h': 38, 'confidence': '0.9646260205440008', 'text': 'recreational activity,'}, {'x': 1041, 'y': 147, 'w': 182, 'h': 36, 'confidence': '0.7225878798261457', 'text': 'likely with'}, {'x': 1231, 'y': 153, 'w': 20, 'h': 22, 'confidence': '0.9994607698859568', 'text': 'a'}, {'x': 1260, 'y': 148, 'w': 98, 'h': 28, 'confidence': '0.9647576988468274', 'text': 'human .'}, {'x': 65, 'y': 181, 'w': 198, 'h': 38, 'confidence': '0.8884422189483462', 'text': 'Can you tell'}, {'x': 270, 'y': 184, 'w': 118, 'h': 30, 'confidence': '0.9751369610895368', 'text': 'me what'}, {'x': 397, 'y': 181, 'w': 134, 'h': 40, 'confidence': '0.8672714889818244', 'text': 'is going'}, {'x': 538, 'y': 184, 'w': 52, 'h': 28, 'confidence': '0.9940515151176933', 'text': 'on?'}, {'x': 599, 'y': 179, 'w': 466, 'h': 41, 'confidence': '0.676688299490369', 'text': 'Or describe what he is doing?'}, {'x': 65, 'y': 217, 'w': 88, 'h': 36, 'confidence': '0.7934706781833067', 'text': 'Maybe'}, {'x': 160, 'y': 222, 'w': 54, 'h': 28, 'confidence': '0.9957901687528329', 'text': 'you'}, {'x': 224, 'y': 220, 'w': 52, 'h': 26, 'confidence': '0.9999884373223668', 'text': 'can'}, {'x': 285, 'y': 213, 'w': 198, 'h': 38, 'confidence': '0.9949454636007369', 'text': 'also provide'}, {'x': 491, 'y': 223, 'w': 20, 'h': 22, 'confidence': '0.9997080777576492', 'text': 'a'}, {'x': 520, 'y': 215, 'w': 105, 'h': 37, 'confidence': '0.8156273437870704', 'text': 'quote?'}, {'x': 77, 'y': 499, 'w': 148, 'h': 44, 'confidence': '0.9620186193709689', 'text': '[image]'}, {'x': 73, 'y': 591, 'w': 110, 'h': 38, 'confidence': '0.9995314810556011', 'text': 'Role:'}, {'x': 282, 'y': 598, 'w': 70, 'h': 30, 'confidence': '0.9999990364428464', 'text': 'are'}, {'x': 366, 'y': 598, 'w': 48, 'h': 30, 'confidence': '0.9999957853177504', 'text': 'an'}, {'x': 427, 'y': 591, 'w': 50, 'h': 36, 'confidence': '0.933387174183297', 'text': 'AI'}, {'x': 491, 'y': 591, 'w': 88, 'h': 38, 'confidence': '0.9999999403953552', 'text': 'that'}, {'x': 590, 'y': 584, 'w': 524, 'h': 54, 'confidence': '0.8519652283107305', 'text': 'does image understanding.'}, {'x': 70, 'y': 678, 'w': 157, 'h': 50, 'confidence': '0.6887493402056584', 'text': 'Gemini ,'}, {'x': 241, 'y': 683, 'w': 90, 'h': 38, 'confidence': '0.956234876126395', 'text': 'this'}, {'x': 424, 'y': 677, 'w': 137, 'h': 52, 'confidence': '0.7001729957135505', 'text': 'having'}, {'x': 572, 'y': 690, 'w': 26, 'h': 28, 'confidence': '0.9997571854187051', 'text': 'a'}, {'x': 611, 'y': 680, 'w': 281, 'h': 50, 'confidence': '0.8705675572968131', 'text': 'blast playing'}, {'x': 904, 'y': 678, 'w': 280, 'h': 57, 'confidence': '0.9884475292079833', 'text': 'fetch, caught'}, {'x': 1193, 'y': 691, 'w': 50, 'h': 36, 'confidence': '0.9986128919826253', 'text': 'my'}, {'x': 1255, 'y': 691, 'w': 86, 'h': 36, 'confidence': '0.9998462796211243', 'text': 'eye.'}, {'x': 74, 'y': 724, 'w': 385, 'h': 50, 'confidence': '0.9456252850605269', 'text': 'Please provide The'}, {'x': 469, 'y': 729, 'w': 110, 'h': 38, 'confidence': '0.6921280627637609', 'text': 'breed'}, {'x': 593, 'y': 729, 'w': 50, 'h': 36, 'confidence': '0.6776711516358918', 'text': 'of'}, {'x': 741, 'y': 729, 'w': 46, 'h': 36, 'confidence': '0.9998860368237108', 'text': 'in'}, {'x': 798, 'y': 726, 'w': 216, 'h': 51, 'confidence': '0.6173281131135475', 'text': 'the image,'}, {'x': 75, 'y': 775, 'w': 70, 'h': 38, 'confidence': '0.999999449395897', 'text': 'and'}, {'x': 158, 'y': 782, 'w': 24, 'h': 28, 'confidence': '0.999965548812046', 'text': 'a'}, {'x': 199, 'y': 775, 'w': 236, 'h': 44, 'confidence': '0.9998686401878472', 'text': 'description'}, {'x': 447, 'y': 775, 'w': 50, 'h': 38, 'confidence': '0.8636081841378586', 'text': 'of'}, {'x': 510, 'y': 769, 'w': 362, 'h': 51, 'confidence': '0.5655551609412689', 'text': 'the setting where'}, {'x': 883, 'y': 775, 'w': 70, 'h': 38, 'confidence': '0.5802300572395325', 'text': 'the'}, {'x': 1051, 'y': 775, 'w': 46, 'h': 38, 'confidence': '0.949766332087407', 'text': 'is'}, {'x': 1111, 'y': 775, 'w': 168, 'h': 44, 'confidence': '0.9054352842048133', 'text': 'playing .'}, {'x': 75, 'y': 867, 'w': 148, 'h': 36, 'confidence': '0.9999628729113953', 'text': 'Answer:'}, {'x': 396, 'y': 144, 'w': 54, 'h': 42, 'confidence': '0.9999344783969167', 'text': 'dog'}, {'x': 200, 'y': 588, 'w': 66, 'h': 44, 'confidence': '0.9999253935141638', 'text': 'You'}, {'x': 346, 'y': 681, 'w': 64, 'h': 50, 'confidence': '0.9999841701482413', 'text': 'dog'}, {'x': 657, 'y': 725, 'w': 64, 'h': 50, 'confidence': '0.9999754293314397', 'text': 'dog'}, {'x': 968, 'y': 771, 'w': 64, 'h': 50, 'confidence': '0.9999591865809455', 'text': 'dog'}]}]\n",
      "> Image for page 95: []\n",
      "> Image for page 96: []\n",
      "> Image for page 97: [{'name': 'img_p96_1.png', 'height': 700, 'width': 1576, 'x': 12.000000384, 'y': 55.761812808, 'original_width': 1576, 'original_height': 700, 'ocr': [{'x': 64, 'y': 166, 'w': 164, 'h': 52, 'confidence': '0.999881775195107', 'text': '[image]'}, {'x': 63, 'y': 269, 'w': 118, 'h': 40, 'confidence': '0.9997870158227751', 'text': 'Role:'}, {'x': 197, 'y': 270, 'w': 80, 'h': 41, 'confidence': '0.9999593930563655', 'text': 'You'}, {'x': 292, 'y': 278, 'w': 74, 'h': 32, 'confidence': '0.9999984170133134', 'text': 'are'}, {'x': 382, 'y': 278, 'w': 52, 'h': 32, 'confidence': '0.9999989884757856', 'text': 'an'}, {'x': 449, 'y': 269, 'w': 54, 'h': 40, 'confidence': '0.9916508395460917', 'text': 'AI'}, {'x': 520, 'y': 270, 'w': 96, 'h': 38, 'confidence': '0.9630043449945631', 'text': 'that'}, {'x': 628, 'y': 261, 'w': 579, 'h': 60, 'confidence': '0.8534318584255608', 'text': 'does image understanding.'}, {'x': 60, 'y': 366, 'w': 169, 'h': 54, 'confidence': '0.9997876396612878', 'text': 'Gemini,'}, {'x': 245, 'y': 371, 'w': 98, 'h': 42, 'confidence': '0.859755087305465', 'text': 'this'}, {'x': 448, 'y': 367, 'w': 149, 'h': 54, 'confidence': '0.9999907532625453', 'text': 'having'}, {'x': 610, 'y': 380, 'w': 30, 'h': 32, 'confidence': '0.9999310982175444', 'text': 'a'}, {'x': 654, 'y': 372, 'w': 122, 'h': 40, 'confidence': '0.9999512726781636', 'text': 'blast'}, {'x': 789, 'y': 364, 'w': 493, 'h': 62, 'confidence': '0.8227719828682741', 'text': 'playing fetch, caught'}, {'x': 1293, 'y': 379, 'w': 56, 'h': 40, 'confidence': '0.9983937402391287', 'text': 'my'}, {'x': 1363, 'y': 381, 'w': 80, 'h': 38, 'confidence': '0.9999810041819183', 'text': 'eye'}, {'x': 62, 'y': 416, 'w': 329, 'h': 55, 'confidence': '0.7388436003607606', 'text': 'Please provide'}, {'x': 403, 'y': 419, 'w': 78, 'h': 42, 'confidence': '0.920150637626648', 'text': 'The'}, {'x': 497, 'y': 421, 'w': 120, 'h': 40, 'confidence': '0.7792499164078255', 'text': 'breed'}, {'x': 633, 'y': 421, 'w': 54, 'h': 40, 'confidence': '0.7574038364912042', 'text': 'of'}, {'x': 795, 'y': 421, 'w': 50, 'h': 40, 'confidence': '0.9612175668126496', 'text': 'in'}, {'x': 862, 'y': 420, 'w': 233, 'h': 53, 'confidence': '0.7072629560297848', 'text': 'the image,'}, {'x': 63, 'y': 473, 'w': 76, 'h': 40, 'confidence': '0.9999995870469189', 'text': 'and'}, {'x': 156, 'y': 480, 'w': 28, 'h': 32, 'confidence': '0.9999756814527814', 'text': 'a'}, {'x': 198, 'y': 472, 'w': 260, 'h': 48, 'confidence': '0.9720739167791893', 'text': 'description'}, {'x': 473, 'y': 473, 'w': 54, 'h': 40, 'confidence': '0.7426154052477105', 'text': 'of'}, {'x': 542, 'y': 467, 'w': 261, 'h': 53, 'confidence': '0.9946700037652971', 'text': 'the setting'}, {'x': 815, 'y': 473, 'w': 122, 'h': 40, 'confidence': '0.9991548024564583', 'text': 'where'}, {'x': 952, 'y': 471, 'w': 78, 'h': 42, 'confidence': '0.9999996558724309', 'text': 'the'}, {'x': 1137, 'y': 473, 'w': 50, 'h': 40, 'confidence': '0.9900012874865044', 'text': 'is'}, {'x': 1201, 'y': 472, 'w': 186, 'h': 48, 'confidence': '0.6574165427983333', 'text': 'playing .'}, {'x': 63, 'y': 573, 'w': 162, 'h': 40, 'confidence': '0.9999788682529235', 'text': 'Answer:'}, {'x': 360, 'y': 365, 'w': 70, 'h': 60, 'confidence': '0.9999814171339712', 'text': 'dog'}, {'x': 702, 'y': 414, 'w': 70, 'h': 59, 'confidence': '0.9999344783969167', 'text': 'dog'}, {'x': 1045, 'y': 468, 'w': 72, 'h': 54, 'confidence': '0.999988712624007', 'text': 'dog'}]}]\n",
      "> Image for page 98: [{'name': 'img_p97_1.png', 'height': 632, 'width': 820, 'x': 14.6653548, 'y': 86.59449095999997, 'original_width': 820, 'original_height': 632, 'ocr': [{'x': 80, 'y': 70, 'w': 296, 'h': 52, 'confidence': '0.9998805528763313', 'text': 'contents'}, {'x': 228, 'y': 142, 'w': 416, 'h': 56, 'confidence': '0.9996314681375457', 'text': 'instruction'}, {'x': 663, 'y': 143, 'w': 70, 'h': 60, 'confidence': '0.950174205008109', 'text': '1,'}, {'x': 225, 'y': 208, 'w': 219, 'h': 69, 'confidence': '0.9964098952251418', 'text': 'fruit,'}, {'x': 228, 'y': 288, 'w': 412, 'h': 56, 'confidence': '0.9994390256838014', 'text': 'instruction'}, {'x': 661, 'y': 287, 'w': 72, 'h': 62, 'confidence': '0.9246988892555237', 'text': '2 ,'}, {'x': 219, 'y': 354, 'w': 261, 'h': 72, 'confidence': '0.9750527936318782', 'text': 'prices ,'}, {'x': 224, 'y': 430, 'w': 363, 'h': 67, 'confidence': '0.7235169987143931', 'text': 'questions ,'}]}]\n",
      "> Image for page 99: [{'name': 'img_p98_1.png', 'height': 1392, 'width': 1110, 'x': 418.998044904, 'y': 47.76771806400001, 'original_width': 1110, 'original_height': 1392, 'ocr': [{'x': 342, 'y': 726, 'w': 30, 'h': 34, 'confidence': '0.999934435965443', 'text': 'A'}, {'x': 708, 'y': 726, 'w': 28, 'h': 34, 'confidence': '0.9999418267127567', 'text': 'B'}, {'x': 87, 'y': 811, 'w': 16, 'h': 24, 'confidence': '0.47398936764656086', 'text': '1'}, {'x': 184, 'y': 800, 'w': 108, 'h': 50, 'confidence': '0.9999883779727591', 'text': 'Fruit'}, {'x': 547, 'y': 799, 'w': 306, 'h': 60, 'confidence': '0.9712615220357308', 'text': 'Price per item'}, {'x': 80, 'y': 882, 'w': 26, 'h': 32, 'confidence': '1.0', 'text': '2'}, {'x': 181, 'y': 874, 'w': 160, 'h': 64, 'confidence': '0.9999974206488531', 'text': 'Apples'}, {'x': 761, 'y': 874, 'w': 132, 'h': 54, 'confidence': '0.9416796073651116', 'text': 'S1.50'}, {'x': 82, 'y': 956, 'w': 24, 'h': 34, 'confidence': '0.999999880790714', 'text': '3'}, {'x': 183, 'y': 951, 'w': 201, 'h': 51, 'confidence': '0.9999985131227251', 'text': 'Bananas'}, {'x': 762, 'y': 948, 'w': 132, 'h': 54, 'confidence': '0.9321219890800997', 'text': 'S0.80'}, {'x': 82, 'y': 1032, 'w': 24, 'h': 30, 'confidence': '0.9999212042118621', 'text': '4'}, {'x': 184, 'y': 1026, 'w': 98, 'h': 50, 'confidence': '0.9993633031845093', 'text': 'Kiwi'}, {'x': 762, 'y': 1024, 'w': 132, 'h': 54, 'confidence': '0.8140611802927779', 'text': 'S1.25'}, {'x': 80, 'y': 1108, 'w': 28, 'h': 34, 'confidence': '0.999964475947209', 'text': '5'}, {'x': 183, 'y': 1099, 'w': 211, 'h': 65, 'confidence': '0.9994974308099112', 'text': 'Mangoes'}, {'x': 762, 'y': 1098, 'w': 132, 'h': 56, 'confidence': '0.965553022845793', 'text': 'S2.00'}, {'x': 82, 'y': 1184, 'w': 24, 'h': 30, 'confidence': '0.9999992847443906', 'text': '6'}, {'x': 181, 'y': 1173, 'w': 199, 'h': 65, 'confidence': '0.9999493105993537', 'text': 'Oranges'}, {'x': 762, 'y': 1174, 'w': 132, 'h': 54, 'confidence': '0.9491796362782774', 'text': 'S0.99'}, {'x': 80, 'y': 1258, 'w': 24, 'h': 30, 'confidence': '0.9999868870211372', 'text': '7'}, {'x': 183, 'y': 1251, 'w': 196, 'h': 50, 'confidence': '0.9999769758506287', 'text': 'Peaches'}, {'x': 761, 'y': 1249, 'w': 134, 'h': 54, 'confidence': '0.9156701605932499', 'text': 'S1.75'}, {'x': 80, 'y': 1332, 'w': 28, 'h': 36, 'confidence': '0.9987723145583697', 'text': '8'}, {'x': 185, 'y': 1325, 'w': 265, 'h': 54, 'confidence': '0.9999581178040879', 'text': 'Watermelon'}, {'x': 762, 'y': 1324, 'w': 132, 'h': 54, 'confidence': '0.671301340297371', 'text': 'S4.00'}]}, {'name': 'img_p98_2.png', 'height': 602, 'width': 1336, 'x': 12.000000384, 'y': 57.09449001599998, 'original_width': 1336, 'original_height': 602, 'ocr': [{'x': 13, 'y': 35, 'w': 140, 'h': 36, 'confidence': '0.9999850799695236', 'text': 'response'}, {'x': 195, 'y': 31, 'w': 230, 'h': 40, 'confidence': '0.9819414758391388', 'text': 'gemini_vision'}, {'x': 214, 'y': 72, 'w': 154, 'h': 32, 'confidence': '0.999944566912145', 'text': 'contents,'}, {'x': 214, 'y': 112, 'w': 42, 'h': 28, 'confidence': '0.9981640715254827', 'text': 'mu'}, {'x': 246, 'y': 103, 'w': 259, 'h': 42, 'confidence': '0.958811447183757', 'text': 'ltimodal_model)'}, {'x': 351, 'y': 187, 'w': 34, 'h': 14, 'confidence': '0.4317965753316777', 'text': 'I'}, {'x': 9, 'y': 180, 'w': 258, 'h': 44, 'confidence': '0.999748038378089', 'text': 'print(response,'}, {'x': 282, 'y': 184, 'w': 74, 'h': 32, 'confidence': '0.7834259867668152', 'text': 'end='}, {'x': 383, 'y': 187, 'w': 16, 'h': 26, 'confidence': '0.8893133372508863', 'text': ')'}, {'x': 26, 'y': 256, 'w': 58, 'h': 32, 'confidence': '0.999949688717797', 'text': 'You'}, {'x': 94, 'y': 256, 'w': 74, 'h': 32, 'confidence': '0.6747044083294594', 'text': 'have'}, {'x': 179, 'y': 257, 'w': 18, 'h': 28, 'confidence': '0.999999880790714', 'text': '2'}, {'x': 212, 'y': 256, 'w': 124, 'h': 32, 'confidence': '0.9999908984976137', 'text': 'bananas'}, {'x': 348, 'y': 256, 'w': 56, 'h': 32, 'confidence': '0.9999976599328428', 'text': 'and'}, {'x': 415, 'y': 257, 'w': 18, 'h': 28, 'confidence': '0.999999880790714', 'text': '2'}, {'x': 444, 'y': 250, 'w': 113, 'h': 49, 'confidence': '0.9926010775630266', 'text': 'apples'}, {'x': 567, 'y': 257, 'w': 124, 'h': 38, 'confidence': '0.6329628609707786', 'text': 'in your'}, {'x': 702, 'y': 256, 'w': 88, 'h': 32, 'confidence': '0.9999234436005648', 'text': 'fruit'}, {'x': 802, 'y': 256, 'w': 86, 'h': 32, 'confidence': '0.9954811864488965', 'text': 'bowl.'}, {'x': 10, 'y': 326, 'w': 40, 'h': 32, 'confidence': '0.9997687059305996', 'text': 'To'}, {'x': 60, 'y': 326, 'w': 74, 'h': 32, 'confidence': '0.9999722242355347', 'text': 'make'}, {'x': 146, 'y': 326, 'w': 56, 'h': 32, 'confidence': '0.9999988299663297', 'text': 'the'}, {'x': 212, 'y': 326, 'w': 90, 'h': 32, 'confidence': '0.9999913101370989', 'text': 'fruit'}, {'x': 313, 'y': 325, 'w': 104, 'h': 36, 'confidence': '0.6972838255514415', 'text': 'salad ,'}, {'x': 430, 'y': 330, 'w': 58, 'h': 32, 'confidence': '0.9976461947123347', 'text': 'you'}, {'x': 498, 'y': 326, 'w': 74, 'h': 32, 'confidence': '0.9999958276748657', 'text': 'need'}, {'x': 581, 'y': 324, 'w': 174, 'h': 37, 'confidence': '0.7910403459555752', 'text': '3 bananas,'}, {'x': 767, 'y': 322, 'w': 156, 'h': 44, 'confidence': '0.7218051585030872', 'text': '2 apples ,'}, {'x': 939, 'y': 329, 'w': 18, 'h': 24, 'confidence': '0.9999957084701805', 'text': '1'}, {'x': 969, 'y': 325, 'w': 90, 'h': 36, 'confidence': '0.9971999097399667', 'text': 'kiwi,'}, {'x': 1072, 'y': 326, 'w': 56, 'h': 32, 'confidence': '0.9999944251353335', 'text': 'and'}, {'x': 1141, 'y': 329, 'w': 18, 'h': 24, 'confidence': '0.9999978542339392', 'text': '1'}, {'x': 1171, 'y': 323, 'w': 125, 'h': 42, 'confidence': '0.9911274618277309', 'text': 'orange.'}, {'x': 77, 'y': 397, 'w': 58, 'h': 36, 'confidence': '0.9992911996800689', 'text': 'you'}, {'x': 144, 'y': 398, 'w': 56, 'h': 26, 'confidence': '0.9999995182214076', 'text': 'are'}, {'x': 209, 'y': 388, 'w': 129, 'h': 45, 'confidence': '0.9990001165919664', 'text': 'missing'}, {'x': 351, 'y': 399, 'w': 14, 'h': 24, 'confidence': '0.9999554162226474', 'text': '1'}, {'x': 378, 'y': 392, 'w': 124, 'h': 39, 'confidence': '0.9999915292956714', 'text': 'banana,'}, {'x': 519, 'y': 399, 'w': 16, 'h': 24, 'confidence': '0.9999825955194552', 'text': '1'}, {'x': 549, 'y': 393, 'w': 88, 'h': 38, 'confidence': '0.9994875494113198', 'text': 'kiwi,'}, {'x': 650, 'y': 394, 'w': 56, 'h': 32, 'confidence': '0.999999380570387', 'text': 'and'}, {'x': 721, 'y': 399, 'w': 16, 'h': 24, 'confidence': '0.9999959468882622', 'text': '1'}, {'x': 751, 'y': 397, 'w': 122, 'h': 36, 'confidence': '0.9995095170594772', 'text': 'orange.'}, {'x': 9, 'y': 459, 'w': 176, 'h': 42, 'confidence': '0.9980736017716804', 'text': 'The prices'}, {'x': 196, 'y': 464, 'w': 56, 'h': 32, 'confidence': '0.883685827255249', 'text': 'for'}, {'x': 264, 'y': 464, 'w': 90, 'h': 32, 'confidence': '0.9999989870716545', 'text': 'these'}, {'x': 364, 'y': 464, 'w': 106, 'h': 32, 'confidence': '0.9999494347114525', 'text': 'fruits'}, {'x': 482, 'y': 468, 'w': 56, 'h': 28, 'confidence': '0.9999973846308725', 'text': 'are'}, {'x': 549, 'y': 463, 'w': 104, 'h': 38, 'confidence': '0.36959717867048153', 'text': 'S0.80 ,'}, {'x': 668, 'y': 466, 'w': 54, 'h': 32, 'confidence': '0.4239582781952629', 'text': '$1.'}, {'x': 785, 'y': 463, 'w': 172, 'h': 38, 'confidence': '0.8077992364870503', 'text': 'and $0.99 ,'}, {'x': 971, 'y': 463, 'w': 222, 'h': 40, 'confidence': '0.9996513380093339', 'text': 'respectively.'}, {'x': 10, 'y': 534, 'w': 58, 'h': 32, 'confidence': '0.999975222855576', 'text': 'The'}, {'x': 78, 'y': 534, 'w': 90, 'h': 32, 'confidence': '0.9999890710298764', 'text': 'total'}, {'x': 178, 'y': 534, 'w': 74, 'h': 32, 'confidence': '0.9999788403511047', 'text': 'cost'}, {'x': 264, 'y': 534, 'w': 56, 'h': 32, 'confidence': '0.9999943563098699', 'text': 'for'}, {'x': 330, 'y': 534, 'w': 90, 'h': 32, 'confidence': '0.9999981340792696', 'text': 'these'}, {'x': 431, 'y': 531, 'w': 210, 'h': 36, 'confidence': '0.9977753064550438', 'text': 'fruits would'}, {'x': 649, 'y': 533, 'w': 154, 'h': 36, 'confidence': '0.8798902586907815', 'text': 'be $3.04 .'}, {'x': 11, 'y': 393, 'w': 46, 'h': 36, 'confidence': '0.9780143371328135', 'text': 'So,'}, {'x': 717, 'y': 460, 'w': 53, 'h': 42, 'confidence': '0.4351405924791409', 'text': '25 ,'}]}]\n",
      "> Image for page 100: [{'name': 'img_p99_1.png', 'height': 1022, 'width': 1034, 'x': 418.99814332919993, 'y': 57.09449001600001, 'original_width': 1034, 'original_height': 1022, 'ocr': [{'x': 372, 'y': 148, 'w': 345, 'h': 167, 'confidence': '0.1386383417777561', 'text': 'Co'}]}, {'name': 'img_p99_2.png', 'height': 654, 'width': 1612, 'x': 12.000000384, 'y': 57.09449001599998, 'original_width': 1612, 'original_height': 654, 'ocr': [{'x': 27, 'y': 8, 'w': 226, 'h': 41, 'confidence': '0.9793294304530576', 'text': '### Remember ,'}, {'x': 265, 'y': 15, 'w': 58, 'h': 36, 'confidence': '0.9980629509234072', 'text': 'you'}, {'x': 334, 'y': 16, 'w': 56, 'h': 28, 'confidence': '0.999999449395897', 'text': 'are'}, {'x': 397, 'y': 6, 'w': 532, 'h': 45, 'confidence': '0.544909253828257', 'text': 'using gemini-1.0-pro-vision-001'}, {'x': 29, 'y': 49, 'w': 277, 'h': 38, 'confidence': '0.9638300996067637', 'text': 'multimodal_model'}, {'x': 349, 'y': 49, 'w': 748, 'h': 40, 'confidence': '0.6075042823739625', 'text': 'GenerativeModel (\"gemini-1.0-pro-vision-001\" )'}, {'x': 31, 'y': 129, 'w': 142, 'h': 36, 'confidence': '0.9999816660512819', 'text': 'response'}, {'x': 213, 'y': 125, 'w': 242, 'h': 40, 'confidence': '0.9758123950248422', 'text': 'gemini_vision('}, {'x': 232, 'y': 159, 'w': 391, 'h': 44, 'confidence': '0.9980402935236392', 'text': 'recommendation_content,'}, {'x': 231, 'y': 201, 'w': 291, 'h': 38, 'confidence': '0.8503032024664721', 'text': 'multimodal_model)'}, {'x': 27, 'y': 274, 'w': 95, 'h': 42, 'confidence': '0.7865317415536814', 'text': 'print'}, {'x': 133, 'y': 281, 'w': 152, 'h': 36, 'confidence': '0.7641607102441093', 'text': 'response,'}, {'x': 300, 'y': 278, 'w': 118, 'h': 30, 'confidence': '0.9602543502366934', 'text': 'end-\"\")'}, {'x': 46, 'y': 350, 'w': 90, 'h': 32, 'confidence': '0.5904019363652371', 'text': 'Chair'}, {'x': 146, 'y': 352, 'w': 34, 'h': 28, 'confidence': '0.995549670002531', 'text': '1:'}, {'x': 196, 'y': 350, 'w': 58, 'h': 32, 'confidence': '0.9999409479413761', 'text': 'The'}, {'x': 264, 'y': 347, 'w': 327, 'h': 44, 'confidence': '0.988443217604868', 'text': 'industrial style of'}, {'x': 602, 'y': 350, 'w': 72, 'h': 32, 'confidence': '0.9999962449073792', 'text': 'this'}, {'x': 686, 'y': 350, 'w': 90, 'h': 32, 'confidence': '0.9998216694328905', 'text': 'chair'}, {'x': 786, 'y': 349, 'w': 90, 'h': 32, 'confidence': '0.9998790341743613', 'text': 'would'}, {'x': 888, 'y': 352, 'w': 56, 'h': 30, 'confidence': '0.9999655184964258', 'text': 'not'}, {'x': 954, 'y': 350, 'w': 90, 'h': 32, 'confidence': '0.6652392880711627', 'text': 'match'}, {'x': 1056, 'y': 350, 'w': 56, 'h': 32, 'confidence': '0.9999937368807252', 'text': 'the'}, {'x': 1123, 'y': 349, 'w': 176, 'h': 40, 'confidence': '0.9973505981734553', 'text': 'boho style'}, {'x': 1308, 'y': 350, 'w': 40, 'h': 32, 'confidence': '0.848297740491603', 'text': 'of'}, {'x': 1360, 'y': 350, 'w': 56, 'h': 32, 'confidence': '0.9999909838629265', 'text': 'the'}, {'x': 1430, 'y': 354, 'w': 74, 'h': 26, 'confidence': '0.8461082296267312', 'text': 'room.'}, {'x': 28, 'y': 420, 'w': 92, 'h': 32, 'confidence': '0.9999699319701848', 'text': 'Chair'}, {'x': 130, 'y': 420, 'w': 36, 'h': 32, 'confidence': '0.5519577264785767', 'text': '2 :'}, {'x': 180, 'y': 420, 'w': 56, 'h': 32, 'confidence': '0.999939709092003', 'text': 'The'}, {'x': 246, 'y': 420, 'w': 108, 'h': 32, 'confidence': '0.9942018274933128', 'text': 'ornate'}, {'x': 365, 'y': 419, 'w': 92, 'h': 38, 'confidence': '0.9999514859274474', 'text': 'style'}, {'x': 465, 'y': 417, 'w': 126, 'h': 36, 'confidence': '0.6591640130124377', 'text': 'of this'}, {'x': 602, 'y': 420, 'w': 90, 'h': 32, 'confidence': '0.9998673586683183', 'text': 'chair'}, {'x': 701, 'y': 417, 'w': 92, 'h': 36, 'confidence': '0.999750549409192', 'text': 'would'}, {'x': 804, 'y': 420, 'w': 56, 'h': 32, 'confidence': '0.9999590489306686', 'text': 'not'}, {'x': 870, 'y': 420, 'w': 90, 'h': 32, 'confidence': '0.9634231652954977', 'text': 'match'}, {'x': 972, 'y': 420, 'w': 56, 'h': 32, 'confidence': '0.999998279362313', 'text': 'the'}, {'x': 1040, 'y': 420, 'w': 72, 'h': 32, 'confidence': '0.9998172521591187', 'text': 'boho'}, {'x': 1123, 'y': 419, 'w': 92, 'h': 38, 'confidence': '0.9999277619117017', 'text': 'style'}, {'x': 1224, 'y': 420, 'w': 40, 'h': 32, 'confidence': '0.7186111774753144', 'text': 'of'}, {'x': 1276, 'y': 420, 'w': 56, 'h': 32, 'confidence': '0.9999993117448777', 'text': 'the'}, {'x': 1344, 'y': 424, 'w': 74, 'h': 26, 'confidence': '0.8269923513764521', 'text': 'room_'}, {'x': 28, 'y': 490, 'w': 90, 'h': 32, 'confidence': '0.9999706250288111', 'text': 'Chair'}, {'x': 130, 'y': 490, 'w': 36, 'h': 32, 'confidence': '0.9968431451968531', 'text': '3:'}, {'x': 179, 'y': 489, 'w': 190, 'h': 38, 'confidence': '0.9928738931223021', 'text': 'The simple,'}, {'x': 383, 'y': 489, 'w': 208, 'h': 38, 'confidence': '0.9959928662928758', 'text': 'rustic style'}, {'x': 602, 'y': 490, 'w': 38, 'h': 32, 'confidence': '0.9259337008145064', 'text': 'of'}, {'x': 651, 'y': 487, 'w': 74, 'h': 36, 'confidence': '0.999994695186615', 'text': 'this'}, {'x': 736, 'y': 490, 'w': 90, 'h': 32, 'confidence': '0.9999653471193823', 'text': 'chair'}, {'x': 835, 'y': 487, 'w': 278, 'h': 40, 'confidence': '0.8323476667803146', 'text': 'would complement'}, {'x': 1124, 'y': 490, 'w': 56, 'h': 32, 'confidence': '0.9999977975838318', 'text': 'the'}, {'x': 1192, 'y': 490, 'w': 72, 'h': 32, 'confidence': '0.9999409317970276', 'text': 'boho'}, {'x': 1376, 'y': 490, 'w': 40, 'h': 32, 'confidence': '0.7085426415491309', 'text': 'of'}, {'x': 1428, 'y': 490, 'w': 56, 'h': 32, 'confidence': '0.999999449395897', 'text': 'the'}, {'x': 1496, 'y': 494, 'w': 74, 'h': 26, 'confidence': '0.7028211737894418', 'text': 'room;'}, {'x': 28, 'y': 558, 'w': 92, 'h': 32, 'confidence': '0.9999443953858821', 'text': 'Chair'}, {'x': 128, 'y': 560, 'w': 36, 'h': 28, 'confidence': '0.9988429279964303', 'text': '4:'}, {'x': 180, 'y': 558, 'w': 56, 'h': 32, 'confidence': '0.9999140374262734', 'text': 'The'}, {'x': 245, 'y': 555, 'w': 262, 'h': 44, 'confidence': '0.9967709324423943', 'text': 'modern style of'}, {'x': 518, 'y': 558, 'w': 72, 'h': 32, 'confidence': '0.9999953508377075', 'text': 'this'}, {'x': 602, 'y': 558, 'w': 90, 'h': 32, 'confidence': '0.9998925756087035', 'text': 'chair'}, {'x': 702, 'y': 558, 'w': 90, 'h': 32, 'confidence': '0.9997793386961202', 'text': 'would'}, {'x': 803, 'y': 556, 'w': 176, 'h': 39, 'confidence': '0.9904023091297472', 'text': 'complement'}, {'x': 990, 'y': 558, 'w': 56, 'h': 32, 'confidence': '0.999996902852449', 'text': 'the'}, {'x': 1055, 'y': 555, 'w': 226, 'h': 44, 'confidence': '0.8638647526441506', 'text': 'boho style of'}, {'x': 1292, 'y': 558, 'w': 56, 'h': 32, 'confidence': '0.9999941498334826', 'text': 'the'}, {'x': 1362, 'y': 562, 'w': 74, 'h': 26, 'confidence': '0.9422511864365833', 'text': 'room.'}, {'x': 1273, 'y': 492, 'w': 94, 'h': 30, 'confidence': '0.950849678491871', 'text': 'style'}]}]\n",
      "> Image for page 101: [{'name': 'img_p100_1.png', 'height': 1372, 'width': 510, 'x': 526.527575904, 'y': 53.95669463999997, 'original_width': 510, 'original_height': 1372, 'ocr': [{'x': 151, 'y': 75, 'w': 118, 'h': 36, 'confidence': '0.10275349976557216', 'text': 'EWETOE We'}, {'x': 121, 'y': 139, 'w': 104, 'h': 20, 'confidence': '0.1997074216047075', 'text': 'sn Frercisco_'}, {'x': 231, 'y': 141, 'w': 66, 'h': 20, 'confidence': '0.4903448244646418', 'text': 'C4 94102'}, {'x': 48, 'y': 174, 'w': 76, 'h': 24, 'confidence': '0.3085684874074197', 'text': 'epinu'}, {'x': 281, 'y': 173, 'w': 85, 'h': 25, 'confidence': '0.1567520229566969', 'text': '148 4'}, {'x': 109, 'y': 213, 'w': 64, 'h': 20, 'confidence': '0.36751683823673464', 'text': 'Jate 0'}, {'x': 318, 'y': 245, 'w': 49, 'h': 25, 'confidence': '0.15039606454804821', 'text': '09.95'}, {'x': 83, 'y': 271, 'w': 48, 'h': 18, 'confidence': '0.32279911337812117', 'text': 'Eanena'}, {'x': 319, 'y': 267, 'w': 46, 'h': 20, 'confidence': '0.11088851243694817', 'text': 'Ws'}, {'x': 50, 'y': 302, 'w': 76, 'h': 24, 'confidence': '0.1951396096747992', 'text': 'Sp Tetel'}, {'x': 311, 'y': 303, 'w': 54, 'h': 20, 'confidence': '0.163690239907561', 'text': 'Gil'}, {'x': 50, 'y': 336, 'w': 76, 'h': 24, 'confidence': '0.37408615931460276', 'text': 'Salea Tut'}, {'x': 321, 'y': 339, 'w': 44, 'h': 20, 'confidence': '0.16685580798790817', 'text': '60,95'}, {'x': 51, 'y': 373, 'w': 88, 'h': 20, 'confidence': '0.13731402441927498', 'text': 'Oroet Tetel'}, {'x': 311, 'y': 377, 'w': 54, 'h': 20, 'confidence': '0.6440398720076442', 'text': '412.26'}, {'x': 313, 'y': 413, 'w': 50, 'h': 20, 'confidence': '0.20134605904181652', 'text': '412.26'}, {'x': 311, 'y': 431, 'w': 52, 'h': 20, 'confidence': '0.23900106760254491', 'text': '012.26'}, {'x': 81, 'y': 447, 'w': 42, 'h': 18, 'confidence': '0.3178282685413295', 'text': 'Cardi'}, {'x': 185, 'y': 447, 'w': 68, 'h': 18, 'confidence': '0.25023916232125964', 'text': '188607'}, {'x': 321, 'y': 595, 'w': 28, 'h': 18, 'confidence': '0.11253400990660768', 'text': 'Iou'}, {'x': 309, 'y': 615, 'w': 26, 'h': 14, 'confidence': '0.23929955878312928', 'text': '10'}, {'x': 160, 'y': 656, 'w': 94, 'h': 26, 'confidence': '0.4409762317704977', 'text': 'Otere Mitel'}, {'x': 24, 'y': 700, 'w': 102, 'h': 32, 'confidence': '0.8084831707201164', 'text': 'lunch:'}, {'x': 155, 'y': 747, 'w': 93, 'h': 29, 'confidence': '0.23913536299225102', 'text': 'SupeR'}, {'x': 155, 'y': 768, 'w': 93, 'h': 31, 'confidence': '0.801118305696529', 'text': 'DUPER'}, {'x': 175, 'y': 893, 'w': 36, 'h': 14, 'confidence': '0.16673642848451556', 'text': 'Se'}, {'x': 211, 'y': 887, 'w': 32, 'h': 20, 'confidence': '0.2694440186023712', 'text': 'tota'}, {'x': 68, 'y': 942, 'w': 97, 'h': 21, 'confidence': '0.16396012931866716', 'text': 'Sane : Drecer'}, {'x': 67, 'y': 961, 'w': 74, 'h': 18, 'confidence': '0.13946984269381502', 'text': 'DedI0.'}, {'x': 69, 'y': 981, 'w': 58, 'h': 16, 'confidence': '0.10077422299095333', 'text': 'Orezted;'}, {'x': 305, 'y': 1029, 'w': 40, 'h': 20, 'confidence': '0.19487938178300562', 'text': '0.7'}, {'x': 307, 'y': 1051, 'w': 36, 'h': 16, 'confidence': '0.142222598195076', 'text': 'D.Ji'}, {'x': 73, 'y': 1127, 'w': 26, 'h': 16, 'confidence': '0.1601263447423497', 'text': 'Io'}, {'x': 71, 'y': 1141, 'w': 40, 'h': 20, 'confidence': '0.44463544392334536', 'text': 'Jotal'}, {'x': 71, 'y': 1177, 'w': 80, 'h': 20, 'confidence': '0.11066723931271376', 'text': 'Creait Gr'}, {'x': 315, 'y': 1229, 'w': 32, 'h': 18, 'confidence': '0.4577496713209342', 'text': 'Ale'}, {'x': 74, 'y': 1250, 'w': 91, 'h': 21, 'confidence': '0.1372523593225584', 'text': 'MhcIntiot'}, {'x': 299, 'y': 1260, 'w': 50, 'h': 26, 'confidence': '0.14123908409517352', 'text': '073015'}, {'x': 74, 'y': 1302, 'w': 98, 'h': 26, 'confidence': '0.2761019853672963', 'text': 'Kolicatim Id'}, {'x': 253, 'y': 1298, 'w': 95, 'h': 24, 'confidence': '0.10901678105810396', 'text': 'pxtidio'}, {'x': 302, 'y': 1318, 'w': 45, 'h': 21, 'confidence': '0.12763745279091798', 'text': 'Eredlt'}, {'x': 73, 'y': 1107, 'w': 22, 'h': 18, 'confidence': '0.13352483295207107', 'text': 'Iu'}]}, {'name': 'img_p100_2.png', 'height': 801, 'width': 2048, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 801, 'ocr': [{'x': 30, 'y': 4, 'w': 44, 'h': 26, 'confidence': '0.9999688221066348', 'text': 'You'}, {'x': 81, 'y': 9, 'w': 42, 'h': 20, 'confidence': '0.9999990364428464', 'text': 'are'}, {'x': 132, 'y': 6, 'w': 116, 'h': 28, 'confidence': '0.9998634212270582', 'text': 'reviewing'}, {'x': 254, 'y': 6, 'w': 80, 'h': 24, 'confidence': '0.9993409730585244', 'text': 'travel'}, {'x': 341, 'y': 7, 'w': 104, 'h': 24, 'confidence': '0.99977110506534', 'text': 'expenses'}, {'x': 454, 'y': 4, 'w': 42, 'h': 26, 'confidence': '0.9999814171339712', 'text': 'for'}, {'x': 528, 'y': 6, 'w': 104, 'h': 24, 'confidence': '0.9999043669065593', 'text': 'business'}, {'x': 640, 'y': 6, 'w': 64, 'h': 26, 'confidence': '0.9995569122552357', 'text': 'trip.'}, {'x': 30, 'y': 29, 'w': 366, 'h': 31, 'confidence': '0.8005733282773151', 'text': 'Please complete the following'}, {'x': 404, 'y': 32, 'w': 78, 'h': 26, 'confidence': '0.9998991121886984', 'text': 'tasks:'}, {'x': 68, 'y': 58, 'w': 230, 'h': 28, 'confidence': '0.8389567923304797', 'text': 'Itemize everything'}, {'x': 305, 'y': 63, 'w': 28, 'h': 18, 'confidence': '0.9973350002435751', 'text': 'on'}, {'x': 342, 'y': 58, 'w': 42, 'h': 24, 'confidence': '0.9999995870469189', 'text': 'the'}, {'x': 392, 'y': 58, 'w': 114, 'h': 26, 'confidence': '0.8349926537514427', 'text': 'receipts ,'}, {'x': 516, 'y': 58, 'w': 80, 'h': 24, 'confidence': '0.999750645208124', 'text': 'includ'}, {'x': 638, 'y': 57, 'w': 94, 'h': 27, 'confidence': '0.9882136247397573', 'text': 'tax and'}, {'x': 740, 'y': 58, 'w': 76, 'h': 24, 'confidence': '0.8631180163593729', 'text': 'total.'}, {'x': 838, 'y': 58, 'w': 56, 'h': 24, 'confidence': '0.9994251132011414', 'text': 'This'}, {'x': 900, 'y': 56, 'w': 218, 'h': 30, 'confidence': '0.8441803093688789', 'text': 'means identifying'}, {'x': 1126, 'y': 58, 'w': 42, 'h': 24, 'confidence': '0.9999995870469189', 'text': 'the'}, {'x': 1174, 'y': 58, 'w': 56, 'h': 24, 'confidence': '0.9999487400054932', 'text': 'cost'}, {'x': 1236, 'y': 58, 'w': 30, 'h': 24, 'confidence': '0.9090045251776749', 'text': 'of'}, {'x': 1274, 'y': 58, 'w': 130, 'h': 24, 'confidence': '0.9997333841284392', 'text': 'individual'}, {'x': 1410, 'y': 58, 'w': 68, 'h': 24, 'confidence': '0.9982398275073305', 'text': 'items'}, {'x': 1486, 'y': 58, 'w': 54, 'h': 24, 'confidence': '0.9999993443489075', 'text': 'that'}, {'x': 1546, 'y': 58, 'w': 44, 'h': 24, 'confidence': '0.9999978664093272', 'text': 'add'}, {'x': 1596, 'y': 62, 'w': 32, 'h': 24, 'confidence': '0.9998565351420436', 'text': 'up'}, {'x': 1634, 'y': 58, 'w': 30, 'h': 24, 'confidence': '0.9999561675589194', 'text': 'to'}, {'x': 1672, 'y': 58, 'w': 42, 'h': 24, 'confidence': '0.9999996558724309', 'text': 'the'}, {'x': 1722, 'y': 58, 'w': 66, 'h': 24, 'confidence': '0.9292972199345791', 'text': 'total'}, {'x': 1797, 'y': 61, 'w': 52, 'h': 20, 'confidence': '0.9999527335166931', 'text': 'cost'}, {'x': 1858, 'y': 57, 'w': 141, 'h': 28, 'confidence': '0.9826317602376661', 'text': 'before tax,'}, {'x': 2007, 'y': 61, 'w': 30, 'h': 20, 'confidence': '0.9997370137949431', 'text': 'as'}, {'x': 31, 'y': 85, 'w': 18, 'h': 22, 'confidence': '1.0', 'text': '2'}, {'x': 68, 'y': 84, 'w': 56, 'h': 26, 'confidence': '0.9999617338180542', 'text': 'What'}, {'x': 130, 'y': 86, 'w': 30, 'h': 24, 'confidence': '0.968145040746828', 'text': 'is'}, {'x': 168, 'y': 84, 'w': 42, 'h': 26, 'confidence': '0.9999983481878129', 'text': 'the'}, {'x': 218, 'y': 84, 'w': 66, 'h': 26, 'confidence': '0.9999892309661262', 'text': 'total'}, {'x': 292, 'y': 84, 'w': 68, 'h': 26, 'confidence': '0.9999395551895086', 'text': 'sales'}, {'x': 366, 'y': 82, 'w': 118, 'h': 30, 'confidence': '0.776800070383561', 'text': 'tax paid?'}, {'x': 504, 'y': 84, 'w': 30, 'h': 26, 'confidence': '0.9999980612455189', 'text': 'In'}, {'x': 541, 'y': 89, 'w': 54, 'h': 20, 'confidence': '0.9993962645530701', 'text': 'some'}, {'x': 604, 'y': 86, 'w': 68, 'h': 24, 'confidence': '0.999879673927652', 'text': 'cases'}, {'x': 690, 'y': 84, 'w': 42, 'h': 26, 'confidence': '0.9999984858388146', 'text': 'the'}, {'x': 740, 'y': 84, 'w': 142, 'h': 26, 'confidence': '0.807346787330447', 'text': 'total sales'}, {'x': 888, 'y': 86, 'w': 44, 'h': 24, 'confidence': '0.9998784551294416', 'text': 'tax'}, {'x': 938, 'y': 88, 'w': 44, 'h': 24, 'confidence': '0.9993241640432052', 'text': 'may'}, {'x': 988, 'y': 86, 'w': 30, 'h': 24, 'confidence': '0.9999771564845276', 'text': 'be'}, {'x': 1051, 'y': 89, 'w': 42, 'h': 20, 'confidence': '0.573286771774292', 'text': 'sum'}, {'x': 1100, 'y': 84, 'w': 30, 'h': 24, 'confidence': '0.9779825118479354', 'text': 'of'}, {'x': 1136, 'y': 86, 'w': 56, 'h': 24, 'confidence': '0.9996870756149292', 'text': 'more'}, {'x': 1200, 'y': 84, 'w': 54, 'h': 26, 'confidence': '0.9999990463256836', 'text': 'than'}, {'x': 1262, 'y': 86, 'w': 42, 'h': 24, 'confidence': '0.9997339253003098', 'text': 'one'}, {'x': 1312, 'y': 84, 'w': 54, 'h': 26, 'confidence': '0.943695468084454', 'text': 'line'}, {'x': 1374, 'y': 84, 'w': 142, 'h': 26, 'confidence': '0.8525444638446946', 'text': 'item of the'}, {'x': 1524, 'y': 84, 'w': 100, 'h': 28, 'confidence': '0.9975195632208581', 'text': 'receipt.'}, {'x': 33, 'y': 115, 'w': 24, 'h': 20, 'confidence': '0.56587441780938', 'text': '3 .'}, {'x': 68, 'y': 112, 'w': 42, 'h': 24, 'confidence': '0.9999847207512171', 'text': 'For'}, {'x': 118, 'y': 110, 'w': 192, 'h': 28, 'confidence': '0.7126500304960272', 'text': 'this particular'}, {'x': 318, 'y': 112, 'w': 102, 'h': 26, 'confidence': '0.9992650999731791', 'text': 'receipt,'}, {'x': 430, 'y': 112, 'w': 42, 'h': 24, 'confidence': '0.9999971781544015', 'text': 'the'}, {'x': 478, 'y': 111, 'w': 106, 'h': 30, 'confidence': '0.9780463993537098', 'text': 'employee'}, {'x': 590, 'y': 112, 'w': 44, 'h': 24, 'confidence': '0.9995685453158122', 'text': 'who'}, {'x': 640, 'y': 107, 'w': 180, 'h': 33, 'confidence': '0.9455311419897349', 'text': 'is adding this'}, {'x': 826, 'y': 112, 'w': 106, 'h': 24, 'confidence': '0.9999275989143177', 'text': 'business'}, {'x': 938, 'y': 108, 'w': 268, 'h': 30, 'confidence': '0.963751899376601', 'text': 'expense purchased the'}, {'x': 1212, 'y': 110, 'w': 116, 'h': 26, 'confidence': '0.6860905905035973', 'text': 'meal with'}, {'x': 1338, 'y': 114, 'w': 100, 'h': 26, 'confidence': '0.8243623698152269', 'text': 'a group.'}, {'x': 1448, 'y': 112, 'w': 42, 'h': 24, 'confidence': '0.9998496865879453', 'text': 'The'}, {'x': 1498, 'y': 111, 'w': 104, 'h': 28, 'confidence': '0.8487215744157034', 'text': 'employee'}, {'x': 1610, 'y': 112, 'w': 56, 'h': 28, 'confidence': '0.9979934096336365', 'text': 'only'}, {'x': 1672, 'y': 110, 'w': 192, 'h': 26, 'confidence': '0.9969905831958893', 'text': 'ordered the KFC'}, {'x': 1870, 'y': 112, 'w': 66, 'h': 24, 'confidence': '0.9900630971579388', 'text': 'Bowl.'}, {'x': 1944, 'y': 112, 'w': 82, 'h': 24, 'confidence': '0.999803381021358', 'text': 'Please'}, {'x': 80, 'y': 138, 'w': 80, 'h': 24, 'confidence': '0.9983124440109534', 'text': 'Please'}, {'x': 167, 'y': 137, 'w': 118, 'h': 24, 'confidence': '0.9999749311213215', 'text': 'calculate'}, {'x': 292, 'y': 138, 'w': 42, 'h': 24, 'confidence': '0.9999988299663297', 'text': 'the'}, {'x': 342, 'y': 137, 'w': 154, 'h': 28, 'confidence': '0.6993969548949255', 'text': 'amount spent'}, {'x': 504, 'y': 136, 'w': 126, 'h': 30, 'confidence': '0.8719906769627512', 'text': 'by others,'}, {'x': 640, 'y': 138, 'w': 68, 'h': 24, 'confidence': '0.9997556675117976', 'text': 'which'}, {'x': 715, 'y': 141, 'w': 42, 'h': 20, 'confidence': '0.9999980728858172', 'text': 'are'}, {'x': 764, 'y': 138, 'w': 44, 'h': 24, 'confidence': '0.997220655437489', 'text': 'all'}, {'x': 814, 'y': 138, 'w': 44, 'h': 24, 'confidence': '0.9999978664093272', 'text': 'the'}, {'x': 864, 'y': 138, 'w': 68, 'h': 24, 'confidence': '0.9993321901251172', 'text': 'other'}, {'x': 940, 'y': 138, 'w': 54, 'h': 24, 'confidence': '0.9963870644569397', 'text': 'line'}, {'x': 1000, 'y': 138, 'w': 68, 'h': 24, 'confidence': '0.999889163595791', 'text': 'items'}, {'x': 1075, 'y': 141, 'w': 30, 'h': 20, 'confidence': '0.9966268862273182', 'text': 'on'}, {'x': 1112, 'y': 138, 'w': 44, 'h': 24, 'confidence': '0.9999990364428464', 'text': 'the'}, {'x': 1164, 'y': 138, 'w': 100, 'h': 28, 'confidence': '0.9989051137227429', 'text': 'receipt.'}, {'x': 1286, 'y': 138, 'w': 80, 'h': 24, 'confidence': '0.9996013021642848', 'text': 'Please'}, {'x': 1374, 'y': 136, 'w': 154, 'h': 30, 'confidence': '0.9910345708229625', 'text': 'provide this'}, {'x': 1537, 'y': 141, 'w': 40, 'h': 20, 'confidence': '0.999635853081893', 'text': 'sum'}, {'x': 1584, 'y': 137, 'w': 141, 'h': 28, 'confidence': '0.9896479039604617', 'text': 'before tax,'}, {'x': 1734, 'y': 138, 'w': 42, 'h': 24, 'confidence': '0.9999990364428464', 'text': 'and'}, {'x': 1784, 'y': 138, 'w': 152, 'h': 28, 'confidence': '0.8035293745685294', 'text': 'if possible,'}, {'x': 1944, 'y': 138, 'w': 68, 'h': 28, 'confidence': '0.9995393431034646', 'text': 'apply'}, {'x': 2020, 'y': 138, 'w': 24, 'h': 24, 'confidence': '0.9586832636657393', 'text': 'tl'}, {'x': 32, 'y': 164, 'w': 26, 'h': 24, 'confidence': '0.565953494046078', 'text': '5.'}, {'x': 68, 'y': 164, 'w': 68, 'h': 24, 'confidence': '0.9919380511212871', 'text': 'Check'}, {'x': 144, 'y': 164, 'w': 42, 'h': 24, 'confidence': '0.9999983481878129', 'text': 'the'}, {'x': 192, 'y': 161, 'w': 204, 'h': 32, 'confidence': '0.999466962913696', 'text': 'expenses against'}, {'x': 404, 'y': 162, 'w': 180, 'h': 30, 'confidence': '0.9806063188483984', 'text': 'company policy'}, {'x': 590, 'y': 161, 'w': 142, 'h': 32, 'confidence': '0.9810672320779089', 'text': 'and flag if'}, {'x': 740, 'y': 164, 'w': 68, 'h': 24, 'confidence': '0.9999988271355889', 'text': 'there'}, {'x': 815, 'y': 167, 'w': 42, 'h': 20, 'confidence': '0.9999980728858172', 'text': 'are'}, {'x': 864, 'y': 164, 'w': 82, 'h': 24, 'confidence': '0.9568123356701035', 'text': 'issues _'}, {'x': 30, 'y': 216, 'w': 218, 'h': 26, 'confidence': '0.9907401038596825', 'text': 'Gemini Multimodal'}, {'x': 32, 'y': 240, 'w': 378, 'h': 31, 'confidence': '0.8831933038557575', 'text': 'Business Travel Expense Policy'}, {'x': 30, 'y': 268, 'w': 118, 'h': 26, 'confidence': '0.9999711114068601', 'text': 'Effective'}, {'x': 154, 'y': 266, 'w': 190, 'h': 31, 'confidence': '0.7772153131295703', 'text': 'Date: April 17 ,'}, {'x': 354, 'y': 268, 'w': 56, 'h': 26, 'confidence': '0.9999996423721313', 'text': '2024'}, {'x': 31, 'y': 321, 'w': 93, 'h': 30, 'confidence': '0.9997492553761741', 'text': 'Purpose'}, {'x': 30, 'y': 348, 'w': 80, 'h': 24, 'confidence': '0.9991867002742832', 'text': 'Gemini'}, {'x': 118, 'y': 347, 'w': 365, 'h': 30, 'confidence': '0.9905808072602085', 'text': 'Multimodal supports essential'}, {'x': 490, 'y': 348, 'w': 106, 'h': 24, 'confidence': '0.9998595204666525', 'text': 'business'}, {'x': 602, 'y': 348, 'w': 80, 'h': 24, 'confidence': '0.9315373771338908', 'text': 'travel'}, {'x': 690, 'y': 348, 'w': 54, 'h': 24, 'confidence': '0.727445996354558', 'text': 'that'}, {'x': 752, 'y': 348, 'w': 104, 'h': 24, 'confidence': '0.9999838998501835', 'text': 'advances'}, {'x': 865, 'y': 351, 'w': 40, 'h': 20, 'confidence': '0.996775258494379', 'text': 'our'}, {'x': 914, 'y': 350, 'w': 92, 'h': 26, 'confidence': '0.9999943678853412', 'text': 'company'}, {'x': 1036, 'y': 345, 'w': 78, 'h': 31, 'confidence': '0.6563596201987308', 'text': 'goals .'}, {'x': 1124, 'y': 346, 'w': 142, 'h': 30, 'confidence': '0.9920853842534744', 'text': 'This policy'}, {'x': 1274, 'y': 350, 'w': 90, 'h': 20, 'confidence': '0.8395158623936367', 'text': 'ensures'}, {'x': 1374, 'y': 348, 'w': 54, 'h': 24, 'confidence': '0.9999992847442627', 'text': 'that'}, {'x': 1436, 'y': 348, 'w': 191, 'h': 27, 'confidence': '0.7454478877374853', 'text': 'travel expenses'}, {'x': 1634, 'y': 346, 'w': 190, 'h': 28, 'confidence': '0.976927772335218', 'text': 'are reasonable,'}, {'x': 1832, 'y': 350, 'w': 128, 'h': 26, 'confidence': '0.9489526791916504', 'text': 'necessary,'}, {'x': 1970, 'y': 348, 'w': 42, 'h': 24, 'confidence': '0.9999990364428464', 'text': 'and'}, {'x': 29, 'y': 399, 'w': 71, 'h': 30, 'confidence': '0.9996524518448598', 'text': 'Scope'}, {'x': 32, 'y': 425, 'w': 240, 'h': 32, 'confidence': '0.8746017850225902', 'text': 'This policy applies'}, {'x': 280, 'y': 426, 'w': 80, 'h': 26, 'confidence': '0.9789076289732268', 'text': 'to all'}, {'x': 366, 'y': 426, 'w': 218, 'h': 26, 'confidence': '0.774307515905906', 'text': 'Gemini Multimodal'}, {'x': 590, 'y': 427, 'w': 118, 'h': 30, 'confidence': '0.9680368340513102', 'text': 'employees'}, {'x': 714, 'y': 428, 'w': 44, 'h': 24, 'confidence': '0.9994055776978554', 'text': 'who'}, {'x': 764, 'y': 428, 'w': 68, 'h': 24, 'confidence': '0.9996909446115282', 'text': 'incur'}, {'x': 838, 'y': 430, 'w': 106, 'h': 24, 'confidence': '0.9999790107782008', 'text': 'expenses'}, {'x': 950, 'y': 424, 'w': 192, 'h': 32, 'confidence': '0.9843841128457312', 'text': 'while traveling'}, {'x': 1150, 'y': 426, 'w': 154, 'h': 30, 'confidence': '0.9980302524978887', 'text': 'for approved'}, {'x': 1312, 'y': 428, 'w': 218, 'h': 28, 'confidence': '0.9946219340916831', 'text': 'business purposes_'}, {'x': 30, 'y': 479, 'w': 204, 'h': 28, 'confidence': '0.9955882916250245', 'text': 'Covered Expenses'}, {'x': 32, 'y': 502, 'w': 166, 'h': 32, 'confidence': '0.992223197588734', 'text': 'The following'}, {'x': 204, 'y': 506, 'w': 168, 'h': 28, 'confidence': '0.9966257808038267', 'text': 'are generally'}, {'x': 380, 'y': 506, 'w': 128, 'h': 26, 'confidence': '0.9038724429220831', 'text': 'considered'}, {'x': 516, 'y': 504, 'w': 266, 'h': 29, 'confidence': '0.9929105218015821', 'text': 'reimbursable business'}, {'x': 788, 'y': 506, 'w': 80, 'h': 24, 'confidence': '0.9999941599575274', 'text': 'travel'}, {'x': 876, 'y': 508, 'w': 106, 'h': 26, 'confidence': '0.9999223535088086', 'text': 'expenses'}, {'x': 56, 'y': 532, 'w': 190, 'h': 28, 'confidence': '0.9370474595353794', 'text': 'Transportation:'}, {'x': 68, 'y': 557, 'w': 230, 'h': 30, 'confidence': '0.826722249538673', 'text': '* Airfare (economy'}, {'x': 306, 'y': 558, 'w': 76, 'h': 26, 'confidence': '0.9994830292098491', 'text': 'class)'}, {'x': 92, 'y': 584, 'w': 68, 'h': 26, 'confidence': '0.999554886292446', 'text': 'Train'}, {'x': 168, 'y': 586, 'w': 54, 'h': 24, 'confidence': '0.9999886751174927', 'text': 'fare'}, {'x': 92, 'y': 612, 'w': 80, 'h': 24, 'confidence': '0.9999913372675846', 'text': 'Rental'}, {'x': 181, 'y': 615, 'w': 40, 'h': 20, 'confidence': '0.9997388805623967', 'text': 'car'}, {'x': 231, 'y': 609, 'w': 103, 'h': 30, 'confidence': '0.9999832254960159', 'text': '(compact'}, {'x': 342, 'y': 610, 'w': 152, 'h': 28, 'confidence': '0.928017549067974', 'text': 'or mid-size,'}, {'x': 504, 'y': 612, 'w': 78, 'h': 24, 'confidence': '0.9998866531396473', 'text': 'unless'}, {'x': 613, 'y': 608, 'w': 107, 'h': 31, 'confidence': '0.9997717640262967', 'text': 'specific'}, {'x': 726, 'y': 612, 'w': 56, 'h': 24, 'confidence': '0.9999858140945435', 'text': 'need'}, {'x': 790, 'y': 608, 'w': 164, 'h': 32, 'confidence': '0.943387671389023', 'text': 'is justified)'}, {'x': 91, 'y': 636, 'w': 79, 'h': 28, 'confidence': '0.9987856142113103', 'text': 'Taxis,'}, {'x': 182, 'y': 636, 'w': 116, 'h': 26, 'confidence': '0.8969585919696003', 'text': 'ride-shar_'}, {'x': 342, 'y': 638, 'w': 104, 'h': 24, 'confidence': '0.9999552817795709', 'text': 'services'}, {'x': 456, 'y': 636, 'w': 152, 'h': 31, 'confidence': '0.8474549071135858', 'text': '(when public'}, {'x': 616, 'y': 638, 'w': 178, 'h': 26, 'confidence': '0.9982568459068579', 'text': 'transportation'}, {'x': 802, 'y': 638, 'w': 30, 'h': 24, 'confidence': '0.9914437397159993', 'text': 'is'}, {'x': 840, 'y': 635, 'w': 142, 'h': 27, 'confidence': '0.9998531659394596', 'text': 'unavailable'}, {'x': 988, 'y': 634, 'w': 190, 'h': 30, 'confidence': '0.7262643078415486', 'text': 'or impractical)'}, {'x': 56, 'y': 664, 'w': 102, 'h': 28, 'confidence': '0.9998192253983608', 'text': 'Lodging:'}, {'x': 168, 'y': 664, 'w': 104, 'h': 24, 'confidence': '0.9996928535477441', 'text': 'Standard'}, {'x': 280, 'y': 663, 'w': 254, 'h': 28, 'confidence': '0.9991865177192315', 'text': 'hotel accommodations'}, {'x': 541, 'y': 669, 'w': 30, 'h': 18, 'confidence': '0.9999587806309789', 'text': 'no'}, {'x': 579, 'y': 667, 'w': 54, 'h': 20, 'confidence': '0.695083790850847', 'text': 'more'}, {'x': 640, 'y': 664, 'w': 118, 'h': 26, 'confidence': '0.9877409409501702', 'text': 'then $150'}, {'x': 764, 'y': 666, 'w': 42, 'h': 24, 'confidence': '0.9867973923683167', 'text': 'per'}, {'x': 814, 'y': 664, 'w': 70, 'h': 28, 'confidence': '0.4354490128692074', 'text': 'night _'}, {'x': 30, 'y': 690, 'w': 144, 'h': 26, 'confidence': '0.7392865665778933', 'text': '* Meals and'}, {'x': 182, 'y': 692, 'w': 150, 'h': 24, 'confidence': '0.9990468814387938', 'text': 'restaurants:'}, {'x': 342, 'y': 690, 'w': 130, 'h': 26, 'confidence': '0.9998988929049696', 'text': 'Reasonable'}, {'x': 478, 'y': 692, 'w': 68, 'h': 24, 'confidence': '0.7289496632090955', 'text': 'costs'}, {'x': 554, 'y': 690, 'w': 126, 'h': 26, 'confidence': '0.9962884873708693', 'text': 'for meals,'}, {'x': 688, 'y': 690, 'w': 56, 'h': 26, 'confidence': '0.9638021438575296', 'text': 'with'}, {'x': 752, 'y': 687, 'w': 338, 'h': 31, 'confidence': '0.9627947982853389', 'text': 'the following daily limits:'}, {'x': 92, 'y': 716, 'w': 204, 'h': 26, 'confidence': '0.9996924364461144', 'text': 'Domestic Travel:'}, {'x': 304, 'y': 716, 'w': 68, 'h': 26, 'confidence': '0.9975552717885146', 'text': 'Total'}, {'x': 381, 'y': 721, 'w': 28, 'h': 20, 'confidence': '0.9999527115634608', 'text': 'no'}, {'x': 416, 'y': 716, 'w': 168, 'h': 26, 'confidence': '0.6541461144598212', 'text': 'more then $40'}, {'x': 590, 'y': 715, 'w': 103, 'h': 30, 'confidence': '0.9195623823194954', 'text': 'per day.'}, {'x': 94, 'y': 742, 'w': 263, 'h': 26, 'confidence': '0.9914980802768375', 'text': 'International Travel:'}, {'x': 366, 'y': 742, 'w': 56, 'h': 26, 'confidence': '0.6915890574455261', 'text': '$100'}, {'x': 430, 'y': 742, 'w': 93, 'h': 29, 'confidence': '0.7092113458725163', 'text': 'per day'}, {'x': 530, 'y': 742, 'w': 42, 'h': 26, 'confidence': '0.998463490956956', 'text': '(or'}, {'x': 580, 'y': 742, 'w': 66, 'h': 26, 'confidence': '0.4973433940108354', 'text': 'local'}, {'x': 652, 'y': 742, 'w': 252, 'h': 28, 'confidence': '0.9965491328092655', 'text': 'currency equivalent)'}, {'x': 590, 'y': 55, 'w': 40, 'h': 32, 'confidence': '0.7135051488876343', 'text': 'ling'}, {'x': 292, 'y': 635, 'w': 40, 'h': 31, 'confidence': '0.9997884333642442', 'text': 'ing'}]}]\n",
      "> Image for page 102: [{'name': 'img_p101_1.png', 'height': 540, 'width': 928, 'x': 352.79534593511994, 'y': 93.51769984296001, 'original_width': 928, 'original_height': 540, 'ocr': [{'x': 358, 'y': 106, 'w': 199, 'h': 43, 'confidence': '0.74669094081151', 'text': 'Google Cloud'}, {'x': 98, 'y': 400, 'w': 142, 'h': 30, 'confidence': '0.5765437349734229', 'text': '0.00 / 5.35'}]}, {'name': 'img_p101_2.png', 'height': 1018, 'width': 1052, 'x': 45.97244241599999, 'y': 90.85236511200003, 'original_width': 1052, 'original_height': 1018, 'ocr': [{'x': 5, 'y': 13, 'w': 648, 'h': 44, 'confidence': '0.7608192774061261', 'text': 'from vertexai.generative_models import'}, {'x': 669, 'y': 23, 'w': 14, 'h': 24, 'confidence': '0.9999911785320279', 'text': '('}, {'x': 69, 'y': 48, 'w': 295, 'h': 48, 'confidence': '0.9992848091365236', 'text': 'GenerationConfig,'}, {'x': 71, 'y': 93, 'w': 276, 'h': 38, 'confidence': '0.9998503811487134', 'text': 'GenerativeModel,'}, {'x': 73, 'y': 133, 'w': 88, 'h': 36, 'confidence': '0.9532121374223201', 'text': 'Part,'}, {'x': 4, 'y': 269, 'w': 127, 'h': 42, 'confidence': '0.9119524492651316', 'text': 'video_1'}, {'x': 173, 'y': 270, 'w': 442, 'h': 41, 'confidence': '0.8363773927056716', 'text': 'Part. from_urilvideo_uri_1,'}, {'x': 626, 'y': 269, 'w': 379, 'h': 42, 'confidence': '0.9031453807858679', 'text': 'mime_type-\"video/mp4\")'}, {'x': 8, 'y': 374, 'w': 72, 'h': 32, 'confidence': '0.9998827576637268', 'text': 'role'}, {'x': 6, 'y': 412, 'w': 56, 'h': 32, 'confidence': '0.9998902241101982', 'text': 'You'}, {'x': 72, 'y': 416, 'w': 58, 'h': 28, 'confidence': '0.9999988987918347', 'text': 'are'}, {'x': 141, 'y': 419, 'w': 18, 'h': 22, 'confidence': '0.9999760390763335', 'text': 'a'}, {'x': 172, 'y': 411, 'w': 229, 'h': 38, 'confidence': '0.9819457809959671', 'text': 'great digital'}, {'x': 409, 'y': 407, 'w': 279, 'h': 42, 'confidence': '0.9810569345756188', 'text': 'marketer working'}, {'x': 696, 'y': 416, 'w': 40, 'h': 28, 'confidence': '0.9987394520010692', 'text': 'on'}, {'x': 751, 'y': 419, 'w': 16, 'h': 22, 'confidence': '0.9999191777348102', 'text': 'a'}, {'x': 782, 'y': 412, 'w': 170, 'h': 32, 'confidence': '0.6701276901202033', 'text': 'new video.'}, {'x': 9, 'y': 453, 'w': 50, 'h': 14, 'confidence': '0.3260515959017454', 'text': 'I'}, {'x': 6, 'y': 554, 'w': 90, 'h': 30, 'confidence': '0.9996393898551956', 'text': 'tasks'}, {'x': 6, 'y': 590, 'w': 56, 'h': 32, 'confidence': '0.9998635890750133', 'text': 'You'}, {'x': 72, 'y': 590, 'w': 142, 'h': 32, 'confidence': '0.9919303158494711', 'text': 'will add'}, {'x': 224, 'y': 589, 'w': 157, 'h': 33, 'confidence': '0.8407817376796943', 'text': 'the video'}, {'x': 394, 'y': 592, 'w': 40, 'h': 30, 'confidence': '0.9999566733146458', 'text': 'to'}, {'x': 443, 'y': 589, 'w': 210, 'h': 38, 'confidence': '0.8201723555603913', 'text': 'your website'}, {'x': 662, 'y': 590, 'w': 58, 'h': 32, 'confidence': '0.9999981417113152', 'text': 'and'}, {'x': 730, 'y': 592, 'w': 40, 'h': 30, 'confidence': '0.9999564204367732', 'text': 'to'}, {'x': 780, 'y': 590, 'w': 42, 'h': 32, 'confidence': '0.9999927507497521', 'text': 'do'}, {'x': 832, 'y': 590, 'w': 72, 'h': 32, 'confidence': '0.9999953508377075', 'text': 'this'}, {'x': 916, 'y': 594, 'w': 56, 'h': 32, 'confidence': '0.9979738455636429', 'text': 'you'}, {'x': 6, 'y': 628, 'w': 74, 'h': 32, 'confidence': '0.9999983310699463', 'text': 'need'}, {'x': 90, 'y': 630, 'w': 40, 'h': 30, 'confidence': '0.9999755549153756', 'text': 'to'}, {'x': 137, 'y': 623, 'w': 147, 'h': 45, 'confidence': '0.9932243360927453', 'text': 'complete'}, {'x': 292, 'y': 632, 'w': 74, 'h': 28, 'confidence': '0.999606728553772', 'text': 'some'}, {'x': 376, 'y': 630, 'w': 104, 'h': 30, 'confidence': '0.6751902012905109', 'text': 'tasks.'}, {'x': 494, 'y': 628, 'w': 108, 'h': 32, 'confidence': '0.7424340630597929', 'text': 'Please'}, {'x': 612, 'y': 630, 'w': 74, 'h': 30, 'confidence': '0.5796383508410455', 'text': 'make'}, {'x': 698, 'y': 632, 'w': 72, 'h': 28, 'confidence': '0.9998302459716797', 'text': 'sure'}, {'x': 866, 'y': 631, 'w': 106, 'h': 26, 'confidence': '0.9999673781188508', 'text': 'answer'}, {'x': 6, 'y': 666, 'w': 38, 'h': 32, 'confidence': '0.9943501805723087', 'text': 'is'}, {'x': 56, 'y': 666, 'w': 180, 'h': 32, 'confidence': '0.9742456891589484', 'text': 'structured_'}, {'x': 6, 'y': 741, 'w': 103, 'h': 32, 'confidence': '0.8275930671724279', 'text': 'Tasks:'}, {'x': 40, 'y': 780, 'w': 72, 'h': 32, 'confidence': '0.9271888006784769', 'text': 'What'}, {'x': 126, 'y': 780, 'w': 38, 'h': 32, 'confidence': '0.9890696824020646', 'text': 'is'}, {'x': 174, 'y': 780, 'w': 158, 'h': 32, 'confidence': '0.9784115439712077', 'text': 'the title'}, {'x': 342, 'y': 780, 'w': 40, 'h': 32, 'confidence': '0.8894433409708339', 'text': 'of'}, {'x': 394, 'y': 780, 'w': 56, 'h': 32, 'confidence': '0.9999941498334826', 'text': 'the'}, {'x': 460, 'y': 780, 'w': 108, 'h': 32, 'confidence': '0.9990910998010079', 'text': 'video?'}, {'x': 37, 'y': 818, 'w': 92, 'h': 32, 'confidence': '0.9999955751015998', 'text': 'Write'}, {'x': 141, 'y': 823, 'w': 20, 'h': 24, 'confidence': '0.9998436035275517', 'text': 'a'}, {'x': 172, 'y': 816, 'w': 177, 'h': 41, 'confidence': '0.7257154020010645', 'text': 'summary of'}, {'x': 360, 'y': 818, 'w': 72, 'h': 32, 'confidence': '0.9997713565826416', 'text': 'what'}, {'x': 446, 'y': 818, 'w': 38, 'h': 32, 'confidence': '0.9800184066415726', 'text': 'is'}, {'x': 496, 'y': 818, 'w': 38, 'h': 32, 'confidence': '0.9989563507317687', 'text': 'in'}, {'x': 546, 'y': 818, 'w': 56, 'h': 32, 'confidence': '0.9999993117448777', 'text': 'the'}, {'x': 612, 'y': 818, 'w': 104, 'h': 32, 'confidence': '0.9990933389394743', 'text': 'video.'}, {'x': 38, 'y': 856, 'w': 142, 'h': 32, 'confidence': '0.9999212684031765', 'text': 'Generate'}, {'x': 190, 'y': 856, 'w': 142, 'h': 32, 'confidence': '0.9999538066120977', 'text': 'metadata'}, {'x': 344, 'y': 856, 'w': 56, 'h': 32, 'confidence': '0.999993117451632', 'text': 'for'}, {'x': 410, 'y': 856, 'w': 58, 'h': 32, 'confidence': '0.9929929375648499', 'text': 'the'}, {'x': 478, 'y': 856, 'w': 90, 'h': 32, 'confidence': '0.9997637711679316', 'text': 'video'}, {'x': 580, 'y': 856, 'w': 38, 'h': 32, 'confidence': '0.9986294068716535', 'text': 'in'}, {'x': 630, 'y': 856, 'w': 74, 'h': 32, 'confidence': '0.9999138712882996', 'text': 'JSON'}, {'x': 714, 'y': 856, 'w': 74, 'h': 32, 'confidence': '0.6906763337151501', 'text': 'that'}, {'x': 798, 'y': 856, 'w': 170, 'h': 32, 'confidence': '0.9911581516139794', 'text': 'includes: |'}, {'x': 3, 'y': 889, 'w': 109, 'h': 42, 'confidence': '0.9971394075228968', 'text': 'Title,'}, {'x': 123, 'y': 892, 'w': 476, 'h': 44, 'confidence': '0.6534639017980978', 'text': 'short description, language ,'}, {'x': 612, 'y': 894, 'w': 56, 'h': 32, 'confidence': '0.9999992429193688', 'text': 'and'}, {'x': 679, 'y': 897, 'w': 140, 'h': 36, 'confidence': '0.6920323164891581', 'text': 'company .'}, {'x': 777, 'y': 632, 'w': 79, 'h': 28, 'confidence': '0.9997251033782959', 'text': 'your'}]}]\n",
      "> Image for page 103: [{'name': 'img_p102_1.png', 'height': 536, 'width': 922, 'x': 360.00038553575996, 'y': 86.40352638696001, 'original_width': 922, 'original_height': 536, 'ocr': [{'x': 100, 'y': 406, 'w': 64, 'h': 32, 'confidence': '0.7756874561309814', 'text': '0.00'}, {'x': 178, 'y': 406, 'w': 64, 'h': 32, 'confidence': '0.998760998249054', 'text': '2.53'}]}, {'name': 'img_p102_2.png', 'height': 876, 'width': 1122, 'x': 13.332677592, 'y': 94.39764081600003, 'original_width': 1122, 'original_height': 876, 'ocr': [{'x': 72, 'y': 42, 'w': 108, 'h': 38, 'confidence': '0.999988514575851', 'text': 'prompt'}, {'x': 74, 'y': 82, 'w': 108, 'h': 32, 'confidence': '0.9998318037080149', 'text': 'Please'}, {'x': 192, 'y': 82, 'w': 74, 'h': 32, 'confidence': '0.7107554391052084', 'text': 'have'}, {'x': 277, 'y': 87, 'w': 18, 'h': 24, 'confidence': '0.999949694312491', 'text': 'a'}, {'x': 308, 'y': 78, 'w': 77, 'h': 38, 'confidence': '0.4223211407661438', 'text': 'Zook'}, {'x': 394, 'y': 82, 'w': 40, 'h': 30, 'confidence': '0.9999997471189183', 'text': 'at'}, {'x': 445, 'y': 78, 'w': 343, 'h': 37, 'confidence': '0.9599571095775363', 'text': 'the video and answer'}, {'x': 797, 'y': 76, 'w': 228, 'h': 43, 'confidence': '0.9974369315981092', 'text': 'the following'}, {'x': 72, 'y': 116, 'w': 163, 'h': 41, 'confidence': '0.9875382481580799', 'text': 'questions '}, {'x': 73, 'y': 193, 'w': 172, 'h': 36, 'confidence': '0.9999843178570138', 'text': 'Questions:'}, {'x': 107, 'y': 231, 'w': 142, 'h': 36, 'confidence': '0.9999860493528355', 'text': 'Question'}, {'x': 260, 'y': 234, 'w': 36, 'h': 32, 'confidence': '0.9983559946482976', 'text': '1:'}, {'x': 307, 'y': 231, 'w': 94, 'h': 36, 'confidence': '0.9999902972077144', 'text': 'Which'}, {'x': 411, 'y': 233, 'w': 124, 'h': 38, 'confidence': '0.9988177864019169', 'text': 'concept'}, {'x': 545, 'y': 228, 'w': 211, 'h': 44, 'confidence': '0.9895316138208097', 'text': 'is explained'}, {'x': 766, 'y': 234, 'w': 38, 'h': 32, 'confidence': '0.9967594358502275', 'text': 'in'}, {'x': 815, 'y': 231, 'w': 176, 'h': 36, 'confidence': '0.7775639743495498', 'text': 'the video?'}, {'x': 107, 'y': 269, 'w': 142, 'h': 36, 'confidence': '0.9999842643118761', 'text': 'Question'}, {'x': 260, 'y': 272, 'w': 36, 'h': 32, 'confidence': '0.999822566378655', 'text': '2:'}, {'x': 309, 'y': 269, 'w': 92, 'h': 36, 'confidence': '0.9348673518275584', 'text': 'Based'}, {'x': 412, 'y': 276, 'w': 38, 'h': 28, 'confidence': '0.9996888861410292', 'text': 'on'}, {'x': 462, 'y': 276, 'w': 74, 'h': 32, 'confidence': '0.999560534954071', 'text': 'your'}, {'x': 546, 'y': 274, 'w': 108, 'h': 30, 'confidence': '0.9999981993210549', 'text': 'answer'}, {'x': 664, 'y': 274, 'w': 40, 'h': 30, 'confidence': '0.9999524586858817', 'text': 'to'}, {'x': 714, 'y': 272, 'w': 142, 'h': 32, 'confidence': '0.8813209909607107', 'text': 'Question'}, {'x': 866, 'y': 272, 'w': 34, 'h': 32, 'confidence': '0.999972436072341', 'text': '1,'}, {'x': 74, 'y': 312, 'w': 56, 'h': 30, 'confidence': '0.9999861660842221', 'text': 'can'}, {'x': 139, 'y': 305, 'w': 195, 'h': 44, 'confidence': '0.9717077728634479', 'text': 'you explain'}, {'x': 344, 'y': 310, 'w': 56, 'h': 32, 'confidence': '0.9999984858388146', 'text': 'the'}, {'x': 412, 'y': 310, 'w': 88, 'h': 32, 'confidence': '0.9996208364638179', 'text': 'basic'}, {'x': 512, 'y': 310, 'w': 74, 'h': 32, 'confidence': '0.9999603033065796', 'text': 'math'}, {'x': 595, 'y': 307, 'w': 278, 'h': 42, 'confidence': '0.7053587695545492', 'text': 'of this concept?'}, {'x': 107, 'y': 345, 'w': 142, 'h': 36, 'confidence': '0.9380509498955011', 'text': 'Question'}, {'x': 260, 'y': 348, 'w': 36, 'h': 32, 'confidence': '0.9997729203325075', 'text': '3:'}, {'x': 309, 'y': 343, 'w': 261, 'h': 42, 'confidence': '0.7204563267685735', 'text': 'Can you provide'}, {'x': 579, 'y': 353, 'w': 20, 'h': 24, 'confidence': '0.9999525552655228', 'text': 'a'}, {'x': 611, 'y': 345, 'w': 228, 'h': 40, 'confidence': '0.7030534814046069', 'text': 'simple scikit'}, {'x': 849, 'y': 343, 'w': 211, 'h': 45, 'confidence': '0.9008396650303245', 'text': 'code example'}, {'x': 73, 'y': 383, 'w': 176, 'h': 40, 'confidence': '0.6723170195287769', 'text': 'explaining'}, {'x': 259, 'y': 383, 'w': 208, 'h': 40, 'confidence': '0.6890119863426373', 'text': 'the concept?'}, {'x': 0, 'y': 525, 'w': 249, 'h': 38, 'confidence': '0.9971078302335363', 'text': '147] contents_2'}, {'x': 296, 'y': 521, 'w': 151, 'h': 43, 'confidence': '0.9946838947604668', 'text': '[video_2,'}, {'x': 461, 'y': 524, 'w': 122, 'h': 38, 'confidence': '0.9994891480581131', 'text': 'prompt]'}, {'x': 0, 'y': 625, 'w': 231, 'h': 40, 'confidence': '0.9451565641753525', 'text': '148] responses'}, {'x': 275, 'y': 624, 'w': 578, 'h': 41, 'confidence': '0.7559275347279795', 'text': 'multimodal_model.generate_content ('}, {'x': 141, 'y': 665, 'w': 188, 'h': 38, 'confidence': '0.9932523266405199', 'text': 'contents_2,'}, {'x': 142, 'y': 704, 'w': 208, 'h': 32, 'confidence': '0.9990117603779456', 'text': 'stream-False'}, {'x': 0, 'y': 841, 'w': 165, 'h': 35, 'confidence': '0.9928013110343167', 'text': '149] print'}, {'x': 178, 'y': 846, 'w': 156, 'h': 30, 'confidence': '0.9993873477058083', 'text': 'responses'}, {'x': 344, 'y': 844, 'w': 74, 'h': 32, 'confidence': '0.9999988675117493', 'text': 'text'}]}]\n",
      "> Image for page 104: [{'name': 'img_p103_1.png', 'height': 536, 'width': 920, 'x': 329.43538455768, 'y': 59.80118301600001, 'original_width': 920, 'original_height': 536, 'ocr': [{'x': 303, 'y': 240, 'w': 320, 'h': 42, 'confidence': '0.26179687417090025', 'text': 'the most searched'}, {'x': 100, 'y': 406, 'w': 64, 'h': 32, 'confidence': '0.9963351488113403', 'text': '0.52'}, {'x': 178, 'y': 406, 'w': 64, 'h': 32, 'confidence': '0.6672900458474949', 'text': '3*48'}]}, {'name': 'img_p103_2.png', 'height': 1370, 'width': 1160, 'x': 29.318898576, 'y': 56.427167159999954, 'original_width': 1160, 'original_height': 1370, 'ocr': [{'x': 0, 'y': 6, 'w': 214, 'h': 48, 'confidence': '0.556312606113735', 'text': '[152] video_4'}, {'x': 257, 'y': 10, 'w': 444, 'h': 44, 'confidence': '0.44179395906925045', 'text': 'Part.from_uri(video_uri_4,'}, {'x': 711, 'y': 9, 'w': 378, 'h': 45, 'confidence': '0.6628797254677884', 'text': 'mime_type-\"video/mp4\" )'}, {'x': 0, 'y': 113, 'w': 247, 'h': 38, 'confidence': '0.6729264790157601', 'text': '[153] questions'}, {'x': 88, 'y': 152, 'w': 111, 'h': 37, 'confidence': '0.999993721954033', 'text': 'Answer'}, {'x': 207, 'y': 148, 'w': 394, 'h': 43, 'confidence': '0.980842983905708', 'text': 'the following questions'}, {'x': 611, 'y': 151, 'w': 358, 'h': 40, 'confidence': '0.7172830451678459', 'text': 'using the video only.'}, {'x': 87, 'y': 227, 'w': 174, 'h': 36, 'confidence': '0.999981905206946', 'text': 'Questions:'}, {'x': 124, 'y': 268, 'w': 72, 'h': 32, 'confidence': '0.9999670531106685', 'text': 'What'}, {'x': 208, 'y': 268, 'w': 38, 'h': 32, 'confidence': '0.9883778256342282', 'text': 'is'}, {'x': 258, 'y': 268, 'w': 58, 'h': 32, 'confidence': '0.9999969716779362', 'text': 'the'}, {'x': 326, 'y': 268, 'w': 72, 'h': 32, 'confidence': '0.9999340176582336', 'text': 'most'}, {'x': 409, 'y': 265, 'w': 261, 'h': 41, 'confidence': '0.8116535715280093', 'text': 'searched sport?'}, {'x': 122, 'y': 306, 'w': 58, 'h': 32, 'confidence': '0.99994555921585', 'text': 'Who'}, {'x': 192, 'y': 306, 'w': 38, 'h': 32, 'confidence': '0.9794068293758842', 'text': 'is'}, {'x': 241, 'y': 303, 'w': 58, 'h': 36, 'confidence': '0.9999986923153217', 'text': 'the'}, {'x': 308, 'y': 306, 'w': 74, 'h': 32, 'confidence': '0.9999513626098633', 'text': 'most'}, {'x': 393, 'y': 303, 'w': 142, 'h': 36, 'confidence': '0.9999951531075558', 'text': 'searched'}, {'x': 545, 'y': 303, 'w': 174, 'h': 36, 'confidence': '0.7937743771099761', 'text': 'scientist?'}, {'x': 0, 'y': 481, 'w': 283, 'h': 40, 'confidence': '0.975713385849282', 'text': '[154] format_html'}, {'x': 90, 'y': 522, 'w': 120, 'h': 32, 'confidence': '0.7328977345955289', 'text': 'Format:'}, {'x': 90, 'y': 560, 'w': 124, 'h': 32, 'confidence': '0.8926898518498407', 'text': 'Present'}, {'x': 224, 'y': 558, 'w': 58, 'h': 32, 'confidence': '0.999999449395897', 'text': 'the'}, {'x': 292, 'y': 556, 'w': 124, 'h': 36, 'confidence': '0.9999836443107158', 'text': 'results'}, {'x': 428, 'y': 560, 'w': 38, 'h': 32, 'confidence': '0.9967257505774506', 'text': 'in'}, {'x': 477, 'y': 565, 'w': 20, 'h': 24, 'confidence': '0.9999492174873836', 'text': 'a'}, {'x': 509, 'y': 557, 'w': 178, 'h': 36, 'confidence': '0.8275411396534292', 'text': 'table with'}, {'x': 699, 'y': 567, 'w': 16, 'h': 22, 'confidence': '0.9999158400123775', 'text': 'a'}, {'x': 732, 'y': 564, 'w': 54, 'h': 26, 'confidence': '0.9999277335586639', 'text': 'row'}, {'x': 797, 'y': 557, 'w': 294, 'h': 38, 'confidence': '0.997622161096743', 'text': 'for each question'}, {'x': 89, 'y': 595, 'w': 58, 'h': 36, 'confidence': '0.9999991740938607', 'text': 'and'}, {'x': 158, 'y': 598, 'w': 56, 'h': 32, 'confidence': '0.9985137234030005', 'text': 'its'}, {'x': 224, 'y': 600, 'w': 120, 'h': 28, 'confidence': '0.9990611877796228', 'text': 'answer.'}, {'x': 88, 'y': 636, 'w': 76, 'h': 32, 'confidence': '0.8996988959990896', 'text': 'Make'}, {'x': 174, 'y': 638, 'w': 74, 'h': 30, 'confidence': '0.9999633431434631', 'text': 'sure'}, {'x': 257, 'y': 633, 'w': 160, 'h': 36, 'confidence': '0.7175525148271596', 'text': 'the table'}, {'x': 428, 'y': 636, 'w': 38, 'h': 32, 'confidence': '0.811157878418889', 'text': 'is'}, {'x': 477, 'y': 633, 'w': 194, 'h': 36, 'confidence': '0.67043221440774', 'text': 'in markdown'}, {'x': 680, 'y': 636, 'w': 120, 'h': 32, 'confidence': '0.6675632288291541', 'text': 'format.'}, {'x': 91, 'y': 675, 'w': 52, 'h': 14, 'confidence': '0.17517707950307582', 'text': 'M'}, {'x': 0, 'y': 773, 'w': 263, 'h': 38, 'confidence': '0.9245846946264338', 'text': '[155] contents_4'}, {'x': 311, 'y': 773, 'w': 152, 'h': 40, 'confidence': '0.7308973545407734', 'text': '[video_4,'}, {'x': 476, 'y': 773, 'w': 173, 'h': 40, 'confidence': '0.9989614755311491', 'text': 'questions,'}, {'x': 662, 'y': 771, 'w': 207, 'h': 43, 'confidence': '0.8090602432974988', 'text': 'format_html]'}, {'x': 0, 'y': 874, 'w': 417, 'h': 41, 'confidence': '0.7750802091881405', 'text': '[156] generation_config_1'}, {'x': 458, 'y': 871, 'w': 281, 'h': 44, 'confidence': '0.9462622989211181', 'text': 'GenerationConfig'}, {'x': 156, 'y': 915, 'w': 274, 'h': 38, 'confidence': '0.8734555888004355', 'text': 'temperature-0.9,'}, {'x': 0, 'y': 1053, 'w': 247, 'h': 41, 'confidence': '0.9981949429498763', 'text': '[157] responses'}, {'x': 290, 'y': 1052, 'w': 565, 'h': 41, 'confidence': '0.7806505818776193', 'text': 'multimodal_model.generate_content'}, {'x': 865, 'y': 1055, 'w': 186, 'h': 36, 'confidence': '0.8292144907558544', 'text': 'contents_4,'}, {'x': 407, 'y': 1089, 'w': 647, 'h': 45, 'confidence': '0.7089582259584877', 'text': 'generation_config-generation_config_1,'}, {'x': 866, 'y': 1132, 'w': 190, 'h': 32, 'confidence': '0.9705103181589926', 'text': 'stream-True'}, {'x': 0, 'y': 1269, 'w': 83, 'h': 36, 'confidence': '0.9999961082220113', 'text': '[158]'}, {'x': 158, 'y': 1271, 'w': 141, 'h': 39, 'confidence': '0.9999979348035396', 'text': 'response'}, {'x': 310, 'y': 1272, 'w': 38, 'h': 32, 'confidence': '0.9972788207386709', 'text': 'in'}, {'x': 362, 'y': 1276, 'w': 168, 'h': 32, 'confidence': '0.999840683888485', 'text': 'responses:'}, {'x': 153, 'y': 1306, 'w': 95, 'h': 42, 'confidence': '0.9999960549099717', 'text': 'print'}, {'x': 258, 'y': 1309, 'w': 239, 'h': 37, 'confidence': '0.9970463770819117', 'text': 'response.text,'}, {'x': 511, 'y': 1308, 'w': 119, 'h': 32, 'confidence': '0.7293539594102963', 'text': 'end-\"\")'}, {'x': 90, 'y': 1266, 'w': 55, 'h': 42, 'confidence': '0.9999768746626454', 'text': 'for'}]}]\n",
      "> Image for page 105: [{'name': 'img_p104_1.png', 'height': 666, 'width': 1160, 'x': 360.00001152, 'y': 79.76966790696002, 'original_width': 1160, 'original_height': 666, 'ocr': [{'x': 514, 'y': 190, 'w': 123, 'h': 50, 'confidence': '0.950062752429044', 'text': 'LLMOps'}, {'x': 451, 'y': 283, 'w': 256, 'h': 40, 'confidence': '0.9999459609883592', 'text': 'Data Preparation'}, {'x': 449, 'y': 507, 'w': 125, 'h': 30, 'confidence': '0.9996109895580694', 'text': 'Google Cloud'}, {'x': 386, 'y': 528, 'w': 64, 'h': 30, 'confidence': '0.4604068100452423', 'text': 'O.00'}, {'x': 631, 'y': 541, 'w': 104, 'h': 14, 'confidence': '0.1797544128283806', 'text': 'peepledrnna'}]}, {'name': 'img_p104_2.png', 'height': 848, 'width': 1142, 'x': 13.990157927999999, 'y': 73.79528779452, 'original_width': 1142, 'original_height': 848, 'ocr': [{'x': 0, 'y': 11, 'w': 73, 'h': 36, 'confidence': '0.9999951124191284', 'text': '165]'}, {'x': 82, 'y': 12, 'w': 72, 'h': 32, 'confidence': '0.9998624324798584', 'text': 'role'}, {'x': 80, 'y': 50, 'w': 56, 'h': 32, 'confidence': '0.9702733755111694', 'text': 'You'}, {'x': 147, 'y': 46, 'w': 260, 'h': 41, 'confidence': '0.9986340795463683', 'text': 'are specialized'}, {'x': 418, 'y': 50, 'w': 38, 'h': 32, 'confidence': '0.9982421706317401', 'text': 'in'}, {'x': 467, 'y': 47, 'w': 278, 'h': 40, 'confidence': '0.924004349561967', 'text': 'analyzing videos'}, {'x': 753, 'y': 44, 'w': 195, 'h': 43, 'confidence': '0.9941287760748309', 'text': 'and finding'}, {'x': 83, 'y': 95, 'w': 16, 'h': 22, 'confidence': '0.9999289525254085', 'text': 'a'}, {'x': 114, 'y': 88, 'w': 108, 'h': 32, 'confidence': '0.9998654824098778', 'text': 'needle'}, {'x': 232, 'y': 88, 'w': 40, 'h': 32, 'confidence': '0.9984530555834731', 'text': 'in'}, {'x': 283, 'y': 95, 'w': 18, 'h': 22, 'confidence': '0.9999060652858702', 'text': 'a'}, {'x': 314, 'y': 86, 'w': 157, 'h': 40, 'confidence': '0.6985897229299273', 'text': 'haystack.'}, {'x': 319, 'y': 231, 'w': 50, 'h': 14, 'confidence': '0.41582931338297513', 'text': 'I'}, {'x': 82, 'y': 228, 'w': 188, 'h': 32, 'confidence': '0.9716687982410074', 'text': 'instruction'}, {'x': 80, 'y': 266, 'w': 74, 'h': 32, 'confidence': '0.9999921321868896', 'text': 'Here'}, {'x': 164, 'y': 270, 'w': 56, 'h': 28, 'confidence': '0.9999984858388146', 'text': 'are'}, {'x': 231, 'y': 263, 'w': 212, 'h': 36, 'confidence': '0.6592995204953528', 'text': 'three videos.'}, {'x': 468, 'y': 266, 'w': 72, 'h': 32, 'confidence': '0.9999374151229858', 'text': 'Each'}, {'x': 552, 'y': 266, 'w': 40, 'h': 32, 'confidence': '0.9940914171039054', 'text': 'is'}, {'x': 603, 'y': 271, 'w': 20, 'h': 24, 'confidence': '0.9999471909819455', 'text': 'a'}, {'x': 637, 'y': 265, 'w': 106, 'h': 32, 'confidence': '0.4623927447679815', 'text': 'Iesson'}, {'x': 754, 'y': 266, 'w': 74, 'h': 32, 'confidence': '0.9999258518218994', 'text': 'from'}, {'x': 838, 'y': 266, 'w': 58, 'h': 32, 'confidence': '0.9999950445645353', 'text': 'the'}, {'x': 75, 'y': 296, 'w': 114, 'h': 50, 'confidence': '0.9210088955027822', 'text': 'LLMOpS'}, {'x': 198, 'y': 308, 'w': 108, 'h': 28, 'confidence': '0.8927056490618596', 'text': 'course'}, {'x': 315, 'y': 299, 'w': 312, 'h': 43, 'confidence': '0.7019729335497192', 'text': 'from Deep Learning'}, {'x': 636, 'y': 304, 'w': 52, 'h': 30, 'confidence': '0.9401186100226367', 'text': 'AI.'}, {'x': 80, 'y': 342, 'w': 74, 'h': 32, 'confidence': '0.9999697208404541', 'text': 'Your'}, {'x': 164, 'y': 346, 'w': 122, 'h': 26, 'confidence': '0.9499116605140362', 'text': 'answers'}, {'x': 298, 'y': 346, 'w': 56, 'h': 26, 'confidence': '0.999999449395897', 'text': 'are'}, {'x': 365, 'y': 343, 'w': 76, 'h': 36, 'confidence': '0.9990113973617554', 'text': 'only'}, {'x': 450, 'y': 342, 'w': 90, 'h': 32, 'confidence': '0.9999985072634486', 'text': 'based'}, {'x': 552, 'y': 346, 'w': 40, 'h': 28, 'confidence': '0.9982658450400816', 'text': 'on'}, {'x': 602, 'y': 342, 'w': 58, 'h': 32, 'confidence': '0.9999949069135972', 'text': 'the'}, {'x': 670, 'y': 342, 'w': 110, 'h': 32, 'confidence': '0.6047891211126444', 'text': 'videos _'}, {'x': 0, 'y': 479, 'w': 237, 'h': 40, 'confidence': '0.9999483856031416', 'text': '167] questions'}, {'x': 79, 'y': 521, 'w': 108, 'h': 30, 'confidence': '0.9999959119710741', 'text': 'Answer'}, {'x': 197, 'y': 515, 'w': 396, 'h': 42, 'confidence': '0.7907524183487996', 'text': 'the following questions'}, {'x': 80, 'y': 560, 'w': 34, 'h': 28, 'confidence': '0.9504065627152019', 'text': '1.'}, {'x': 130, 'y': 558, 'w': 108, 'h': 32, 'confidence': '0.9591048698704394', 'text': 'Create'}, {'x': 249, 'y': 563, 'w': 18, 'h': 24, 'confidence': '0.9998850855463957', 'text': 'a'}, {'x': 282, 'y': 562, 'w': 124, 'h': 32, 'confidence': '0.9646086987180675', 'text': 'summary'}, {'x': 416, 'y': 558, 'w': 40, 'h': 32, 'confidence': '0.9015871899892635', 'text': 'of'}, {'x': 466, 'y': 557, 'w': 175, 'h': 33, 'confidence': '0.8988325861652374', 'text': 'each video'}, {'x': 652, 'y': 558, 'w': 58, 'h': 32, 'confidence': '0.9041779637336731', 'text': 'and'}, {'x': 720, 'y': 558, 'w': 74, 'h': 32, 'confidence': '0.5885601593317554', 'text': 'what'}, {'x': 806, 'y': 558, 'w': 38, 'h': 32, 'confidence': '0.9919980523751981', 'text': 'is'}, {'x': 854, 'y': 558, 'w': 158, 'h': 32, 'confidence': '0.9999965031911162', 'text': 'discussed'}, {'x': 1024, 'y': 560, 'w': 40, 'h': 30, 'confidence': '0.9988633202160316', 'text': 'in'}, {'x': 80, 'y': 596, 'w': 56, 'h': 32, 'confidence': '0.9999940810080215', 'text': 'the'}, {'x': 146, 'y': 596, 'w': 106, 'h': 32, 'confidence': '0.827157994106226', 'text': 'video .'}, {'x': 80, 'y': 634, 'w': 90, 'h': 32, 'confidence': '0.9998923623579367', 'text': 'Limit'}, {'x': 181, 'y': 632, 'w': 242, 'h': 41, 'confidence': '0.9917625358198918', 'text': 'the summary to'}, {'x': 435, 'y': 639, 'w': 18, 'h': 24, 'confidence': '0.9999465949513251', 'text': 'a'}, {'x': 466, 'y': 638, 'w': 58, 'h': 28, 'confidence': '0.9969488382339478', 'text': 'max'}, {'x': 534, 'y': 634, 'w': 40, 'h': 32, 'confidence': '0.8882092954206994', 'text': 'of'}, {'x': 586, 'y': 633, 'w': 159, 'h': 33, 'confidence': '0.8106174028196722', 'text': '100 words'}, {'x': 80, 'y': 672, 'w': 34, 'h': 30, 'confidence': '0.9476920724710776', 'text': '2 .'}, {'x': 130, 'y': 671, 'w': 139, 'h': 33, 'confidence': '0.9981684242803448', 'text': 'In which'}, {'x': 282, 'y': 672, 'w': 40, 'h': 32, 'confidence': '0.8605817749088686', 'text': 'of'}, {'x': 334, 'y': 672, 'w': 56, 'h': 32, 'confidence': '0.9999979352348233', 'text': 'the'}, {'x': 399, 'y': 669, 'w': 210, 'h': 38, 'confidence': '0.9969891419716991', 'text': 'three videos'}, {'x': 620, 'y': 672, 'w': 72, 'h': 32, 'confidence': '0.9999933242797852', 'text': 'does'}, {'x': 704, 'y': 672, 'w': 56, 'h': 32, 'confidence': '0.9999935992298111', 'text': 'the'}, {'x': 772, 'y': 672, 'w': 174, 'h': 32, 'confidence': '0.9998390627542691', 'text': 'instructor'}, {'x': 958, 'y': 676, 'w': 54, 'h': 28, 'confidence': '0.9999980728858172', 'text': 'run'}, {'x': 80, 'y': 710, 'w': 56, 'h': 32, 'confidence': '0.9999979352348233', 'text': 'and'}, {'x': 147, 'y': 709, 'w': 142, 'h': 38, 'confidence': '0.9999423002748689', 'text': 'explains'}, {'x': 298, 'y': 710, 'w': 74, 'h': 32, 'confidence': '0.9999973773956299', 'text': 'this'}, {'x': 383, 'y': 709, 'w': 108, 'h': 38, 'confidence': '0.999936683797243', 'text': 'Python'}, {'x': 502, 'y': 710, 'w': 86, 'h': 32, 'confidence': '0.9999540982307388', 'text': 'code:'}, {'x': 601, 'y': 707, 'w': 297, 'h': 45, 'confidence': '0.4474401219154356', 'text': 'bq_client.query( ) _'}, {'x': 80, 'y': 748, 'w': 90, 'h': 32, 'confidence': '0.9999867252978659', 'text': 'Where'}, {'x': 179, 'y': 747, 'w': 110, 'h': 40, 'confidence': '0.9434421723862425', 'text': 'do you'}, {'x': 300, 'y': 752, 'w': 56, 'h': 28, 'confidence': '0.9996683372107699', 'text': 'see'}, {'x': 366, 'y': 748, 'w': 74, 'h': 32, 'confidence': '0.5599549012158396', 'text': 'this'}, {'x': 450, 'y': 748, 'w': 74, 'h': 32, 'confidence': '0.9999917149543762', 'text': 'code'}, {'x': 536, 'y': 750, 'w': 38, 'h': 30, 'confidence': '0.9986441523758829', 'text': 'in'}, {'x': 586, 'y': 748, 'w': 56, 'h': 32, 'confidence': '0.9999941498334826', 'text': 'the'}, {'x': 652, 'y': 748, 'w': 108, 'h': 32, 'confidence': '0.9990879357990782', 'text': 'video?'}, {'x': 83, 'y': 789, 'w': 50, 'h': 14, 'confidence': '0.25141606016001106', 'text': 'I'}]}]\n",
      "> Image for page 106: [{'name': 'img_p105_1.png', 'height': 842, 'width': 1660, 'x': 16.661417856, 'y': 69.09449040000004, 'original_width': 1660, 'original_height': 842, 'ocr': [{'x': 167, 'y': 87, 'w': 86, 'h': 38, 'confidence': '0.9999940991401672', 'text': 'User'}, {'x': 649, 'y': 87, 'w': 184, 'h': 42, 'confidence': '0.9999966573016765', 'text': 'Application'}, {'x': 1411, 'y': 85, 'w': 108, 'h': 38, 'confidence': '0.9788932088307792', 'text': 'Model'}, {'x': 431, 'y': 171, 'w': 85, 'h': 31, 'confidence': '0.8167925272756414', 'text': 'Prompt'}, {'x': 941, 'y': 171, 'w': 345, 'h': 31, 'confidence': '0.988090912533713', 'text': 'Prompt and Function declaration'}, {'x': 932, 'y': 308, 'w': 358, 'h': 30, 'confidence': '0.7553840908410222', 'text': 'Function identifier and paramelers'}, {'x': 915, 'y': 379, 'w': 93, 'h': 30, 'confidence': '0.9998855534196203', 'text': 'Request'}, {'x': 637, 'y': 421, 'w': 214, 'h': 38, 'confidence': '0.6804888375226557', 'text': 'Function call'}, {'x': 1101, 'y': 425, 'w': 66, 'h': 40, 'confidence': '0.9906054690152295', 'text': 'API'}, {'x': 915, 'y': 481, 'w': 109, 'h': 31, 'confidence': '0.9999821296700919', 'text': 'Response'}, {'x': 1015, 'y': 552, 'w': 205, 'h': 31, 'confidence': '0.9909007374001287', 'text': 'Response from API'}, {'x': 419, 'y': 677, 'w': 111, 'h': 30, 'confidence': '0.9999791793670547', 'text': 'Response'}, {'x': 1035, 'y': 677, 'w': 111, 'h': 30, 'confidence': '0.99998427917432', 'text': 'Response'}]}]\n",
      "> Image for page 107: [{'name': 'img_p106_1.png', 'height': 1244, 'width': 1226, 'x': 346.1614677700799, 'y': 48.46259997599998, 'original_width': 1226, 'original_height': 1244, 'ocr': [{'x': 33, 'y': 15, 'w': 378, 'h': 43, 'confidence': '0.8708558173374882', 'text': 'get_exchange_rate_func'}, {'x': 455, 'y': 17, 'w': 342, 'h': 36, 'confidence': '0.9987278815712517', 'text': 'FunctionDeclaration('}, {'x': 101, 'y': 52, 'w': 410, 'h': 44, 'confidence': '0.6742608712299543', 'text': 'name-\"get_exchange_rate\"'}, {'x': 101, 'y': 93, 'w': 276, 'h': 40, 'confidence': '0.9619660184354446', 'text': 'description-\"Get'}, {'x': 387, 'y': 93, 'w': 210, 'h': 38, 'confidence': '0.8882835655169913', 'text': 'the exchange'}, {'x': 608, 'y': 96, 'w': 74, 'h': 30, 'confidence': '0.9999879514760434', 'text': 'rate'}, {'x': 692, 'y': 93, 'w': 239, 'h': 33, 'confidence': '0.7943130992073701', 'text': 'for currencies'}, {'x': 320, 'y': 132, 'w': 124, 'h': 32, 'confidence': '0.9999983779520284', 'text': 'between'}, {'x': 456, 'y': 132, 'w': 174, 'h': 32, 'confidence': '0.9999688994569058', 'text': 'countries\"'}, {'x': 100, 'y': 168, 'w': 211, 'h': 39, 'confidence': '0.9862992132545699', 'text': 'parameters={'}, {'x': 167, 'y': 207, 'w': 110, 'h': 38, 'confidence': '0.9999691936895285', 'text': '\"type\"'}, {'x': 300, 'y': 204, 'w': 145, 'h': 42, 'confidence': '0.970052077195303', 'text': '\"object\"'}, {'x': 121, 'y': 253, 'w': 188, 'h': 40, 'confidence': '0.9999534172184225', 'text': '(parameter)'}, {'x': 320, 'y': 253, 'w': 191, 'h': 40, 'confidence': '0.9188809071340608', 'text': 'parameters:'}, {'x': 523, 'y': 252, 'w': 156, 'h': 39, 'confidence': '0.9674108476567187', 'text': 'Dict [str,'}, {'x': 693, 'y': 253, 'w': 70, 'h': 38, 'confidence': '0.9999906420707703', 'text': 'Any]'}, {'x': 255, 'y': 295, 'w': 48, 'h': 20, 'confidence': '0.26699268261213377', 'text': 'cu/'}, {'x': 320, 'y': 294, 'w': 156, 'h': 26, 'confidence': '0.319032296397612', 'text': 'cncy_ualc'}, {'x': 300, 'y': 320, 'w': 111, 'h': 42, 'confidence': '0.9941402996829621', 'text': '\"type\"'}, {'x': 437, 'y': 321, 'w': 144, 'h': 40, 'confidence': '0.998040550407597', 'text': '\"string\"_'}, {'x': 300, 'y': 354, 'w': 231, 'h': 44, 'confidence': '0.9954636225608997', 'text': '\"description\"'}, {'x': 556, 'y': 358, 'w': 40, 'h': 32, 'confidence': '0.9998824966084493', 'text': '\"A'}, {'x': 606, 'y': 360, 'w': 76, 'h': 32, 'confidence': '1.0', 'text': 'date'}, {'x': 692, 'y': 360, 'w': 72, 'h': 32, 'confidence': '0.8516495704728979', 'text': 'that'}, {'x': 774, 'y': 362, 'w': 74, 'h': 30, 'confidence': '0.9999700784683228', 'text': 'must'}, {'x': 861, 'y': 365, 'w': 20, 'h': 24, 'confidence': '0.9999251379672955', 'text': 'a'}, {'x': 875, 'y': 358, 'w': 93, 'h': 40, 'confidence': '0.5619567008598355', 'text': 'Zways'}, {'x': 978, 'y': 360, 'w': 40, 'h': 32, 'confidence': '0.9998910942804529', 'text': 'be'}, {'x': 1030, 'y': 360, 'w': 38, 'h': 32, 'confidence': '0.999618760896895', 'text': 'in'}, {'x': 555, 'y': 398, 'w': 192, 'h': 32, 'confidence': '0.998629056168632', 'text': '\"YYYY-MM-DD'}, {'x': 759, 'y': 398, 'w': 106, 'h': 32, 'confidence': '0.6415712461275581', 'text': 'format'}, {'x': 876, 'y': 402, 'w': 38, 'h': 26, 'confidence': '0.9668520735480604', 'text': 'or'}, {'x': 928, 'y': 398, 'w': 56, 'h': 32, 'confidence': '0.9999991052683532', 'text': 'the'}, {'x': 994, 'y': 398, 'w': 92, 'h': 32, 'confidence': '0.9998813266234295', 'text': 'value'}, {'x': 559, 'y': 439, 'w': 34, 'h': 14, 'confidence': '0.1185087338089943', 'text': 'I ['}, {'x': 589, 'y': 436, 'w': 120, 'h': 32, 'confidence': '0.9979325056334948', 'text': \"latest'\"}, {'x': 726, 'y': 436, 'w': 38, 'h': 32, 'confidence': '0.9925575023343423', 'text': 'if'}, {'x': 775, 'y': 441, 'w': 20, 'h': 24, 'confidence': '0.999941111477952', 'text': 'a'}, {'x': 807, 'y': 432, 'w': 195, 'h': 41, 'confidence': '0.9963927705753911', 'text': 'time period'}, {'x': 1012, 'y': 438, 'w': 38, 'h': 30, 'confidence': '0.9872022885390147', 'text': 'is'}, {'x': 1062, 'y': 438, 'w': 56, 'h': 30, 'confidence': '0.9999180980860193', 'text': 'not'}, {'x': 554, 'y': 470, 'w': 195, 'h': 41, 'confidence': '0.999976565013755', 'text': '\"specified\"'}, {'x': 236, 'y': 514, 'w': 24, 'h': 30, 'confidence': '0.9998736421449053', 'text': '}'}, {'x': 233, 'y': 546, 'w': 262, 'h': 44, 'confidence': '0.8268603422910228', 'text': '\"currency_from\"'}, {'x': 522, 'y': 550, 'w': 24, 'h': 30, 'confidence': '0.9997337041778707', 'text': '{'}, {'x': 301, 'y': 587, 'w': 112, 'h': 40, 'confidence': '0.9947961948294336', 'text': '\"type\"'}, {'x': 437, 'y': 587, 'w': 144, 'h': 40, 'confidence': '0.6961430083583814', 'text': '\"string\" _'}, {'x': 300, 'y': 624, 'w': 241, 'h': 38, 'confidence': '0.950174733567051', 'text': '\"description\" :'}, {'x': 556, 'y': 626, 'w': 74, 'h': 32, 'confidence': '0.9998157024383545', 'text': '\"The'}, {'x': 642, 'y': 630, 'w': 140, 'h': 32, 'confidence': '0.9999783785698939', 'text': 'currency'}, {'x': 792, 'y': 628, 'w': 40, 'h': 30, 'confidence': '0.9999716774352768', 'text': 'to'}, {'x': 844, 'y': 628, 'w': 122, 'h': 30, 'confidence': '0.9886032528907864', 'text': 'convert'}, {'x': 978, 'y': 626, 'w': 74, 'h': 32, 'confidence': '0.9999109506607056', 'text': 'from'}, {'x': 556, 'y': 664, 'w': 54, 'h': 30, 'confidence': '0.9986676569932419', 'text': '\"in'}, {'x': 624, 'y': 664, 'w': 140, 'h': 32, 'confidence': '0.9477078212511355', 'text': 'ISO 4217'}, {'x': 776, 'y': 664, 'w': 122, 'h': 32, 'confidence': '0.7847496256465876', 'text': 'format\"'}, {'x': 237, 'y': 705, 'w': 20, 'h': 28, 'confidence': '0.9991094665392666', 'text': '}'}, {'x': 233, 'y': 735, 'w': 242, 'h': 45, 'confidence': '0.9784339952723002', 'text': '\"currency_to\":'}, {'x': 488, 'y': 740, 'w': 24, 'h': 30, 'confidence': '0.999716540399632', 'text': '{'}, {'x': 301, 'y': 777, 'w': 112, 'h': 40, 'confidence': '0.9979151921789494', 'text': '\"type\"'}, {'x': 437, 'y': 777, 'w': 144, 'h': 40, 'confidence': '0.995255281620089', 'text': '\"string\"_'}, {'x': 300, 'y': 812, 'w': 229, 'h': 42, 'confidence': '0.9589569704522966', 'text': '\"description\"'}, {'x': 556, 'y': 816, 'w': 74, 'h': 32, 'confidence': '0.9997934103012085', 'text': '\"The'}, {'x': 642, 'y': 820, 'w': 140, 'h': 32, 'confidence': '0.9999873980594047', 'text': 'currency'}, {'x': 792, 'y': 818, 'w': 40, 'h': 30, 'confidence': '0.9999656083448327', 'text': 'to'}, {'x': 844, 'y': 818, 'w': 122, 'h': 30, 'confidence': '0.9998649998695918', 'text': 'convert'}, {'x': 978, 'y': 818, 'w': 40, 'h': 30, 'confidence': '0.999974121933087', 'text': 'to'}, {'x': 556, 'y': 854, 'w': 56, 'h': 30, 'confidence': '0.9988210432452548', 'text': '\"in'}, {'x': 624, 'y': 854, 'w': 56, 'h': 32, 'confidence': '0.9391547982077763', 'text': 'ISO'}, {'x': 692, 'y': 854, 'w': 72, 'h': 32, 'confidence': '0.9999998807907104', 'text': '4217'}, {'x': 776, 'y': 854, 'w': 122, 'h': 32, 'confidence': '0.6507262586058316', 'text': 'format\"'}, {'x': 239, 'y': 897, 'w': 16, 'h': 24, 'confidence': '0.9849028153329442', 'text': '}'}, {'x': 168, 'y': 932, 'w': 26, 'h': 30, 'confidence': '0.9996868617140855', 'text': '}'}, {'x': 183, 'y': 959, 'w': 164, 'h': 49, 'confidence': '0.8073078502788633', 'text': 'required\"='}, {'x': 377, 'y': 971, 'w': 14, 'h': 26, 'confidence': '0.6608029324246765', 'text': 'L'}, {'x': 233, 'y': 1002, 'w': 262, 'h': 44, 'confidence': '0.8272251476385953', 'text': '\"currency_from\"'}, {'x': 235, 'y': 1043, 'w': 260, 'h': 40, 'confidence': '0.8712011558851523', 'text': '\"currency_date\"'}]}, {'name': 'img_p106_2.png', 'height': 1048, 'width': 1184, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 1184, 'original_height': 1048, 'ocr': [{'x': 9, 'y': 5, 'w': 68, 'h': 36, 'confidence': '0.9182757532766785', 'text': '[12]'}, {'x': 89, 'y': 6, 'w': 61, 'h': 36, 'confidence': '0.9943906303171383', 'text': 'url'}, {'x': 189, 'y': 3, 'w': 610, 'h': 42, 'confidence': '0.38313305283165494', 'text': '\"https / JLapi_frankfurter_app/latest\"'}, {'x': 9, 'y': 107, 'w': 68, 'h': 36, 'confidence': '0.8472735631189201', 'text': '[13]'}, {'x': 93, 'y': 107, 'w': 258, 'h': 41, 'confidence': '0.9938239172069809', 'text': 'import requests'}, {'x': 94, 'y': 206, 'w': 968, 'h': 50, 'confidence': '0.574865999217161', 'text': \"Get the response from Frankfurter for latest/today's exchange rates:\"}, {'x': 95, 'y': 263, 'w': 426, 'h': 42, 'confidence': '0.8366221361016946', 'text': 'The base currency is in Euros:'}, {'x': 9, 'y': 371, 'w': 68, 'h': 36, 'confidence': '0.6692661838947382', 'text': '[14]'}, {'x': 94, 'y': 378, 'w': 138, 'h': 32, 'confidence': '0.9998701768700767', 'text': 'response'}, {'x': 278, 'y': 373, 'w': 289, 'h': 40, 'confidence': '0.870473604421854', 'text': 'requests.get (url)'}, {'x': 9, 'y': 473, 'w': 68, 'h': 36, 'confidence': '0.7800270617669447', 'text': '[15]'}, {'x': 93, 'y': 477, 'w': 224, 'h': 36, 'confidence': '0.9764482644795884', 'text': 'response.text'}, {'x': 19, 'y': 545, 'w': 46, 'h': 42, 'confidence': '0.5353907387257664', 'text': '2'}, {'x': 105, 'y': 547, 'w': 784, 'h': 38, 'confidence': '0.6310498331105073', 'text': '{\"amount\":1.0,\"base\" :\"EUR\" , \"date\":\"2024-11-29\"'}, {'x': 916, 'y': 550, 'w': 106, 'h': 32, 'confidence': '0.9999989293261206', 'text': 'rates\"'}, {'x': 1033, 'y': 547, 'w': 148, 'h': 36, 'confidence': '0.5700586879584953', 'text': '{\"AUD\" :1='}, {'x': 89, 'y': 582, 'w': 714, 'h': 39, 'confidence': '0.35448418165905193', 'text': '9 , \"GBP\" : 0.83205, \"HKD\" : 8.2211, \"HUF\": 411.75 ,'}, {'x': 814, 'y': 586, 'w': 68, 'h': 32, 'confidence': '0.9998547434806824', 'text': 'IDR\"'}, {'x': 899, 'y': 585, 'w': 106, 'h': 36, 'confidence': '0.8295313150206369', 'text': '16754 ,'}, {'x': 1018, 'y': 586, 'w': 166, 'h': 32, 'confidence': '0.9965687252639547', 'text': 'ILS\":3.841'}, {'x': 89, 'y': 619, 'w': 174, 'h': 38, 'confidence': '0.82849900778905', 'text': 'D\" : 1.7873 ,'}, {'x': 275, 'y': 621, 'w': 714, 'h': 36, 'confidence': '0.4524936233011761', 'text': 'PHP\" : 61.939,\"PLN\" :4.296, \"RON\" : 4.9774,\"SEK\"'}, {'x': 999, 'y': 619, 'w': 185, 'h': 38, 'confidence': '0.566344484005468', 'text': '11.518, \"SGD'}, {'x': 9, 'y': 719, 'w': 68, 'h': 36, 'confidence': '0.8396733839091437', 'text': '[16]'}, {'x': 92, 'y': 722, 'w': 74, 'h': 32, 'confidence': '0.9998356699943542', 'text': 'from'}, {'x': 175, 'y': 719, 'w': 564, 'h': 42, 'confidence': '0.9055136657749253', 'text': 'vertexai.generative_models import'}, {'x': 158, 'y': 758, 'w': 139, 'h': 39, 'confidence': '0.9999797694279506', 'text': 'Content,'}, {'x': 158, 'y': 794, 'w': 341, 'h': 41, 'confidence': '0.9767528212694935', 'text': 'FunctionDeclaration,'}, {'x': 157, 'y': 828, 'w': 293, 'h': 48, 'confidence': '0.9994881903977079', 'text': 'GenerationConfig,'}, {'x': 158, 'y': 869, 'w': 273, 'h': 42, 'confidence': '0.987994538226123', 'text': 'GenerativeModel,'}, {'x': 158, 'y': 910, 'w': 89, 'h': 39, 'confidence': '0.9999457281948999', 'text': 'Part,'}, {'x': 159, 'y': 949, 'w': 88, 'h': 38, 'confidence': '0.9987318787808093', 'text': 'Tool,'}]}]\n",
      "> Image for page 108: []\n",
      "> Image for page 109: []\n",
      "> Image for page 110: [{'name': 'img_p109_1.png', 'height': 462, 'width': 754, 'x': 26.397638639999997, 'y': 1.3051181520000341, 'original_width': 754, 'original_height': 462, 'ocr': [{'x': 428, 'y': 50, 'w': 142, 'h': 24, 'confidence': '0.9999529839417323', 'text': 'Vectorstores'}, {'x': 621, 'y': 139, 'w': 101, 'h': 27, 'confidence': '0.9998648714800688', 'text': 'Prompts'}, {'x': 28, 'y': 155, 'w': 119, 'h': 24, 'confidence': '0.9851105103061547', 'text': 'Document'}, {'x': 43, 'y': 179, 'w': 92, 'h': 26, 'confidence': '0.9997894420594076', 'text': 'Loaders'}, {'x': 267, 'y': 228, 'w': 211, 'h': 53, 'confidence': '0.7478017954284927', 'text': 'LangChain'}, {'x': 630, 'y': 270, 'w': 84, 'h': 26, 'confidence': '0.9999891472482919', 'text': 'Agents'}, {'x': 50, 'y': 400, 'w': 62, 'h': 26, 'confidence': '0.998555600643158', 'text': 'LLMs'}, {'x': 392, 'y': 418, 'w': 80, 'h': 24, 'confidence': '0.9783275845332932', 'text': 'Chains'}, {'x': 609, 'y': 413, 'w': 144, 'h': 38, 'confidence': '0.9997685607885288', 'text': 'ProjectPro'}]}]\n",
      "> Image for page 111: []\n",
      "> Image for page 112: []\n",
      "> Image for page 113: [{'name': 'img_p112_1.png', 'height': 1578, 'width': 1668, 'x': 147.62598897599997, 'y': 7.0000002240000185, 'original_width': 1668, 'original_height': 1578, 'ocr': [{'x': 48, 'y': 92, 'w': 122, 'h': 26, 'confidence': '0.999954703266263', 'text': 'Observability'}, {'x': 257, 'y': 89, 'w': 176, 'h': 42, 'confidence': '0.9973578476978179', 'text': 'LangSmith'}, {'x': 47, 'y': 255, 'w': 125, 'h': 30, 'confidence': '0.9995892243307148', 'text': 'Deployments'}, {'x': 253, 'y': 259, 'w': 179, 'h': 50, 'confidence': '0.9998241708684944', 'text': 'LangServe'}, {'x': 890, 'y': 268, 'w': 240, 'h': 28, 'confidence': '0.6055823714856746', 'text': 'Chains as Rest APIs'}, {'x': 1188, 'y': 270, 'w': 66, 'h': 24, 'confidence': '0.986452801203035', 'text': 'Python'}, {'x': 255, 'y': 437, 'w': 173, 'h': 48, 'confidence': '0.9999731777299917', 'text': 'Templates'}, {'x': 847, 'y': 443, 'w': 284, 'h': 36, 'confidence': '0.6733933866599234', 'text': 'Reference Applications'}, {'x': 1188, 'y': 446, 'w': 66, 'h': 26, 'confidence': '0.9943842224934781', 'text': 'Python'}, {'x': 254, 'y': 622, 'w': 180, 'h': 48, 'confidence': '0.9630715745539873', 'text': 'LangChain'}, {'x': 1038, 'y': 630, 'w': 64, 'h': 26, 'confidence': '0.952931181585262', 'text': 'Pvthon'}, {'x': 1163, 'y': 628, 'w': 91, 'h': 28, 'confidence': '0.7219099607061054', 'text': 'JavaScript'}, {'x': 100, 'y': 629, 'w': 55, 'h': 133, 'confidence': '0.3869803498005183', 'text': 'Hl'}, {'x': 289, 'y': 727, 'w': 91, 'h': 33, 'confidence': '0.9999874438992078', 'text': 'Chains'}, {'x': 403, 'y': 729, 'w': 94, 'h': 36, 'confidence': '0.9999893419167171', 'text': 'Agents'}, {'x': 521, 'y': 729, 'w': 242, 'h': 36, 'confidence': '0.7976097052746146', 'text': 'Retrieval Strategies'}, {'x': 1421, 'y': 683, 'w': 134, 'h': 38, 'confidence': '0.6511759159324962', 'text': 'Debugging'}, {'x': 1421, 'y': 761, 'w': 138, 'h': 36, 'confidence': '0.9055407846122728', 'text': 'Playground'}, {'x': 1422, 'y': 840, 'w': 126, 'h': 26, 'confidence': '0.3223209948753314', 'text': 'Evaluation'}, {'x': 254, 'y': 853, 'w': 372, 'h': 44, 'confidence': '0.8339663517857774', 'text': 'LangChain-Community'}, {'x': 1036, 'y': 860, 'w': 64, 'h': 24, 'confidence': '0.9924708202266642', 'text': 'Python'}, {'x': 1164, 'y': 860, 'w': 90, 'h': 24, 'confidence': '0.8068762018829511', 'text': 'JavaScript'}, {'x': 1424, 'y': 916, 'w': 134, 'h': 30, 'confidence': '0.9999660721069327', 'text': 'Annotation'}, {'x': 290, 'y': 958, 'w': 120, 'h': 30, 'confidence': '0.5961273628915628', 'text': 'Model I/O'}, {'x': 633, 'y': 958, 'w': 112, 'h': 30, 'confidence': '0.9999986489609287', 'text': 'Retrieval'}, {'x': 979, 'y': 954, 'w': 171, 'h': 39, 'confidence': '0.7803586091416376', 'text': 'Agent Tooling'}, {'x': 1421, 'y': 987, 'w': 135, 'h': 44, 'confidence': '0.9995883255135454', 'text': 'Monitoring'}, {'x': 47, 'y': 1038, 'w': 115, 'h': 31, 'confidence': '0.9960282575921501', 'text': 'Integrations'}, {'x': 634, 'y': 1032, 'w': 98, 'h': 26, 'confidence': '0.9999979734410509', 'text': 'Retriever'}, {'x': 47, 'y': 1069, 'w': 123, 'h': 30, 'confidence': '0.9999099961788218', 'text': 'Components'}, {'x': 290, 'y': 1064, 'w': 68, 'h': 26, 'confidence': '0.9999837398198221', 'text': 'Model'}, {'x': 636, 'y': 1064, 'w': 180, 'h': 26, 'confidence': '0.9997690351314324', 'text': 'Document Loader'}, {'x': 287, 'y': 1095, 'w': 81, 'h': 29, 'confidence': '0.9999496260026338', 'text': 'Prompt'}, {'x': 634, 'y': 1096, 'w': 128, 'h': 26, 'confidence': '0.9974396703039656', 'text': 'Vector Store'}, {'x': 290, 'y': 1128, 'w': 176, 'h': 28, 'confidence': '0.9999743253505173', 'text': 'Example Selector'}, {'x': 634, 'y': 1128, 'w': 126, 'h': 28, 'confidence': '0.8502209049564132', 'text': 'Text Splitter'}, {'x': 980, 'y': 1128, 'w': 48, 'h': 26, 'confidence': '0.999819278717041', 'text': 'Tool'}, {'x': 287, 'y': 1159, 'w': 147, 'h': 30, 'confidence': '0.94155290656357', 'text': 'Output Parser'}, {'x': 634, 'y': 1160, 'w': 182, 'h': 30, 'confidence': '0.8636106276426715', 'text': 'Embedding Model'}, {'x': 980, 'y': 1160, 'w': 72, 'h': 26, 'confidence': '0.890683374886528', 'text': 'Toolkit'}, {'x': 257, 'y': 1273, 'w': 264, 'h': 44, 'confidence': '0.6136644951797322', 'text': 'LangChain-Core'}, {'x': 1036, 'y': 1280, 'w': 64, 'h': 24, 'confidence': '0.9993904556446888', 'text': 'Python'}, {'x': 1163, 'y': 1277, 'w': 91, 'h': 29, 'confidence': '0.99996999269765', 'text': 'JavaScript'}, {'x': 289, 'y': 1377, 'w': 470, 'h': 39, 'confidence': '0.7175773871396093', 'text': 'LCEL - LangChain Expression Language'}, {'x': 48, 'y': 1406, 'w': 82, 'h': 24, 'confidence': '0.7577084859102957', 'text': 'Protocol'}, {'x': 289, 'y': 1441, 'w': 142, 'h': 26, 'confidence': '0.7592196427281342', 'text': 'Parallelization'}, {'x': 470, 'y': 1442, 'w': 98, 'h': 26, 'confidence': '0.8930428488239264', 'text': 'Fallbacks'}, {'x': 603, 'y': 1441, 'w': 81, 'h': 31, 'confidence': '0.9999848608525616', 'text': 'Tracing'}, {'x': 720, 'y': 1437, 'w': 98, 'h': 36, 'confidence': '0.9622472824819176', 'text': 'Batching'}, {'x': 853, 'y': 1441, 'w': 109, 'h': 31, 'confidence': '0.999843750254174', 'text': 'Streaming'}, {'x': 999, 'y': 1441, 'w': 67, 'h': 30, 'confidence': '0.9999411433309986', 'text': 'Async'}, {'x': 1103, 'y': 1441, 'w': 133, 'h': 30, 'confidence': '0.9999900797125297', 'text': 'Composition'}]}]\n",
      "> Image for page 114: []\n",
      "> Image for page 115: []\n",
      "> Image for page 116: [{'name': 'img_p115_1.png', 'height': 786, 'width': 2048, 'x': 0, 'y': 74.6063016, 'original_width': 2048, 'original_height': 786, 'ocr': [{'x': 147, 'y': 84, 'w': 196, 'h': 53, 'confidence': '0.964967891975702', 'text': 'Model I/O'}, {'x': 411, 'y': 205, 'w': 146, 'h': 42, 'confidence': '0.7475357084877025', 'text': 'Format'}, {'x': 1135, 'y': 203, 'w': 148, 'h': 44, 'confidence': '0.6356056049900167', 'text': 'Predict'}, {'x': 1711, 'y': 203, 'w': 118, 'h': 44, 'confidence': '0.7440532923759595', 'text': 'Parse'}, {'x': 180, 'y': 356, 'w': 42, 'h': 24, 'confidence': '0.9777879759736722', 'text': 'X='}, {'x': 219, 'y': 348, 'w': 111, 'h': 40, 'confidence': '0.891665048203742', 'text': '\"foo\",y ='}, {'x': 338, 'y': 354, 'w': 54, 'h': 26, 'confidence': '0.981757663534608', 'text': '\\\\\\'bar\"'}, {'x': 1066, 'y': 398, 'w': 56, 'h': 30, 'confidence': '0.9999589801055311', 'text': 'LLM'}, {'x': 578, 'y': 411, 'w': 201, 'h': 31, 'confidence': '0.8753064831099276', 'text': \"'Does foo like bar;\"}, {'x': 1646, 'y': 455, 'w': 145, 'h': 31, 'confidence': '0.8284129114830757', 'text': '\"likes\": True,'}, {'x': 1312, 'y': 474, 'w': 132, 'h': 28, 'confidence': '0.23909738982508646', 'text': '\"Foo does .-'}, {'x': 1646, 'y': 494, 'w': 220, 'h': 26, 'confidence': '0.9911724232397291', 'text': '\"reason\": \"Because'}, {'x': 612, 'y': 542, 'w': 126, 'h': 30, 'confidence': '0.9938090996184201', 'text': 'and why?\"'}, {'x': 1060, 'y': 550, 'w': 62, 'h': 30, 'confidence': '0.9999921321868896', 'text': 'Chat'}, {'x': 184, 'y': 572, 'w': 202, 'h': 32, 'confidence': '0.7259820418378053', 'text': '\"Does {x} like {y} ,'}, {'x': 1056, 'y': 588, 'w': 78, 'h': 28, 'confidence': '0.9999942956124749', 'text': 'Model'}, {'x': 224, 'y': 608, 'w': 124, 'h': 30, 'confidence': '0.8082240356571606', 'text': 'and why?\"'}]}]\n",
      "> Image for page 117: []\n",
      "> Image for page 118: [{'name': 'img_p117_1.png', 'height': 851, 'width': 2048, 'x': -14.041815409967999, 'y': 76.6341559956, 'original_width': 2048, 'original_height': 851, 'ocr': [{'x': 119, 'y': 86, 'w': 248, 'h': 39, 'confidence': '0.7983497343020403', 'text': 'Vector Stores'}, {'x': 1436, 'y': 180, 'w': 394, 'h': 51, 'confidence': '0.9976966410060712', 'text': '2. Query Vector Store'}, {'x': 183, 'y': 254, 'w': 360, 'h': 41, 'confidence': '0.6142976326765984', 'text': '1. Load Source Data'}, {'x': 955, 'y': 241, 'w': 124, 'h': 38, 'confidence': '0.9999829665213629', 'text': 'Vector'}, {'x': 969, 'y': 283, 'w': 102, 'h': 38, 'confidence': '0.9821333994004483', 'text': 'Store'}, {'x': 1314, 'y': 296, 'w': 88, 'h': 30, 'confidence': '0.9999914167612376', 'text': 'Embed'}, {'x': 1319, 'y': 349, 'w': 82, 'h': 20, 'confidence': '0.5111712414620893', 'text': '5.5 -0.3-.'}, {'x': 1617, 'y': 342, 'w': 172, 'h': 20, 'confidence': '0.6132641762724773', 'text': 'xxxXXXXXXXXXX'}, {'x': 1332, 'y': 370, 'w': 54, 'h': 24, 'confidence': '0.9964907380208045', 'text': '2.1,0.1'}, {'x': 1617, 'y': 376, 'w': 172, 'h': 20, 'confidence': '0.9976888222318677', 'text': 'XXXXXXXXXXXXX'}, {'x': 569, 'y': 411, 'w': 291, 'h': 33, 'confidence': '0.6489885144426047', 'text': 'Load, Transform, Embed'}, {'x': 957, 'y': 423, 'w': 122, 'h': 20, 'confidence': '0.5372610561111127', 'text': '0.5,0.2__0.1,0.9'}, {'x': 959, 'y': 469, 'w': 118, 'h': 20, 'confidence': '0.4302004365989653', 'text': '21,0.1_-1.7,0.9'}, {'x': 1625, 'y': 534, 'w': 172, 'h': 20, 'confidence': '0.6899860566897784', 'text': 'xxXXXXXXXXXXX'}, {'x': 1625, 'y': 568, 'w': 172, 'h': 20, 'confidence': '0.9975535688476969', 'text': 'XXXXXXXXXXXXX'}, {'x': 1397, 'y': 681, 'w': 442, 'h': 40, 'confidence': '0.7351567054577952', 'text': \"3. Retrieve 'most similar'\"}]}]\n",
      "> Image for page 119: [{'name': 'img_p118_1.png', 'height': 284, 'width': 873, 'x': -1.968504e-06, 'y': 96.00000307200006, 'original_width': 873, 'original_height': 284, 'ocr': [{'x': 33, 'y': 19, 'w': 138, 'h': 20, 'confidence': '0.7674203579748998', 'text': 'Data connection'}, {'x': 340, 'y': 36, 'w': 86, 'h': 16, 'confidence': '0.8833088548538589', 'text': 'Transform'}, {'x': 487, 'y': 35, 'w': 60, 'h': 20, 'confidence': '0.9999923763784254', 'text': 'Embed'}, {'x': 41, 'y': 57, 'w': 62, 'h': 18, 'confidence': '0.9999406258776757', 'text': 'Source'}, {'x': 219, 'y': 59, 'w': 48, 'h': 18, 'confidence': '0.9999271631240845', 'text': 'Load'}, {'x': 623, 'y': 55, 'w': 48, 'h': 20, 'confidence': '0.9999611887641832', 'text': 'Store'}, {'x': 749, 'y': 55, 'w': 72, 'h': 20, 'confidence': '0.8975637279268549', 'text': 'Retrieve'}, {'x': 216, 'y': 128, 'w': 54, 'h': 8, 'confidence': '0.17333433941337476', 'text': 'DOOCOOCXC'}, {'x': 757, 'y': 137, 'w': 58, 'h': 14, 'confidence': '0.10617309686744207', 'text': 'KXXXXXKXXX'}, {'x': 490, 'y': 154, 'w': 24, 'h': 8, 'confidence': '0.592075538084528', 'text': '41,74'}, {'x': 520, 'y': 154, 'w': 24, 'h': 8, 'confidence': '0.2341869161563217', 'text': 'TL 15'}, {'x': 621, 'y': 167, 'w': 52, 'h': 12, 'confidence': '0.21718743216923386', 'text': '21,01-17 0,0'}, {'x': 490, 'y': 222, 'w': 52, 'h': 8, 'confidence': '0.12534867407194478', 'text': '2,L_L,Q9'}]}]\n",
      "> Image for page 120: []\n",
      "> Image for page 121: []\n",
      "> Image for page 122: [{'name': 'img_p121_1.png', 'height': 1047, 'width': 2048, 'x': 1.968504e-07, 'y': -11.853838961999998, 'original_width': 2048, 'original_height': 1047, 'ocr': [{'x': 744, 'y': 292, 'w': 90, 'h': 28, 'confidence': '0.9999417409109936', 'text': 'Prompt:'}, {'x': 1288, 'y': 306, 'w': 165, 'h': 36, 'confidence': '0.6360627522010299', 'text': 'Output parser:'}, {'x': 164, 'y': 326, 'w': 130, 'h': 28, 'confidence': '0.9207022013340748', 'text': '{\"question\":'}, {'x': 692, 'y': 326, 'w': 200, 'h': 30, 'confidence': '0.9987334460796132', 'text': '\"{past_messages}'}, {'x': 1056, 'y': 326, 'w': 70, 'h': 26, 'confidence': '0.9999833133228728', 'text': 'Model'}, {'x': 1672, 'y': 334, 'w': 116, 'h': 26, 'confidence': '0.9998660940251859', 'text': '{\"answer\":'}, {'x': 1256, 'y': 342, 'w': 230, 'h': 32, 'confidence': '0.8515226421816768', 'text': 'regex(\"Answer: (.*)\")'}, {'x': 730, 'y': 360, 'w': 124, 'h': 28, 'confidence': '0.8008746594439013', 'text': '{question}\"'}, {'x': 350, 'y': 627, 'w': 254, 'h': 30, 'confidence': '0.49926703271892736', 'text': '{\"past_messages\": [-~]}'}, {'x': 952, 'y': 798, 'w': 145, 'h': 48, 'confidence': '0.9999529387730786', 'text': 'Memory'}, {'x': 396, 'y': 892, 'w': 156, 'h': 56, 'confidence': '0.9904499923328011', 'text': 'READ'}, {'x': 1399, 'y': 891, 'w': 182, 'h': 60, 'confidence': '0.571587897418636', 'text': 'WRITE'}]}]\n",
      "> Image for page 123: []\n",
      "> Image for page 124: [{'name': 'img_p123_1.png', 'height': 544, 'width': 1352, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 1352, 'original_height': 544, 'ocr': [{'x': 29, 'y': 3, 'w': 60, 'h': 38, 'confidence': '0.9999938057061831', 'text': 'pip'}, {'x': 99, 'y': 1, 'w': 124, 'h': 36, 'confidence': '0.7219017876729777', 'text': 'install'}, {'x': 235, 'y': 0, 'w': 326, 'h': 41, 'confidence': '0.8695146414851329', 'text': 'Langchain_community'}, {'x': 29, 'y': 41, 'w': 60, 'h': 38, 'confidence': '0.9999945627862629', 'text': 'pip'}, {'x': 99, 'y': 39, 'w': 192, 'h': 38, 'confidence': '0.9306617645091214', 'text': 'install ~qU'}, {'x': 301, 'y': 41, 'w': 376, 'h': 38, 'confidence': '0.8584912102738168', 'text': 'Zangchain-google-genai'}, {'x': 13, 'y': 181, 'w': 108, 'h': 38, 'confidence': '0.9994195596279704', 'text': 'import'}, {'x': 132, 'y': 186, 'w': 38, 'h': 28, 'confidence': '0.2523233771632083', 'text': '0s'}, {'x': 13, 'y': 217, 'w': 312, 'h': 36, 'confidence': '0.6058637977026319', 'text': '0S.environ [\"GOOGLE'}, {'x': 334, 'y': 220, 'w': 152, 'h': 32, 'confidence': '0.8440244321377374', 'text': 'API_KEY\" ]'}, {'x': 535, 'y': 217, 'w': 158, 'h': 36, 'confidence': '0.5658324967314649', 'text': 'userdata.='}, {'x': 743, 'y': 223, 'w': 16, 'h': 26, 'confidence': '0.9932288501408983', 'text': '('}, {'x': 772, 'y': 220, 'w': 108, 'h': 32, 'confidence': '0.9957162139232819', 'text': 'GOOGLE'}, {'x': 890, 'y': 220, 'w': 126, 'h': 32, 'confidence': '0.9867237265246758', 'text': 'API_KEY'}, {'x': 13, 'y': 318, 'w': 462, 'h': 42, 'confidence': '0.7108470526413517', 'text': 'from Langchain_google_genai'}, {'x': 485, 'y': 316, 'w': 496, 'h': 43, 'confidence': '0.8448743995423204', 'text': 'import ChatGoogleGenerativeAI'}, {'x': 16, 'y': 398, 'w': 56, 'h': 30, 'confidence': '0.2547890761300908', 'text': 'llm'}, {'x': 114, 'y': 392, 'w': 881, 'h': 43, 'confidence': '0.5564501947142253', 'text': 'ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\")'}, {'x': 15, 'y': 437, 'w': 140, 'h': 36, 'confidence': '0.7910412647099789', 'text': 'response'}, {'x': 201, 'y': 435, 'w': 258, 'h': 38, 'confidence': '0.562309884618427', 'text': '1Zm. invoke( \"Why'}, {'x': 469, 'y': 433, 'w': 126, 'h': 40, 'confidence': '0.9817639433879664', 'text': 'the sky'}, {'x': 605, 'y': 433, 'w': 170, 'h': 36, 'confidence': '0.7541053883580275', 'text': 'is blue?\")'}, {'x': 11, 'y': 469, 'w': 95, 'h': 42, 'confidence': '0.792720449053473', 'text': 'print'}, {'x': 115, 'y': 473, 'w': 278, 'h': 38, 'confidence': '0.92907825958407', 'text': 'response. content_'}, {'x': 685, 'y': 222, 'w': 60, 'h': 30, 'confidence': '0.9999987611408254', 'text': 'get'}]}]\n",
      "> Image for page 125: [{'name': 'img_p124_1.png', 'height': 524, 'width': 1040, 'x': 19.303150224, 'y': 53.11023792000003, 'original_width': 1040, 'original_height': 524, 'ocr': [{'x': 6, 'y': 14, 'w': 74, 'h': 30, 'confidence': '0.9995917677879333', 'text': 'from'}, {'x': 90, 'y': 9, 'w': 377, 'h': 45, 'confidence': '0.6766242779271654', 'text': 'Langchain_google_genai'}, {'x': 477, 'y': 10, 'w': 496, 'h': 41, 'confidence': '0.8922616334551993', 'text': 'import ChatGoogleGenerativeAI'}, {'x': 8, 'y': 90, 'w': 56, 'h': 30, 'confidence': '0.31167323455564155', 'text': 'llm'}, {'x': 106, 'y': 86, 'w': 379, 'h': 41, 'confidence': '0.9812653265412781', 'text': 'ChatGoogleGenerativeAI'}, {'x': 71, 'y': 122, 'w': 480, 'h': 43, 'confidence': '0.635309196670359', 'text': 'model=\"gemini-1.5-flash-001\"'}, {'x': 71, 'y': 164, 'w': 232, 'h': 40, 'confidence': '0.7177246507255326', 'text': 'temperature-0,'}, {'x': 72, 'y': 204, 'w': 264, 'h': 32, 'confidence': '0.7243944967591842', 'text': 'max_tokens-None'}, {'x': 74, 'y': 242, 'w': 210, 'h': 32, 'confidence': '0.9914779820143041', 'text': 'timeout-None_'}, {'x': 71, 'y': 279, 'w': 242, 'h': 38, 'confidence': '0.9250960588967416', 'text': 'max_retries-2,'}, {'x': 105, 'y': 315, 'w': 226, 'h': 40, 'confidence': '0.7013488113915516', 'text': 'other params .'}, {'x': 6, 'y': 431, 'w': 143, 'h': 39, 'confidence': '0.9999865551178873', 'text': 'response'}, {'x': 191, 'y': 431, 'w': 260, 'h': 38, 'confidence': '0.36616568473233063', 'text': 'Ilm. invoke( \"Why'}, {'x': 461, 'y': 431, 'w': 126, 'h': 38, 'confidence': '0.9786597337653082', 'text': 'the sky'}, {'x': 595, 'y': 429, 'w': 173, 'h': 36, 'confidence': '0.771147923878458', 'text': 'is blue?\")'}, {'x': 3, 'y': 465, 'w': 394, 'h': 42, 'confidence': '0.8210067865949738', 'text': 'print(response.content)'}]}]\n",
      "> Image for page 126: []\n",
      "> Image for page 127: [{'name': 'img_p126_1.png', 'height': 574, 'width': 1234, 'x': 12.000000384, 'y': 53.77559227199998, 'original_width': 1234, 'original_height': 574, 'ocr': [{'x': 37, 'y': 4, 'w': 380, 'h': 44, 'confidence': '0.8237372971837927', 'text': 'from Langchain.prompts'}, {'x': 427, 'y': 5, 'w': 362, 'h': 40, 'confidence': '0.9234568237633526', 'text': 'import PromptTemplate'}, {'x': 37, 'y': 43, 'w': 582, 'h': 44, 'confidence': '0.494161332296549', 'text': 'from Langchain_core-output_parsers'}, {'x': 629, 'y': 45, 'w': 108, 'h': 38, 'confidence': '0.9994359138399971', 'text': 'import'}, {'x': 747, 'y': 45, 'w': 260, 'h': 38, 'confidence': '0.6330058609879642', 'text': 'StroutputParser'}, {'x': 39, 'y': 121, 'w': 108, 'h': 38, 'confidence': '0.9999963013073241', 'text': 'prompt'}, {'x': 190, 'y': 117, 'w': 582, 'h': 43, 'confidence': '0.8736431727917311', 'text': 'PromptTemplate. from_template( \"Tell'}, {'x': 780, 'y': 124, 'w': 40, 'h': 28, 'confidence': '0.9997730889086921', 'text': 'me'}, {'x': 833, 'y': 127, 'w': 18, 'h': 24, 'confidence': '0.9999525552655228', 'text': 'a'}, {'x': 865, 'y': 121, 'w': 76, 'h': 38, 'confidence': '0.9994823932647705', 'text': 'joke'}, {'x': 949, 'y': 119, 'w': 258, 'h': 40, 'confidence': '0.7617504601708371', 'text': 'about {topic}\" )'}, {'x': 39, 'y': 158, 'w': 225, 'h': 38, 'confidence': '0.5991829240248507', 'text': 'output_parser'}, {'x': 306, 'y': 156, 'w': 295, 'h': 42, 'confidence': '0.916313615940465', 'text': 'StroutputParser( )'}, {'x': 40, 'y': 236, 'w': 90, 'h': 32, 'confidence': '0.9999479140012353', 'text': 'chain'}, {'x': 172, 'y': 234, 'w': 111, 'h': 42, 'confidence': '0.9999907532625453', 'text': 'prompt'}, {'x': 328, 'y': 236, 'w': 56, 'h': 32, 'confidence': '0.30514233334271806', 'text': '1Lm'}, {'x': 427, 'y': 235, 'w': 228, 'h': 38, 'confidence': '0.8919749486103951', 'text': 'output_parser'}, {'x': 40, 'y': 311, 'w': 141, 'h': 39, 'confidence': '0.9980668815605891', 'text': 'response'}, {'x': 225, 'y': 308, 'w': 509, 'h': 41, 'confidence': '0.7853705810224384', 'text': 'chain. invoke( {\"topic\" :\"bear\"})'}, {'x': 37, 'y': 346, 'w': 260, 'h': 41, 'confidence': '0.9999771919941147', 'text': 'print(response)'}, {'x': 37, 'y': 421, 'w': 58, 'h': 38, 'confidence': '0.9999790770726399', 'text': 'Why'}, {'x': 106, 'y': 422, 'w': 56, 'h': 32, 'confidence': '0.9970983266830444', 'text': 'don'}, {'x': 173, 'y': 423, 'w': 18, 'h': 26, 'confidence': '0.9996707710446486', 'text': 't'}, {'x': 203, 'y': 417, 'w': 265, 'h': 43, 'confidence': '0.9838160635175052', 'text': 'they play poker'}, {'x': 478, 'y': 422, 'w': 38, 'h': 32, 'confidence': '0.9981666832250308', 'text': 'in'}, {'x': 526, 'y': 422, 'w': 191, 'h': 32, 'confidence': '0.4683698447115507', 'text': 'the forest?'}, {'x': 38, 'y': 492, 'w': 124, 'h': 32, 'confidence': '0.9994932152436908', 'text': 'Because'}, {'x': 173, 'y': 489, 'w': 92, 'h': 36, 'confidence': '0.9999990266601202', 'text': 'there'}, {'x': 277, 'y': 497, 'w': 16, 'h': 24, 'confidence': '0.7888777195660168', 'text': '5'}, {'x': 307, 'y': 491, 'w': 142, 'h': 38, 'confidence': '0.8515607164399471', 'text': 'too many'}, {'x': 460, 'y': 492, 'w': 142, 'h': 32, 'confidence': '0.9999753439677161', 'text': 'cheetahs'}]}]\n",
      "> Image for page 128: [{'name': 'img_p127_1.png', 'height': 976, 'width': 1692, 'x': 56.484253775999996, 'y': 45.094489632000034, 'original_width': 1692, 'original_height': 976, 'ocr': [{'x': 15, 'y': 8, 'w': 902, 'h': 42, 'confidence': '0.769767413236315', 'text': 'from Langchain_core-prompts import ChatPromptTemplate'}, {'x': 15, 'y': 47, 'w': 970, 'h': 40, 'confidence': '0.5249639277184944', 'text': 'from Langchain_core.output_parsers import StrOutputParser'}, {'x': 15, 'y': 125, 'w': 107, 'h': 36, 'confidence': '0.9999958633040404', 'text': 'prompt'}, {'x': 167, 'y': 123, 'w': 546, 'h': 40, 'confidence': '0.9654013744228668', 'text': 'ChatPromptTemplate. from_messages'}, {'x': 217, 'y': 237, 'w': 136, 'h': 38, 'confidence': '0.9931381713977402', 'text': '\"system\"'}, {'x': 216, 'y': 276, 'w': 76, 'h': 32, 'confidence': '0.9998593330383301', 'text': '\"You'}, {'x': 302, 'y': 280, 'w': 56, 'h': 26, 'confidence': '0.8623997569084167', 'text': 'are'}, {'x': 371, 'y': 281, 'w': 18, 'h': 24, 'confidence': '0.9999349127870261', 'text': 'a'}, {'x': 403, 'y': 275, 'w': 126, 'h': 38, 'confidence': '0.7439864580702896', 'text': 'helpful'}, {'x': 538, 'y': 276, 'w': 158, 'h': 32, 'confidence': '0.9999654290072402', 'text': 'assistant'}, {'x': 706, 'y': 276, 'w': 74, 'h': 32, 'confidence': '0.6975217859873533', 'text': 'that'}, {'x': 789, 'y': 274, 'w': 464, 'h': 41, 'confidence': '0.8151174204204215', 'text': 'translates {input_language}'}, {'x': 1263, 'y': 275, 'w': 358, 'h': 40, 'confidence': '0.6081948081107201', 'text': 'to {output_language}.'}, {'x': 151, 'y': 349, 'w': 142, 'h': 36, 'confidence': '0.998938954500967', 'text': '(\"human\"'}, {'x': 317, 'y': 349, 'w': 182, 'h': 42, 'confidence': '0.3279268702442044', 'text': '\"{input}\" )='}, {'x': 15, 'y': 505, 'w': 228, 'h': 38, 'confidence': '0.8446410383909433', 'text': 'output_parser'}, {'x': 282, 'y': 503, 'w': 293, 'h': 40, 'confidence': '0.6888164540140295', 'text': 'StroutputParser( )'}, {'x': 16, 'y': 579, 'w': 89, 'h': 32, 'confidence': '0.9995885811895223', 'text': 'chain'}, {'x': 149, 'y': 581, 'w': 110, 'h': 36, 'confidence': '0.9999804844947469', 'text': 'prompt'}, {'x': 304, 'y': 580, 'w': 56, 'h': 32, 'confidence': '0.33243722540530934', 'text': '1Zm'}, {'x': 403, 'y': 580, 'w': 226, 'h': 38, 'confidence': '0.8223004186522253', 'text': 'output_parser'}, {'x': 15, 'y': 616, 'w': 210, 'h': 37, 'confidence': '0.8775614409051937', 'text': 'chain. invoke'}, {'x': 167, 'y': 693, 'w': 272, 'h': 40, 'confidence': '0.5533690761471091', 'text': 'input_language\" :'}, {'x': 451, 'y': 690, 'w': 162, 'h': 42, 'confidence': '0.968226788911308', 'text': '\"English\"'}, {'x': 148, 'y': 730, 'w': 297, 'h': 42, 'confidence': '0.8653179404329724', 'text': '\"output_language\"'}, {'x': 470, 'y': 732, 'w': 142, 'h': 32, 'confidence': '0.7132392652141928', 'text': '\"German\"'}, {'x': 148, 'y': 766, 'w': 139, 'h': 42, 'confidence': '0.8177115817596008', 'text': '\"input\" :'}, {'x': 302, 'y': 770, 'w': 38, 'h': 30, 'confidence': '0.9613946115724696', 'text': '\"I'}, {'x': 353, 'y': 769, 'w': 280, 'h': 38, 'confidence': '0.7772052862111629', 'text': 'love programming_'}, {'x': 30, 'y': 920, 'w': 56, 'h': 32, 'confidence': '0.9999943563098699', 'text': 'Ich'}, {'x': 99, 'y': 917, 'w': 340, 'h': 43, 'confidence': '0.6930094329031151', 'text': 'Liebe Programmieren.'}, {'x': 454, 'y': 922, 'w': 40, 'h': 32, 'confidence': '0.997413922642942', 'text': 'In'}]}]\n",
      "> Image for page 129: [{'name': 'img_p128_1.png', 'height': 585, 'width': 2048, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 2048, 'original_height': 585, 'ocr': [{'x': 2, 'y': 19, 'w': 418, 'h': 31, 'confidence': '0.7525600410210344', 'text': 'from langchain.output_parsers'}, {'x': 429, 'y': 17, 'w': 534, 'h': 36, 'confidence': '0.8499472845314932', 'text': 'import CommaSeparatedListOutputParser'}, {'x': 1, 'y': 49, 'w': 634, 'h': 36, 'confidence': '0.6385408696530509', 'text': 'from langchain.prompts import PromptTemplate'}, {'x': 1, 'y': 81, 'w': 590, 'h': 38, 'confidence': '0.6486921376781817', 'text': 'from Langchain.output_parsers. list import'}, {'x': 600, 'y': 84, 'w': 234, 'h': 32, 'confidence': '0.7811697337413489', 'text': 'ListOutputParser'}, {'x': 0, 'y': 146, 'w': 94, 'h': 36, 'confidence': '0.9999887579114158', 'text': 'prompt'}, {'x': 129, 'y': 145, 'w': 490, 'h': 36, 'confidence': '0.8899126243098805', 'text': 'PromptTemplate. from_template(\"List'}, {'x': 627, 'y': 144, 'w': 177, 'h': 36, 'confidence': '0.4899117144771777', 'text': '3 {things}\" )'}, {'x': 0, 'y': 178, 'w': 193, 'h': 37, 'confidence': '0.7193016754616663', 'text': 'output_parser'}, {'x': 227, 'y': 179, 'w': 250, 'h': 36, 'confidence': '0.9387310973006022', 'text': 'StroutputParser( )'}, {'x': 4, 'y': 244, 'w': 74, 'h': 28, 'confidence': '0.9998698643718846', 'text': 'chain'}, {'x': 116, 'y': 244, 'w': 92, 'h': 32, 'confidence': '0.9999906072612734', 'text': 'prompt'}, {'x': 246, 'y': 244, 'w': 48, 'h': 28, 'confidence': '0.42866494690945817', 'text': '1lm'}, {'x': 330, 'y': 244, 'w': 190, 'h': 32, 'confidence': '0.988162369042587', 'text': 'output_parser'}, {'x': 3, 'y': 308, 'w': 119, 'h': 31, 'confidence': '0.9999922449674185', 'text': 'response'}, {'x': 160, 'y': 307, 'w': 316, 'h': 33, 'confidence': '0.89465210311777', 'text': 'chain. invoke( {\"things\"'}, {'x': 486, 'y': 307, 'w': 104, 'h': 32, 'confidence': '0.8676225641610789', 'text': '\"sports'}, {'x': 600, 'y': 307, 'w': 146, 'h': 29, 'confidence': '0.9961196364744126', 'text': \"that don't\"}, {'x': 756, 'y': 308, 'w': 176, 'h': 30, 'confidence': '0.9990897169444993', 'text': 'use balls\"})'}, {'x': 0, 'y': 336, 'w': 82, 'h': 38, 'confidence': '0.9999805944043165', 'text': 'print'}, {'x': 90, 'y': 342, 'w': 128, 'h': 30, 'confidence': '0.9999734161517542', 'text': 'response)'}, {'x': 0, 'y': 402, 'w': 62, 'h': 26, 'confidence': '0.9999898672103882', 'text': 'Here'}, {'x': 72, 'y': 404, 'w': 48, 'h': 24, 'confidence': '0.9999995870469189', 'text': 'are'}, {'x': 131, 'y': 405, 'w': 16, 'h': 22, 'confidence': '0.9999986886982448', 'text': '3'}, {'x': 157, 'y': 401, 'w': 89, 'h': 30, 'confidence': '0.9999525007655262', 'text': 'sports'}, {'x': 256, 'y': 400, 'w': 62, 'h': 28, 'confidence': '0.9999999403953552', 'text': 'that'}, {'x': 328, 'y': 402, 'w': 50, 'h': 28, 'confidence': '0.5643860697746277', 'text': 'don'}, {'x': 387, 'y': 405, 'w': 16, 'h': 22, 'confidence': '0.999736207241174', 'text': 't'}, {'x': 414, 'y': 404, 'w': 46, 'h': 24, 'confidence': '0.9997320670778755', 'text': 'use'}, {'x': 470, 'y': 400, 'w': 88, 'h': 28, 'confidence': '0.7984012597835041', 'text': 'balls:'}, {'x': 1, 'y': 453, 'w': 202, 'h': 38, 'confidence': '0.8857269626292891', 'text': '1. **Swimming:'}, {'x': 256, 'y': 458, 'w': 148, 'h': 33, 'confidence': '0.7976696374139626', 'text': 'This sport'}, {'x': 414, 'y': 460, 'w': 88, 'h': 26, 'confidence': '0.9999837938632605', 'text': 'relies'}, {'x': 512, 'y': 462, 'w': 34, 'h': 24, 'confidence': '0.9978179969182477', 'text': 'on'}, {'x': 556, 'y': 460, 'w': 48, 'h': 28, 'confidence': '0.9999975911073493', 'text': 'the'}, {'x': 612, 'y': 458, 'w': 106, 'h': 28, 'confidence': '0.9999475082942795', 'text': 'athlete'}, {'x': 752, 'y': 453, 'w': 249, 'h': 40, 'confidence': '0.7317065286905928', 'text': 'ability to propel'}, {'x': 1010, 'y': 457, 'w': 262, 'h': 33, 'confidence': '0.9975230399444931', 'text': 'themselves through'}, {'x': 1280, 'y': 460, 'w': 76, 'h': 26, 'confidence': '0.999859041859679', 'text': 'water'}, {'x': 1366, 'y': 460, 'w': 76, 'h': 30, 'confidence': '0.999973077389649', 'text': 'using'}, {'x': 1452, 'y': 460, 'w': 158, 'h': 30, 'confidence': '0.9380240315891862', 'text': 'their body.'}, {'x': 2, 'y': 490, 'w': 28, 'h': 26, 'confidence': '0.8252995014190674', 'text': '2 .'}, {'x': 42, 'y': 490, 'w': 106, 'h': 26, 'confidence': '0.7640518615246341', 'text': 'xxTrack'}, {'x': 158, 'y': 490, 'w': 46, 'h': 26, 'confidence': '0.999999380570387', 'text': 'and'}, {'x': 214, 'y': 488, 'w': 120, 'h': 28, 'confidence': '0.5917073743813315', 'text': 'Field:**'}, {'x': 356, 'y': 488, 'w': 146, 'h': 31, 'confidence': '0.757735989836003', 'text': 'This sport'}, {'x': 512, 'y': 492, 'w': 162, 'h': 26, 'confidence': '0.8041728427751712', 'text': 'encompasses'}, {'x': 712, 'y': 490, 'w': 104, 'h': 30, 'confidence': '0.9979136141248842', 'text': 'variety'}, {'x': 826, 'y': 488, 'w': 32, 'h': 28, 'confidence': '0.9384055543334893', 'text': 'of'}, {'x': 867, 'y': 488, 'w': 103, 'h': 30, 'confidence': '0.9996183898029654', 'text': 'events,'}, {'x': 982, 'y': 483, 'w': 133, 'h': 38, 'confidence': '0.9998695807848461', 'text': 'including'}, {'x': 1126, 'y': 490, 'w': 114, 'h': 30, 'confidence': '0.9999429746404684', 'text': 'running,'}, {'x': 1252, 'y': 490, 'w': 116, 'h': 30, 'confidence': '0.9409552181466742', 'text': 'jumping ,'}, {'x': 1379, 'y': 484, 'w': 189, 'h': 38, 'confidence': '0.9968454430310776', 'text': 'and throwing,'}, {'x': 1580, 'y': 492, 'w': 62, 'h': 24, 'confidence': '0.9999778866767883', 'text': 'none'}, {'x': 1650, 'y': 488, 'w': 120, 'h': 30, 'confidence': '0.8308168608106555', 'text': 'of which'}, {'x': 1780, 'y': 488, 'w': 104, 'h': 28, 'confidence': '0.9993355650776571', 'text': 'involve'}, {'x': 1920, 'y': 488, 'w': 66, 'h': 28, 'confidence': '0.9297878733474461', 'text': 'ball_'}, {'x': 0, 'y': 515, 'w': 263, 'h': 37, 'confidence': '0.38236342023664105', 'text': '3. *xGymnastics:**'}, {'x': 284, 'y': 518, 'w': 148, 'h': 31, 'confidence': '0.9981477364915551', 'text': 'This sport'}, {'x': 442, 'y': 517, 'w': 104, 'h': 28, 'confidence': '0.9999845454528696', 'text': 'focuses'}, {'x': 556, 'y': 522, 'w': 32, 'h': 24, 'confidence': '0.9987089490902719', 'text': 'on'}, {'x': 596, 'y': 512, 'w': 321, 'h': 41, 'confidence': '0.999225189971657', 'text': 'strength, flexibility,'}, {'x': 924, 'y': 516, 'w': 244, 'h': 32, 'confidence': '0.9498896956731664', 'text': 'and coordination,'}, {'x': 1182, 'y': 522, 'w': 34, 'h': 24, 'confidence': '0.6864636641356003', 'text': 'us_'}, {'x': 1266, 'y': 518, 'w': 134, 'h': 32, 'confidence': '0.9999895201222115', 'text': 'equipment'}, {'x': 1410, 'y': 517, 'w': 142, 'h': 31, 'confidence': '0.47667856896937344', 'text': 'like bars ,'}, {'x': 1563, 'y': 515, 'w': 91, 'h': 36, 'confidence': '0.6657913454266926', 'text': 'rings ,'}, {'x': 1664, 'y': 518, 'w': 48, 'h': 28, 'confidence': '0.999998279362313', 'text': 'and'}, {'x': 1722, 'y': 518, 'w': 86, 'h': 28, 'confidence': '0.8675395095728283', 'text': 'beams .'}, {'x': 196, 'y': 464, 'w': 38, 'h': 18, 'confidence': '0.2775075635830824', 'text': '**'}, {'x': 1211, 'y': 515, 'w': 44, 'h': 38, 'confidence': '0.9999809353565783', 'text': 'ing'}]}]\n",
      "> Image for page 130: []\n",
      "> Image for page 131: [{'name': 'img_p130_1.png', 'height': 288, 'width': 910, 'x': 150.35433551999998, 'y': 266.04136678104, 'original_width': 910, 'original_height': 288, 'ocr': [{'x': 357, 'y': 134, 'w': 374, 'h': 45, 'confidence': '0.9733067806089839', 'text': 'Large Language Model'}]}]\n",
      "> Image for page 132: []\n",
      "> Image for page 133: [{'name': 'img_p132_1.png', 'height': 532, 'width': 1132, 'x': 12.000000384, 'y': 57.75984436800002, 'original_width': 1132, 'original_height': 532, 'ocr': [{'x': 15, 'y': 8, 'w': 480, 'h': 41, 'confidence': '0.6410745849372521', 'text': 'from Langchain. chains import'}, {'x': 504, 'y': 10, 'w': 294, 'h': 32, 'confidence': '0.9997264769570069', 'text': 'ConversationChain'}, {'x': 16, 'y': 48, 'w': 74, 'h': 32, 'confidence': '0.9998952746391296', 'text': 'from'}, {'x': 101, 'y': 47, 'w': 275, 'h': 38, 'confidence': '0.5837991049571091', 'text': 'langchain.memory'}, {'x': 387, 'y': 44, 'w': 529, 'h': 43, 'confidence': '0.9993501732311959', 'text': 'import ConversationBufferMemory'}, {'x': 15, 'y': 149, 'w': 462, 'h': 40, 'confidence': '0.6110823835074665', 'text': 'from langchain_google_genai'}, {'x': 487, 'y': 144, 'w': 495, 'h': 45, 'confidence': '0.9303074630763924', 'text': 'import ChatGoogleGenerativeAI'}, {'x': 18, 'y': 226, 'w': 54, 'h': 32, 'confidence': '0.23557102090782228', 'text': 'Ulm'}, {'x': 115, 'y': 221, 'w': 378, 'h': 44, 'confidence': '0.8382968879025501', 'text': 'ChatGoogleGenerativeAI'}, {'x': 503, 'y': 225, 'w': 492, 'h': 38, 'confidence': '0.7838339732476318', 'text': 'model=\"gemini-1.5-flash-001\" )'}, {'x': 13, 'y': 301, 'w': 111, 'h': 38, 'confidence': '0.9998476697178232', 'text': 'memory'}, {'x': 166, 'y': 296, 'w': 415, 'h': 45, 'confidence': '0.9972518332062137', 'text': 'ConversationBufferMemory'}, {'x': 16, 'y': 340, 'w': 208, 'h': 32, 'confidence': '0.999978285377297', 'text': 'conversation'}, {'x': 268, 'y': 340, 'w': 294, 'h': 32, 'confidence': '0.99665302048057', 'text': 'ConversationChain'}, {'x': 84, 'y': 373, 'w': 138, 'h': 42, 'confidence': '0.31298547446828984', 'text': 'llm-LLm,'}, {'x': 81, 'y': 420, 'w': 108, 'h': 32, 'confidence': '0.9998491784458712', 'text': 'memory'}, {'x': 231, 'y': 415, 'w': 127, 'h': 41, 'confidence': '0.8714689284065991', 'text': 'memory ,'}, {'x': 84, 'y': 454, 'w': 208, 'h': 32, 'confidence': '0.9981873784531375', 'text': 'verbose-True'}]}]\n",
      "> Image for page 134: [{'name': 'img_p133_1.png', 'height': 474, 'width': 1116, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 1116, 'original_height': 474, 'ocr': [{'x': 21, 'y': 18, 'w': 480, 'h': 41, 'confidence': '0.6337151504889909', 'text': 'from Langchain.memory import'}, {'x': 509, 'y': 18, 'w': 514, 'h': 39, 'confidence': '0.8953820288512492', 'text': 'ConversationBufferWindowMemory'}, {'x': 24, 'y': 160, 'w': 56, 'h': 32, 'confidence': '0.18314836023541423', 'text': 'Ulm'}, {'x': 121, 'y': 155, 'w': 378, 'h': 44, 'confidence': '0.86756071538665', 'text': 'ChatGoogleGenerativeAI'}, {'x': 510, 'y': 160, 'w': 110, 'h': 32, 'confidence': '0.44288036464988384', 'text': 'model='}, {'x': 626, 'y': 155, 'w': 377, 'h': 42, 'confidence': '0.9534190025823506', 'text': 'gemini-1.5-flash-001\")'}, {'x': 22, 'y': 240, 'w': 105, 'h': 32, 'confidence': '0.9989306090476963', 'text': 'memory'}, {'x': 172, 'y': 231, 'w': 515, 'h': 42, 'confidence': '0.9479345180755603', 'text': 'ConversationBufferWindowMemory'}, {'x': 696, 'y': 236, 'w': 70, 'h': 32, 'confidence': '0.5319153070449829', 'text': 'k-1)'}, {'x': 20, 'y': 272, 'w': 211, 'h': 38, 'confidence': '0.9989343931351654', 'text': 'conversation'}, {'x': 273, 'y': 273, 'w': 296, 'h': 36, 'confidence': '0.958000309724396', 'text': 'ConversationChain'}, {'x': 90, 'y': 307, 'w': 138, 'h': 42, 'confidence': '0.3165249828406372', 'text': 'llm-LLm,'}, {'x': 87, 'y': 350, 'w': 111, 'h': 37, 'confidence': '0.9998461123205921', 'text': 'memory'}, {'x': 237, 'y': 349, 'w': 127, 'h': 41, 'confidence': '0.8978755714723017', 'text': 'memory ,'}, {'x': 90, 'y': 388, 'w': 208, 'h': 32, 'confidence': '0.9976936366883833', 'text': 'verbose-True'}]}]\n",
      "> Image for page 135: [{'name': 'img_p134_1.png', 'height': 438, 'width': 1266, 'x': 12.000000384, 'y': 57.09450970103998, 'original_width': 1266, 'original_height': 438, 'ocr': [{'x': 13, 'y': 7, 'w': 480, 'h': 40, 'confidence': '0.6708441992864072', 'text': 'from Langchain.memory import'}, {'x': 501, 'y': 5, 'w': 498, 'h': 40, 'confidence': '0.7769462140226213', 'text': 'ConversationTokenBufferMemory'}, {'x': 16, 'y': 148, 'w': 56, 'h': 32, 'confidence': '0.19048044567135394', 'text': 'Ulm'}, {'x': 113, 'y': 143, 'w': 884, 'h': 44, 'confidence': '0.56979255823187', 'text': 'ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\")'}, {'x': 14, 'y': 190, 'w': 106, 'h': 32, 'confidence': '0.9996029569898957', 'text': 'memory'}, {'x': 164, 'y': 182, 'w': 645, 'h': 41, 'confidence': '0.634837450847564', 'text': 'ConversationTokenBufferMemory ( Llm-Lm,'}, {'x': 819, 'y': 181, 'w': 328, 'h': 44, 'confidence': '0.8103056169341402', 'text': 'max_token_limit-50)'}, {'x': 13, 'y': 223, 'w': 210, 'h': 36, 'confidence': '0.7286810574554666', 'text': 'conversation'}, {'x': 265, 'y': 223, 'w': 296, 'h': 36, 'confidence': '0.8600838629249279', 'text': 'ConversationChain'}, {'x': 78, 'y': 298, 'w': 112, 'h': 39, 'confidence': '0.9997512073978876', 'text': 'memory'}, {'x': 229, 'y': 297, 'w': 127, 'h': 43, 'confidence': '0.7801543123883635', 'text': 'memory ,'}, {'x': 81, 'y': 337, 'w': 208, 'h': 32, 'confidence': '0.7176442557115187', 'text': 'verbose-True'}]}]\n",
      "> Image for page 136: [{'name': 'img_p135_1.png', 'height': 808, 'width': 1456, 'x': 61.13189171999999, 'y': 49.791340176000006, 'original_width': 1456, 'original_height': 808, 'ocr': [{'x': 1, 'y': 19, 'w': 14, 'h': 28, 'confidence': '0.9133863773699069', 'text': ']'}, {'x': 25, 'y': 16, 'w': 480, 'h': 42, 'confidence': '0.6169756275585194', 'text': 'from Langchain.memory import'}, {'x': 513, 'y': 15, 'w': 530, 'h': 42, 'confidence': '0.9155223149714242', 'text': 'ConversationSummaryBufferMemory'}, {'x': 60, 'y': 120, 'w': 106, 'h': 32, 'confidence': '0.9999994159960977', 'text': 'create'}, {'x': 179, 'y': 127, 'w': 18, 'h': 22, 'confidence': '0.9999425419478172', 'text': 'a'}, {'x': 210, 'y': 115, 'w': 194, 'h': 43, 'confidence': '0.9074528044619031', 'text': 'long string'}, {'x': 26, 'y': 158, 'w': 140, 'h': 32, 'confidence': '0.9999695697835935', 'text': 'schedule'}, {'x': 212, 'y': 158, 'w': 106, 'h': 32, 'confidence': '0.9999520627579308', 'text': '\"There'}, {'x': 330, 'y': 158, 'w': 38, 'h': 32, 'confidence': '0.9909372687971755', 'text': 'is'}, {'x': 381, 'y': 163, 'w': 18, 'h': 24, 'confidence': '0.9999628070474955', 'text': 'a'}, {'x': 408, 'y': 150, 'w': 133, 'h': 48, 'confidence': '0.9999675138218107', 'text': 'meeting'}, {'x': 548, 'y': 160, 'w': 40, 'h': 30, 'confidence': '0.9999996628252286', 'text': 'at'}, {'x': 597, 'y': 153, 'w': 363, 'h': 44, 'confidence': '0.9875453788070292', 'text': '8am with your product'}, {'x': 970, 'y': 160, 'w': 86, 'h': 30, 'confidence': '0.7231476116299146', 'text': 'team.'}, {'x': 26, 'y': 196, 'w': 56, 'h': 32, 'confidence': '0.9998960053707007', 'text': 'You'}, {'x': 92, 'y': 196, 'w': 74, 'h': 32, 'confidence': '0.9982696771621704', 'text': 'will'}, {'x': 178, 'y': 196, 'w': 72, 'h': 32, 'confidence': '0.9999985694885254', 'text': 'need'}, {'x': 261, 'y': 199, 'w': 76, 'h': 36, 'confidence': '0.886889341384261', 'text': 'your'}, {'x': 345, 'y': 192, 'w': 560, 'h': 43, 'confidence': '0.8324117507278586', 'text': 'powerpoint presentation prepared.'}, {'x': 24, 'y': 229, 'w': 145, 'h': 43, 'confidence': '0.9974981304898769', 'text': '9am-12pm'}, {'x': 178, 'y': 234, 'w': 74, 'h': 32, 'confidence': '0.9999752044677734', 'text': 'have'}, {'x': 262, 'y': 234, 'w': 74, 'h': 32, 'confidence': '0.9999393820762634', 'text': 'time'}, {'x': 346, 'y': 236, 'w': 40, 'h': 30, 'confidence': '0.9999726889513998', 'text': 'to'}, {'x': 396, 'y': 236, 'w': 74, 'h': 28, 'confidence': '0.9996422529220581', 'text': 'work'}, {'x': 482, 'y': 238, 'w': 38, 'h': 28, 'confidence': '0.6584241941358704', 'text': 'on'}, {'x': 529, 'y': 230, 'w': 246, 'h': 42, 'confidence': '0.8157397383156388', 'text': 'your LangChain'}, {'x': 25, 'y': 271, 'w': 126, 'h': 38, 'confidence': '0.9999561593490703', 'text': 'project'}, {'x': 160, 'y': 272, 'w': 90, 'h': 32, 'confidence': '0.99936614973825', 'text': 'which'}, {'x': 260, 'y': 272, 'w': 76, 'h': 32, 'confidence': '0.9748747944831848', 'text': 'will'}, {'x': 345, 'y': 269, 'w': 480, 'h': 43, 'confidence': '0.84559100934481', 'text': 'go quickly because Langchain'}, {'x': 836, 'y': 272, 'w': 38, 'h': 32, 'confidence': '0.9844460552506131', 'text': 'is'}, {'x': 886, 'y': 272, 'w': 72, 'h': 32, 'confidence': '0.999924898147583', 'text': 'such'}, {'x': 971, 'y': 279, 'w': 18, 'h': 22, 'confidence': '0.9999064228969736', 'text': 'a'}, {'x': 1001, 'y': 268, 'w': 145, 'h': 43, 'confidence': '0.9999479902287046', 'text': 'powerful'}, {'x': 1156, 'y': 272, 'w': 86, 'h': 32, 'confidence': '0.9983769734137705', 'text': 'tool.'}, {'x': 25, 'y': 308, 'w': 140, 'h': 37, 'confidence': '0.8991275928523657', 'text': 'At Noon,'}, {'x': 180, 'y': 310, 'w': 88, 'h': 32, 'confidence': '0.8861046972894063', 'text': 'lunch'}, {'x': 278, 'y': 312, 'w': 40, 'h': 30, 'confidence': '0.9999995785315409', 'text': 'at'}, {'x': 330, 'y': 310, 'w': 56, 'h': 32, 'confidence': '0.9999987611408254', 'text': 'the'}, {'x': 398, 'y': 310, 'w': 122, 'h': 32, 'confidence': '0.999769885983747', 'text': 'italian'}, {'x': 534, 'y': 310, 'w': 154, 'h': 32, 'confidence': '0.9885501983741212', 'text': 'resturant'}, {'x': 698, 'y': 310, 'w': 76, 'h': 32, 'confidence': '0.5931752643473125', 'text': 'with'}, {'x': 785, 'y': 315, 'w': 18, 'h': 24, 'confidence': '0.9998769797969089', 'text': 'a'}, {'x': 818, 'y': 312, 'w': 142, 'h': 30, 'confidence': '0.9999268319622103', 'text': 'customer'}, {'x': 970, 'y': 310, 'w': 56, 'h': 32, 'confidence': '0.9997050884931816', 'text': 'who'}, {'x': 1037, 'y': 305, 'w': 177, 'h': 42, 'confidence': '0.988383003154744', 'text': 'is driving'}, {'x': 26, 'y': 348, 'w': 74, 'h': 32, 'confidence': '0.9998974800109863', 'text': 'from'}, {'x': 110, 'y': 350, 'w': 74, 'h': 30, 'confidence': '0.9982128739356995', 'text': 'over'}, {'x': 194, 'y': 352, 'w': 40, 'h': 28, 'confidence': '0.9999981455391691', 'text': 'an'}, {'x': 246, 'y': 348, 'w': 72, 'h': 32, 'confidence': '0.9999237060546875', 'text': 'hour'}, {'x': 330, 'y': 352, 'w': 72, 'h': 32, 'confidence': '0.9999971985816956', 'text': 'away'}, {'x': 414, 'y': 350, 'w': 38, 'h': 30, 'confidence': '0.9999536387814112', 'text': 'to'}, {'x': 464, 'y': 350, 'w': 72, 'h': 30, 'confidence': '0.9998365044593811', 'text': 'meet'}, {'x': 547, 'y': 351, 'w': 58, 'h': 36, 'confidence': '0.9990493737131507', 'text': 'you'}, {'x': 616, 'y': 347, 'w': 223, 'h': 33, 'confidence': '0.9313493244974688', 'text': 'to understand'}, {'x': 852, 'y': 348, 'w': 56, 'h': 32, 'confidence': '0.8613669872283936', 'text': 'the'}, {'x': 922, 'y': 347, 'w': 104, 'h': 32, 'confidence': '0.9129606686658117', 'text': 'latest'}, {'x': 1038, 'y': 348, 'w': 38, 'h': 32, 'confidence': '0.9983620608757777', 'text': 'in'}, {'x': 1088, 'y': 350, 'w': 44, 'h': 30, 'confidence': '0.6610963940620422', 'text': 'AI_'}, {'x': 26, 'y': 388, 'w': 40, 'h': 30, 'confidence': '0.9999919078146757', 'text': 'Be'}, {'x': 76, 'y': 390, 'w': 72, 'h': 26, 'confidence': '0.9998294115066528', 'text': 'sure'}, {'x': 159, 'y': 381, 'w': 143, 'h': 42, 'confidence': '0.9900979238298888', 'text': 'to bring'}, {'x': 311, 'y': 384, 'w': 194, 'h': 41, 'confidence': '0.8919018687264152', 'text': 'your laptop'}, {'x': 514, 'y': 388, 'w': 40, 'h': 30, 'confidence': '0.9999457995830391', 'text': 'to'}, {'x': 566, 'y': 386, 'w': 74, 'h': 32, 'confidence': '0.9987821578979492', 'text': 'show'}, {'x': 650, 'y': 386, 'w': 56, 'h': 32, 'confidence': '0.999992016244482', 'text': 'the'}, {'x': 718, 'y': 386, 'w': 106, 'h': 32, 'confidence': '0.9962940700295345', 'text': 'latest'}, {'x': 836, 'y': 386, 'w': 56, 'h': 32, 'confidence': '0.9999751540302894', 'text': 'LLM'}, {'x': 902, 'y': 386, 'w': 88, 'h': 32, 'confidence': '0.6871349584219384', 'text': 'demo .'}, {'x': 23, 'y': 461, 'w': 112, 'h': 38, 'confidence': '0.9998868478125571', 'text': 'memory'}, {'x': 177, 'y': 459, 'w': 678, 'h': 42, 'confidence': '0.4301182744527477', 'text': 'ConversationSummaryBufferMemory ( m-lLm,'}, {'x': 934, 'y': 459, 'w': 275, 'h': 38, 'confidence': '0.8825695752513391', 'text': 'token_limit-100)'}, {'x': 25, 'y': 497, 'w': 480, 'h': 41, 'confidence': '0.7086702838768012', 'text': 'memory. save_context ( {\"input\"'}, {'x': 531, 'y': 499, 'w': 156, 'h': 38, 'confidence': '0.6447441669146451', 'text': '\"Hello\"} ,'}, {'x': 699, 'y': 499, 'w': 160, 'h': 40, 'confidence': '0.9994023145155991', 'text': '{\"output\"'}, {'x': 886, 'y': 500, 'w': 92, 'h': 32, 'confidence': '0.9999962148460897', 'text': '\"What'}, {'x': 987, 'y': 505, 'w': 20, 'h': 24, 'confidence': '0.6769870570997547', 'text': '5'}, {'x': 1019, 'y': 499, 'w': 90, 'h': 38, 'confidence': '0.6238755770292189', 'text': 'up\"})'}, {'x': 25, 'y': 537, 'w': 480, 'h': 41, 'confidence': '0.9259504968742445', 'text': 'memory. save_context ( {\"input\"'}, {'x': 532, 'y': 538, 'w': 72, 'h': 32, 'confidence': '0.9999533891677856', 'text': '\"Not'}, {'x': 615, 'y': 537, 'w': 88, 'h': 38, 'confidence': '0.9998891102830784', 'text': 'much,'}, {'x': 715, 'y': 537, 'w': 76, 'h': 40, 'confidence': '0.9997404217720032', 'text': 'just'}, {'x': 801, 'y': 537, 'w': 172, 'h': 38, 'confidence': '0.9879453734654338', 'text': 'hanging\"} ,'}, {'x': 361, 'y': 575, 'w': 160, 'h': 38, 'confidence': '0.9990988742474658', 'text': '{\"output\"'}, {'x': 547, 'y': 573, 'w': 142, 'h': 38, 'confidence': '0.6914243988864659', 'text': '\"Cool\"})'}, {'x': 24, 'y': 613, 'w': 481, 'h': 40, 'confidence': '0.7299617933189096', 'text': 'memory. save_context ( {\"input\"'}, {'x': 532, 'y': 614, 'w': 88, 'h': 32, 'confidence': '0.9999801924915246', 'text': '\"What'}, {'x': 634, 'y': 614, 'w': 38, 'h': 32, 'confidence': '0.9824502358876039', 'text': 'is'}, {'x': 684, 'y': 618, 'w': 38, 'h': 28, 'confidence': '0.9994212885344735', 'text': 'on'}, {'x': 734, 'y': 614, 'w': 56, 'h': 32, 'confidence': '0.9999942186589443', 'text': 'the'}, {'x': 801, 'y': 611, 'w': 308, 'h': 40, 'confidence': '0.9093728952840456', 'text': 'schedule today?\"} ,'}, {'x': 361, 'y': 651, 'w': 172, 'h': 40, 'confidence': '0.6052572982722977', 'text': '{\"output\":'}, {'x': 547, 'y': 649, 'w': 258, 'h': 38, 'confidence': '0.9869358890111378', 'text': 'f\"{schedule}\"})'}, {'x': 21, 'y': 716, 'w': 615, 'h': 48, 'confidence': '0.5584634338890587', 'text': '<ipython-input-129-ZeeS8cceOc01>:10:'}, {'x': 647, 'y': 723, 'w': 476, 'h': 40, 'confidence': '0.9989946705096475', 'text': 'LangChainDeprecationWarning:'}, {'x': 1136, 'y': 724, 'w': 108, 'h': 32, 'confidence': '0.999515299056344', 'text': 'Please'}, {'x': 1254, 'y': 728, 'w': 56, 'h': 28, 'confidence': '0.9998364723668183', 'text': 'see'}, {'x': 1322, 'y': 724, 'w': 56, 'h': 32, 'confidence': '0.9479759931564331', 'text': 'the'}, {'x': 55, 'y': 757, 'w': 111, 'h': 38, 'confidence': '0.9998513685340625', 'text': 'memory'}, {'x': 209, 'y': 757, 'w': 678, 'h': 40, 'confidence': '0.5311010142756442', 'text': 'ConversationSummaryBufferMemory (  lm-llm,'}, {'x': 897, 'y': 755, 'w': 346, 'h': 38, 'confidence': '0.7681558455176066', 'text': 'max_token_limit-100)'}, {'x': 869, 'y': 461, 'w': 68, 'h': 38, 'confidence': '0.7574082998081745', 'text': 'max_'}, {'x': 1390, 'y': 718, 'w': 66, 'h': 46, 'confidence': '0.4463813304901123', 'text': 'migr'}]}]\n",
      "> Image for page 137: []\n",
      "> Image for page 138: []\n",
      "> Image for page 139: [{'name': 'img_p138_1.png', 'height': 558, 'width': 1216, 'x': 15.316929623999998, 'y': 57.045277415999976, 'original_width': 1216, 'original_height': 558, 'ocr': [{'x': 14, 'y': 12, 'w': 77, 'h': 36, 'confidence': '0.9998970627784729', 'text': 'from'}, {'x': 101, 'y': 11, 'w': 292, 'h': 43, 'confidence': '0.7780488293213839', 'text': 'Langchain.prompts'}, {'x': 405, 'y': 11, 'w': 428, 'h': 40, 'confidence': '0.9484135553692901', 'text': 'import ChatPromptTemplate'}, {'x': 15, 'y': 49, 'w': 361, 'h': 40, 'confidence': '0.683308978865326', 'text': 'from Langchain. chains'}, {'x': 387, 'y': 51, 'w': 108, 'h': 38, 'confidence': '0.9998324364027409', 'text': 'import'}, {'x': 506, 'y': 52, 'w': 140, 'h': 32, 'confidence': '0.9994702824344437', 'text': 'LLMChain'}, {'x': 18, 'y': 152, 'w': 56, 'h': 32, 'confidence': '0.4445805585383659', 'text': 'Um'}, {'x': 116, 'y': 147, 'w': 879, 'h': 44, 'confidence': '0.6100512506898806', 'text': 'ChatGoogleGenerativeAI (model-\"gemini-1.5-flash-001\")'}, {'x': 15, 'y': 254, 'w': 107, 'h': 38, 'confidence': '0.9999842318677323', 'text': 'prompt'}, {'x': 167, 'y': 253, 'w': 560, 'h': 40, 'confidence': '0.8213691073669196', 'text': 'ChatPromptTemplate. from_template('}, {'x': 81, 'y': 293, 'w': 90, 'h': 32, 'confidence': '0.9999945088606758', 'text': '\"What'}, {'x': 186, 'y': 294, 'w': 38, 'h': 32, 'confidence': '0.9826007638263119', 'text': 'is'}, {'x': 234, 'y': 294, 'w': 58, 'h': 32, 'confidence': '0.9999997246979434', 'text': 'the'}, {'x': 302, 'y': 294, 'w': 74, 'h': 32, 'confidence': '0.9999982118606567', 'text': 'best'}, {'x': 386, 'y': 296, 'w': 74, 'h': 30, 'confidence': '0.9998543858528137', 'text': 'name'}, {'x': 470, 'y': 294, 'w': 40, 'h': 32, 'confidence': '0.999974627691473', 'text': 'to'}, {'x': 522, 'y': 294, 'w': 140, 'h': 32, 'confidence': '0.9999938886992309', 'text': 'describe'}, {'x': 673, 'y': 299, 'w': 20, 'h': 24, 'confidence': '0.9999728204666667', 'text': 'a'}, {'x': 707, 'y': 291, 'w': 208, 'h': 40, 'confidence': '0.7460775918149934', 'text': 'company that'}, {'x': 923, 'y': 289, 'w': 293, 'h': 40, 'confidence': '0.9596340444448278', 'text': 'makes {product}?\"'}, {'x': 16, 'y': 434, 'w': 90, 'h': 32, 'confidence': '0.9999614020132174', 'text': 'chain'}, {'x': 149, 'y': 433, 'w': 110, 'h': 38, 'confidence': '0.9999895365851338', 'text': 'prompt'}, {'x': 304, 'y': 434, 'w': 56, 'h': 32, 'confidence': '0.2912593082382567', 'text': '1Zm'}, {'x': 401, 'y': 431, 'w': 294, 'h': 40, 'confidence': '0.928693237512238', 'text': 'StroutputParser( )'}, {'x': 13, 'y': 468, 'w': 128, 'h': 41, 'confidence': '0.912590663112696', 'text': 'product'}, {'x': 183, 'y': 469, 'w': 110, 'h': 36, 'confidence': '0.999965494971244', 'text': '\"Queen'}, {'x': 301, 'y': 468, 'w': 260, 'h': 38, 'confidence': '0.9854456618951076', 'text': 'Size Sheet Set\"'}, {'x': 15, 'y': 504, 'w': 360, 'h': 43, 'confidence': '0.8719344021548134', 'text': 'chain. invoke(product)'}]}]\n",
      "> Image for page 140: [{'name': 'img_p139_1.png', 'height': 188, 'width': 466, 'x': 172.87205277599998, 'y': 232.330716096, 'original_width': 466, 'original_height': 188, 'ocr': [{'x': 83, 'y': 44, 'w': 291, 'h': 110, 'confidence': '0.9431510332055195', 'text': '000'}]}]\n",
      "> Image for page 141: [{'name': 'img_p140_1.png', 'height': 508, 'width': 1282, 'x': 12.000000384, 'y': 81.37204984799996, 'original_width': 1282, 'original_height': 508, 'ocr': [{'x': 217, 'y': 123, 'w': 120, 'h': 36, 'confidence': '0.7271554893491455', 'text': 'Chain 1'}, {'x': 885, 'y': 131, 'w': 124, 'h': 38, 'confidence': '0.9981752788600317', 'text': 'Chain 2'}, {'x': 508, 'y': 258, 'w': 111, 'h': 44, 'confidence': '0.9981769016064823', 'text': 'Output'}, {'x': 667, 'y': 261, 'w': 84, 'h': 40, 'confidence': '0.9998107935459039', 'text': 'Input'}, {'x': 20, 'y': 294, 'w': 95, 'h': 44, 'confidence': '0.9999334663440265', 'text': 'Input'}, {'x': 217, 'y': 291, 'w': 162, 'h': 72, 'confidence': '0.8366155961438605', 'text': '000'}, {'x': 543, 'y': 301, 'w': 40, 'h': 36, 'confidence': '0.9989581203585646', 'text': 'of'}, {'x': 684, 'y': 304, 'w': 38, 'h': 32, 'confidence': '0.999802758446846', 'text': 'to'}, {'x': 881, 'y': 285, 'w': 197, 'h': 61, 'confidence': '0.3438485264778137', 'text': '0007'}, {'x': 1134, 'y': 298, 'w': 119, 'h': 44, 'confidence': '0.9999438866082339', 'text': 'Output'}, {'x': 501, 'y': 339, 'w': 118, 'h': 38, 'confidence': '0.9957038126783405', 'text': 'Chain 1'}, {'x': 640, 'y': 339, 'w': 123, 'h': 37, 'confidence': '0.8954652829544298', 'text': 'Chain 2'}]}]\n",
      "> Image for page 142: [{'name': 'img_p141_1.png', 'height': 962, 'width': 1478, 'x': 78.393703296, 'y': 49.79134017599995, 'original_width': 1478, 'original_height': 962, 'ocr': [{'x': 17, 'y': 15, 'w': 364, 'h': 43, 'confidence': '0.5209367065191102', 'text': 'from Langchain. chains'}, {'x': 391, 'y': 16, 'w': 477, 'h': 41, 'confidence': '0.9350018355457779', 'text': 'import SimpleSequentialChain'}, {'x': 22, 'y': 122, 'w': 56, 'h': 30, 'confidence': '0.2850547332030605', 'text': '1lm'}, {'x': 118, 'y': 117, 'w': 380, 'h': 42, 'confidence': '0.8045735841732367', 'text': 'ChatGoogLeGenerativeAI'}, {'x': 507, 'y': 119, 'w': 496, 'h': 40, 'confidence': '0.592026972083469', 'text': 'model-\"gemini-1.5-flash-001\" )'}, {'x': 17, 'y': 197, 'w': 143, 'h': 38, 'confidence': '0.5403682678144442', 'text': '# prompt'}, {'x': 171, 'y': 197, 'w': 142, 'h': 38, 'confidence': '0.9999087082000268', 'text': 'template'}, {'x': 327, 'y': 201, 'w': 14, 'h': 24, 'confidence': '0.9999837876023321', 'text': '1'}, {'x': 19, 'y': 235, 'w': 210, 'h': 40, 'confidence': '0.8135750893172898', 'text': 'first_prompt'}, {'x': 270, 'y': 232, 'w': 565, 'h': 42, 'confidence': '0.7040704848472165', 'text': 'ChatPromptTemplate. from_template('}, {'x': 84, 'y': 270, 'w': 93, 'h': 37, 'confidence': '0.9999945088606758', 'text': '\"What'}, {'x': 190, 'y': 274, 'w': 38, 'h': 32, 'confidence': '0.9865144249539869', 'text': 'is'}, {'x': 237, 'y': 271, 'w': 144, 'h': 36, 'confidence': '0.9425337238531625', 'text': 'the best'}, {'x': 390, 'y': 276, 'w': 74, 'h': 30, 'confidence': '0.9996605515480042', 'text': 'name'}, {'x': 473, 'y': 271, 'w': 196, 'h': 36, 'confidence': '0.9953168545547246', 'text': 'to describe'}, {'x': 677, 'y': 279, 'w': 20, 'h': 24, 'confidence': '0.9999520784397333', 'text': 'a'}, {'x': 709, 'y': 271, 'w': 210, 'h': 40, 'confidence': '0.6652900177632227', 'text': 'company that'}, {'x': 928, 'y': 274, 'w': 92, 'h': 32, 'confidence': '0.7604879842614094', 'text': 'makes'}, {'x': 1031, 'y': 271, 'w': 192, 'h': 38, 'confidence': '0.8550995688785628', 'text': '{product}?\"'}, {'x': 17, 'y': 385, 'w': 128, 'h': 36, 'confidence': '0.9995771574056035', 'text': '# Chain'}, {'x': 155, 'y': 391, 'w': 20, 'h': 24, 'confidence': '0.9999966621426779', 'text': '1'}, {'x': 20, 'y': 423, 'w': 159, 'h': 41, 'confidence': '0.9966400385670219', 'text': 'chain_one'}, {'x': 221, 'y': 423, 'w': 246, 'h': 36, 'confidence': '0.25993520499141054', 'text': 'LLMChain( lm-l-'}, {'x': 525, 'y': 423, 'w': 342, 'h': 40, 'confidence': '0.9123909020507099', 'text': 'prompt-first_prompt)'}, {'x': 17, 'y': 523, 'w': 296, 'h': 43, 'confidence': '0.9958830354632583', 'text': '# prompt template'}, {'x': 323, 'y': 529, 'w': 20, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 19, 'y': 565, 'w': 226, 'h': 38, 'confidence': '0.960241869417761', 'text': 'second_prompt'}, {'x': 289, 'y': 563, 'w': 548, 'h': 40, 'confidence': '0.896279947143642', 'text': 'ChatPromptTemplate. from_template'}, {'x': 85, 'y': 603, 'w': 110, 'h': 32, 'confidence': '0.9999943546257334', 'text': '\"Write'}, {'x': 205, 'y': 609, 'w': 20, 'h': 24, 'confidence': '0.9999303829865767', 'text': 'a'}, {'x': 238, 'y': 604, 'w': 40, 'h': 32, 'confidence': '0.9999964596665606', 'text': '20'}, {'x': 287, 'y': 602, 'w': 296, 'h': 38, 'confidence': '0.9793233298477354', 'text': 'words description'}, {'x': 594, 'y': 604, 'w': 56, 'h': 32, 'confidence': '0.8536514639854431', 'text': 'for'}, {'x': 659, 'y': 598, 'w': 631, 'h': 43, 'confidence': '0.9174787827610078', 'text': 'the following company: {company_name}\"'}, {'x': 18, 'y': 682, 'w': 24, 'h': 26, 'confidence': '0.9999988079074598', 'text': '#'}, {'x': 53, 'y': 677, 'w': 92, 'h': 36, 'confidence': '0.9999933359955044', 'text': 'chain'}, {'x': 155, 'y': 679, 'w': 20, 'h': 28, 'confidence': '1.0', 'text': '2'}, {'x': 22, 'y': 718, 'w': 90, 'h': 32, 'confidence': '0.9732710595314048', 'text': 'chain_'}, {'x': 122, 'y': 718, 'w': 54, 'h': 32, 'confidence': '0.9999644172933476', 'text': 'two'}, {'x': 221, 'y': 714, 'w': 290, 'h': 39, 'confidence': '0.3664605499972305', 'text': 'LLMChain ( Llm-LLm,'}, {'x': 524, 'y': 713, 'w': 357, 'h': 44, 'confidence': '0.9957860913388287', 'text': 'prompt-second_prompt)'}, {'x': 19, 'y': 815, 'w': 314, 'h': 44, 'confidence': '0.9262655228943057', 'text': 'chains= [chain_one'}, {'x': 356, 'y': 817, 'w': 173, 'h': 36, 'confidence': '0.9990757332851048', 'text': 'chain_two]'}, {'x': 18, 'y': 851, 'w': 345, 'h': 45, 'confidence': '0.8618941801779703', 'text': 'overall_simple_chain'}, {'x': 405, 'y': 853, 'w': 832, 'h': 42, 'confidence': '0.9591358870882447', 'text': 'SimpleSequentialChain(chains-chains, verbose-True)'}, {'x': 19, 'y': 890, 'w': 562, 'h': 43, 'confidence': '0.7493016784921953', 'text': 'overall_simple_chain. run(product)'}, {'x': 461, 'y': 423, 'w': 46, 'h': 38, 'confidence': '0.6036978363990784', 'text': 'Lm ,'}]}]\n",
      "> Image for page 143: [{'name': 'img_p142_1.png', 'height': 892, 'width': 1470, 'x': 12.000000384, 'y': 57.09449001600001, 'original_width': 1470, 'original_height': 892, 'ocr': [{'x': 19, 'y': 7, 'w': 364, 'h': 43, 'confidence': '0.48745172071534737', 'text': 'from Langchain. chains'}, {'x': 393, 'y': 9, 'w': 477, 'h': 40, 'confidence': '0.9318676754006954', 'text': 'import SimpleSequentialChain'}, {'x': 24, 'y': 88, 'w': 56, 'h': 30, 'confidence': '0.2710336193215316', 'text': '1lm'}, {'x': 121, 'y': 81, 'w': 884, 'h': 44, 'confidence': '0.560833653522345', 'text': 'ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\")'}, {'x': 21, 'y': 188, 'w': 141, 'h': 38, 'confidence': '0.8330317961319722', 'text': '# prompt'}, {'x': 173, 'y': 189, 'w': 144, 'h': 38, 'confidence': '0.9998453582598984', 'text': 'template'}, {'x': 329, 'y': 193, 'w': 16, 'h': 24, 'confidence': '0.9999516016140575', 'text': '1'}, {'x': 20, 'y': 225, 'w': 211, 'h': 41, 'confidence': '0.8543458066912667', 'text': 'first_prompt'}, {'x': 273, 'y': 225, 'w': 548, 'h': 40, 'confidence': '0.9489365542237537', 'text': 'ChatPromptTemplate. from_template'}, {'x': 20, 'y': 306, 'w': 24, 'h': 26, 'confidence': '0.9999983310706426', 'text': '#'}, {'x': 56, 'y': 304, 'w': 90, 'h': 32, 'confidence': '0.9999326133450446', 'text': 'Chain'}, {'x': 159, 'y': 307, 'w': 16, 'h': 24, 'confidence': '0.9999980926522767', 'text': '1'}, {'x': 21, 'y': 340, 'w': 159, 'h': 38, 'confidence': '0.9990753763692919', 'text': 'chain_one'}, {'x': 223, 'y': 337, 'w': 644, 'h': 45, 'confidence': '0.2782865462155849', 'text': 'LLMChain( Llm-llm, prompt-first_prompt)'}, {'x': 53, 'y': 443, 'w': 109, 'h': 38, 'confidence': '0.9999942086245797', 'text': 'prompt'}, {'x': 173, 'y': 441, 'w': 144, 'h': 40, 'confidence': '0.9997450402498199', 'text': 'template'}, {'x': 325, 'y': 445, 'w': 20, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 21, 'y': 479, 'w': 226, 'h': 40, 'confidence': '0.7941846498519443', 'text': 'second_prompt'}, {'x': 291, 'y': 479, 'w': 548, 'h': 40, 'confidence': '0.9051686807563452', 'text': 'ChatPromptTemplate. from_template'}, {'x': 56, 'y': 595, 'w': 89, 'h': 32, 'confidence': '0.9998985466279933', 'text': 'chain'}, {'x': 157, 'y': 597, 'w': 18, 'h': 26, 'confidence': '0.9999997615814351', 'text': '2'}, {'x': 24, 'y': 633, 'w': 89, 'h': 32, 'confidence': '0.9998566960916634', 'text': 'chain'}, {'x': 124, 'y': 634, 'w': 56, 'h': 32, 'confidence': '0.9999596683569345', 'text': 'two'}, {'x': 223, 'y': 631, 'w': 142, 'h': 36, 'confidence': '0.9999334913569219', 'text': 'LLMChain'}, {'x': 377, 'y': 629, 'w': 494, 'h': 44, 'confidence': '0.5806489984857857', 'text': 'lm-lZm, prompt-second_prompt'}, {'x': 24, 'y': 736, 'w': 122, 'h': 32, 'confidence': '0.9978786262049244', 'text': 'chains='}, {'x': 159, 'y': 733, 'w': 177, 'h': 41, 'confidence': '0.9502619094662355', 'text': '[chain_one_'}, {'x': 357, 'y': 731, 'w': 174, 'h': 42, 'confidence': '0.9942355950820954', 'text': 'chain_two]'}, {'x': 21, 'y': 773, 'w': 344, 'h': 38, 'confidence': '0.9941875119493324', 'text': 'overall_simple_chain'}, {'x': 409, 'y': 770, 'w': 830, 'h': 41, 'confidence': '0.9480602339883891', 'text': 'SimpleSequentialChain(chains-chains, verbose-True)'}, {'x': 21, 'y': 806, 'w': 560, 'h': 43, 'confidence': '0.6747142702260395', 'text': 'overall_Simple_chain. run(product)'}]}]\n",
      "> Image for page 144: [{'name': 'img_p143_1.png', 'height': 624, 'width': 1304, 'x': 16.074803663999997, 'y': 66.97441159200002, 'original_width': 1304, 'original_height': 624, 'ocr': [{'x': 574, 'y': 28, 'w': 98, 'h': 30, 'confidence': '0.9998165277965436', 'text': 'Chain 2'}, {'x': 152, 'y': 60, 'w': 98, 'h': 32, 'confidence': '0.9530618319880565', 'text': 'Chain 1'}, {'x': 362, 'y': 90, 'w': 123, 'h': 38, 'confidence': '0.7694352637538991', 'text': 'Output of'}, {'x': 764, 'y': 106, 'w': 123, 'h': 38, 'confidence': '0.9939541738177156', 'text': 'Output of'}, {'x': 374, 'y': 124, 'w': 78, 'h': 32, 'confidence': '0.9999948820450144', 'text': 'Chain'}, {'x': 774, 'y': 140, 'w': 100, 'h': 32, 'confidence': '0.9995781574821851', 'text': 'Chain 2'}, {'x': 556, 'y': 154, 'w': 46, 'h': 30, 'confidence': '0.9780468878995094', 'text': '0'}, {'x': 371, 'y': 186, 'w': 100, 'h': 38, 'confidence': '0.9978714579437107', 'text': 'Input to'}, {'x': 996, 'y': 178, 'w': 78, 'h': 30, 'confidence': '0.9999960549099717', 'text': 'Chain'}, {'x': 773, 'y': 202, 'w': 100, 'h': 38, 'confidence': '0.9998921016566132', 'text': 'Input to'}, {'x': 376, 'y': 220, 'w': 92, 'h': 30, 'confidence': '0.9998818594929307', 'text': 'chain 2'}, {'x': 776, 'y': 236, 'w': 94, 'h': 30, 'confidence': '0.9980267207399077', 'text': 'chain 4'}, {'x': 28, 'y': 274, 'w': 64, 'h': 30, 'confidence': '0.9999901652336121', 'text': 'User'}, {'x': 1166, 'y': 276, 'w': 121, 'h': 38, 'confidence': '0.9986264756526466', 'text': 'Output of'}, {'x': 23, 'y': 304, 'w': 74, 'h': 38, 'confidence': '0.9999278152241711', 'text': 'Input'}, {'x': 1176, 'y': 310, 'w': 98, 'h': 30, 'confidence': '0.808915827597345', 'text': 'Chain 4'}, {'x': 720, 'y': 352, 'w': 123, 'h': 38, 'confidence': '0.7274684827554221', 'text': 'Output of'}, {'x': 732, 'y': 386, 'w': 98, 'h': 30, 'confidence': '0.8147838121152041', 'text': 'Chain 3'}, {'x': 359, 'y': 407, 'w': 78, 'h': 36, 'confidence': '0.8121831798585566', 'text': '00'}, {'x': 729, 'y': 448, 'w': 100, 'h': 38, 'confidence': '0.9981871969867459', 'text': 'Input to'}, {'x': 734, 'y': 482, 'w': 92, 'h': 30, 'confidence': '0.9996890780034771', 'text': 'chain 4'}, {'x': 370, 'y': 538, 'w': 98, 'h': 30, 'confidence': '0.6933175529774659', 'text': 'Chain 3'}, {'x': 187, 'y': 196, 'w': 123, 'h': 32, 'confidence': '0.782751098232491', 'text': '900'}]}]\n",
      "> Image for page 145: [{'name': 'img_p144_1.png', 'height': 1210, 'width': 1568, 'x': 138.14764221599998, 'y': 53.77559227199998, 'original_width': 1568, 'original_height': 1210, 'ocr': [{'x': 17, 'y': 11, 'w': 364, 'h': 43, 'confidence': '0.497380071731042', 'text': 'from Langchain. chains'}, {'x': 391, 'y': 13, 'w': 378, 'h': 40, 'confidence': '0.6991790496827885', 'text': 'import SequentialChain'}, {'x': 22, 'y': 118, 'w': 56, 'h': 30, 'confidence': '0.33128214582126314', 'text': 'llm'}, {'x': 118, 'y': 111, 'w': 885, 'h': 45, 'confidence': '0.660563639933967', 'text': 'ChatGoogleGenerativeAI (model-\"gemini-1.5-flash-001\")'}, {'x': 19, 'y': 192, 'w': 294, 'h': 39, 'confidence': '0.739187104980193', 'text': '# prompt template'}, {'x': 324, 'y': 194, 'w': 36, 'h': 32, 'confidence': '0.9988987119609928', 'text': '1:'}, {'x': 373, 'y': 191, 'w': 160, 'h': 36, 'confidence': '0.9992067035095507', 'text': 'translate'}, {'x': 542, 'y': 194, 'w': 40, 'h': 32, 'confidence': '0.9999641753667189', 'text': 'to'}, {'x': 593, 'y': 191, 'w': 124, 'h': 40, 'confidence': '0.9978805198911433', 'text': 'english'}, {'x': 19, 'y': 231, 'w': 210, 'h': 38, 'confidence': '0.8030211220710465', 'text': 'first_prompt'}, {'x': 270, 'y': 228, 'w': 565, 'h': 41, 'confidence': '0.8122444628323096', 'text': 'ChatPromptTemplate. from_template('}, {'x': 85, 'y': 269, 'w': 176, 'h': 32, 'confidence': '0.9995531537285691', 'text': '\"Translate'}, {'x': 271, 'y': 264, 'w': 228, 'h': 43, 'confidence': '0.9966492986588248', 'text': 'the following'}, {'x': 510, 'y': 270, 'w': 106, 'h': 32, 'confidence': '0.9999041249993722', 'text': 'review'}, {'x': 626, 'y': 272, 'w': 40, 'h': 30, 'confidence': '0.999948581232014', 'text': 'to'}, {'x': 677, 'y': 267, 'w': 142, 'h': 40, 'confidence': '0.8110123628512582', 'text': 'english:\"'}, {'x': 84, 'y': 304, 'w': 244, 'h': 36, 'confidence': '0.9354901351062457', 'text': '\"Inln{Review}\"'}, {'x': 17, 'y': 419, 'w': 128, 'h': 36, 'confidence': '0.8160177976392045', 'text': '# chain'}, {'x': 154, 'y': 422, 'w': 36, 'h': 32, 'confidence': '0.9989792716832439', 'text': '1:'}, {'x': 205, 'y': 417, 'w': 684, 'h': 43, 'confidence': '0.8573488291804113', 'text': 'input= Review and output= English_Review'}, {'x': 20, 'y': 455, 'w': 159, 'h': 44, 'confidence': '0.9015865713868743', 'text': 'chain_one'}, {'x': 221, 'y': 456, 'w': 290, 'h': 39, 'confidence': '0.32596679603680834', 'text': 'LLMChain ( llm-LLm,'}, {'x': 524, 'y': 457, 'w': 813, 'h': 43, 'confidence': '0.806631057770695', 'text': 'prompt-first_prompt,output_key-\"English_Review\" )'}, {'x': 19, 'y': 559, 'w': 226, 'h': 40, 'confidence': '0.7752251229020529', 'text': 'second_prompt'}, {'x': 288, 'y': 558, 'w': 565, 'h': 41, 'confidence': '0.7833609414787892', 'text': 'ChatPromptTemplate. from_template('}, {'x': 85, 'y': 597, 'w': 76, 'h': 36, 'confidence': '0.9780503206070993', 'text': '\"Can'}, {'x': 172, 'y': 604, 'w': 56, 'h': 32, 'confidence': '0.998130864372785', 'text': 'you'}, {'x': 240, 'y': 600, 'w': 156, 'h': 32, 'confidence': '0.9999742903646398', 'text': 'summarize'}, {'x': 407, 'y': 594, 'w': 227, 'h': 43, 'confidence': '0.9673761304000762', 'text': 'the following'}, {'x': 645, 'y': 599, 'w': 106, 'h': 32, 'confidence': '0.9999128365695336', 'text': 'review'}, {'x': 762, 'y': 600, 'w': 40, 'h': 32, 'confidence': '0.9973720606942409', 'text': 'in'}, {'x': 815, 'y': 603, 'w': 16, 'h': 24, 'confidence': '0.9999964237245109', 'text': '1'}, {'x': 846, 'y': 600, 'w': 154, 'h': 32, 'confidence': '0.9999624884584403', 'text': 'sentence:'}, {'x': 84, 'y': 631, 'w': 380, 'h': 44, 'confidence': '0.6180462304228032', 'text': '\"Inin{English_Review}\"'}, {'x': 18, 'y': 754, 'w': 24, 'h': 26, 'confidence': '0.9999989271166818', 'text': '#'}, {'x': 53, 'y': 749, 'w': 92, 'h': 36, 'confidence': '0.9999934426196176', 'text': 'chain'}, {'x': 153, 'y': 748, 'w': 480, 'h': 42, 'confidence': '0.5421014400169797', 'text': '2: input= English_Review and'}, {'x': 643, 'y': 749, 'w': 262, 'h': 40, 'confidence': '0.8924450088366412', 'text': 'output= summary'}, {'x': 20, 'y': 790, 'w': 158, 'h': 32, 'confidence': '0.9921689081399169', 'text': 'chain_two'}, {'x': 221, 'y': 786, 'w': 290, 'h': 39, 'confidence': '0.3640108382888853', 'text': 'LLMChain ( Llm-LLm,'}, {'x': 525, 'y': 787, 'w': 710, 'h': 40, 'confidence': '0.7085611831622431', 'text': 'prompt-second_prompt, output_key-\"summary\" )'}, {'x': 19, 'y': 928, 'w': 294, 'h': 39, 'confidence': '0.739187104980193', 'text': '# prompt template'}, {'x': 324, 'y': 930, 'w': 36, 'h': 32, 'confidence': '0.9998524892170094', 'text': '3:'}, {'x': 373, 'y': 927, 'w': 160, 'h': 36, 'confidence': '0.9992067035095507', 'text': 'translate'}, {'x': 542, 'y': 930, 'w': 40, 'h': 32, 'confidence': '0.9999641753667189', 'text': 'to'}, {'x': 593, 'y': 927, 'w': 124, 'h': 40, 'confidence': '0.9978805198911433', 'text': 'english'}, {'x': 19, 'y': 965, 'w': 210, 'h': 40, 'confidence': '0.8463110154843646', 'text': 'third_prompt'}, {'x': 270, 'y': 964, 'w': 551, 'h': 41, 'confidence': '0.7631561326524686', 'text': 'ChatPromptTemplate. from_template'}, {'x': 84, 'y': 1002, 'w': 93, 'h': 37, 'confidence': '0.953480826154455', 'text': '\"What'}, {'x': 188, 'y': 1004, 'w': 143, 'h': 40, 'confidence': '0.4997394928365075', 'text': 'Zanguage'}, {'x': 342, 'y': 1006, 'w': 38, 'h': 32, 'confidence': '0.9708287592934485', 'text': 'is'}, {'x': 389, 'y': 1000, 'w': 228, 'h': 43, 'confidence': '0.997068065628235', 'text': 'the following'}, {'x': 626, 'y': 1001, 'w': 345, 'h': 40, 'confidence': '0.7622543552057335', 'text': 'review: Inln{Review}\"'}, {'x': 18, 'y': 1122, 'w': 24, 'h': 26, 'confidence': '0.9999989271166818', 'text': '#'}, {'x': 53, 'y': 1117, 'w': 92, 'h': 36, 'confidence': '0.9999934426196176', 'text': 'chain'}, {'x': 153, 'y': 1116, 'w': 632, 'h': 44, 'confidence': '0.5379222803264154', 'text': '3: input= Review and output= Language'}, {'x': 20, 'y': 1157, 'w': 192, 'h': 33, 'confidence': '0.8035489107016079', 'text': 'chain_three'}, {'x': 255, 'y': 1153, 'w': 1014, 'h': 44, 'confidence': '0.42039443763363044', 'text': 'LLMChain(  lm-llm, prompt-third_prompt,output_key=\" Language\" )'}]}]\n",
      "> Image for page 146: [{'name': 'img_p145_1.png', 'height': 982, 'width': 1610, 'x': 84.63976648799999, 'y': 57.75984436799996, 'original_width': 1610, 'original_height': 982, 'ocr': [{'x': 21, 'y': 17, 'w': 16, 'h': 26, 'confidence': '0.5739339319320358', 'text': '['}, {'x': 49, 'y': 17, 'w': 16, 'h': 28, 'confidence': '0.9896418071868176', 'text': ']'}, {'x': 89, 'y': 11, 'w': 364, 'h': 43, 'confidence': '0.49681177007576743', 'text': 'from Langchain. chains'}, {'x': 463, 'y': 13, 'w': 378, 'h': 40, 'confidence': '0.6860112632487654', 'text': 'import SequentialChain'}, {'x': 21, 'y': 119, 'w': 16, 'h': 26, 'confidence': '0.5021549923257886', 'text': '['}, {'x': 47, 'y': 119, 'w': 18, 'h': 26, 'confidence': '0.15059778303341265', 'text': 'J'}, {'x': 94, 'y': 118, 'w': 56, 'h': 30, 'confidence': '0.33128214582126314', 'text': 'llm'}, {'x': 190, 'y': 113, 'w': 885, 'h': 42, 'confidence': '0.4551330509978527', 'text': 'ChatGoogleGenerativeAI(model-\"gemini-1.5-flash-001\" )'}, {'x': 90, 'y': 190, 'w': 211, 'h': 42, 'confidence': '0.9939336904665138', 'text': 'first_prompt'}, {'x': 342, 'y': 191, 'w': 565, 'h': 40, 'confidence': '0.7147336694378424', 'text': 'ChatPromptTemplate. from_template('}, {'x': 92, 'y': 342, 'w': 159, 'h': 42, 'confidence': '0.9394706923039301', 'text': 'chain_one'}, {'x': 293, 'y': 343, 'w': 246, 'h': 36, 'confidence': '0.20896148556290026', 'text': 'LLMChain(  lm-l-'}, {'x': 597, 'y': 343, 'w': 532, 'h': 40, 'confidence': '0.8818848998423691', 'text': \"prompt-first_prompt,output_key='\"}, {'x': 23, 'y': 449, 'w': 12, 'h': 26, 'confidence': '0.7169619781559646', 'text': 'L'}, {'x': 49, 'y': 451, 'w': 16, 'h': 24, 'confidence': '0.2682626305159488', 'text': 'J'}, {'x': 91, 'y': 447, 'w': 226, 'h': 38, 'confidence': '0.9993363232346889', 'text': 'second_prompt'}, {'x': 360, 'y': 445, 'w': 561, 'h': 40, 'confidence': '0.7802102620303855', 'text': 'ChatPromptTemplate. from_template('}, {'x': 91, 'y': 595, 'w': 160, 'h': 42, 'confidence': '0.9999623776959665', 'text': 'chain_two'}, {'x': 293, 'y': 596, 'w': 290, 'h': 39, 'confidence': '0.33478569221562043', 'text': 'LLMChain ( llm-LLm,'}, {'x': 596, 'y': 598, 'w': 549, 'h': 39, 'confidence': '0.9053019536193548', 'text': 'prompt-second_prompt, output_key='}, {'x': 91, 'y': 735, 'w': 306, 'h': 42, 'confidence': '0.7063500075370522', 'text': 'chains-[chain_one,'}, {'x': 410, 'y': 733, 'w': 165, 'h': 44, 'confidence': '0.9860483822620997', 'text': 'chain_two_'}, {'x': 597, 'y': 737, 'w': 206, 'h': 38, 'confidence': '0.9987474838707635', 'text': 'chain_three,'}, {'x': 815, 'y': 735, 'w': 190, 'h': 42, 'confidence': '0.9832023175160808', 'text': 'chain_four]'}, {'x': 90, 'y': 773, 'w': 227, 'h': 43, 'confidence': '0.9017429230492445', 'text': 'overall_chain'}, {'x': 360, 'y': 774, 'w': 277, 'h': 41, 'confidence': '0.8437095896180113', 'text': 'SequentialChain('}, {'x': 159, 'y': 816, 'w': 124, 'h': 32, 'confidence': '0.9991017510019214', 'text': 'chains='}, {'x': 295, 'y': 815, 'w': 110, 'h': 36, 'confidence': '0.9997692151542457', 'text': 'chains'}, {'x': 159, 'y': 851, 'w': 308, 'h': 40, 'confidence': '0.6977702394404651', 'text': 'input_variables= [\"_'}, {'x': 159, 'y': 889, 'w': 294, 'h': 40, 'confidence': '0.8988752107106072', 'text': 'output_variables='}, {'x': 160, 'y': 930, 'w': 208, 'h': 32, 'confidence': '0.9878779115148979', 'text': 'verbose-True'}, {'x': 532, 'y': 341, 'w': 48, 'h': 41, 'confidence': '0.2996349929965228', 'text': 'Lm ,'}]}]\n",
      "> Image for page 147: [{'name': 'img_p146_1.png', 'height': 600, 'width': 1296, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1296, 'original_height': 600, 'ocr': [{'x': 264, 'y': 84, 'w': 178, 'h': 32, 'confidence': '0.9991435798183962', 'text': 'Router Chain'}, {'x': 852, 'y': 78, 'w': 236, 'h': 32, 'confidence': '0.9606666466431023', 'text': 'Destination Chain'}, {'x': 489, 'y': 142, 'w': 150, 'h': 38, 'confidence': '0.6948072446679546', 'text': 'If the input'}, {'x': 490, 'y': 178, 'w': 160, 'h': 32, 'confidence': '0.9537429296269058', 'text': 'is related t0'}, {'x': 301, 'y': 203, 'w': 120, 'h': 38, 'confidence': '0.9999926242902437', 'text': 'Subjects'}, {'x': 709, 'y': 207, 'w': 108, 'h': 38, 'confidence': '0.9999902226424093', 'text': 'Subject'}, {'x': 917, 'y': 213, 'w': 76, 'h': 38, 'confidence': '0.23968751036591643', 'text': '0 '}, {'x': 1158, 'y': 206, 'w': 99, 'h': 42, 'confidence': '0.9990665665578488', 'text': 'Output'}, {'x': 21, 'y': 273, 'w': 78, 'h': 36, 'confidence': '0.9936162901771036', 'text': 'Input'}, {'x': 293, 'y': 275, 'w': 20, 'h': 26, 'confidence': '0.34062162373942223', 'text': '1 _'}, {'x': 352, 'y': 274, 'w': 72, 'h': 32, 'confidence': '0.9933735989321489', 'text': 'Math'}, {'x': 290, 'y': 308, 'w': 30, 'h': 30, 'confidence': '0.9722285333544851', 'text': '2.'}, {'x': 349, 'y': 302, 'w': 103, 'h': 44, 'confidence': '0.8513272349174016', 'text': 'History'}, {'x': 150, 'y': 330, 'w': 64, 'h': 32, 'confidence': '0.9994955260231464', 'text': 'LLM'}, {'x': 290, 'y': 342, 'w': 24, 'h': 30, 'confidence': '0.8437552236269057', 'text': '3'}, {'x': 516, 'y': 358, 'w': 62, 'h': 30, 'confidence': '0.9999895095825195', 'text': 'else'}, {'x': 718, 'y': 382, 'w': 76, 'h': 32, 'confidence': '0.9999964237213135', 'text': 'None'}, {'x': 911, 'y': 371, 'w': 164, 'h': 60, 'confidence': '0.7966700716615623', 'text': '000'}, {'x': 1168, 'y': 380, 'w': 99, 'h': 40, 'confidence': '0.998826094665085', 'text': 'Output'}, {'x': 892, 'y': 504, 'w': 182, 'h': 32, 'confidence': '0.9992503438403854', 'text': 'Default Chain'}]}]\n",
      "> Image for page 148: []\n",
      "> Image for page 149: [{'name': 'img_p148_1.png', 'height': 1150, 'width': 1272, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1272, 'original_height': 1150, 'ocr': [{'x': 37, 'y': 25, 'w': 304, 'h': 40, 'confidence': '0.9152156566769287', 'text': '1 physics_template'}, {'x': 381, 'y': 22, 'w': 111, 'h': 38, 'confidence': '0.9326854949498736', 'text': '\"\"You'}, {'x': 502, 'y': 30, 'w': 56, 'h': 30, 'confidence': '0.9999980040603199', 'text': 'are'}, {'x': 567, 'y': 21, 'w': 528, 'h': 45, 'confidence': '0.7818971540247', 'text': 'a very smart physics professor.'}, {'x': 35, 'y': 63, 'w': 87, 'h': 36, 'confidence': '0.9597282388410712', 'text': '2 You'}, {'x': 131, 'y': 64, 'w': 159, 'h': 39, 'confidence': '0.7995069156524323', 'text': 'are great'}, {'x': 299, 'y': 61, 'w': 378, 'h': 42, 'confidence': '0.936580540659516', 'text': 'at answering questions'}, {'x': 686, 'y': 58, 'w': 229, 'h': 48, 'confidence': '0.980251516451648', 'text': 'about physics'}, {'x': 926, 'y': 66, 'w': 38, 'h': 32, 'confidence': '0.9986021910513216', 'text': 'in'}, {'x': 975, 'y': 71, 'w': 18, 'h': 24, 'confidence': '0.999953032091426', 'text': 'a'}, {'x': 1007, 'y': 63, 'w': 140, 'h': 36, 'confidence': '0.9647587255157668', 'text': 'concisel'}, {'x': 35, 'y': 101, 'w': 86, 'h': 36, 'confidence': '0.9974166384648946', 'text': '3 and'}, {'x': 132, 'y': 108, 'w': 74, 'h': 32, 'confidence': '0.9999954700469971', 'text': 'easy'}, {'x': 215, 'y': 101, 'w': 226, 'h': 36, 'confidence': '0.9654643193303268', 'text': 'to understand'}, {'x': 450, 'y': 106, 'w': 122, 'h': 30, 'confidence': '0.9953635978084608', 'text': 'manner.'}, {'x': 36, 'y': 142, 'w': 100, 'h': 32, 'confidence': '0.9832744311008027', 'text': '4 When'}, {'x': 148, 'y': 146, 'w': 58, 'h': 32, 'confidence': '0.99757229980947', 'text': 'you'}, {'x': 216, 'y': 142, 'w': 56, 'h': 32, 'confidence': '0.999996145772132', 'text': 'don'}, {'x': 283, 'y': 143, 'w': 20, 'h': 26, 'confidence': '0.9994825794223949', 'text': 't'}, {'x': 318, 'y': 142, 'w': 74, 'h': 32, 'confidence': '0.9995575547218323', 'text': 'know'}, {'x': 402, 'y': 142, 'w': 56, 'h': 32, 'confidence': '0.999999449395897', 'text': 'the'}, {'x': 467, 'y': 143, 'w': 107, 'h': 30, 'confidence': '0.9999987346581147', 'text': 'answer'}, {'x': 586, 'y': 142, 'w': 40, 'h': 32, 'confidence': '0.9999639224882906', 'text': 'to'}, {'x': 637, 'y': 147, 'w': 20, 'h': 24, 'confidence': '0.9998868735837938', 'text': 'a'}, {'x': 668, 'y': 137, 'w': 145, 'h': 42, 'confidence': '0.9999904747934458', 'text': 'question'}, {'x': 821, 'y': 139, 'w': 176, 'h': 40, 'confidence': '0.8436929890145951', 'text': 'you admitl'}, {'x': 36, 'y': 180, 'w': 100, 'h': 32, 'confidence': '0.8662519655679924', 'text': '5 that'}, {'x': 147, 'y': 181, 'w': 60, 'h': 36, 'confidence': '0.9951473167516958', 'text': 'you'}, {'x': 216, 'y': 180, 'w': 58, 'h': 32, 'confidence': '0.9999960081211735', 'text': 'don'}, {'x': 283, 'y': 181, 'w': 20, 'h': 26, 'confidence': '0.9993823528630088', 'text': 't'}, {'x': 318, 'y': 180, 'w': 76, 'h': 32, 'confidence': '0.9894947315163898', 'text': 'know_'}, {'x': 37, 'y': 219, 'w': 18, 'h': 26, 'confidence': '0.9999789000670525', 'text': '6'}, {'x': 64, 'y': 256, 'w': 74, 'h': 32, 'confidence': '0.9999974966049194', 'text': 'Here'}, {'x': 150, 'y': 256, 'w': 38, 'h': 32, 'confidence': '0.9750179713487258', 'text': 'is'}, {'x': 199, 'y': 261, 'w': 18, 'h': 22, 'confidence': '0.9999536281239649', 'text': 'a'}, {'x': 230, 'y': 251, 'w': 157, 'h': 42, 'confidence': '0.9999883174555035', 'text': 'question:'}, {'x': 33, 'y': 290, 'w': 205, 'h': 40, 'confidence': '0.6823182735813418', 'text': '8 {input}\"un'}, {'x': 37, 'y': 333, 'w': 18, 'h': 26, 'confidence': '0.9999988079074598', 'text': '9'}, {'x': 19, 'y': 363, 'w': 272, 'h': 45, 'confidence': '0.9844601322202574', 'text': '10 math_template'}, {'x': 452, 'y': 374, 'w': 56, 'h': 28, 'confidence': '0.5294108986854553', 'text': 'are'}, {'x': 517, 'y': 365, 'w': 444, 'h': 43, 'confidence': '0.7976826401051633', 'text': 'a very good mathematician.'}, {'x': 18, 'y': 408, 'w': 102, 'h': 32, 'confidence': '0.9997291512728965', 'text': '11 You'}, {'x': 132, 'y': 412, 'w': 54, 'h': 26, 'confidence': '0.5106180906295776', 'text': 'are'}, {'x': 195, 'y': 406, 'w': 95, 'h': 40, 'confidence': '0.9999985072634486', 'text': 'great'}, {'x': 299, 'y': 401, 'w': 464, 'h': 44, 'confidence': '0.9457873869220342', 'text': 'at answering math questions_'}, {'x': 18, 'y': 446, 'w': 102, 'h': 32, 'confidence': '0.9733756097735536', 'text': '12 You'}, {'x': 132, 'y': 450, 'w': 54, 'h': 26, 'confidence': '0.9999969716779362', 'text': 'are'}, {'x': 198, 'y': 450, 'w': 38, 'h': 26, 'confidence': '0.20588105391091605', 'text': 'So'}, {'x': 245, 'y': 441, 'w': 80, 'h': 43, 'confidence': '0.9999760985374451', 'text': 'good'}, {'x': 334, 'y': 446, 'w': 124, 'h': 32, 'confidence': '0.9987908412159147', 'text': 'because'}, {'x': 468, 'y': 450, 'w': 58, 'h': 32, 'confidence': '0.9984692711115917', 'text': 'you'}, {'x': 536, 'y': 448, 'w': 56, 'h': 30, 'confidence': '0.9999971093289124', 'text': 'are'}, {'x': 604, 'y': 446, 'w': 74, 'h': 32, 'confidence': '0.9999767541885376', 'text': 'able'}, {'x': 688, 'y': 446, 'w': 224, 'h': 32, 'confidence': '0.5291085760415296', 'text': 'to break down'}, {'x': 19, 'y': 478, 'w': 270, 'h': 43, 'confidence': '0.6789676289829802', 'text': '13 hard prob Lems'}, {'x': 302, 'y': 484, 'w': 72, 'h': 32, 'confidence': '0.9995438456535339', 'text': 'into'}, {'x': 383, 'y': 481, 'w': 376, 'h': 41, 'confidence': '0.7049420392599677', 'text': 'their component parts,'}, {'x': 20, 'y': 522, 'w': 150, 'h': 30, 'confidence': '0.9910030633774529', 'text': '14 answer'}, {'x': 181, 'y': 519, 'w': 342, 'h': 41, 'confidence': '0.9857252814267772', 'text': 'the component parts,'}, {'x': 536, 'y': 520, 'w': 56, 'h': 32, 'confidence': '0.9999972469798912', 'text': 'and'}, {'x': 603, 'y': 519, 'w': 74, 'h': 36, 'confidence': '0.9999986886978149', 'text': 'then'}, {'x': 753, 'y': 517, 'w': 244, 'h': 43, 'confidence': '0.6949006304314679', 'text': 'them togetheri'}, {'x': 20, 'y': 560, 'w': 84, 'h': 32, 'confidence': '0.996002788920867', 'text': '15 to'}, {'x': 114, 'y': 564, 'w': 106, 'h': 26, 'confidence': '0.9999990266601202', 'text': 'answer'}, {'x': 231, 'y': 556, 'w': 358, 'h': 41, 'confidence': '0.906749253905962', 'text': 'the broader question.'}, {'x': 18, 'y': 598, 'w': 40, 'h': 32, 'confidence': '0.9999984827137908', 'text': '16'}, {'x': 20, 'y': 636, 'w': 118, 'h': 32, 'confidence': '0.998455329456873', 'text': '17 Here'}, {'x': 150, 'y': 636, 'w': 38, 'h': 32, 'confidence': '0.9754148483954851', 'text': 'is'}, {'x': 199, 'y': 641, 'w': 18, 'h': 24, 'confidence': '0.9998233396357961', 'text': 'a'}, {'x': 230, 'y': 632, 'w': 157, 'h': 39, 'confidence': '0.9957913009572839', 'text': 'question:'}, {'x': 19, 'y': 670, 'w': 219, 'h': 40, 'confidence': '0.6213398361994847', 'text': '18 {input}\"nn'}, {'x': 18, 'y': 712, 'w': 40, 'h': 30, 'confidence': '0.9999993256504904', 'text': '19'}, {'x': 17, 'y': 746, 'w': 324, 'h': 42, 'confidence': '0.8779584948232985', 'text': '20 history_template'}, {'x': 502, 'y': 754, 'w': 56, 'h': 28, 'confidence': '0.9999985546643163', 'text': 'are'}, {'x': 569, 'y': 755, 'w': 20, 'h': 24, 'confidence': '0.9999618533911416', 'text': 'a'}, {'x': 601, 'y': 745, 'w': 342, 'h': 43, 'confidence': '0.7612373601242246', 'text': 'very good historian.'}, {'x': 18, 'y': 788, 'w': 102, 'h': 32, 'confidence': '0.9924057086731471', 'text': '21 You'}, {'x': 132, 'y': 788, 'w': 72, 'h': 32, 'confidence': '0.9999877382276774', 'text': 'have'}, {'x': 216, 'y': 790, 'w': 40, 'h': 30, 'confidence': '0.9999992413568111', 'text': 'an'}, {'x': 265, 'y': 781, 'w': 378, 'h': 45, 'confidence': '0.7011488419216915', 'text': 'excellent knowledge of'}, {'x': 653, 'y': 781, 'w': 294, 'h': 44, 'confidence': '0.9616002411956802', 'text': 'and understanding'}, {'x': 957, 'y': 785, 'w': 174, 'h': 42, 'confidence': '0.9608897163838399', 'text': 'of people,'}, {'x': 18, 'y': 826, 'w': 151, 'h': 32, 'confidence': '0.7455074345000938', 'text': '22 events'}, {'x': 181, 'y': 823, 'w': 58, 'h': 36, 'confidence': '0.9999991740938607', 'text': 'and'}, {'x': 249, 'y': 822, 'w': 229, 'h': 38, 'confidence': '0.9967522030091527', 'text': 'contexts from'}, {'x': 485, 'y': 831, 'w': 20, 'h': 24, 'confidence': '0.9999480254251125', 'text': 'a'}, {'x': 519, 'y': 821, 'w': 476, 'h': 42, 'confidence': '0.7475213969350051', 'text': 'range of historical periods.'}, {'x': 18, 'y': 864, 'w': 102, 'h': 32, 'confidence': '0.9999443732842316', 'text': '23 You'}, {'x': 132, 'y': 864, 'w': 72, 'h': 32, 'confidence': '0.9999868852341599', 'text': 'have'}, {'x': 215, 'y': 858, 'w': 194, 'h': 43, 'confidence': '0.9972373369364761', 'text': 'the ability'}, {'x': 417, 'y': 860, 'w': 156, 'h': 39, 'confidence': '0.9836901897871306', 'text': 'to think,'}, {'x': 587, 'y': 863, 'w': 120, 'h': 36, 'confidence': '0.9686762944938051', 'text': 'reflect ,'}, {'x': 718, 'y': 859, 'w': 125, 'h': 40, 'confidence': '0.9516509853564143', 'text': 'debate,'}, {'x': 853, 'y': 861, 'w': 128, 'h': 36, 'confidence': '0.9999740921877658', 'text': 'discuss'}, {'x': 990, 'y': 864, 'w': 58, 'h': 32, 'confidence': '0.9999986234898187', 'text': 'and'}, {'x': 18, 'y': 902, 'w': 188, 'h': 32, 'confidence': '0.8080568157451634', 'text': '24 evaluate'}, {'x': 215, 'y': 898, 'w': 156, 'h': 42, 'confidence': '0.928517662922907', 'text': 'the past.'}, {'x': 384, 'y': 902, 'w': 56, 'h': 32, 'confidence': '0.9999635225659663', 'text': 'You'}, {'x': 452, 'y': 902, 'w': 74, 'h': 32, 'confidence': '0.9863334864640939', 'text': 'have'}, {'x': 537, 'y': 907, 'w': 18, 'h': 22, 'confidence': '0.999672439700646', 'text': 'a'}, {'x': 570, 'y': 900, 'w': 123, 'h': 40, 'confidence': '0.9999993692036675', 'text': 'respect'}, {'x': 705, 'y': 899, 'w': 242, 'h': 36, 'confidence': '0.7503164266703135', 'text': 'for historical'}, {'x': 957, 'y': 899, 'w': 156, 'h': 36, 'confidence': '0.9784040495178663', 'text': 'evidencel'}, {'x': 17, 'y': 937, 'w': 104, 'h': 36, 'confidence': '0.9970498467349261', 'text': '25 and'}, {'x': 131, 'y': 935, 'w': 195, 'h': 42, 'confidence': '0.9524066143626644', 'text': 'the ability'}, {'x': 334, 'y': 940, 'w': 40, 'h': 30, 'confidence': '0.9998101758716786', 'text': 'to'}, {'x': 384, 'y': 940, 'w': 74, 'h': 32, 'confidence': '0.7421519892598174', 'text': 'make'}, {'x': 468, 'y': 944, 'w': 56, 'h': 26, 'confidence': '0.9999659314476219', 'text': 'use'}, {'x': 536, 'y': 940, 'w': 40, 'h': 32, 'confidence': '0.9619973730000071', 'text': 'of'}, {'x': 588, 'y': 940, 'w': 38, 'h': 32, 'confidence': '0.9996148838220645', 'text': 'it'}, {'x': 635, 'y': 938, 'w': 177, 'h': 42, 'confidence': '0.91309431943806', 'text': 'to support'}, {'x': 821, 'y': 935, 'w': 294, 'h': 43, 'confidence': '0.970824905119028', 'text': 'your explanations'}, {'x': 17, 'y': 975, 'w': 292, 'h': 40, 'confidence': '0.8409691868603275', 'text': '26 and judgements_'}, {'x': 18, 'y': 1016, 'w': 38, 'h': 30, 'confidence': '1.0', 'text': '27'}, {'x': 18, 'y': 1054, 'w': 120, 'h': 32, 'confidence': '0.8881831473281638', 'text': '28 Here'}, {'x': 150, 'y': 1054, 'w': 38, 'h': 32, 'confidence': '0.9699304637201203', 'text': 'is'}, {'x': 199, 'y': 1059, 'w': 20, 'h': 24, 'confidence': '0.9998020031717125', 'text': 'a'}, {'x': 230, 'y': 1048, 'w': 159, 'h': 43, 'confidence': '0.999881979321056', 'text': 'question:'}, {'x': 17, 'y': 1088, 'w': 221, 'h': 40, 'confidence': '0.7407366206698894', 'text': '29 {input}\"uu'}, {'x': 21, 'y': 1131, 'w': 40, 'h': 19, 'confidence': '0.7505388581514778', 'text': '30'}, {'x': 334, 'y': 361, 'w': 101, 'h': 42, 'confidence': '0.9687935404763465', 'text': '\"\"You'}, {'x': 683, 'y': 524, 'w': 62, 'h': 30, 'confidence': '0.9999905020849161', 'text': 'put'}, {'x': 385, 'y': 741, 'w': 102, 'h': 42, 'confidence': '0.9593837376808353', 'text': '\"\"You'}]}, {'name': 'img_p148_2.png', 'height': 880, 'width': 1294, 'x': 388.06060296911994, 'y': 63.84450991703997, 'original_width': 1294, 'original_height': 880, 'ocr': [{'x': 12, 'y': 15, 'w': 213, 'h': 45, 'confidence': '0.9949981800770066', 'text': 'prompt_infos'}, {'x': 275, 'y': 23, 'w': 14, 'h': 24, 'confidence': '0.4379433801483721', 'text': 'L'}, {'x': 165, 'y': 96, 'w': 92, 'h': 32, 'confidence': '0.9999172593486836', 'text': 'name\"'}, {'x': 300, 'y': 91, 'w': 145, 'h': 43, 'confidence': '0.9980596027418557', 'text': 'physics\"_'}, {'x': 148, 'y': 128, 'w': 229, 'h': 44, 'confidence': '0.9999921641135221', 'text': '\"description\"'}, {'x': 403, 'y': 131, 'w': 92, 'h': 36, 'confidence': '0.9997887218499757', 'text': '\"Good'}, {'x': 505, 'y': 128, 'w': 649, 'h': 44, 'confidence': '0.9135099343486557', 'text': 'for answering questions about physics\" _'}, {'x': 149, 'y': 170, 'w': 306, 'h': 39, 'confidence': '0.7092218620458438', 'text': '\"prompt_template\" :'}, {'x': 469, 'y': 171, 'w': 280, 'h': 38, 'confidence': '0.7062085294565894', 'text': 'physics_template'}, {'x': 150, 'y': 286, 'w': 106, 'h': 30, 'confidence': '0.9342073893569252', 'text': '\"name\"'}, {'x': 284, 'y': 286, 'w': 108, 'h': 30, 'confidence': '0.9212879518215686', 'text': '\"math\"'}, {'x': 148, 'y': 318, 'w': 229, 'h': 44, 'confidence': '0.9999915689808895', 'text': '\"description\"'}, {'x': 403, 'y': 321, 'w': 92, 'h': 36, 'confidence': '0.999786162809046', 'text': '\"Good'}, {'x': 505, 'y': 319, 'w': 226, 'h': 42, 'confidence': '0.8172508628493949', 'text': 'for answering'}, {'x': 739, 'y': 319, 'w': 262, 'h': 40, 'confidence': '0.5652616110076892', 'text': 'math questions\"_'}, {'x': 149, 'y': 360, 'w': 306, 'h': 39, 'confidence': '0.5430794709196934', 'text': '\"prompt_template\" :'}, {'x': 469, 'y': 360, 'w': 228, 'h': 39, 'confidence': '0.784862797206057', 'text': 'math_template'}, {'x': 150, 'y': 476, 'w': 106, 'h': 30, 'confidence': '0.9768465369189319', 'text': '\"name\"'}, {'x': 285, 'y': 475, 'w': 160, 'h': 38, 'confidence': '0.9670416850846976', 'text': '\"History\"'}, {'x': 148, 'y': 508, 'w': 229, 'h': 44, 'confidence': '0.9999917342955382', 'text': '\"description\"'}, {'x': 403, 'y': 511, 'w': 92, 'h': 36, 'confidence': '0.9997936799895769', 'text': '\"Good'}, {'x': 505, 'y': 509, 'w': 530, 'h': 42, 'confidence': '0.8110226905188649', 'text': 'for answering history questions\"'}, {'x': 165, 'y': 548, 'w': 584, 'h': 42, 'confidence': '0.6582391961243921', 'text': 'prompt_template\" : history_template'}, {'x': 150, 'y': 666, 'w': 106, 'h': 30, 'confidence': '0.9532177106348536', 'text': '\"name\"'}, {'x': 282, 'y': 662, 'w': 313, 'h': 42, 'confidence': '0.7968101365824466', 'text': '\"computer science\"'}, {'x': 148, 'y': 698, 'w': 213, 'h': 45, 'confidence': '0.7303593711093268', 'text': '\"description\"'}, {'x': 401, 'y': 701, 'w': 94, 'h': 36, 'confidence': '0.6518479913515688', 'text': '\"Good'}, {'x': 505, 'y': 699, 'w': 698, 'h': 45, 'confidence': '0.8989111247820143', 'text': 'for answering computer science questions\"'}, {'x': 149, 'y': 740, 'w': 306, 'h': 39, 'confidence': '0.47860949681310055', 'text': '\"prompt_template\" :'}, {'x': 471, 'y': 741, 'w': 412, 'h': 38, 'confidence': '0.9167379473519166', 'text': 'computerscience_template'}, {'x': 15, 'y': 821, 'w': 18, 'h': 26, 'confidence': '0.8417754416662007', 'text': ']'}]}]\n",
      "> Image for page 150: [{'name': 'img_p149_1.png', 'height': 1146, 'width': 1486, 'x': 133.50000427199998, 'y': 57.09449001600001, 'original_width': 1486, 'original_height': 1146, 'ocr': [{'x': 27, 'y': 11, 'w': 210, 'h': 40, 'confidence': '0.9879790710455716', 'text': 'prompt_infos'}, {'x': 287, 'y': 17, 'w': 14, 'h': 24, 'confidence': '0.47319805493737377', 'text': 'L'}, {'x': 160, 'y': 88, 'w': 108, 'h': 32, 'confidence': '0.9941613811367027', 'text': '\"name\"'}, {'x': 295, 'y': 87, 'w': 160, 'h': 40, 'confidence': '0.9793271580610952', 'text': '\"physics\"'}, {'x': 160, 'y': 122, 'w': 229, 'h': 44, 'confidence': '0.756725283994044', 'text': '\"description\"'}, {'x': 413, 'y': 125, 'w': 94, 'h': 36, 'confidence': '0.999796718847898', 'text': '\"Good'}, {'x': 517, 'y': 121, 'w': 649, 'h': 45, 'confidence': '0.8482195236397762', 'text': 'for answering questions about physics\" _'}, {'x': 177, 'y': 164, 'w': 290, 'h': 39, 'confidence': '0.8673325640919146', 'text': 'prompt_template\" :'}, {'x': 481, 'y': 164, 'w': 280, 'h': 39, 'confidence': '0.764528904523597', 'text': 'physics_template'}, {'x': 162, 'y': 278, 'w': 106, 'h': 32, 'confidence': '0.8300407556568623', 'text': '\"name\"'}, {'x': 296, 'y': 278, 'w': 106, 'h': 32, 'confidence': '0.7897573984618713', 'text': '\"math\"'}, {'x': 160, 'y': 314, 'w': 229, 'h': 42, 'confidence': '0.6182284940225008', 'text': '\"description\"'}, {'x': 413, 'y': 315, 'w': 94, 'h': 36, 'confidence': '0.5736887337094908', 'text': '\"Good'}, {'x': 517, 'y': 311, 'w': 496, 'h': 44, 'confidence': '0.7478427515628548', 'text': 'for answering math questions\"'}, {'x': 177, 'y': 354, 'w': 279, 'h': 39, 'confidence': '0.7683510847680116', 'text': 'prompt_template\"'}, {'x': 481, 'y': 354, 'w': 228, 'h': 39, 'confidence': '0.6815698362827534', 'text': 'math_template'}, {'x': 162, 'y': 470, 'w': 106, 'h': 30, 'confidence': '0.9242315553465845', 'text': '\"name\"'}, {'x': 294, 'y': 466, 'w': 163, 'h': 41, 'confidence': '0.7523256781429137', 'text': '\"History\"'}, {'x': 160, 'y': 504, 'w': 229, 'h': 42, 'confidence': '0.5791022265935728', 'text': '\"description\"'}, {'x': 413, 'y': 505, 'w': 94, 'h': 36, 'confidence': '0.6944636164680268', 'text': '\"Good'}, {'x': 517, 'y': 503, 'w': 546, 'h': 42, 'confidence': '0.8252280688830159', 'text': 'for answering history questions\"'}, {'x': 176, 'y': 544, 'w': 280, 'h': 39, 'confidence': '0.9990895285981356', 'text': 'prompt_template\"'}, {'x': 482, 'y': 542, 'w': 277, 'h': 42, 'confidence': '0.9991253377838621', 'text': 'history_template'}, {'x': 96, 'y': 586, 'w': 24, 'h': 28, 'confidence': '0.9991704754438615', 'text': '}'}, {'x': 162, 'y': 660, 'w': 106, 'h': 30, 'confidence': '0.98254016339313', 'text': '\"name\"'}, {'x': 295, 'y': 657, 'w': 312, 'h': 40, 'confidence': '0.9983559381039881', 'text': '\"computer science\"'}, {'x': 159, 'y': 695, 'w': 230, 'h': 40, 'confidence': '0.9297773100057796', 'text': '\"description\"'}, {'x': 413, 'y': 695, 'w': 94, 'h': 36, 'confidence': '0.6003613277702279', 'text': '\"Good'}, {'x': 516, 'y': 690, 'w': 700, 'h': 48, 'confidence': '0.8699827559791615', 'text': 'for answering computer science questions\" _'}, {'x': 176, 'y': 734, 'w': 291, 'h': 39, 'confidence': '0.9422421992331178', 'text': 'prompt_template\" :'}, {'x': 483, 'y': 733, 'w': 412, 'h': 40, 'confidence': '0.8038832274833844', 'text': 'computerscience_template'}, {'x': 31, 'y': 815, 'w': 14, 'h': 24, 'confidence': '0.7047822837487026', 'text': '1'}, {'x': 25, 'y': 909, 'w': 886, 'h': 43, 'confidence': '0.6052879971935852', 'text': 'from Langchain. chains.router import MultiPromptChain'}, {'x': 25, 'y': 947, 'w': 1357, 'h': 43, 'confidence': '0.448421526766863', 'text': 'from Langchain. chains. router. (lm_router import LLMRouterChain,RouteroutputParser'}, {'x': 26, 'y': 988, 'w': 497, 'h': 41, 'confidence': '0.7107876210816496', 'text': 'from Langchain.prompts import'}, {'x': 533, 'y': 989, 'w': 244, 'h': 38, 'confidence': '0.9994848353126503', 'text': 'PromptTemplate'}, {'x': 0, 'y': 1091, 'w': 17, 'h': 30, 'confidence': '0.73159472586602', 'text': ']'}, {'x': 30, 'y': 1092, 'w': 56, 'h': 30, 'confidence': '0.29110958028524864', 'text': 'llm'}, {'x': 128, 'y': 1085, 'w': 879, 'h': 44, 'confidence': '0.6205398260817755', 'text': 'ChatGoogleGenerativeAI (model-\"gemini-1.5-flash-001\")'}]}]\n",
      "> Image for page 151: [{'name': 'img_p150_1.png', 'height': 1140, 'width': 1504, 'x': 153.25000490399998, 'y': 58.844490071999985, 'original_width': 1504, 'original_height': 1140, 'ocr': [{'x': 44, 'y': 19, 'w': 117, 'h': 32, 'confidence': '0.9903607019206145', 'text': '1 MULTI'}, {'x': 171, 'y': 19, 'w': 106, 'h': 32, 'confidence': '0.9995948775413719', 'text': 'PROMPT'}, {'x': 290, 'y': 20, 'w': 258, 'h': 32, 'confidence': '0.8085675074055242', 'text': 'ROUTER_TEMPLATE'}, {'x': 591, 'y': 19, 'w': 140, 'h': 30, 'confidence': '0.6782936881225601', 'text': '\"\"Given'}, {'x': 745, 'y': 25, 'w': 18, 'h': 24, 'confidence': '0.9999291909355321', 'text': 'a'}, {'x': 780, 'y': 24, 'w': 54, 'h': 26, 'confidence': '0.9991531372070312', 'text': 'raw'}, {'x': 845, 'y': 18, 'w': 176, 'h': 40, 'confidence': '0.8546228333972647', 'text': 'text input'}, {'x': 1030, 'y': 22, 'w': 40, 'h': 30, 'confidence': '0.9999572633630879', 'text': 'to'}, {'x': 1081, 'y': 25, 'w': 20, 'h': 24, 'confidence': '0.9999103566233316', 'text': 'a'}, {'x': 43, 'y': 61, 'w': 18, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 69, 'y': 56, 'w': 144, 'h': 43, 'confidence': '0.5171895648288912', 'text': 'Zanguage'}, {'x': 222, 'y': 58, 'w': 90, 'h': 32, 'confidence': '0.9999142205336049', 'text': 'model'}, {'x': 322, 'y': 58, 'w': 106, 'h': 32, 'confidence': '0.9999874438992078', 'text': 'select'}, {'x': 440, 'y': 58, 'w': 58, 'h': 32, 'confidence': '0.9999980728858172', 'text': 'the'}, {'x': 507, 'y': 57, 'w': 209, 'h': 38, 'confidence': '0.9933098731547197', 'text': 'model prompt'}, {'x': 728, 'y': 58, 'w': 72, 'h': 32, 'confidence': '0.9999837279319763', 'text': 'best'}, {'x': 811, 'y': 55, 'w': 108, 'h': 36, 'confidence': '0.9999504567297118', 'text': 'suited'}, {'x': 930, 'y': 58, 'w': 56, 'h': 32, 'confidence': '0.9999878867191166', 'text': 'for'}, {'x': 997, 'y': 56, 'w': 172, 'h': 40, 'confidence': '0.7984233006880804', 'text': 'the input.'}, {'x': 42, 'y': 96, 'w': 84, 'h': 32, 'confidence': '0.8039656824754275', 'text': '3 You'}, {'x': 136, 'y': 96, 'w': 76, 'h': 32, 'confidence': '0.9982238411903381', 'text': 'will'}, {'x': 221, 'y': 95, 'w': 142, 'h': 38, 'confidence': '0.9861270076388933', 'text': 'be given'}, {'x': 374, 'y': 96, 'w': 56, 'h': 32, 'confidence': '0.9999989676173402', 'text': 'the'}, {'x': 440, 'y': 100, 'w': 90, 'h': 28, 'confidence': '0.5789960721430202', 'text': 'names'}, {'x': 542, 'y': 96, 'w': 40, 'h': 32, 'confidence': '0.9759373958054831', 'text': 'of'}, {'x': 591, 'y': 95, 'w': 362, 'h': 40, 'confidence': '0.9152047492471449', 'text': 'the available prompts'}, {'x': 964, 'y': 96, 'w': 56, 'h': 32, 'confidence': '0.9999983481878129', 'text': 'and'}, {'x': 1031, 'y': 101, 'w': 18, 'h': 24, 'confidence': '0.9998262004080658', 'text': 'a'}, {'x': 45, 'y': 139, 'w': 16, 'h': 22, 'confidence': '1.0', 'text': '4'}, {'x': 69, 'y': 133, 'w': 194, 'h': 38, 'confidence': '0.9999970167319567', 'text': 'description'}, {'x': 272, 'y': 134, 'w': 40, 'h': 32, 'confidence': '0.8843655111588093', 'text': 'of'}, {'x': 322, 'y': 134, 'w': 74, 'h': 32, 'confidence': '0.9997580051422119', 'text': 'what'}, {'x': 407, 'y': 133, 'w': 174, 'h': 38, 'confidence': '0.5422201024783676', 'text': 'the prompt'}, {'x': 594, 'y': 134, 'w': 38, 'h': 32, 'confidence': '0.987536362788372', 'text': 'is'}, {'x': 644, 'y': 134, 'w': 72, 'h': 32, 'confidence': '0.9999907612800598', 'text': 'best'}, {'x': 728, 'y': 134, 'w': 106, 'h': 32, 'confidence': '0.999885777111448', 'text': 'suited'}, {'x': 846, 'y': 134, 'w': 68, 'h': 32, 'confidence': '0.999057948589325', 'text': 'for.'}, {'x': 42, 'y': 172, 'w': 84, 'h': 32, 'confidence': '0.9847052163713856', 'text': '5 You'}, {'x': 136, 'y': 176, 'w': 58, 'h': 32, 'confidence': '0.9998877464284966', 'text': 'may'}, {'x': 204, 'y': 172, 'w': 74, 'h': 32, 'confidence': '0.9999289512634277', 'text': 'also'}, {'x': 290, 'y': 172, 'w': 106, 'h': 32, 'confidence': '0.9999767857858483', 'text': 'revise'}, {'x': 407, 'y': 171, 'w': 210, 'h': 38, 'confidence': '0.8889668484381757', 'text': 'the original'}, {'x': 627, 'y': 173, 'w': 90, 'h': 38, 'confidence': '0.9957300973819956', 'text': 'input'}, {'x': 728, 'y': 172, 'w': 40, 'h': 32, 'confidence': '0.9935511489272764', 'text': 'if'}, {'x': 778, 'y': 176, 'w': 56, 'h': 32, 'confidence': '0.9987277311789504', 'text': 'you'}, {'x': 846, 'y': 172, 'w': 90, 'h': 32, 'confidence': '0.9999985605754728', 'text': 'think'}, {'x': 945, 'y': 167, 'w': 242, 'h': 43, 'confidence': '0.8018698759205155', 'text': 'that revising|'}, {'x': 42, 'y': 210, 'w': 66, 'h': 32, 'confidence': '0.7210095026632928', 'text': '6 it'}, {'x': 117, 'y': 209, 'w': 264, 'h': 38, 'confidence': '0.9962616316397119', 'text': 'will ultimately'}, {'x': 392, 'y': 210, 'w': 72, 'h': 32, 'confidence': '0.8741954565048218', 'text': 'lead'}, {'x': 474, 'y': 212, 'w': 40, 'h': 30, 'confidence': '0.999964934002116', 'text': 'to'}, {'x': 525, 'y': 215, 'w': 20, 'h': 24, 'confidence': '0.9999003435169129', 'text': 'a'}, {'x': 558, 'y': 210, 'w': 108, 'h': 32, 'confidence': '0.9999987346581147', 'text': 'better'}, {'x': 678, 'y': 214, 'w': 140, 'h': 32, 'confidence': '0.9999981455379533', 'text': 'response'}, {'x': 828, 'y': 210, 'w': 74, 'h': 32, 'confidence': '0.9806099615871791', 'text': 'from'}, {'x': 911, 'y': 208, 'w': 212, 'h': 43, 'confidence': '0.48347864089903964', 'text': 'the Language'}, {'x': 1132, 'y': 210, 'w': 104, 'h': 32, 'confidence': '0.9982865919534524', 'text': 'model.'}, {'x': 45, 'y': 253, 'w': 14, 'h': 22, 'confidence': '0.9717041586387865', 'text': '7'}, {'x': 41, 'y': 287, 'w': 20, 'h': 28, 'confidence': '0.6012184604290148', 'text': '8'}, {'x': 70, 'y': 290, 'w': 38, 'h': 24, 'confidence': '0.9045753651562852', 'text': '<<'}, {'x': 120, 'y': 285, 'w': 175, 'h': 32, 'confidence': '0.9999635086389413', 'text': 'FORMATTING'}, {'x': 305, 'y': 293, 'w': 36, 'h': 20, 'confidence': '0.2638834512845015', 'text': '7>'}, {'x': 40, 'y': 326, 'w': 136, 'h': 30, 'confidence': '0.942440689933737', 'text': '9 Return'}, {'x': 191, 'y': 331, 'w': 16, 'h': 22, 'confidence': '0.9999039196205928', 'text': 'a'}, {'x': 222, 'y': 324, 'w': 140, 'h': 32, 'confidence': '0.9999006156855278', 'text': 'markdown'}, {'x': 373, 'y': 323, 'w': 208, 'h': 40, 'confidence': '0.9977243308448731', 'text': 'code snippet'}, {'x': 590, 'y': 324, 'w': 76, 'h': 32, 'confidence': '0.740031938923383', 'text': 'with'}, {'x': 677, 'y': 331, 'w': 20, 'h': 22, 'confidence': '0.9999672177140475', 'text': 'a'}, {'x': 709, 'y': 323, 'w': 194, 'h': 38, 'confidence': '0.8904039555399034', 'text': 'JSON object'}, {'x': 914, 'y': 324, 'w': 156, 'h': 32, 'confidence': '0.6723874261678552', 'text': 'formatted'}, {'x': 1082, 'y': 326, 'w': 40, 'h': 30, 'confidence': '0.9999554932180673', 'text': 'to'}, {'x': 1134, 'y': 324, 'w': 72, 'h': 32, 'confidence': '0.7356314659118652', 'text': 'look'}, {'x': 1216, 'y': 324, 'w': 86, 'h': 32, 'confidence': '0.9951297717661446', 'text': 'like:'}, {'x': 26, 'y': 364, 'w': 38, 'h': 30, 'confidence': '0.9999994099441718', 'text': '10'}, {'x': 119, 'y': 363, 'w': 76, 'h': 36, 'confidence': '0.9967959523200989', 'text': 'json'}, {'x': 23, 'y': 397, 'w': 122, 'h': 38, 'confidence': '0.9989824448858452', 'text': '11 {{{{'}, {'x': 26, 'y': 438, 'w': 38, 'h': 32, 'confidence': '0.9999993256504904', 'text': '12'}, {'x': 135, 'y': 432, 'w': 363, 'h': 45, 'confidence': '0.7566331870179597', 'text': '\"destination\": string'}, {'x': 542, 'y': 442, 'w': 74, 'h': 28, 'confidence': '0.868690133087488', 'text': 'name'}, {'x': 626, 'y': 438, 'w': 40, 'h': 32, 'confidence': '0.9218460890759405', 'text': 'of'}, {'x': 675, 'y': 437, 'w': 176, 'h': 38, 'confidence': '0.9800977887265724', 'text': 'the prompt'}, {'x': 862, 'y': 440, 'w': 40, 'h': 30, 'confidence': '0.9999715088492855', 'text': 'to'}, {'x': 912, 'y': 442, 'w': 56, 'h': 26, 'confidence': '0.9999671014761352', 'text': 'use'}, {'x': 980, 'y': 442, 'w': 38, 'h': 26, 'confidence': '0.9620453786665842', 'text': 'or'}, {'x': 1030, 'y': 438, 'w': 158, 'h': 32, 'confidence': '0.9840761428531092', 'text': '\"DEFAULT\"'}, {'x': 24, 'y': 478, 'w': 40, 'h': 30, 'confidence': '0.9903514844903148', 'text': '13'}, {'x': 134, 'y': 473, 'w': 241, 'h': 42, 'confidence': '0.8925348789485232', 'text': '\"next_inputs\" :'}, {'x': 387, 'y': 471, 'w': 111, 'h': 42, 'confidence': '0.9999764937823832', 'text': 'string'}, {'x': 541, 'y': 481, 'w': 20, 'h': 24, 'confidence': '0.9998955753886207', 'text': 'a'}, {'x': 572, 'y': 473, 'w': 197, 'h': 42, 'confidence': '0.9998321730804596', 'text': 'potentially'}, {'x': 778, 'y': 476, 'w': 124, 'h': 32, 'confidence': '0.9999092139812822', 'text': 'modified'}, {'x': 912, 'y': 476, 'w': 124, 'h': 32, 'confidence': '0.9990711483534643', 'text': 'version'}, {'x': 1046, 'y': 476, 'w': 42, 'h': 32, 'confidence': '0.9746745180215195', 'text': 'of'}, {'x': 1097, 'y': 474, 'w': 312, 'h': 40, 'confidence': '0.9811074962659199', 'text': 'the original input'}, {'x': 23, 'y': 513, 'w': 122, 'h': 36, 'confidence': '0.999333717348695', 'text': '14 }}}}'}, {'x': 26, 'y': 554, 'w': 38, 'h': 30, 'confidence': '0.9999994942378553', 'text': '15'}, {'x': 26, 'y': 590, 'w': 38, 'h': 32, 'confidence': '0.9999976397772992', 'text': '16'}, {'x': 24, 'y': 628, 'w': 200, 'h': 32, 'confidence': '0.9997576267694236', 'text': '17 REMEMBER:'}, {'x': 238, 'y': 627, 'w': 224, 'h': 32, 'confidence': '0.9999959663430746', 'text': '\"destination\"'}, {'x': 474, 'y': 628, 'w': 74, 'h': 32, 'confidence': '0.9998043179512024', 'text': 'MUST'}, {'x': 558, 'y': 628, 'w': 40, 'h': 32, 'confidence': '0.9999855015148964', 'text': 'be'}, {'x': 608, 'y': 632, 'w': 58, 'h': 28, 'confidence': '0.9996396383014953', 'text': 'one'}, {'x': 676, 'y': 628, 'w': 40, 'h': 32, 'confidence': '0.8899175277716765', 'text': 'of'}, {'x': 728, 'y': 628, 'w': 56, 'h': 32, 'confidence': '0.9999986923153217', 'text': 'the'}, {'x': 794, 'y': 628, 'w': 158, 'h': 32, 'confidence': '0.9999882777188411', 'text': 'candidate'}, {'x': 963, 'y': 628, 'w': 108, 'h': 36, 'confidence': '0.9999920186067003', 'text': 'prompt'}, {'x': 23, 'y': 662, 'w': 391, 'h': 42, 'confidence': '0.840564764896748', 'text': '18 names specified below'}, {'x': 424, 'y': 666, 'w': 40, 'h': 32, 'confidence': '0.9987676800759784', 'text': 'OR'}, {'x': 476, 'y': 666, 'w': 38, 'h': 32, 'confidence': '0.9996804575499292', 'text': 'it'}, {'x': 526, 'y': 670, 'w': 56, 'h': 28, 'confidence': '0.9997383988006605', 'text': 'can'}, {'x': 592, 'y': 666, 'w': 40, 'h': 32, 'confidence': '0.99997622926019', 'text': 'be'}, {'x': 642, 'y': 666, 'w': 158, 'h': 32, 'confidence': '0.9997402658283085', 'text': '\"DEFAULT\"'}, {'x': 812, 'y': 666, 'w': 40, 'h': 32, 'confidence': '0.9971633482352924', 'text': 'if'}, {'x': 861, 'y': 664, 'w': 160, 'h': 40, 'confidence': '0.9969799824693782', 'text': 'the input'}, {'x': 1032, 'y': 666, 'w': 38, 'h': 32, 'confidence': '0.9788423571126617', 'text': 'is'}, {'x': 1082, 'y': 668, 'w': 70, 'h': 30, 'confidence': '0.8746953010559082', 'text': 'notl'}, {'x': 23, 'y': 700, 'w': 238, 'h': 39, 'confidence': '0.7444117495211671', 'text': '19 well suited'}, {'x': 274, 'y': 704, 'w': 56, 'h': 32, 'confidence': '0.9999902267832098', 'text': 'for'}, {'x': 340, 'y': 708, 'w': 56, 'h': 32, 'confidence': '0.9999973846308725', 'text': 'any'}, {'x': 406, 'y': 704, 'w': 40, 'h': 32, 'confidence': '0.9184459606780622', 'text': 'of'}, {'x': 457, 'y': 701, 'w': 226, 'h': 38, 'confidence': '0.9988257081711699', 'text': 'the candidate'}, {'x': 693, 'y': 705, 'w': 128, 'h': 36, 'confidence': '0.8496123320583109', 'text': 'prompts _'}, {'x': 24, 'y': 742, 'w': 200, 'h': 32, 'confidence': '0.9451633752981647', 'text': '20 REMEMBER:'}, {'x': 255, 'y': 741, 'w': 208, 'h': 38, 'confidence': '0.8553274377613251', 'text': 'next_inputs\"'}, {'x': 474, 'y': 746, 'w': 56, 'h': 28, 'confidence': '0.9997996516136742', 'text': 'can'}, {'x': 541, 'y': 743, 'w': 74, 'h': 36, 'confidence': '0.9999247193336487', 'text': 'just'}, {'x': 626, 'y': 742, 'w': 40, 'h': 32, 'confidence': '0.999695713315078', 'text': 'be'}, {'x': 677, 'y': 741, 'w': 210, 'h': 40, 'confidence': '0.770565235384574', 'text': 'the original'}, {'x': 897, 'y': 741, 'w': 90, 'h': 38, 'confidence': '0.999610653407021', 'text': 'input'}, {'x': 24, 'y': 780, 'w': 86, 'h': 32, 'confidence': '0.9951865152954574', 'text': '21 if'}, {'x': 120, 'y': 784, 'w': 58, 'h': 32, 'confidence': '0.9977714186613993', 'text': 'you'}, {'x': 188, 'y': 780, 'w': 58, 'h': 32, 'confidence': '0.9999960081211735', 'text': 'don'}, {'x': 255, 'y': 783, 'w': 20, 'h': 26, 'confidence': '0.999456837044054', 'text': 't'}, {'x': 288, 'y': 780, 'w': 92, 'h': 32, 'confidence': '0.9999993069437767', 'text': 'think'}, {'x': 390, 'y': 784, 'w': 56, 'h': 32, 'confidence': '0.9999980728858172', 'text': 'any'}, {'x': 456, 'y': 780, 'w': 210, 'h': 32, 'confidence': '0.9999402542535866', 'text': 'modifications'}, {'x': 676, 'y': 784, 'w': 56, 'h': 26, 'confidence': '0.999999449395897', 'text': 'are'}, {'x': 744, 'y': 780, 'w': 114, 'h': 32, 'confidence': '0.9514048178787258', 'text': 'needed _'}, {'x': 24, 'y': 820, 'w': 40, 'h': 30, 'confidence': '0.9999996628252286', 'text': '22'}, {'x': 24, 'y': 856, 'w': 40, 'h': 32, 'confidence': '0.9999998314126102', 'text': '23'}, {'x': 71, 'y': 863, 'w': 36, 'h': 20, 'confidence': '0.9265847643943098', 'text': '<<'}, {'x': 120, 'y': 856, 'w': 158, 'h': 32, 'confidence': '0.9997614479842771', 'text': 'CANDIDATE'}, {'x': 290, 'y': 856, 'w': 124, 'h': 32, 'confidence': '0.9998742437050842', 'text': 'PROMPTS'}, {'x': 422, 'y': 860, 'w': 38, 'h': 24, 'confidence': '0.4718257870331991', 'text': '>>'}, {'x': 24, 'y': 894, 'w': 288, 'h': 32, 'confidence': '0.9989738655340461', 'text': '24 {destinations}'}, {'x': 24, 'y': 934, 'w': 40, 'h': 30, 'confidence': '1.0', 'text': '25'}, {'x': 24, 'y': 970, 'w': 40, 'h': 32, 'confidence': '0.9999651025877826', 'text': '26'}, {'x': 71, 'y': 975, 'w': 36, 'h': 20, 'confidence': '0.48981471711641794', 'text': '4<'}, {'x': 122, 'y': 970, 'w': 90, 'h': 32, 'confidence': '0.9995112213450511', 'text': 'INPUT'}, {'x': 220, 'y': 974, 'w': 38, 'h': 24, 'confidence': '0.48452510844890173', 'text': '>>'}, {'x': 23, 'y': 1005, 'w': 206, 'h': 40, 'confidence': '0.9350699721933363', 'text': '27 {{input}}'}, {'x': 24, 'y': 1046, 'w': 40, 'h': 32, 'confidence': '0.9162513783436457', 'text': '28'}, {'x': 847, 'y': 1087, 'w': 34, 'h': 14, 'confidence': '0.21814212024436586', 'text': 'M'}, {'x': 24, 'y': 1086, 'w': 40, 'h': 30, 'confidence': '0.9999993256504904', 'text': '29'}, {'x': 70, 'y': 1088, 'w': 38, 'h': 24, 'confidence': '0.8299528221894068', 'text': '<<'}, {'x': 120, 'y': 1084, 'w': 108, 'h': 32, 'confidence': '0.9909467870744301', 'text': 'OUTPUT'}, {'x': 242, 'y': 1084, 'w': 154, 'h': 32, 'confidence': '0.9999621705610137', 'text': '(remember'}, {'x': 406, 'y': 1086, 'w': 40, 'h': 30, 'confidence': '0.9999575162410229', 'text': 'to'}, {'x': 458, 'y': 1084, 'w': 124, 'h': 32, 'confidence': '0.8853928698987661', 'text': 'include'}, {'x': 592, 'y': 1084, 'w': 58, 'h': 32, 'confidence': '0.9999929798007293', 'text': 'the'}, {'x': 707, 'y': 1085, 'w': 126, 'h': 36, 'confidence': '0.6012241321712121', 'text': 'json)>>'}]}]\n",
      "> Image for page 152: [{'name': 'img_p151_1.png', 'height': 1020, 'width': 1346, 'x': 142.82185496399998, 'y': 63.844490232, 'original_width': 1346, 'original_height': 1020, 'ocr': [{'x': 25, 'y': 11, 'w': 286, 'h': 40, 'confidence': '0.9136351645841356', 'text': '1 router_template'}, {'x': 353, 'y': 14, 'w': 94, 'h': 31, 'confidence': '0.9998408088275503', 'text': 'MULTI'}, {'x': 458, 'y': 14, 'w': 106, 'h': 31, 'confidence': '0.9998253307491114', 'text': 'PROMPT'}, {'x': 574, 'y': 14, 'w': 392, 'h': 32, 'confidence': '0.7846678536720922', 'text': 'ROUTER_TEMPLATE. format ('}, {'x': 23, 'y': 55, 'w': 20, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 117, 'y': 44, 'w': 499, 'h': 48, 'confidence': '0.9816619403417007', 'text': 'destinations-destinations_str'}, {'x': 22, 'y': 92, 'w': 24, 'h': 28, 'confidence': '0.9999997615814351', 'text': '3'}, {'x': 25, 'y': 131, 'w': 18, 'h': 24, 'confidence': '0.999999880790714', 'text': '4'}, {'x': 52, 'y': 126, 'w': 225, 'h': 42, 'confidence': '0.9210108316233047', 'text': 'router_prompt'}, {'x': 321, 'y': 127, 'w': 260, 'h': 38, 'confidence': '0.877563434112119', 'text': 'PromptTemplate('}, {'x': 23, 'y': 167, 'w': 20, 'h': 28, 'confidence': '0.9999997615814351', 'text': '5'}, {'x': 119, 'y': 161, 'w': 416, 'h': 44, 'confidence': '0.7732599116281021', 'text': 'template-router_template_'}, {'x': 23, 'y': 205, 'w': 20, 'h': 28, 'confidence': '0.40650106129206115', 'text': '6'}, {'x': 118, 'y': 202, 'w': 433, 'h': 42, 'confidence': '0.565341008276329', 'text': 'input_variables= [\"input\"] ='}, {'x': 23, 'y': 243, 'w': 20, 'h': 26, 'confidence': '0.9999997615814351', 'text': '7'}, {'x': 119, 'y': 241, 'w': 594, 'h': 40, 'confidence': '0.6812172155992895', 'text': 'output_parser-RouterOutputParser( ) ,'}, {'x': 23, 'y': 281, 'w': 20, 'h': 28, 'confidence': '0.49340320333642423', 'text': '8'}, {'x': 23, 'y': 319, 'w': 20, 'h': 28, 'confidence': '0.999988794358174', 'text': '9'}, {'x': 7, 'y': 352, 'w': 254, 'h': 43, 'confidence': '0.966802014458043', 'text': '10 router_chain'}, {'x': 304, 'y': 356, 'w': 330, 'h': 32, 'confidence': '0.8420112131665408', 'text': 'LLMRouterChain. from'}, {'x': 642, 'y': 350, 'w': 392, 'h': 48, 'confidence': '0.3514885318703601', 'text': 'LZm( LZm, router_prompt)'}, {'x': 26, 'y': 458, 'w': 116, 'h': 32, 'confidence': '0.9488846462613023', 'text': '1 chain'}, {'x': 185, 'y': 454, 'w': 730, 'h': 43, 'confidence': '0.9874954509636317', 'text': 'MultiPromptChain(router_chain-router_chain,'}, {'x': 23, 'y': 497, 'w': 20, 'h': 28, 'confidence': '0.7075345423453503', 'text': '2'}, {'x': 472, 'y': 490, 'w': 635, 'h': 45, 'confidence': '0.9969594771700998', 'text': 'destination_chains-destination_chains'}, {'x': 23, 'y': 533, 'w': 20, 'h': 30, 'confidence': '0.6643366135947851', 'text': '3'}, {'x': 470, 'y': 526, 'w': 480, 'h': 49, 'confidence': '0.9984374479581959', 'text': 'default_chain-default_chain,'}, {'x': 962, 'y': 534, 'w': 208, 'h': 32, 'confidence': '0.9930870408611436', 'text': 'verbose-True'}, {'x': 25, 'y': 575, 'w': 18, 'h': 24, 'confidence': '0.999999880790714', 'text': '4'}, {'x': 26, 'y': 673, 'w': 284, 'h': 33, 'confidence': '0.510564034801679', 'text': '1 chain. run ( \"What'}, {'x': 321, 'y': 672, 'w': 223, 'h': 40, 'confidence': '0.9035852138202345', 'text': 'is gravity?\" )'}, {'x': 24, 'y': 776, 'w': 286, 'h': 32, 'confidence': '0.5007265706375837', 'text': '1 chain.run ( \"what'}, {'x': 322, 'y': 776, 'w': 38, 'h': 32, 'confidence': '0.9934893109151929', 'text': 'is'}, {'x': 373, 'y': 777, 'w': 20, 'h': 28, 'confidence': '0.999999880790714', 'text': '2'}, {'x': 404, 'y': 780, 'w': 24, 'h': 24, 'confidence': '0.968396586317656', 'text': '+'}, {'x': 438, 'y': 776, 'w': 56, 'h': 32, 'confidence': '0.5855049560434954', 'text': '2\" )'}, {'x': 25, 'y': 877, 'w': 286, 'h': 36, 'confidence': '0.6974431463692159', 'text': '1 chain. run (\"what'}, {'x': 322, 'y': 878, 'w': 38, 'h': 32, 'confidence': '0.9943146678000975', 'text': 'is'}, {'x': 373, 'y': 885, 'w': 18, 'h': 22, 'confidence': '0.9998807942631629', 'text': 'a'}, {'x': 406, 'y': 878, 'w': 104, 'h': 32, 'confidence': '0.7211475908037214', 'text': 'DNA?\" )'}, {'x': 26, 'y': 980, 'w': 266, 'h': 32, 'confidence': '0.7138607045431786', 'text': '1 chain.run (\"who'}, {'x': 306, 'y': 980, 'w': 38, 'h': 32, 'confidence': '0.9912534679305236', 'text': 'is'}, {'x': 354, 'y': 980, 'w': 154, 'h': 32, 'confidence': '0.5877309905833917', 'text': 'Alfred?\" )'}]}]\n",
      "> Image for page 153: [{'name': 'img_p152_1.png', 'height': 168, 'width': 1454, 'x': 12.000000384, 'y': 63.844478420976, 'original_width': 1454, 'original_height': 168, 'ocr': [{'x': 31, 'y': 29, 'w': 910, 'h': 40, 'confidence': '0.5115024443997106', 'text': '1 from Langchain. chains. router import MultiPromptChain'}, {'x': 26, 'y': 62, 'w': 1388, 'h': 49, 'confidence': '0.5333664444776195', 'text': '2 from Langchain.chains. router. llm_router import LLMRouterChain,RouteroutputParser'}, {'x': 27, 'y': 103, 'w': 781, 'h': 43, 'confidence': '0.635313009209832', 'text': '3 from Langchain.prompts import PromptTemplate'}]}]\n",
      "> Image for page 154: []\n",
      "> Image for page 155: []\n",
      "> Image for page 156: [{'name': 'img_p155_1.png', 'height': 984, 'width': 1854, 'x': 112.00000358399998, 'y': 123.872059082016, 'original_width': 1854, 'original_height': 984, 'ocr': [{'x': 27, 'y': 28, 'w': 223, 'h': 84, 'confidence': '0.9998303594698091', 'text': 'Tools'}, {'x': 131, 'y': 235, 'w': 249, 'h': 50, 'confidence': '0.5551409271357458', 'text': 'Alpha Vantage'}, {'x': 1028, 'y': 236, 'w': 98, 'h': 48, 'confidence': '0.9347311282940667', 'text': 'Apify'}, {'x': 90, 'y': 311, 'w': 420, 'h': 32, 'confidence': '0.9873778030021455', 'text': 'Alpha Vantage Alpha Vantage provides'}, {'x': 986, 'y': 314, 'w': 470, 'h': 30, 'confidence': '0.6994355081322035', 'text': 'This notebook shows how to use the [Apify'}, {'x': 133, 'y': 525, 'w': 96, 'h': 36, 'confidence': '0.9958278393797466', 'text': 'ArXiv'}, {'x': 1031, 'y': 525, 'w': 224, 'h': 38, 'confidence': '0.8887843586422096', 'text': 'AWS Lambda'}, {'x': 90, 'y': 596, 'w': 692, 'h': 33, 'confidence': '0.8355894548632724', 'text': 'This notebook goes over how to use the arxiv tool with an agent'}, {'x': 987, 'y': 596, 'w': 285, 'h': 31, 'confidence': '0.9408830658379144', 'text': 'Amazon AWS Lambda is a'}, {'x': 129, 'y': 807, 'w': 206, 'h': 44, 'confidence': '0.9928872701260952', 'text': 'Shell (bash)'}, {'x': 1029, 'y': 809, 'w': 394, 'h': 44, 'confidence': '0.9992467201332871', 'text': 'Bearly Code Interpreter'}, {'x': 88, 'y': 883, 'w': 712, 'h': 31, 'confidence': '0.6249977001696158', 'text': 'Giving agents access to the shell is powerful (though risky outsid.'}, {'x': 987, 'y': 883, 'w': 705, 'h': 29, 'confidence': '0.7689777972622083', 'text': 'Bearly Code Interpreter allows for remote execution of code. This'}]}]\n",
      "> Image for page 157: []\n",
      "> Image for page 158: [{'name': 'img_p157_1.png', 'height': 213, 'width': 569, 'x': 169.52951329895998, 'y': 210.812998872, 'original_width': 569, 'original_height': 213, 'ocr': [{'x': 8, 'y': 20, 'w': 82, 'h': 24, 'confidence': '0.9156049328630868', 'text': 'REAct:'}, {'x': 98, 'y': 18, 'w': 324, 'h': 26, 'confidence': '0.789497527729165', 'text': 'SYNERGIZING REASONING AND'}, {'x': 428, 'y': 20, 'w': 112, 'h': 24, 'confidence': '0.8967140889924512', 'text': 'ACTING IN'}, {'x': 6, 'y': 46, 'w': 212, 'h': 24, 'confidence': '0.9513899535539027', 'text': 'LANGUAGE MODELS'}, {'x': 9, 'y': 101, 'w': 78, 'h': 16, 'confidence': '0.5893546117045404', 'text': 'Shunyu Yao  '}, {'x': 91, 'y': 101, 'w': 74, 'h': 16, 'confidence': '0.7134626216423935', 'text': 'Jeffrey Zhao\"_'}, {'x': 169, 'y': 101, 'w': 104, 'h': 16, 'confidence': '0.5889764006693753', 'text': 'Dian Yu\" . Nan Du\"'}, {'x': 277, 'y': 101, 'w': 196, 'h': 16, 'confidence': '0.5287776156665067', 'text': 'Izhak Shafran\" . Karthik Narasimhan\\\\\\''}, {'x': 481, 'y': 101, 'w': 60, 'h': 16, 'confidence': '0.534300801053626', 'text': 'Yuan Cao-'}, {'x': 127, 'y': 131, 'w': 82, 'h': 14, 'confidence': '0.9985075987700339', 'text': 'Department of'}, {'x': 208, 'y': 128, 'w': 219, 'h': 20, 'confidence': '0.9335265468861952', 'text': 'Computer Science, Princeton University'}, {'x': 196, 'y': 144, 'w': 161, 'h': 18, 'confidence': '0.701200044854362', 'text': 'Google Research. Brain team'}, {'x': 148, 'y': 158, 'w': 139, 'h': 18, 'confidence': '0.8414413585095724', 'text': '{shunyuy, karthikn'}, {'x': 291, 'y': 161, 'w': 84, 'h': 14, 'confidence': '0.9280019425017306', 'text': '@princeton'}, {'x': 379, 'y': 161, 'w': 28, 'h': 14, 'confidence': '0.9988535926404846', 'text': 'edu'}, {'x': 65, 'y': 173, 'w': 106, 'h': 18, 'confidence': '0.6829701587400602', 'text': '2{jeffreyzhao'}, {'x': 175, 'y': 175, 'w': 52, 'h': 14, 'confidence': '0.9999824798495865', 'text': 'dianyu'}, {'x': 231, 'y': 177, 'w': 44, 'h': 12, 'confidence': '0.9734420345292103', 'text': 'cunan'}, {'x': 279, 'y': 174, 'w': 162, 'h': 17, 'confidence': '0.5336750108556055', 'text': 'izhak,Yuancao| @googl'}, {'x': 455, 'y': 177, 'w': 28, 'h': 12, 'confidence': '0.9882874880990168', 'text': 'com'}]}]\n",
      "> Image for page 159: [{'name': 'img_p158_1.png', 'height': 552, 'width': 2048, 'x': 68.66337227596799, 'y': 190.29134467199998, 'original_width': 2048, 'original_height': 552, 'ocr': [{'x': 736, 'y': 63, 'w': 129, 'h': 43, 'confidence': '0.9999912589536624', 'text': 'Actions'}, {'x': 1769, 'y': 64, 'w': 131, 'h': 45, 'confidence': '0.9999916644666671', 'text': 'Actions'}, {'x': 305, 'y': 186, 'w': 187, 'h': 60, 'confidence': '0.9999823172105461', 'text': 'Reasoning'}, {'x': 1321, 'y': 169, 'w': 181, 'h': 53, 'confidence': '0.9999698398223335', 'text': 'Reasoning'}, {'x': 89, 'y': 221, 'w': 62, 'h': 42, 'confidence': '0.999933324336724', 'text': 'LM'}, {'x': 615, 'y': 215, 'w': 62, 'h': 42, 'confidence': '0.9999860072749682', 'text': 'LM'}, {'x': 887, 'y': 215, 'w': 76, 'h': 42, 'confidence': '0.9999717815920222', 'text': 'Env'}, {'x': 1353, 'y': 227, 'w': 115, 'h': 45, 'confidence': '0.9999207694370205', 'text': 'Traces'}, {'x': 1649, 'y': 215, 'w': 64, 'h': 42, 'confidence': '0.9999803596250854', 'text': 'LM'}, {'x': 1921, 'y': 215, 'w': 76, 'h': 42, 'confidence': '0.9999690974075516', 'text': 'Env'}, {'x': 338, 'y': 248, 'w': 119, 'h': 48, 'confidence': '0.9999404312071191', 'text': 'Traces'}, {'x': 687, 'y': 367, 'w': 226, 'h': 42, 'confidence': '0.7985380094891794', 'text': 'Observations'}, {'x': 1721, 'y': 364, 'w': 227, 'h': 48, 'confidence': '0.9999578781351443', 'text': 'Observations'}, {'x': 38, 'y': 446, 'w': 470, 'h': 51, 'confidence': '0.8395054241639154', 'text': 'Reason Only (eg: Chain-of-thought)'}, {'x': 600, 'y': 448, 'w': 398, 'h': 53, 'confidence': '0.7691791979943421', 'text': 'Act Only (eg: SayCan; WebGPT)'}, {'x': 1595, 'y': 453, 'w': 212, 'h': 42, 'confidence': '0.7180182481646733', 'text': 'ReAct (Reason'}, {'x': 1828, 'y': 462, 'w': 56, 'h': 32, 'confidence': '0.9990400671958923', 'text': 'Act)'}]}]\n",
      "> Image for page 160: [{'name': 'img_p159_1.png', 'height': 563, 'width': 1603, 'x': 10.285432415748, 'y': 95.77166448201598, 'original_width': 1603, 'original_height': 563, 'ocr': [{'x': 15, 'y': 20, 'w': 257, 'h': 31, 'confidence': '0.9207958424034691', 'text': 'agent.run( \"What year'}, {'x': 278, 'y': 20, 'w': 868, 'h': 32, 'confidence': '0.5130399482205865', 'text': 'Was Albert Einstein born? What is that year number multiplied by 5?\")'}, {'x': 42, 'y': 128, 'w': 106, 'h': 30, 'confidence': '0.9999930036130095', 'text': 'Entering'}, {'x': 155, 'y': 133, 'w': 42, 'h': 20, 'confidence': '0.9970639310143556', 'text': 'new'}, {'x': 216, 'y': 128, 'w': 74, 'h': 26, 'confidence': '0.902931314722368', 'text': 'chain_'}, {'x': 43, 'y': 163, 'w': 40, 'h': 20, 'confidence': '0.9999993117448777', 'text': 'can'}, {'x': 93, 'y': 163, 'w': 40, 'h': 20, 'confidence': '0.999989263227318', 'text': 'use'}, {'x': 142, 'y': 158, 'w': 42, 'h': 26, 'confidence': '0.9999997935234566', 'text': 'the'}, {'x': 192, 'y': 158, 'w': 142, 'h': 26, 'confidence': '0.9994671865947673', 'text': 'search tool'}, {'x': 342, 'y': 158, 'w': 144, 'h': 26, 'confidence': '0.9479304523818497', 'text': 'to find the'}, {'x': 554, 'y': 158, 'w': 194, 'h': 26, 'confidence': '0.9882173479853931', 'text': 'Albert Einstein'}, {'x': 754, 'y': 157, 'w': 117, 'h': 28, 'confidence': '0.9792070714674616', 'text': 'was born.'}, {'x': 878, 'y': 158, 'w': 58, 'h': 26, 'confidence': '0.9999690055847168', 'text': 'Then'}, {'x': 967, 'y': 163, 'w': 42, 'h': 20, 'confidence': '0.9999949069135972', 'text': 'can'}, {'x': 1017, 'y': 163, 'w': 42, 'h': 20, 'confidence': '0.9999854090049941', 'text': 'use'}, {'x': 1066, 'y': 160, 'w': 44, 'h': 24, 'confidence': '0.9999972469798912', 'text': 'the'}, {'x': 1118, 'y': 158, 'w': 130, 'h': 26, 'confidence': '0.9999885399864927', 'text': 'calculator'}, {'x': 1254, 'y': 156, 'w': 334, 'h': 33, 'confidence': '0.9410257901182012', 'text': 'to multiply that year by 5'}, {'x': 16, 'y': 188, 'w': 92, 'h': 26, 'confidence': '0.9975948757729952', 'text': 'Action:'}, {'x': 116, 'y': 188, 'w': 82, 'h': 26, 'confidence': '0.9999910452650745', 'text': 'Search'}, {'x': 16, 'y': 218, 'w': 166, 'h': 28, 'confidence': '0.9982903289979144', 'text': 'Action Input:'}, {'x': 192, 'y': 218, 'w': 92, 'h': 24, 'confidence': '0.9999261508992932', 'text': '\"Albert'}, {'x': 292, 'y': 218, 'w': 106, 'h': 24, 'confidence': '0.9998922702515367', 'text': 'Einstein'}, {'x': 404, 'y': 218, 'w': 133, 'h': 29, 'confidence': '0.6892365345189067', 'text': 'birth year\"'}, {'x': 16, 'y': 248, 'w': 153, 'h': 24, 'confidence': '0.8029225605038648', 'text': 'Observation:'}, {'x': 178, 'y': 248, 'w': 118, 'h': 28, 'confidence': '0.9918303902746697', 'text': 'March 14,'}, {'x': 304, 'y': 248, 'w': 56, 'h': 24, 'confidence': '0.8769963660137363', 'text': '1879'}, {'x': 18, 'y': 278, 'w': 92, 'h': 28, 'confidence': '0.9996509697679128', 'text': 'Thought'}, {'x': 118, 'y': 278, 'w': 44, 'h': 24, 'confidence': '0.9943642212763517', 'text': 'Now'}, {'x': 193, 'y': 283, 'w': 40, 'h': 18, 'confidence': '0.9999975911073493', 'text': 'can'}, {'x': 243, 'y': 283, 'w': 40, 'h': 18, 'confidence': '0.9999610448599316', 'text': 'use'}, {'x': 292, 'y': 278, 'w': 42, 'h': 24, 'confidence': '0.9999993117448777', 'text': 'the'}, {'x': 341, 'y': 277, 'w': 130, 'h': 24, 'confidence': '0.9999914803919744', 'text': 'calculator'}, {'x': 478, 'y': 278, 'w': 144, 'h': 30, 'confidence': '0.9917361905993094', 'text': 'to multiply'}, {'x': 628, 'y': 278, 'w': 94, 'h': 28, 'confidence': '0.6719470722695688', 'text': '1879 by'}, {'x': 728, 'y': 278, 'w': 30, 'h': 24, 'confidence': '0.6336201766926226', 'text': '5 .'}, {'x': 16, 'y': 308, 'w': 92, 'h': 24, 'confidence': '0.9999731910425704', 'text': 'Action:'}, {'x': 116, 'y': 307, 'w': 132, 'h': 24, 'confidence': '0.9999883891963325', 'text': 'Calculator'}, {'x': 16, 'y': 338, 'w': 166, 'h': 28, 'confidence': '0.9991890161296948', 'text': 'Action Input:'}, {'x': 192, 'y': 338, 'w': 56, 'h': 24, 'confidence': '0.999998927116394', 'text': '1879'}, {'x': 15, 'y': 365, 'w': 155, 'h': 29, 'confidence': '0.9996837101387306', 'text': 'Observation:'}, {'x': 177, 'y': 367, 'w': 92, 'h': 24, 'confidence': '0.9998712247703154', 'text': 'Answer:'}, {'x': 278, 'y': 366, 'w': 56, 'h': 26, 'confidence': '0.9999999403953552', 'text': '9395'}, {'x': 18, 'y': 396, 'w': 116, 'h': 30, 'confidence': '0.998384458821766', 'text': 'Thought:I'}, {'x': 143, 'y': 401, 'w': 42, 'h': 20, 'confidence': '0.962038812528988', 'text': 'now'}, {'x': 192, 'y': 396, 'w': 180, 'h': 26, 'confidence': '0.5357815935188478', 'text': 'know the final'}, {'x': 381, 'y': 401, 'w': 78, 'h': 20, 'confidence': '0.9996187751448113', 'text': 'answer'}, {'x': 16, 'y': 426, 'w': 68, 'h': 26, 'confidence': '0.9999963747822046', 'text': 'Final'}, {'x': 92, 'y': 428, 'w': 90, 'h': 24, 'confidence': '0.9999202933601633', 'text': 'Answer:'}, {'x': 192, 'y': 426, 'w': 192, 'h': 30, 'confidence': '0.8495427790650404', 'text': 'The year Albert'}, {'x': 392, 'y': 428, 'w': 154, 'h': 24, 'confidence': '0.8059253231400834', 'text': 'Einstein was'}, {'x': 554, 'y': 426, 'w': 56, 'h': 26, 'confidence': '0.9999863505363464', 'text': 'born'}, {'x': 616, 'y': 428, 'w': 32, 'h': 24, 'confidence': '0.9785275741266565', 'text': 'is'}, {'x': 654, 'y': 428, 'w': 66, 'h': 24, 'confidence': '0.9465394449639147', 'text': '1879 .'}, {'x': 728, 'y': 426, 'w': 268, 'h': 30, 'confidence': '0.9483465050803934', 'text': 'When multiplied by 5,'}, {'x': 1004, 'y': 426, 'w': 132, 'h': 26, 'confidence': '0.96631221006968', 'text': 'the result'}, {'x': 1142, 'y': 428, 'w': 30, 'h': 24, 'confidence': '0.9876568828661667', 'text': 'is'}, {'x': 1178, 'y': 428, 'w': 60, 'h': 24, 'confidence': '0.7980691808187111', 'text': '9395 _'}, {'x': 42, 'y': 486, 'w': 106, 'h': 24, 'confidence': '0.9999959960460711', 'text': 'Finished'}, {'x': 154, 'y': 486, 'w': 78, 'h': 24, 'confidence': '0.9999451032981284', 'text': 'chain.'}, {'x': 30, 'y': 526, 'w': 104, 'h': 28, 'confidence': '0.9887240948910122', 'text': 'The year'}, {'x': 142, 'y': 526, 'w': 80, 'h': 24, 'confidence': '0.9998597798267034', 'text': 'Albert'}, {'x': 230, 'y': 526, 'w': 104, 'h': 24, 'confidence': '0.9998543360970353', 'text': 'Einstein'}, {'x': 341, 'y': 531, 'w': 42, 'h': 18, 'confidence': '0.5569432377815247', 'text': 'was'}, {'x': 392, 'y': 526, 'w': 56, 'h': 24, 'confidence': '0.9999783039093018', 'text': 'born'}, {'x': 454, 'y': 526, 'w': 30, 'h': 24, 'confidence': '0.9917111304280332', 'text': 'is'}, {'x': 492, 'y': 526, 'w': 58, 'h': 24, 'confidence': '0.7103430275326291', 'text': '1879_'}, {'x': 566, 'y': 526, 'w': 194, 'h': 28, 'confidence': '0.9749978935220459', 'text': 'When multiplied'}, {'x': 768, 'y': 526, 'w': 64, 'h': 28, 'confidence': '0.9973718961512379', 'text': 'by 5,'}, {'x': 842, 'y': 526, 'w': 44, 'h': 24, 'confidence': '0.9999958704702177', 'text': 'the'}, {'x': 892, 'y': 526, 'w': 80, 'h': 24, 'confidence': '0.9999956199688642', 'text': 'result'}, {'x': 980, 'y': 526, 'w': 30, 'h': 24, 'confidence': '0.9911782197784186', 'text': 'is'}, {'x': 1016, 'y': 526, 'w': 60, 'h': 24, 'confidence': '0.9673287910923813', 'text': '9395 _'}, {'x': 487, 'y': 163, 'w': 61, 'h': 18, 'confidence': '0.9995980262756348', 'text': 'year'}]}]\n",
      "> Image for page 161: [{'name': 'img_p160_1.png', 'height': 1092, 'width': 1470, 'x': 133.909453104, 'y': 51.118111871999986, 'original_width': 1470, 'original_height': 1092, 'ocr': [{'x': 52, 'y': 4, 'w': 560, 'h': 54, 'confidence': '0.5365453934541004', 'text': 'Create Agent (Math; Wikipedia)'}, {'x': 1, 'y': 133, 'w': 70, 'h': 36, 'confidence': '0.7977982631064641', 'text': '158]'}, {'x': 93, 'y': 135, 'w': 60, 'h': 38, 'confidence': '0.9999944939607979', 'text': 'pip'}, {'x': 163, 'y': 133, 'w': 124, 'h': 36, 'confidence': '0.9997560975243629', 'text': 'install'}, {'x': 297, 'y': 132, 'w': 207, 'h': 40, 'confidence': '0.9556116310174287', 'text': '~U wikipedia'}, {'x': 93, 'y': 173, 'w': 60, 'h': 38, 'confidence': '0.9999907773866326', 'text': 'pip'}, {'x': 164, 'y': 174, 'w': 122, 'h': 32, 'confidence': '0.9998293198494229', 'text': 'install'}, {'x': 299, 'y': 169, 'w': 376, 'h': 43, 'confidence': '0.6099799177956319', 'text': 'langchain_experimental'}, {'x': 1, 'y': 273, 'w': 438, 'h': 40, 'confidence': '0.7540246350119977', 'text': '159] from Langchain.agents'}, {'x': 449, 'y': 275, 'w': 108, 'h': 38, 'confidence': '0.9998570140897617', 'text': 'import'}, {'x': 567, 'y': 273, 'w': 188, 'h': 38, 'confidence': '0.4515087084534814', 'text': 'Load_tools,'}, {'x': 769, 'y': 272, 'w': 277, 'h': 42, 'confidence': '0.9996992330780357', 'text': 'initialize_agent'}, {'x': 75, 'y': 309, 'w': 650, 'h': 43, 'confidence': '0.5690603667042655', 'text': 'from Langchain.agents import AgentType'}, {'x': 80, 'y': 414, 'w': 56, 'h': 32, 'confidence': '0.37191076297397085', 'text': 'Um'}, {'x': 178, 'y': 410, 'w': 883, 'h': 43, 'confidence': '0.5299652989140676', 'text': 'ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\")'}, {'x': 78, 'y': 454, 'w': 90, 'h': 32, 'confidence': '0.9999349057796136', 'text': 'tools'}, {'x': 213, 'y': 453, 'w': 176, 'h': 38, 'confidence': '0.7004062284982056', 'text': 'Zoad_tools'}, {'x': 401, 'y': 451, 'w': 410, 'h': 40, 'confidence': '0.6569233022960539', 'text': '[\"Im-math\" , \"wikipedia\"] _'}, {'x': 838, 'y': 454, 'w': 136, 'h': 32, 'confidence': '0.20620771302401156', 'text': '1lm=llm)'}, {'x': 75, 'y': 492, 'w': 108, 'h': 32, 'confidence': '0.9996327437456092', 'text': '#tools'}, {'x': 229, 'y': 489, 'w': 414, 'h': 40, 'confidence': '0.39710393481326306', 'text': 'load_tools ( [\"wikipedia\"]_'}, {'x': 667, 'y': 489, 'w': 140, 'h': 36, 'confidence': '0.14355918830452488', 'text': 'Ulm-LLm)'}, {'x': 75, 'y': 526, 'w': 95, 'h': 43, 'confidence': '0.9999996268158868', 'text': 'agent'}, {'x': 212, 'y': 525, 'w': 293, 'h': 43, 'confidence': '0.8915621756132155', 'text': 'initialize_agent ('}, {'x': 144, 'y': 564, 'w': 105, 'h': 39, 'confidence': '0.999333017588071', 'text': 'tools,'}, {'x': 145, 'y': 602, 'w': 72, 'h': 39, 'confidence': '0.43733248114585876', 'text': '1Zm,'}, {'x': 143, 'y': 642, 'w': 822, 'h': 39, 'confidence': '0.9489866379820548', 'text': 'agent-AgentType. CHAT_ZERO_SHOT_REACT_DESCRIPTION'}, {'x': 144, 'y': 678, 'w': 459, 'h': 43, 'confidence': '0.88313173550493', 'text': 'handle_parsing_errors-True,'}, {'x': 146, 'y': 720, 'w': 124, 'h': 32, 'confidence': '0.9998008872629849', 'text': 'verbose'}, {'x': 314, 'y': 720, 'w': 86, 'h': 32, 'confidence': '0.8145551013271621', 'text': 'True)'}, {'x': 1, 'y': 819, 'w': 268, 'h': 41, 'confidence': '0.9360393022188633', 'text': '162] agent ( \"What'}, {'x': 282, 'y': 822, 'w': 38, 'h': 32, 'confidence': '0.9751540238055281', 'text': 'is'}, {'x': 330, 'y': 820, 'w': 58, 'h': 32, 'confidence': '0.999999449395897', 'text': 'the'}, {'x': 397, 'y': 819, 'w': 224, 'h': 36, 'confidence': '0.7793888578622484', 'text': '25% of 3002\" )'}, {'x': 1, 'y': 921, 'w': 218, 'h': 38, 'confidence': '0.9999631675985834', 'text': '163] question'}, {'x': 259, 'y': 919, 'w': 79, 'h': 38, 'confidence': '0.9997932314872742', 'text': '\"Tom'}, {'x': 346, 'y': 924, 'w': 36, 'h': 30, 'confidence': '0.9060205018593731', 'text': 'M.'}, {'x': 395, 'y': 921, 'w': 146, 'h': 36, 'confidence': '0.9997561681674594', 'text': 'Mitchell'}, {'x': 550, 'y': 924, 'w': 38, 'h': 32, 'confidence': '0.9861615631278149', 'text': 'is'}, {'x': 600, 'y': 926, 'w': 40, 'h': 30, 'confidence': '0.9999987355947788', 'text': 'an'}, {'x': 651, 'y': 921, 'w': 462, 'h': 41, 'confidence': '0.8331983192322291', 'text': 'American computer scientist'}, {'x': 77, 'y': 959, 'w': 58, 'h': 36, 'confidence': '0.9999992429193688', 'text': 'and'}, {'x': 145, 'y': 959, 'w': 58, 'h': 36, 'confidence': '0.9999988987918347', 'text': 'the'}, {'x': 213, 'y': 955, 'w': 496, 'h': 44, 'confidence': '0.8638601096173262', 'text': 'Founders University Professor'}, {'x': 717, 'y': 955, 'w': 498, 'h': 44, 'confidence': '0.9952784904707718', 'text': 'at Carnegie Mellon University'}, {'x': 1225, 'y': 959, 'w': 104, 'h': 36, 'confidence': '0.979613428716687', 'text': '(CMU) |'}, {'x': 78, 'y': 1000, 'w': 72, 'h': 32, 'confidence': '0.999915599822998', 'text': 'what'}, {'x': 161, 'y': 997, 'w': 142, 'h': 36, 'confidence': '0.98946254163417', 'text': 'book did'}, {'x': 313, 'y': 997, 'w': 176, 'h': 36, 'confidence': '0.9965775008183257', 'text': 'he write?\"'}, {'x': 80, 'y': 1038, 'w': 104, 'h': 32, 'confidence': '0.9999720650608137', 'text': 'result'}, {'x': 228, 'y': 1036, 'w': 259, 'h': 40, 'confidence': '0.9026993550366859', 'text': 'agent (question)'}]}]\n",
      "> Image for page 162: [{'name': 'img_p161_1.png', 'height': 730, 'width': 1500, 'x': 27.647638679999996, 'y': 63.218505960000016, 'original_width': 1500, 'original_height': 730, 'ocr': [{'x': 38, 'y': 45, 'w': 143, 'h': 44, 'confidence': '0.9999948580790059', 'text': 'Entering'}, {'x': 191, 'y': 49, 'w': 398, 'h': 40, 'confidence': '0.603617004642151', 'text': 'new AgentExecutor chain '}, {'x': 7, 'y': 85, 'w': 138, 'h': 38, 'confidence': '0.9997774122313973', 'text': 'Thought:'}, {'x': 156, 'y': 88, 'w': 42, 'h': 30, 'confidence': '0.9999052551991905', 'text': 'We'}, {'x': 208, 'y': 86, 'w': 74, 'h': 32, 'confidence': '0.9999971389770508', 'text': 'need'}, {'x': 292, 'y': 88, 'w': 40, 'h': 30, 'confidence': '0.9999726046583781', 'text': 'to'}, {'x': 344, 'y': 86, 'w': 158, 'h': 32, 'confidence': '0.9999759990523585', 'text': 'calculate'}, {'x': 511, 'y': 85, 'w': 190, 'h': 38, 'confidence': '0.48148946923087194', 'text': '25% of 300 ,'}, {'x': 710, 'y': 82, 'w': 94, 'h': 36, 'confidence': '0.9992152107826353', 'text': 'which'}, {'x': 814, 'y': 89, 'w': 90, 'h': 28, 'confidence': '0.9987833324248268', 'text': 'means'}, {'x': 916, 'y': 90, 'w': 40, 'h': 28, 'confidence': '0.9895837729449877', 'text': 'we'}, {'x': 966, 'y': 86, 'w': 76, 'h': 32, 'confidence': '0.9999945163726807', 'text': 'need'}, {'x': 1051, 'y': 85, 'w': 260, 'h': 40, 'confidence': '0.9258955916795584', 'text': 'to multiply 300'}, {'x': 1321, 'y': 87, 'w': 42, 'h': 36, 'confidence': '0.9999205962607762', 'text': 'by'}, {'x': 1372, 'y': 86, 'w': 86, 'h': 32, 'confidence': '0.527873101572608', 'text': '0. 25 .'}, {'x': 5, 'y': 152, 'w': 121, 'h': 36, 'confidence': '0.9999674687644614', 'text': 'Action:'}, {'x': 39, 'y': 257, 'w': 154, 'h': 36, 'confidence': '0.48405479718973793', 'text': '\"action\" :'}, {'x': 207, 'y': 256, 'w': 210, 'h': 36, 'confidence': '0.6901297793714878', 'text': '\"Calculator\" '}, {'x': 37, 'y': 287, 'w': 261, 'h': 50, 'confidence': '0.53137323169126', 'text': '\"action_input\" :'}, {'x': 310, 'y': 294, 'w': 174, 'h': 32, 'confidence': '0.9768223790438374', 'text': '\"300*0.25\"'}, {'x': 6, 'y': 468, 'w': 204, 'h': 32, 'confidence': '0.9998325372561165', 'text': 'Observation:'}, {'x': 224, 'y': 470, 'w': 122, 'h': 30, 'confidence': '0.9998647813623829', 'text': 'Answer:'}, {'x': 360, 'y': 470, 'w': 74, 'h': 30, 'confidence': '0.6367081650479538', 'text': '75 . 0'}, {'x': 7, 'y': 501, 'w': 192, 'h': 40, 'confidence': '0.9813203870202986', 'text': 'Thought: The'}, {'x': 208, 'y': 502, 'w': 176, 'h': 32, 'confidence': '0.9999642249024411', 'text': 'calculator'}, {'x': 394, 'y': 502, 'w': 72, 'h': 32, 'confidence': '0.9990695714950562', 'text': 'tool'}, {'x': 478, 'y': 502, 'w': 142, 'h': 32, 'confidence': '0.9999924557023288', 'text': 'returned'}, {'x': 630, 'y': 502, 'w': 58, 'h': 32, 'confidence': '0.9999991052683532', 'text': 'the'}, {'x': 695, 'y': 506, 'w': 108, 'h': 26, 'confidence': '0.9999817011746336', 'text': 'answer'}, {'x': 813, 'y': 503, 'w': 90, 'h': 36, 'confidence': '0.6790128447741175', 'text': '75.0 ,'}, {'x': 916, 'y': 502, 'w': 92, 'h': 32, 'confidence': '0.9672417590116135', 'text': 'which'}, {'x': 1018, 'y': 502, 'w': 238, 'h': 32, 'confidence': '0.7046783708786825', 'text': 'is 25% of 300 .'}, {'x': 6, 'y': 572, 'w': 90, 'h': 32, 'confidence': '0.9924360127879236', 'text': 'Final'}, {'x': 106, 'y': 574, 'w': 122, 'h': 30, 'confidence': '0.9995749943794346', 'text': 'Answer:'}, {'x': 242, 'y': 572, 'w': 176, 'h': 32, 'confidence': '0.9765358461597542', 'text': '25% of 300'}, {'x': 428, 'y': 572, 'w': 40, 'h': 32, 'confidence': '0.9968332919777119', 'text': 'is'}, {'x': 478, 'y': 574, 'w': 86, 'h': 30, 'confidence': '0.8826995424194025', 'text': '75.0 .'}, {'x': 39, 'y': 639, 'w': 142, 'h': 36, 'confidence': '0.6379563825414184', 'text': 'Finished'}, {'x': 191, 'y': 639, 'w': 96, 'h': 36, 'confidence': '0.6960324043369152', 'text': 'chain _'}, {'x': 5, 'y': 675, 'w': 128, 'h': 38, 'confidence': '0.998750781306112', 'text': \"{'input\"}, {'x': 141, 'y': 683, 'w': 16, 'h': 22, 'confidence': '0.963304399136419', 'text': ':'}, {'x': 190, 'y': 676, 'w': 74, 'h': 32, 'confidence': '0.9723217314971289', 'text': 'What'}, {'x': 278, 'y': 678, 'w': 36, 'h': 30, 'confidence': '0.9732860061593444', 'text': 'is'}, {'x': 326, 'y': 676, 'w': 56, 'h': 32, 'confidence': '0.9999944939607979', 'text': 'the'}, {'x': 394, 'y': 676, 'w': 106, 'h': 32, 'confidence': '0.6522240026624555', 'text': '25% of'}, {'x': 512, 'y': 676, 'w': 88, 'h': 32, 'confidence': '0.6214402471240993', 'text': \"300? '\"}, {'x': 630, 'y': 674, 'w': 125, 'h': 39, 'confidence': '0.9976741463536946', 'text': \"'output\"}, {'x': 814, 'y': 676, 'w': 108, 'h': 32, 'confidence': '0.9463810668104662', 'text': '25% f'}, {'x': 934, 'y': 676, 'w': 56, 'h': 32, 'confidence': '0.9999988987918347', 'text': '300'}, {'x': 1002, 'y': 678, 'w': 38, 'h': 30, 'confidence': '0.9891805102785943', 'text': 'is'}, {'x': 1052, 'y': 678, 'w': 88, 'h': 30, 'confidence': '0.969937417172235', 'text': '75.0 .'}, {'x': 1150, 'y': 676, 'w': 24, 'h': 32, 'confidence': '0.999953508917443', 'text': '}'}]}]\n",
      "> Image for page 163: [{'name': 'img_p162_1.png', 'height': 302, 'width': 1346, 'x': 12.000000384, 'y': 117.05120453303999, 'original_width': 1346, 'original_height': 302, 'ocr': [{'x': 0, 'y': 14, 'w': 344, 'h': 54, 'confidence': '0.7350696014518844', 'text': 'Wikipedia example'}, {'x': 47, 'y': 143, 'w': 170, 'h': 38, 'confidence': '0.999815160272484', 'text': '1 question'}, {'x': 257, 'y': 141, 'w': 124, 'h': 40, 'confidence': '0.7279777335036067', 'text': '\"Tom M.'}, {'x': 393, 'y': 143, 'w': 146, 'h': 36, 'confidence': '0.9997084947957392', 'text': 'Mitchell'}, {'x': 550, 'y': 146, 'w': 38, 'h': 32, 'confidence': '0.9781248827782991', 'text': 'is'}, {'x': 598, 'y': 148, 'w': 40, 'h': 30, 'confidence': '0.9999983141264758', 'text': 'an'}, {'x': 649, 'y': 142, 'w': 462, 'h': 43, 'confidence': '0.9061688061690562', 'text': 'American computer scientist'}, {'x': 45, 'y': 181, 'w': 88, 'h': 36, 'confidence': '0.9961667464951348', 'text': '2 and'}, {'x': 144, 'y': 184, 'w': 56, 'h': 30, 'confidence': '0.999995182215476', 'text': 'the'}, {'x': 211, 'y': 178, 'w': 496, 'h': 43, 'confidence': '0.9508144199611889', 'text': 'Founders University Professor'}, {'x': 715, 'y': 177, 'w': 498, 'h': 45, 'confidence': '0.7696764808310471', 'text': 'at Carnegie Mellon University'}, {'x': 1222, 'y': 180, 'w': 106, 'h': 36, 'confidence': '0.9735286885391089', 'text': '(CMU) |'}, {'x': 48, 'y': 222, 'w': 100, 'h': 32, 'confidence': '0.9914193089452139', 'text': '3 what'}, {'x': 159, 'y': 219, 'w': 142, 'h': 36, 'confidence': '0.9947478093615114', 'text': 'book did'}, {'x': 311, 'y': 217, 'w': 176, 'h': 41, 'confidence': '0.4370062121391865', 'text': 'he write?\"'}, {'x': 50, 'y': 259, 'w': 131, 'h': 32, 'confidence': '0.823896511913336', 'text': '4 result'}, {'x': 226, 'y': 255, 'w': 259, 'h': 43, 'confidence': '0.9964262762595062', 'text': 'agent(question)'}]}]\n",
      "> Image for page 164: [{'name': 'img_p163_1.png', 'height': 1272, 'width': 1764, 'x': 122.21457084, 'y': 56.43110416799999, 'original_width': 1764, 'original_height': 1272, 'ocr': [{'x': 17, 'y': 5, 'w': 60, 'h': 38, 'confidence': '0.9999911215137923', 'text': 'pip'}, {'x': 88, 'y': 4, 'w': 122, 'h': 32, 'confidence': '0.9998962322755132', 'text': 'install'}, {'x': 222, 'y': 6, 'w': 36, 'h': 28, 'confidence': '0.9952683398906473', 'text': '~U'}, {'x': 268, 'y': 0, 'w': 298, 'h': 46, 'confidence': '0.7538930625482662', 'text': 'duckduckgo_search'}, {'x': 10, 'y': 92, 'w': 466, 'h': 33, 'confidence': '0.8856437711922618', 'text': 'This file was updated remotely or in another'}, {'x': 8, 'y': 122, 'w': 138, 'h': 26, 'confidence': '0.6675578171050943', 'text': 'tab. To force'}, {'x': 150, 'y': 124, 'w': 284, 'h': 28, 'confidence': '0.7739585893126499', 'text': 'a save, overwriting the last'}, {'x': 10, 'y': 149, 'w': 426, 'h': 31, 'confidence': '0.7707088879177193', 'text': \"update, select 'Save' from the File menu\"}, {'x': 2, 'y': 182, 'w': 74, 'h': 32, 'confidence': '0.9998857975006104', 'text': 'from'}, {'x': 86, 'y': 184, 'w': 106, 'h': 30, 'confidence': '0.9999501647245188', 'text': 'dotenv'}, {'x': 205, 'y': 179, 'w': 310, 'h': 44, 'confidence': '0.5274670308345163', 'text': 'import load_dotenv'}, {'x': 1, 'y': 217, 'w': 344, 'h': 43, 'confidence': '0.8665881190373933', 'text': 'from Langchain.tools'}, {'x': 357, 'y': 218, 'w': 205, 'h': 39, 'confidence': '0.6945989401630956', 'text': 'import Tool,'}, {'x': 574, 'y': 220, 'w': 394, 'h': 32, 'confidence': '0.7662639921628726', 'text': 'DuckDuckGoSearchResults'}, {'x': 1, 'y': 256, 'w': 496, 'h': 41, 'confidence': '0.7005512916795655', 'text': 'from Langchain.prompts import'}, {'x': 507, 'y': 257, 'w': 244, 'h': 38, 'confidence': '0.9601227042070146', 'text': 'PromptTemplate'}, {'x': 2, 'y': 296, 'w': 74, 'h': 32, 'confidence': '0.9998897910118103', 'text': 'from'}, {'x': 87, 'y': 295, 'w': 394, 'h': 40, 'confidence': '0.5904995656124722', 'text': 'Zangchain. chains import'}, {'x': 491, 'y': 295, 'w': 142, 'h': 36, 'confidence': '0.7930889415838662', 'text': 'LLMChain'}, {'x': 1, 'y': 330, 'w': 952, 'h': 44, 'confidence': '0.8115159700421964', 'text': 'from Langchain.agents import initialize_agent, AgentType'}, {'x': 1, 'y': 434, 'w': 176, 'h': 41, 'confidence': '0.7969683690049871', 'text': 'ddg_search'}, {'x': 221, 'y': 435, 'w': 394, 'h': 36, 'confidence': '0.7972838287688688', 'text': 'DuckDuckGoSearchResults'}, {'x': 1, 'y': 535, 'w': 159, 'h': 39, 'confidence': '0.8315301101582321', 'text': 'def parse_'}, {'x': 169, 'y': 535, 'w': 224, 'h': 38, 'confidence': '0.9888327032825988', 'text': 'html(content)'}, {'x': 407, 'y': 545, 'w': 36, 'h': 20, 'confidence': '0.35708983311363474', 'text': '7>'}, {'x': 458, 'y': 540, 'w': 68, 'h': 30, 'confidence': '0.9997568130493164', 'text': 'str:'}, {'x': 70, 'y': 580, 'w': 74, 'h': 32, 'confidence': '0.9999630451202393', 'text': 'soup'}, {'x': 186, 'y': 571, 'w': 375, 'h': 42, 'confidence': '0.9958586023331865', 'text': 'BeautifulSoup(content,'}, {'x': 589, 'y': 574, 'w': 224, 'h': 41, 'confidence': '0.6762363028295477', 'text': \"html.parser' \"}, {'x': 69, 'y': 613, 'w': 394, 'h': 40, 'confidence': '0.9822837916018182', 'text': 'text_content_with_links'}, {'x': 506, 'y': 614, 'w': 145, 'h': 41, 'confidence': '0.9964097327589484', 'text': 'soup.get_'}, {'x': 659, 'y': 613, 'w': 106, 'h': 36, 'confidence': '0.9350667339214846', 'text': 'text ( )'}, {'x': 70, 'y': 654, 'w': 106, 'h': 30, 'confidence': '0.6351668628792009', 'text': 'return'}, {'x': 187, 'y': 649, 'w': 296, 'h': 42, 'confidence': '0.9968408624095422', 'text': 'text_content_with'}, {'x': 492, 'y': 652, 'w': 88, 'h': 32, 'confidence': '0.9909634194300757', 'text': 'links'}, {'x': 2, 'y': 754, 'w': 124, 'h': 32, 'confidence': '0.9999090738888968', 'text': 'HEADERS'}, {'x': 83, 'y': 791, 'w': 180, 'h': 38, 'confidence': '0.9993601580650467', 'text': 'User-Agent'}, {'x': 319, 'y': 791, 'w': 196, 'h': 36, 'confidence': '0.9989877967044272', 'text': 'Mozilla/5.0'}, {'x': 524, 'y': 791, 'w': 188, 'h': 36, 'confidence': '0.9986503875319139', 'text': '(Macintosh;'}, {'x': 726, 'y': 792, 'w': 158, 'h': 32, 'confidence': '0.6730080366055115', 'text': 'Intel Mac'}, {'x': 893, 'y': 791, 'w': 192, 'h': 36, 'confidence': '0.8501167996973361', 'text': '0S X 10.15;'}, {'x': 1099, 'y': 787, 'w': 392, 'h': 41, 'confidence': '0.9315237004301818', 'text': 'rv:90.0) Gecko/20100101'}, {'x': 1501, 'y': 791, 'w': 224, 'h': 36, 'confidence': '0.7653803921200727', 'text': \"Firefox/90.0 '\"}, {'x': 1, 'y': 833, 'w': 20, 'h': 26, 'confidence': '0.9836563829480873', 'text': '}'}, {'x': 1, 'y': 903, 'w': 58, 'h': 36, 'confidence': '0.9999938607215881', 'text': 'def'}, {'x': 69, 'y': 905, 'w': 324, 'h': 40, 'confidence': '0.933646235600073', 'text': 'fetch_web_page(url:'}, {'x': 406, 'y': 906, 'w': 72, 'h': 32, 'confidence': '0.9999651312828064', 'text': 'str)'}, {'x': 491, 'y': 913, 'w': 36, 'h': 20, 'confidence': '0.3538143357106791', 'text': '7>'}, {'x': 542, 'y': 908, 'w': 70, 'h': 30, 'confidence': '0.9993687272071838', 'text': 'str:'}, {'x': 71, 'y': 947, 'w': 140, 'h': 36, 'confidence': '0.9999911069985851', 'text': 'response'}, {'x': 255, 'y': 943, 'w': 290, 'h': 40, 'confidence': '0.545324859603458', 'text': 'requests.get (url,'}, {'x': 558, 'y': 944, 'w': 272, 'h': 32, 'confidence': '0.7285923586573593', 'text': 'headers-HEADERS )'}, {'x': 70, 'y': 984, 'w': 106, 'h': 30, 'confidence': '0.9170760242501284', 'text': 'return'}, {'x': 187, 'y': 981, 'w': 475, 'h': 40, 'confidence': '0.7514781747999713', 'text': 'parse_html(response. content)'}, {'x': 2, 'y': 1084, 'w': 58, 'h': 32, 'confidence': '0.999677300453186', 'text': 'web'}, {'x': 70, 'y': 1084, 'w': 174, 'h': 32, 'confidence': '0.959727437259468', 'text': 'fetch_tool'}, {'x': 288, 'y': 1084, 'w': 160, 'h': 32, 'confidence': '0.9889551838008442', 'text': 'Tool.from'}, {'x': 458, 'y': 1084, 'w': 140, 'h': 32, 'confidence': '0.9996211964753746', 'text': 'function'}, {'x': 69, 'y': 1121, 'w': 340, 'h': 40, 'confidence': '0.8635524910881522', 'text': 'func-fetch_web_page,'}, {'x': 69, 'y': 1159, 'w': 294, 'h': 36, 'confidence': '0.6516346555017826', 'text': 'name-\"WebFetcher\"'}, {'x': 69, 'y': 1197, 'w': 344, 'h': 40, 'confidence': '0.9820997829951438', 'text': 'description-\"Fetches'}, {'x': 424, 'y': 1198, 'w': 56, 'h': 32, 'confidence': '0.9999992429193688', 'text': 'the'}, {'x': 490, 'y': 1198, 'w': 124, 'h': 32, 'confidence': '0.9597212696311769', 'text': 'content'}, {'x': 624, 'y': 1198, 'w': 40, 'h': 32, 'confidence': '0.9720427766745232', 'text': 'of'}, {'x': 677, 'y': 1203, 'w': 18, 'h': 24, 'confidence': '0.9999392041863899', 'text': 'a'}, {'x': 706, 'y': 1194, 'w': 164, 'h': 48, 'confidence': '0.9980776837220731', 'text': 'web page\"'}]}]\n",
      "> Image for page 165: [{'name': 'img_p164_1.png', 'height': 682, 'width': 1652, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1652, 'original_height': 682, 'ocr': [{'x': 39, 'y': 19, 'w': 16, 'h': 24, 'confidence': '0.9999759198684757', 'text': '1'}, {'x': 79, 'y': 15, 'w': 60, 'h': 38, 'confidence': '0.9999946316117284', 'text': 'pip'}, {'x': 149, 'y': 11, 'w': 494, 'h': 42, 'confidence': '0.9345888540357261', 'text': 'install google-search-results'}, {'x': 37, 'y': 117, 'w': 134, 'h': 38, 'confidence': '0.9537225742593105', 'text': '1 import'}, {'x': 182, 'y': 122, 'w': 38, 'h': 28, 'confidence': '0.22632384651967757', 'text': '0s'}, {'x': 35, 'y': 157, 'w': 20, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 37, 'y': 195, 'w': 18, 'h': 26, 'confidence': '0.999999880790714', 'text': '3'}, {'x': 63, 'y': 191, 'w': 396, 'h': 36, 'confidence': '0.6899525076025783', 'text': '0S.environ [\"SERPAPI_API'}, {'x': 468, 'y': 194, 'w': 88, 'h': 32, 'confidence': '0.8745735532806191', 'text': 'KEY\" ]'}, {'x': 604, 'y': 194, 'w': 154, 'h': 32, 'confidence': '0.7999778764350354', 'text': 'userdata.'}, {'x': 837, 'y': 189, 'w': 290, 'h': 40, 'confidence': '0.7256517063357036', 'text': \"SERPAPI_API_KEY' \"}, {'x': 37, 'y': 292, 'w': 388, 'h': 42, 'confidence': '0.6895226026987946', 'text': '1 from Langchain.agents'}, {'x': 435, 'y': 295, 'w': 108, 'h': 38, 'confidence': '0.9975125184539828', 'text': 'import'}, {'x': 555, 'y': 295, 'w': 74, 'h': 36, 'confidence': '0.4684331501658006', 'text': 'load_'}, {'x': 638, 'y': 296, 'w': 88, 'h': 32, 'confidence': '0.99994652788021', 'text': 'tools'}, {'x': 35, 'y': 332, 'w': 104, 'h': 36, 'confidence': '0.6323117929645672', 'text': '2 from'}, {'x': 149, 'y': 333, 'w': 276, 'h': 38, 'confidence': '0.947455560286788', 'text': 'Zangchain.agents'}, {'x': 435, 'y': 333, 'w': 108, 'h': 38, 'confidence': '0.9998342858175775', 'text': 'import'}, {'x': 553, 'y': 333, 'w': 276, 'h': 38, 'confidence': '0.9997094713160751', 'text': 'initialize_agent'}, {'x': 36, 'y': 372, 'w': 102, 'h': 32, 'confidence': '0.9998672831425369', 'text': '3 from'}, {'x': 149, 'y': 371, 'w': 276, 'h': 38, 'confidence': '0.9481374269929489', 'text': 'Zangchain.agents'}, {'x': 435, 'y': 371, 'w': 276, 'h': 38, 'confidence': '0.9975987345536231', 'text': 'import AgentType'}, {'x': 38, 'y': 409, 'w': 100, 'h': 33, 'confidence': '0.6378370362420331', 'text': '4 from'}, {'x': 149, 'y': 406, 'w': 360, 'h': 41, 'confidence': '0.648921040915412', 'text': 'Langchain. chat_models'}, {'x': 519, 'y': 406, 'w': 292, 'h': 42, 'confidence': '0.9374867331594894', 'text': 'import ChatOpenAI'}, {'x': 37, 'y': 449, 'w': 18, 'h': 26, 'confidence': '0.9999997615814351', 'text': '5'}, {'x': 37, 'y': 487, 'w': 18, 'h': 26, 'confidence': '0.9999613765631352', 'text': '6'}, {'x': 66, 'y': 486, 'w': 56, 'h': 30, 'confidence': '0.23041931188116732', 'text': 'llm'}, {'x': 37, 'y': 527, 'w': 16, 'h': 22, 'confidence': '0.9999997615814351', 'text': '7'}, {'x': 64, 'y': 524, 'w': 90, 'h': 32, 'confidence': '0.9999292013482581', 'text': 'tools'}, {'x': 200, 'y': 524, 'w': 74, 'h': 32, 'confidence': '0.5055581911505962', 'text': 'load_'}, {'x': 284, 'y': 524, 'w': 88, 'h': 32, 'confidence': '0.9999262158499427', 'text': 'tools'}, {'x': 387, 'y': 521, 'w': 156, 'h': 40, 'confidence': '0.7131405288667495', 'text': '[\"serpapi'}, {'x': 568, 'y': 524, 'w': 188, 'h': 30, 'confidence': '0.6429669540916055', 'text': '\"tlm-math\"]'}, {'x': 39, 'y': 629, 'w': 16, 'h': 24, 'confidence': '0.9999698402771493', 'text': '1'}, {'x': 61, 'y': 623, 'w': 262, 'h': 41, 'confidence': '0.7866078899764106', 'text': 'agent. run ( \"What'}, {'x': 333, 'y': 627, 'w': 74, 'h': 36, 'confidence': '0.999908447265625', 'text': 'year'}, {'x': 416, 'y': 628, 'w': 58, 'h': 30, 'confidence': '0.9943376060100063', 'text': 'was'}, {'x': 486, 'y': 626, 'w': 106, 'h': 32, 'confidence': '0.9998283968887134', 'text': 'Albert'}, {'x': 603, 'y': 623, 'w': 142, 'h': 36, 'confidence': '0.9998463698488507', 'text': 'Einstein'}, {'x': 755, 'y': 623, 'w': 90, 'h': 36, 'confidence': '0.9999404502699604', 'text': 'born?'}, {'x': 855, 'y': 623, 'w': 74, 'h': 36, 'confidence': '0.9999797414100798', 'text': 'What'}, {'x': 942, 'y': 626, 'w': 38, 'h': 32, 'confidence': '0.9865192945882777', 'text': 'is'}, {'x': 989, 'y': 623, 'w': 464, 'h': 40, 'confidence': '0.7810255478417368', 'text': 'that year number multiplied'}, {'x': 1463, 'y': 625, 'w': 42, 'h': 38, 'confidence': '0.9999486655244425', 'text': 'by'}, {'x': 1514, 'y': 626, 'w': 70, 'h': 32, 'confidence': '0.4760767282661197', 'text': '57\" )'}, {'x': 751, 'y': 196, 'w': 62, 'h': 30, 'confidence': '0.9999984858388146', 'text': 'get'}]}]\n",
      "> Image for page 166: [{'name': 'img_p165_1.png', 'height': 664, 'width': 1428, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1428, 'original_height': 664, 'ocr': [{'x': 28, 'y': 7, 'w': 250, 'h': 33, 'confidence': '0.9665274215905956', 'text': '1 from datetime'}, {'x': 289, 'y': 7, 'w': 108, 'h': 38, 'confidence': '0.9982014884488759', 'text': 'import'}, {'x': 408, 'y': 8, 'w': 140, 'h': 32, 'confidence': '0.999982087522931', 'text': 'datetime'}, {'x': 25, 'y': 44, 'w': 120, 'h': 39, 'confidence': '0.9882776212951639', 'text': '2 @tool'}, {'x': 25, 'y': 83, 'w': 336, 'h': 40, 'confidence': '0.7974951241273202', 'text': '3 def get_time(text:'}, {'x': 374, 'y': 84, 'w': 70, 'h': 32, 'confidence': '0.631590913425525', 'text': 'str)'}, {'x': 459, 'y': 91, 'w': 36, 'h': 20, 'confidence': '0.2839444557117778', 'text': '~>'}, {'x': 508, 'y': 86, 'w': 72, 'h': 30, 'confidence': '0.9998363852500916', 'text': 'str:'}, {'x': 29, 'y': 127, 'w': 16, 'h': 24, 'confidence': '1.0', 'text': '4'}, {'x': 170, 'y': 122, 'w': 126, 'h': 32, 'confidence': '0.9999979724399027', 'text': 'Returns'}, {'x': 306, 'y': 122, 'w': 58, 'h': 32, 'confidence': '0.9999983481878129', 'text': 'the'}, {'x': 374, 'y': 124, 'w': 124, 'h': 30, 'confidence': '0.9999832676431569', 'text': 'current'}, {'x': 508, 'y': 122, 'w': 88, 'h': 32, 'confidence': '0.9994295955464837', 'text': 'time.'}, {'x': 610, 'y': 122, 'w': 58, 'h': 32, 'confidence': '0.9999794211992603', 'text': 'Use'}, {'x': 678, 'y': 122, 'w': 72, 'h': 32, 'confidence': '0.9999954700469971', 'text': 'this'}, {'x': 762, 'y': 122, 'w': 58, 'h': 32, 'confidence': '0.9999913968155315', 'text': 'for'}, {'x': 829, 'y': 117, 'w': 226, 'h': 42, 'confidence': '0.9853421226833662', 'text': 'any questions'}, {'x': 25, 'y': 161, 'w': 20, 'h': 28, 'confidence': '0.9999997615814351', 'text': '5'}, {'x': 123, 'y': 159, 'w': 156, 'h': 38, 'confidence': '0.9823576670414171', 'text': 'regarding'}, {'x': 290, 'y': 160, 'w': 56, 'h': 32, 'confidence': '0.9999911903392261', 'text': 'the'}, {'x': 358, 'y': 162, 'w': 122, 'h': 30, 'confidence': '0.9999493105993537', 'text': 'current'}, {'x': 492, 'y': 160, 'w': 86, 'h': 32, 'confidence': '0.9988536607855446', 'text': 'time.'}, {'x': 592, 'y': 158, 'w': 93, 'h': 42, 'confidence': '0.9999965880303532', 'text': 'Input'}, {'x': 694, 'y': 160, 'w': 40, 'h': 32, 'confidence': '0.9939991085364291', 'text': 'is'}, {'x': 744, 'y': 164, 'w': 40, 'h': 28, 'confidence': '0.9999996628252286', 'text': 'an'}, {'x': 795, 'y': 155, 'w': 278, 'h': 44, 'confidence': '0.6520281563476168', 'text': 'empty string and'}, {'x': 25, 'y': 199, 'w': 20, 'h': 28, 'confidence': '0.9999914169495696', 'text': '6'}, {'x': 122, 'y': 198, 'w': 56, 'h': 32, 'confidence': '0.9999987611408254', 'text': 'the'}, {'x': 190, 'y': 200, 'w': 122, 'h': 30, 'confidence': '0.5069235958418473', 'text': 'current'}, {'x': 322, 'y': 198, 'w': 76, 'h': 32, 'confidence': '0.9999257326126099', 'text': 'time'}, {'x': 410, 'y': 198, 'w': 38, 'h': 32, 'confidence': '0.9888745871234442', 'text': 'is'}, {'x': 460, 'y': 198, 'w': 140, 'h': 32, 'confidence': '0.9980674781838985', 'text': 'returned'}, {'x': 612, 'y': 200, 'w': 38, 'h': 30, 'confidence': '0.9994524720572767', 'text': 'in'}, {'x': 661, 'y': 205, 'w': 20, 'h': 22, 'confidence': '0.9999589924248085', 'text': 'a'}, {'x': 690, 'y': 191, 'w': 115, 'h': 48, 'confidence': '0.999972211062694', 'text': 'string'}, {'x': 814, 'y': 198, 'w': 118, 'h': 32, 'confidence': '0.9995445766638775', 'text': 'format.'}, {'x': 945, 'y': 197, 'w': 78, 'h': 38, 'confidence': '0.9939447641372681', 'text': 'Only'}, {'x': 1032, 'y': 202, 'w': 56, 'h': 28, 'confidence': '0.9999281465077696', 'text': 'use'}, {'x': 1098, 'y': 198, 'w': 74, 'h': 32, 'confidence': '0.9999966621398926', 'text': 'this'}, {'x': 1184, 'y': 198, 'w': 140, 'h': 32, 'confidence': '0.9239935195516333', 'text': 'function'}, {'x': 27, 'y': 239, 'w': 16, 'h': 24, 'confidence': '0.6279527480946291', 'text': '7'}, {'x': 122, 'y': 236, 'w': 56, 'h': 32, 'confidence': '0.9999926356734838', 'text': 'for'}, {'x': 190, 'y': 236, 'w': 56, 'h': 32, 'confidence': '0.9999969716779362', 'text': 'the'}, {'x': 256, 'y': 238, 'w': 124, 'h': 30, 'confidence': '0.9999766926802661', 'text': 'current'}, {'x': 390, 'y': 236, 'w': 86, 'h': 30, 'confidence': '0.9980280788181913', 'text': 'time.'}, {'x': 492, 'y': 236, 'w': 174, 'h': 32, 'confidence': '0.9830255533676817', 'text': 'Other time'}, {'x': 679, 'y': 232, 'w': 292, 'h': 41, 'confidence': '0.9861962912711448', 'text': 'related questions'}, {'x': 982, 'y': 236, 'w': 106, 'h': 32, 'confidence': '0.9999575135160482', 'text': 'should'}, {'x': 1100, 'y': 240, 'w': 56, 'h': 28, 'confidence': '0.9999739840005138', 'text': 'use'}, {'x': 1166, 'y': 236, 'w': 222, 'h': 32, 'confidence': '0.9921163749438805', 'text': \"another tool'\"}, {'x': 27, 'y': 275, 'w': 18, 'h': 28, 'confidence': '0.5155469290959493', 'text': '8'}, {'x': 124, 'y': 276, 'w': 104, 'h': 30, 'confidence': '0.9999982966550707', 'text': 'return'}, {'x': 239, 'y': 271, 'w': 324, 'h': 38, 'confidence': '0.9604399986829708', 'text': 'str(datetime.now( ) )'}, {'x': 29, 'y': 381, 'w': 16, 'h': 24, 'confidence': '0.9999408730664072', 'text': '1'}, {'x': 51, 'y': 374, 'w': 95, 'h': 42, 'confidence': '0.9999987205115435', 'text': 'agent'}, {'x': 189, 'y': 374, 'w': 276, 'h': 42, 'confidence': '0.9981160570611748', 'text': 'initialize_agent'}, {'x': 475, 'y': 374, 'w': 276, 'h': 41, 'confidence': '0.7958083375654307', 'text': 'tools+ [get_time]'}, {'x': 25, 'y': 415, 'w': 20, 'h': 28, 'confidence': '0.9918744341359843', 'text': '2'}, {'x': 475, 'y': 412, 'w': 71, 'h': 37, 'confidence': '0.24677651976437048', 'text': '1Lm,'}, {'x': 27, 'y': 453, 'w': 18, 'h': 28, 'confidence': '0.999999880790714', 'text': '3'}, {'x': 475, 'y': 451, 'w': 346, 'h': 40, 'confidence': '0.994075742664871', 'text': 'agent-AgentType. ZERO_'}, {'x': 830, 'y': 452, 'w': 74, 'h': 32, 'confidence': '0.998984158039093', 'text': 'SHOT'}, {'x': 913, 'y': 447, 'w': 308, 'h': 42, 'confidence': '0.9938413701363569', 'text': 'REACT_DESCRIPTION,'}, {'x': 29, 'y': 495, 'w': 16, 'h': 22, 'confidence': '1.0', 'text': '4'}, {'x': 475, 'y': 487, 'w': 222, 'h': 38, 'confidence': '0.998172903324673', 'text': 'verbose-True)'}, {'x': 29, 'y': 597, 'w': 16, 'h': 24, 'confidence': '0.9999408730664072', 'text': '1'}, {'x': 51, 'y': 590, 'w': 194, 'h': 42, 'confidence': '0.9911846232521738', 'text': 'agent ( \"What'}, {'x': 255, 'y': 589, 'w': 142, 'h': 36, 'confidence': '0.9994212346216702', 'text': 'time did'}, {'x': 408, 'y': 591, 'w': 90, 'h': 32, 'confidence': '0.9979498515068472', 'text': 'Pearl'}, {'x': 507, 'y': 590, 'w': 326, 'h': 44, 'confidence': '0.6094929625067594', 'text': 'Harbor happen at?\")'}]}]\n",
      "> Image for page 167: [{'name': 'img_p166_1.png', 'height': 556, 'width': 1174, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1174, 'original_height': 556, 'ocr': [{'x': 48, 'y': 51, 'w': 262, 'h': 41, 'confidence': '0.6891668045956875', 'text': 'agent ( \"What time'}, {'x': 318, 'y': 56, 'w': 36, 'h': 30, 'confidence': '0.9899401866254001', 'text': 'is'}, {'x': 364, 'y': 54, 'w': 82, 'h': 32, 'confidence': '0.994643207551994', 'text': 'it?\")'}, {'x': 44, 'y': 151, 'w': 135, 'h': 42, 'confidence': '0.9999881567065189', 'text': 'Entering'}, {'x': 186, 'y': 162, 'w': 52, 'h': 24, 'confidence': '0.9999816236100062', 'text': 'new'}, {'x': 266, 'y': 156, 'w': 88, 'h': 32, 'confidence': '0.626188417605285', 'text': 'chain _'}, {'x': 33, 'y': 193, 'w': 16, 'h': 24, 'confidence': '0.9991014830899623', 'text': 'I'}, {'x': 62, 'y': 190, 'w': 68, 'h': 30, 'confidence': '0.9999934434890747', 'text': 'need'}, {'x': 140, 'y': 192, 'w': 38, 'h': 28, 'confidence': '0.9999789266407801', 'text': 'to'}, {'x': 188, 'y': 190, 'w': 68, 'h': 30, 'confidence': '0.9968145941402022', 'text': 'find'}, {'x': 266, 'y': 190, 'w': 52, 'h': 30, 'confidence': '0.9994848587970532', 'text': 'out'}, {'x': 328, 'y': 188, 'w': 256, 'h': 32, 'confidence': '0.9542497070107975', 'text': 'the current time'}, {'x': 14, 'y': 222, 'w': 114, 'h': 32, 'confidence': '0.999716798713358', 'text': 'Action:'}, {'x': 139, 'y': 221, 'w': 134, 'h': 38, 'confidence': '0.9979148959072864', 'text': 'get_time'}, {'x': 13, 'y': 253, 'w': 210, 'h': 38, 'confidence': '0.9987362777252733', 'text': 'Action Input:'}, {'x': 14, 'y': 288, 'w': 192, 'h': 30, 'confidence': '0.844499967906326', 'text': 'Observation:'}, {'x': 218, 'y': 288, 'w': 414, 'h': 30, 'confidence': '0.830320880809944', 'text': '2023-07-19 15:48:45.919918'}, {'x': 15, 'y': 319, 'w': 128, 'h': 36, 'confidence': '0.9997768221210349', 'text': 'Thought:'}, {'x': 159, 'y': 325, 'w': 16, 'h': 22, 'confidence': '0.7419415862414667', 'text': '1'}, {'x': 188, 'y': 322, 'w': 52, 'h': 26, 'confidence': '0.9910828048085839', 'text': 'now'}, {'x': 250, 'y': 318, 'w': 224, 'h': 32, 'confidence': '0.8701429438177277', 'text': 'know the final'}, {'x': 484, 'y': 322, 'w': 98, 'h': 26, 'confidence': '0.883886551366761', 'text': 'answer'}, {'x': 14, 'y': 352, 'w': 84, 'h': 32, 'confidence': '0.9999664666762026', 'text': 'Final'}, {'x': 110, 'y': 354, 'w': 110, 'h': 28, 'confidence': '0.9937827846370415', 'text': 'Answer:'}, {'x': 234, 'y': 352, 'w': 54, 'h': 32, 'confidence': '0.9999319318756357', 'text': 'The'}, {'x': 298, 'y': 354, 'w': 114, 'h': 30, 'confidence': '0.9999923403215568', 'text': 'current'}, {'x': 422, 'y': 351, 'w': 542, 'h': 33, 'confidence': '0.46716825840483234', 'text': 'time is 2023-07-19 15:48: 45.919918 _'}, {'x': 46, 'y': 416, 'w': 132, 'h': 32, 'confidence': '0.9999761869131482', 'text': 'Finished'}, {'x': 188, 'y': 416, 'w': 88, 'h': 32, 'confidence': '0.7359385163299721', 'text': 'chain _'}, {'x': 39, 'y': 463, 'w': 20, 'h': 26, 'confidence': '0.9988567522261214', 'text': '{'}, {'x': 71, 'y': 461, 'w': 86, 'h': 36, 'confidence': '0.9998314257313937', 'text': 'input'}, {'x': 210, 'y': 462, 'w': 148, 'h': 30, 'confidence': '0.46754352125522175', 'text': 'What time'}, {'x': 368, 'y': 462, 'w': 36, 'h': 30, 'confidence': '0.9799751677488787', 'text': 'is'}, {'x': 416, 'y': 462, 'w': 64, 'h': 28, 'confidence': '0.9990972280502319', 'text': \"it?'\"}, {'x': 69, 'y': 495, 'w': 104, 'h': 36, 'confidence': '0.9998243087021078', 'text': 'output'}, {'x': 214, 'y': 494, 'w': 66, 'h': 32, 'confidence': '0.9999669194221497', 'text': \"'The\"}, {'x': 289, 'y': 495, 'w': 113, 'h': 30, 'confidence': '0.9999845003957682', 'text': 'current'}, {'x': 414, 'y': 496, 'w': 70, 'h': 30, 'confidence': '0.9999551177024841', 'text': 'time'}, {'x': 494, 'y': 496, 'w': 36, 'h': 30, 'confidence': '0.9900967650462003', 'text': 'is'}, {'x': 540, 'y': 494, 'w': 162, 'h': 32, 'confidence': '0.8437412279917974', 'text': '2023-07-19'}, {'x': 712, 'y': 494, 'w': 254, 'h': 32, 'confidence': '0.874377576602302', 'text': '15:48:45.919918 .'}, {'x': 977, 'y': 497, 'w': 20, 'h': 26, 'confidence': '0.9996639772453229', 'text': '}'}]}]\n",
      "> Image for page 168: [{'name': 'img_p167_1.png', 'height': 1016, 'width': 1532, 'x': 105.89370417599999, 'y': 59.46260032799995, 'original_width': 1532, 'original_height': 1016, 'ocr': [{'x': 39, 'y': 19, 'w': 14, 'h': 24, 'confidence': '0.9999600652867038', 'text': '1'}, {'x': 63, 'y': 13, 'w': 480, 'h': 40, 'confidence': '0.6338208716911025', 'text': 'from langchain.agents import'}, {'x': 554, 'y': 14, 'w': 72, 'h': 32, 'confidence': '0.9812051653862', 'text': 'Tool'}, {'x': 35, 'y': 49, 'w': 391, 'h': 43, 'confidence': '0.6308147118022362', 'text': '2 from Langchain.agents'}, {'x': 435, 'y': 48, 'w': 276, 'h': 44, 'confidence': '0.7054968365124082', 'text': 'import AgentType'}, {'x': 35, 'y': 85, 'w': 928, 'h': 45, 'confidence': '0.6223206758389067', 'text': '3 from Langchain.memory import ConversationBufferMemory'}, {'x': 36, 'y': 128, 'w': 102, 'h': 32, 'confidence': '0.8777241946078111', 'text': '4 from'}, {'x': 149, 'y': 126, 'w': 662, 'h': 42, 'confidence': '0.506309074008875', 'text': 'Langchain. chat_models import ChatOpenAI'}, {'x': 37, 'y': 164, 'w': 792, 'h': 42, 'confidence': '0.6899643046432871', 'text': '5 from Langchain.agents import initialize_agent'}, {'x': 35, 'y': 201, 'w': 508, 'h': 43, 'confidence': '0.6802188888923923', 'text': '6 from Langchain.agents import'}, {'x': 555, 'y': 203, 'w': 172, 'h': 40, 'confidence': '0.5133223011088024', 'text': 'Zoad_tools'}, {'x': 38, 'y': 309, 'w': 131, 'h': 32, 'confidence': '0.9937397709302138', 'text': '1 memory'}, {'x': 213, 'y': 301, 'w': 867, 'h': 48, 'confidence': '0.6137037456336739', 'text': 'ConversationBufferMemory (memory_key-\"chat_history\")'}, {'x': 37, 'y': 407, 'w': 519, 'h': 38, 'confidence': '0.5774408970524427', 'text': '1 Um-ChatopenAI(temperature-0)'}, {'x': 36, 'y': 446, 'w': 118, 'h': 32, 'confidence': '0.9857172236045519', 'text': '2 tools'}, {'x': 199, 'y': 445, 'w': 174, 'h': 36, 'confidence': '0.5784464890027937', 'text': 'Zoad_tools'}, {'x': 387, 'y': 445, 'w': 220, 'h': 38, 'confidence': '0.3697955908940285', 'text': '[\"llm-math\"] ,'}, {'x': 622, 'y': 446, 'w': 136, 'h': 32, 'confidence': '0.22941592740417893', 'text': 'llm-lZm)'}, {'x': 35, 'y': 483, 'w': 220, 'h': 40, 'confidence': '0.8511750203801788', 'text': '3 agent_chain'}, {'x': 301, 'y': 479, 'w': 391, 'h': 45, 'confidence': '0.766868144976043', 'text': 'initialize_agent (tools ,'}, {'x': 584, 'y': 518, 'w': 75, 'h': 41, 'confidence': '0.2173738330602646', 'text': '1Zm,'}, {'x': 34, 'y': 524, 'w': 24, 'h': 104, 'confidence': '0.87594881266293', 'text': '6'}, {'x': 584, 'y': 556, 'w': 821, 'h': 43, 'confidence': '0.6981901311389314', 'text': 'agent-AgentType. CONVERSATIONAL_REACT_DESCRIPTION'}, {'x': 584, 'y': 596, 'w': 215, 'h': 37, 'confidence': '0.6525897516178094', 'text': 'verbose-True,'}, {'x': 35, 'y': 635, 'w': 20, 'h': 28, 'confidence': '0.9999992847443906', 'text': '7'}, {'x': 585, 'y': 639, 'w': 228, 'h': 36, 'confidence': '0.9984692147629032', 'text': 'memory-memory'}, {'x': 37, 'y': 735, 'w': 488, 'h': 43, 'confidence': '0.8348628308523178', 'text': '1 agent_chain. run( input-\"What'}, {'x': 536, 'y': 742, 'w': 56, 'h': 28, 'confidence': '0.9999979352348233', 'text': 'are'}, {'x': 603, 'y': 735, 'w': 160, 'h': 41, 'confidence': '0.986756512784901', 'text': 'some good'}, {'x': 772, 'y': 738, 'w': 72, 'h': 32, 'confidence': '0.8214879393816393', 'text': 'thai'}, {'x': 855, 'y': 736, 'w': 258, 'h': 40, 'confidence': '0.669095203565469', 'text': 'food recipes?\" )'}, {'x': 37, 'y': 837, 'w': 404, 'h': 42, 'confidence': '0.6937754771404725', 'text': '1 agent_chain. run( \"Which'}, {'x': 452, 'y': 844, 'w': 56, 'h': 28, 'confidence': '0.9995750833646235', 'text': 'one'}, {'x': 518, 'y': 840, 'w': 40, 'h': 32, 'confidence': '0.9129308662769127', 'text': 'of'}, {'x': 570, 'y': 840, 'w': 90, 'h': 32, 'confidence': '0.6009455994557662', 'text': 'those'}, {'x': 670, 'y': 840, 'w': 108, 'h': 32, 'confidence': '0.8088757266076162', 'text': 'dishes'}, {'x': 790, 'y': 840, 'w': 38, 'h': 32, 'confidence': '0.9765675911963458', 'text': 'is'}, {'x': 838, 'y': 832, 'w': 260, 'h': 49, 'confidence': '0.984311999810253', 'text': 'the spiciest?\")'}, {'x': 37, 'y': 937, 'w': 388, 'h': 44, 'confidence': '0.960266000533275', 'text': '1 agent_chain. run(\"Give'}, {'x': 434, 'y': 946, 'w': 40, 'h': 28, 'confidence': '0.9717692601122238', 'text': 'me'}, {'x': 485, 'y': 949, 'w': 20, 'h': 22, 'confidence': '0.9999492174873836', 'text': 'a'}, {'x': 516, 'y': 941, 'w': 278, 'h': 40, 'confidence': '0.9948788617212236', 'text': 'grocery shopping'}, {'x': 806, 'y': 942, 'w': 72, 'h': 32, 'confidence': '0.9957415461540222', 'text': 'list'}, {'x': 890, 'y': 944, 'w': 40, 'h': 30, 'confidence': '0.9999672099093186', 'text': 'to'}, {'x': 940, 'y': 944, 'w': 74, 'h': 30, 'confidence': '0.7597295140566023', 'text': 'make'}, {'x': 1024, 'y': 942, 'w': 189, 'h': 32, 'confidence': '0.5206990027325118', 'text': 'that dish\" )'}]}]\n",
      "> Image for page 169: []\n",
      "> Image for page 170: []\n",
      "> Image for page 171: [{'name': 'img_p170_1.png', 'height': 587, 'width': 2048, 'x': 12.000000384, 'y': 98.27167637304001, 'original_width': 2048, 'original_height': 587, 'ocr': [{'x': 111, 'y': 19, 'w': 242, 'h': 36, 'confidence': '0.8213150373389688', 'text': 'Document Loading'}, {'x': 554, 'y': 15, 'w': 115, 'h': 40, 'confidence': '0.9720852681071571', 'text': 'Splitting'}, {'x': 837, 'y': 19, 'w': 105, 'h': 33, 'confidence': '0.9999460092833354', 'text': 'Storage'}, {'x': 1158, 'y': 20, 'w': 116, 'h': 28, 'confidence': '0.7141604170193083', 'text': 'Retrieval'}, {'x': 1600, 'y': 16, 'w': 97, 'h': 38, 'confidence': '0.9835175168854193', 'text': 'Output'}, {'x': 104, 'y': 120, 'w': 58, 'h': 24, 'confidence': '0.9840196967124939', 'text': 'URLs'}, {'x': 104, 'y': 224, 'w': 58, 'h': 24, 'confidence': '0.9997758269309998', 'text': 'PDFs'}, {'x': 1235, 'y': 261, 'w': 92, 'h': 24, 'confidence': '0.9999973447470837', 'text': 'Relevant'}, {'x': 1475, 'y': 271, 'w': 79, 'h': 27, 'confidence': '0.9999089431324635', 'text': 'Prompt'}, {'x': 310, 'y': 298, 'w': 116, 'h': 24, 'confidence': '0.9999885558754611', 'text': 'Documents'}, {'x': 576, 'y': 298, 'w': 62, 'h': 28, 'confidence': '0.9999311843458658', 'text': 'Splits'}, {'x': 840, 'y': 301, 'w': 118, 'h': 24, 'confidence': '0.9997969446855893', 'text': 'Vectorstore'}, {'x': 1252, 'y': 286, 'w': 60, 'h': 28, 'confidence': '0.8475756326902806', 'text': 'Splits'}, {'x': 1712, 'y': 302, 'w': 48, 'h': 24, 'confidence': '0.9999474863164742', 'text': 'LLM'}, {'x': 1934, 'y': 310, 'w': 84, 'h': 24, 'confidence': '0.9999868598936574', 'text': 'Answer'}, {'x': 1107, 'y': 301, 'w': 110, 'h': 134, 'confidence': '0.3170212445020082', 'text': 'To'}, {'x': 86, 'y': 438, 'w': 96, 'h': 26, 'confidence': '0.9999958696053126', 'text': 'Database'}, {'x': 1122, 'y': 444, 'w': 67, 'h': 31, 'confidence': '0.9999910435767463', 'text': 'Query'}, {'x': 1108, 'y': 476, 'w': 98, 'h': 26, 'confidence': '0.9999978926566547', 'text': 'Question'}]}]\n",
      "> Image for page 172: []\n",
      "> Image for page 173: []\n",
      "> Image for page 174: [{'name': 'img_p173_1.png', 'height': 514, 'width': 1048, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1048, 'original_height': 514, 'ocr': [{'x': 37, 'y': 20, 'w': 424, 'h': 39, 'confidence': '0.5673927387382646', 'text': '1 from Langchain.document_'}, {'x': 470, 'y': 21, 'w': 122, 'h': 32, 'confidence': '0.9968075822493552', 'text': 'loaders'}, {'x': 603, 'y': 19, 'w': 278, 'h': 40, 'confidence': '0.9992757815396918', 'text': 'import CSVLoader'}, {'x': 35, 'y': 61, 'w': 20, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 37, 'y': 99, 'w': 18, 'h': 26, 'confidence': '0.999999880790714', 'text': '3'}, {'x': 66, 'y': 98, 'w': 106, 'h': 32, 'confidence': '0.8215526193980428', 'text': 'loader'}, {'x': 215, 'y': 95, 'w': 178, 'h': 36, 'confidence': '0.9289713169580588', 'text': 'CSVLoader('}, {'x': 401, 'y': 93, 'w': 362, 'h': 41, 'confidence': '0.5959463600896736', 'text': '[content/penguins_CSV'}, {'x': 773, 'y': 101, 'w': 16, 'h': 26, 'confidence': '0.9891053774446767', 'text': ')'}, {'x': 38, 'y': 136, 'w': 98, 'h': 32, 'confidence': '0.9999480233525179', 'text': '4 data'}, {'x': 182, 'y': 133, 'w': 221, 'h': 36, 'confidence': '0.7183206278528824', 'text': 'loader. load ( )'}, {'x': 35, 'y': 169, 'w': 254, 'h': 42, 'confidence': '0.6852723605668819', 'text': '5 print(data [0]'}, {'x': 299, 'y': 171, 'w': 224, 'h': 42, 'confidence': '0.9990433228953097', 'text': 'page_content)'}, {'x': 10, 'y': 241, 'w': 141, 'h': 43, 'confidence': '0.9998639039899989', 'text': 'species:'}, {'x': 163, 'y': 246, 'w': 106, 'h': 32, 'confidence': '0.9999895365851338', 'text': 'Adelie'}, {'x': 13, 'y': 278, 'w': 292, 'h': 43, 'confidence': '0.8421268940143756', 'text': 'island: Torgersen'}, {'x': 11, 'y': 312, 'w': 256, 'h': 41, 'confidence': '0.7693145480417349', 'text': 'bill_length_mm:'}, {'x': 282, 'y': 314, 'w': 72, 'h': 32, 'confidence': '0.9994873404502869', 'text': '39.1'}, {'x': 10, 'y': 345, 'w': 239, 'h': 41, 'confidence': '0.6582298785744937', 'text': 'bill_depth_mm:'}, {'x': 266, 'y': 350, 'w': 72, 'h': 32, 'confidence': '0.49360520325380497', 'text': '18 . 7'}, {'x': 11, 'y': 383, 'w': 245, 'h': 40, 'confidence': '0.9928941087859013', 'text': 'flipper_length'}, {'x': 264, 'y': 388, 'w': 54, 'h': 28, 'confidence': '0.3716200888156891', 'text': 'mm :'}, {'x': 334, 'y': 384, 'w': 54, 'h': 32, 'confidence': '0.9526853561401367', 'text': '181'}, {'x': 11, 'y': 417, 'w': 206, 'h': 40, 'confidence': '0.7772533333103712', 'text': 'body_mass_g:'}, {'x': 230, 'y': 418, 'w': 74, 'h': 32, 'confidence': '0.8320298525532684', 'text': '3750'}, {'x': 12, 'y': 458, 'w': 66, 'h': 26, 'confidence': '0.9984145164489746', 'text': 'sex:'}, {'x': 96, 'y': 454, 'w': 74, 'h': 32, 'confidence': '0.9994613715877295', 'text': 'MALE'}]}]\n",
      "> Image for page 175: [{'name': 'img_p174_1.png', 'height': 276, 'width': 1092, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1092, 'original_height': 276, 'ocr': [{'x': 39, 'y': 16, 'w': 424, 'h': 41, 'confidence': '0.6977192871915017', 'text': '1 from Langchain.document'}, {'x': 471, 'y': 16, 'w': 242, 'h': 42, 'confidence': '0.6532984389220043', 'text': 'loaders import'}, {'x': 723, 'y': 17, 'w': 210, 'h': 36, 'confidence': '0.9998738025881838', 'text': 'BSHTMLLoader'}, {'x': 39, 'y': 59, 'w': 18, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 39, 'y': 95, 'w': 18, 'h': 28, 'confidence': '0.999999880790714', 'text': '3'}, {'x': 68, 'y': 94, 'w': 106, 'h': 32, 'confidence': '0.9863971501485281', 'text': 'loader'}, {'x': 216, 'y': 91, 'w': 713, 'h': 39, 'confidence': '0.6114999032004538', 'text': \"BSHTMLLoader( ' /content/ some_website.html' \"}, {'x': 39, 'y': 135, 'w': 18, 'h': 26, 'confidence': '1.0', 'text': '4'}, {'x': 36, 'y': 170, 'w': 102, 'h': 32, 'confidence': '0.9902512115279974', 'text': '5 data'}, {'x': 185, 'y': 169, 'w': 189, 'h': 33, 'confidence': '0.598782389925067', 'text': 'loader. load'}, {'x': 38, 'y': 208, 'w': 100, 'h': 32, 'confidence': '0.9722740812654079', 'text': '6 data'}]}]\n",
      "> Image for page 176: [{'name': 'img_p175_1.png', 'height': 260, 'width': 1386, 'x': 12.000000384, 'y': 86.37992402399999, 'original_width': 1386, 'original_height': 260, 'ocr': [{'x': 35, 'y': 7, 'w': 422, 'h': 43, 'confidence': '0.5130100308064982', 'text': '1 from Langchain.document_'}, {'x': 467, 'y': 8, 'w': 124, 'h': 36, 'confidence': '0.9442985785921687', 'text': 'loaders'}, {'x': 601, 'y': 9, 'w': 344, 'h': 40, 'confidence': '0.7166593669940672', 'text': 'import WebBaseLoader'}, {'x': 33, 'y': 51, 'w': 20, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 33, 'y': 85, 'w': 138, 'h': 36, 'confidence': '0.6191216066824888', 'text': '3 Loader'}, {'x': 211, 'y': 83, 'w': 1102, 'h': 41, 'confidence': '0.4517861149769138', 'text': 'WebBaseLoader(\"https / Lgithub_com/basecamp handbook/tree master\" )'}, {'x': 35, 'y': 129, 'w': 18, 'h': 22, 'confidence': '0.9999949932161059', 'text': '4'}, {'x': 34, 'y': 164, 'w': 100, 'h': 32, 'confidence': '0.9975551946274729', 'text': '5 docs'}, {'x': 181, 'y': 161, 'w': 222, 'h': 36, 'confidence': '0.37330438639187624', 'text': 'loader. Load ( )'}, {'x': 33, 'y': 203, 'w': 20, 'h': 26, 'confidence': '0.9999907016970297', 'text': '6'}, {'x': 59, 'y': 196, 'w': 548, 'h': 44, 'confidence': '0.74612616417464', 'text': 'print(docs [0] . page_content [: 500]'}]}]\n",
      "> Image for page 177: [{'name': 'img_p176_1.png', 'height': 160, 'width': 1180, 'x': 17.633858831999998, 'y': 127.692905660976, 'original_width': 1180, 'original_height': 160, 'ocr': [{'x': 33, 'y': 29, 'w': 16, 'h': 24, 'confidence': '0.9999926090377045', 'text': '1'}, {'x': 59, 'y': 22, 'w': 396, 'h': 41, 'confidence': '0.8431424286638168', 'text': 'from Langchain.document_'}, {'x': 465, 'y': 23, 'w': 124, 'h': 36, 'confidence': '0.9167337346131376', 'text': 'loaders'}, {'x': 599, 'y': 23, 'w': 311, 'h': 38, 'confidence': '0.99224458849738', 'text': 'import PyPDFLoader'}, {'x': 29, 'y': 61, 'w': 140, 'h': 36, 'confidence': '0.6025524195880098', 'text': '2 loader'}, {'x': 210, 'y': 58, 'w': 899, 'h': 41, 'confidence': '0.634242850041463', 'text': 'PyPDFLoader(\" [content /MachineLearning_Lecture01_pdf\" )'}, {'x': 29, 'y': 99, 'w': 122, 'h': 40, 'confidence': '0.8929996742215658', 'text': '3 pages'}, {'x': 196, 'y': 100, 'w': 220, 'h': 32, 'confidence': '0.6881047501810613', 'text': 'loader. load ( )'}]}]\n",
      "> Image for page 178: []\n",
      "> Image for page 179: [{'name': 'img_p178_1.png', 'height': 786, 'width': 1644, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1644, 'original_height': 786, 'ocr': [{'x': 29, 'y': 15, 'w': 1146, 'h': 43, 'confidence': '0.6904977235336225', 'text': '1 from langchain.text_splitter import RecursiveCharacterTextSplitter'}, {'x': 25, 'y': 55, 'w': 206, 'h': 38, 'confidence': '0.9924533936096651', 'text': '2 chunk_size'}, {'x': 240, 'y': 56, 'w': 58, 'h': 32, 'confidence': '0.9938687940870732', 'text': '=26'}, {'x': 27, 'y': 92, 'w': 253, 'h': 40, 'confidence': '0.7477606165970154', 'text': '3 chunk_overlap'}, {'x': 291, 'y': 101, 'w': 22, 'h': 20, 'confidence': '0.9798421682670302', 'text': '='}, {'x': 327, 'y': 97, 'w': 18, 'h': 24, 'confidence': '1.0', 'text': '4'}, {'x': 31, 'y': 201, 'w': 16, 'h': 24, 'confidence': '0.9999363432524575', 'text': '1'}, {'x': 54, 'y': 188, 'w': 179, 'h': 51, 'confidence': '0.9997350053622396', 'text': 'r_splitter'}, {'x': 272, 'y': 192, 'w': 533, 'h': 42, 'confidence': '0.8097196454985004', 'text': 'RecursiveCharacterTextSplitter('}, {'x': 31, 'y': 239, 'w': 16, 'h': 24, 'confidence': '0.999994277962287', 'text': '2'}, {'x': 122, 'y': 231, 'w': 376, 'h': 40, 'confidence': '0.6167762528904659', 'text': 'chunk_size-chunk_size,'}, {'x': 29, 'y': 275, 'w': 18, 'h': 26, 'confidence': '0.9999997615814351', 'text': '3'}, {'x': 123, 'y': 271, 'w': 462, 'h': 40, 'confidence': '0.8681683061779412', 'text': 'chunk_overlap-chunk_overlap'}, {'x': 28, 'y': 312, 'w': 46, 'h': 28, 'confidence': '0.9891278147697449', 'text': '4 )'}, {'x': 259, 'y': 415, 'w': 36, 'h': 14, 'confidence': '0.22199140351378688', 'text': 'I'}, {'x': 31, 'y': 417, 'w': 14, 'h': 24, 'confidence': '0.9999380121300874', 'text': '1'}, {'x': 56, 'y': 414, 'w': 156, 'h': 32, 'confidence': '0.9993936830943291', 'text': 'some_text'}, {'x': 289, 'y': 407, 'w': 410, 'h': 42, 'confidence': '0.8927297561892248', 'text': '\"When writing documents,'}, {'x': 712, 'y': 412, 'w': 124, 'h': 32, 'confidence': '0.9994148465265553', 'text': 'writers'}, {'x': 846, 'y': 412, 'w': 76, 'h': 32, 'confidence': '0.9957358241081238', 'text': 'will'}, {'x': 932, 'y': 416, 'w': 58, 'h': 28, 'confidence': '0.9999236040688645', 'text': 'use'}, {'x': 1000, 'y': 412, 'w': 140, 'h': 32, 'confidence': '0.9996410929047441', 'text': 'document'}, {'x': 1152, 'y': 414, 'w': 158, 'h': 30, 'confidence': '0.9999537065234488', 'text': 'structure'}, {'x': 1319, 'y': 413, 'w': 144, 'h': 38, 'confidence': '0.9937834186800741', 'text': 'to group'}, {'x': 1472, 'y': 412, 'w': 136, 'h': 32, 'confidence': '0.9997327546534428', 'text': 'content.'}, {'x': 26, 'y': 450, 'w': 102, 'h': 32, 'confidence': '0.9989793836637806', 'text': '2 This'}, {'x': 140, 'y': 454, 'w': 56, 'h': 28, 'confidence': '0.9999430126907883', 'text': 'can'}, {'x': 208, 'y': 454, 'w': 106, 'h': 32, 'confidence': '0.9999753744355896', 'text': 'convey'}, {'x': 326, 'y': 452, 'w': 40, 'h': 30, 'confidence': '0.9999420064289986', 'text': 'to'}, {'x': 376, 'y': 450, 'w': 56, 'h': 32, 'confidence': '0.9999955263428388', 'text': 'the'}, {'x': 444, 'y': 447, 'w': 121, 'h': 40, 'confidence': '0.7674388909481593', 'text': 'reader ,'}, {'x': 577, 'y': 450, 'w': 90, 'h': 32, 'confidence': '0.9999108411834607', 'text': 'which'}, {'x': 679, 'y': 447, 'w': 76, 'h': 36, 'confidence': '0.9993822574615479', 'text': 'idea'}, {'x': 765, 'y': 453, 'w': 18, 'h': 26, 'confidence': '0.3827064593559193', 'text': '5'}, {'x': 798, 'y': 454, 'w': 56, 'h': 28, 'confidence': '0.9999984170133134', 'text': 'are'}, {'x': 866, 'y': 450, 'w': 128, 'h': 32, 'confidence': '0.7992701357712658', 'text': 'related;'}, {'x': 1015, 'y': 447, 'w': 208, 'h': 43, 'confidence': '0.9881824626548239', 'text': 'For example,'}, {'x': 1235, 'y': 449, 'w': 126, 'h': 38, 'confidence': '0.9993032521950719', 'text': 'closely'}, {'x': 1371, 'y': 447, 'w': 124, 'h': 36, 'confidence': '0.9999956294799149', 'text': 'related'}, {'x': 1505, 'y': 450, 'w': 90, 'h': 32, 'confidence': '0.9998102604138298', 'text': 'ideas'}, {'x': 29, 'y': 489, 'w': 18, 'h': 28, 'confidence': '0.999999880790714', 'text': '3'}, {'x': 56, 'y': 492, 'w': 56, 'h': 28, 'confidence': '0.9999977975838318', 'text': 'are'}, {'x': 124, 'y': 488, 'w': 38, 'h': 32, 'confidence': '0.9982336613650037', 'text': 'in'}, {'x': 174, 'y': 490, 'w': 160, 'h': 30, 'confidence': '0.8448995951688402', 'text': 'sentances _'}, {'x': 357, 'y': 488, 'w': 126, 'h': 32, 'confidence': '0.9997801146378046', 'text': 'Similar'}, {'x': 493, 'y': 485, 'w': 92, 'h': 36, 'confidence': '0.9996968624590322', 'text': 'ideas'}, {'x': 596, 'y': 492, 'w': 56, 'h': 28, 'confidence': '0.9999991740938607', 'text': 'are'}, {'x': 664, 'y': 488, 'w': 38, 'h': 32, 'confidence': '0.9989254245450501', 'text': 'in'}, {'x': 713, 'y': 487, 'w': 178, 'h': 38, 'confidence': '0.7365827090309386', 'text': 'paragraphs _'}, {'x': 915, 'y': 487, 'w': 176, 'h': 38, 'confidence': '0.9999875221526553', 'text': 'Paragraphs'}, {'x': 1102, 'y': 488, 'w': 70, 'h': 32, 'confidence': '0.700623215155975', 'text': 'form'}, {'x': 1185, 'y': 493, 'w': 20, 'h': 24, 'confidence': '0.999894383358324', 'text': 'a'}, {'x': 1218, 'y': 488, 'w': 154, 'h': 32, 'confidence': '0.9997802454694724', 'text': 'document.'}, {'x': 1387, 'y': 487, 'w': 76, 'h': 36, 'confidence': '0.49225714802742004', 'text': 'InIn'}, {'x': 29, 'y': 529, 'w': 18, 'h': 24, 'confidence': '0.9999997615814351', 'text': '4'}, {'x': 55, 'y': 525, 'w': 176, 'h': 40, 'confidence': '0.8377607352764616', 'text': 'Paragraphs'}, {'x': 242, 'y': 525, 'w': 155, 'h': 33, 'confidence': '0.977117420943273', 'text': 'are often'}, {'x': 410, 'y': 526, 'w': 158, 'h': 32, 'confidence': '0.9997860476173726', 'text': 'delimited'}, {'x': 578, 'y': 526, 'w': 74, 'h': 32, 'confidence': '0.5891272865772423', 'text': 'with'}, {'x': 663, 'y': 531, 'w': 18, 'h': 24, 'confidence': '0.999816068524698', 'text': 'a'}, {'x': 694, 'y': 521, 'w': 145, 'h': 43, 'confidence': '0.9927808729883776', 'text': 'carriage'}, {'x': 850, 'y': 528, 'w': 104, 'h': 30, 'confidence': '0.9999975179828857', 'text': 'return'}, {'x': 966, 'y': 530, 'w': 38, 'h': 26, 'confidence': '0.9784851920942111', 'text': 'or'}, {'x': 1018, 'y': 528, 'w': 56, 'h': 30, 'confidence': '0.9999326889494393', 'text': 'two'}, {'x': 1080, 'y': 519, 'w': 149, 'h': 48, 'confidence': '0.9999617303582284', 'text': 'carriage'}, {'x': 1238, 'y': 528, 'w': 136, 'h': 30, 'confidence': '0.9925531195031817', 'text': 'returns.'}, {'x': 31, 'y': 567, 'w': 16, 'h': 26, 'confidence': '0.9999959468882622', 'text': '5'}, {'x': 53, 'y': 559, 'w': 146, 'h': 43, 'confidence': '0.6972208195606545', 'text': 'Carriage'}, {'x': 210, 'y': 566, 'w': 120, 'h': 30, 'confidence': '0.9999938272017952', 'text': 'returns'}, {'x': 342, 'y': 568, 'w': 56, 'h': 26, 'confidence': '0.9566996097564697', 'text': 'are'}, {'x': 410, 'y': 563, 'w': 242, 'h': 33, 'confidence': '0.9113251814302441', 'text': 'the \"backslash'}, {'x': 662, 'y': 564, 'w': 38, 'h': 30, 'confidence': '0.9999959539049404', 'text': 'n\"'}, {'x': 712, 'y': 568, 'w': 58, 'h': 32, 'confidence': '0.9992916125939462', 'text': 'you'}, {'x': 779, 'y': 561, 'w': 210, 'h': 36, 'confidence': '0.9906421038144992', 'text': 'see embedded'}, {'x': 1000, 'y': 564, 'w': 40, 'h': 32, 'confidence': '0.9984642615812', 'text': 'in'}, {'x': 1049, 'y': 563, 'w': 208, 'h': 38, 'confidence': '0.8791525929626965', 'text': 'this string.'}, {'x': 29, 'y': 600, 'w': 184, 'h': 37, 'confidence': '0.9856573728480784', 'text': '6 Sentences'}, {'x': 224, 'y': 602, 'w': 74, 'h': 32, 'confidence': '0.9999732375144958', 'text': 'have'}, {'x': 309, 'y': 607, 'w': 18, 'h': 24, 'confidence': '0.999912979111869', 'text': 'a'}, {'x': 339, 'y': 598, 'w': 112, 'h': 41, 'confidence': '0.9999834045259162', 'text': 'period'}, {'x': 460, 'y': 604, 'w': 40, 'h': 30, 'confidence': '0.9999994942378553', 'text': 'at'}, {'x': 509, 'y': 601, 'w': 140, 'h': 36, 'confidence': '0.9985591147284834', 'text': 'the end,'}, {'x': 661, 'y': 599, 'w': 157, 'h': 40, 'confidence': '0.9785841974064841', 'text': 'but also,'}, {'x': 832, 'y': 602, 'w': 74, 'h': 32, 'confidence': '0.6963440315315248', 'text': 'have'}, {'x': 915, 'y': 609, 'w': 20, 'h': 22, 'confidence': '0.9999504095503653', 'text': 'a'}, {'x': 950, 'y': 606, 'w': 120, 'h': 32, 'confidence': '0.560324721615605', 'text': 'space. |'}, {'x': 615, 'y': 641, 'w': 50, 'h': 16, 'confidence': '0.6937633966413728', 'text': 'M'}, {'x': 31, 'y': 645, 'w': 14, 'h': 22, 'confidence': '0.8700514478734931', 'text': '7'}, {'x': 56, 'y': 640, 'w': 56, 'h': 32, 'confidence': '0.9999980040603199', 'text': 'and'}, {'x': 122, 'y': 640, 'w': 90, 'h': 32, 'confidence': '0.9998978535634702', 'text': 'words'}, {'x': 224, 'y': 644, 'w': 56, 'h': 26, 'confidence': '0.9999988299663297', 'text': 'are'}, {'x': 290, 'y': 638, 'w': 211, 'h': 42, 'confidence': '0.9987136638581579', 'text': 'separated by'}, {'x': 511, 'y': 643, 'w': 94, 'h': 36, 'confidence': '0.5301308874842006', 'text': 'space _'}, {'x': 31, 'y': 747, 'w': 16, 'h': 24, 'confidence': '0.9999547009829826', 'text': '1'}, {'x': 57, 'y': 741, 'w': 360, 'h': 40, 'confidence': '0.6924994749729456', 'text': 'r_splitter.split_text'}, {'x': 426, 'y': 746, 'w': 76, 'h': 30, 'confidence': '0.9996840137938788', 'text': 'some_'}, {'x': 512, 'y': 744, 'w': 74, 'h': 30, 'confidence': '0.7683250489384197', 'text': 'text_'}]}]\n",
      "> Image for page 180: [{'name': 'img_p179_1.png', 'height': 948, 'width': 1424, 'x': 123.42126379199999, 'y': 63.844490232, 'original_width': 1424, 'original_height': 948, 'ocr': [{'x': 41, 'y': 9, 'w': 14, 'h': 24, 'confidence': '0.9999461181269567', 'text': '1'}, {'x': 65, 'y': 2, 'w': 398, 'h': 41, 'confidence': '0.8441782401378369', 'text': 'from Langchain.document_'}, {'x': 471, 'y': 0, 'w': 446, 'h': 42, 'confidence': '0.6905101963185027', 'text': 'loaders import PyPDFLoader'}, {'x': 37, 'y': 45, 'w': 20, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 36, 'y': 82, 'w': 52, 'h': 28, 'confidence': '0.9945616523843356', 'text': '3 #'}, {'x': 100, 'y': 80, 'w': 74, 'h': 32, 'confidence': '0.99998939037323', 'text': 'Load'}, {'x': 184, 'y': 80, 'w': 56, 'h': 32, 'confidence': '0.9997293141566014', 'text': 'PDF'}, {'x': 38, 'y': 118, 'w': 151, 'h': 32, 'confidence': '0.9983936849261925', 'text': '4 loaders'}, {'x': 241, 'y': 121, 'w': 12, 'h': 26, 'confidence': '0.548658309509026', 'text': '['}, {'x': 37, 'y': 157, 'w': 20, 'h': 28, 'confidence': '0.9999997615814351', 'text': '5'}, {'x': 131, 'y': 154, 'w': 362, 'h': 39, 'confidence': '0.8832887630941707', 'text': '# Duplicate documents'}, {'x': 504, 'y': 160, 'w': 40, 'h': 28, 'confidence': '0.9992799548973479', 'text': 'on'}, {'x': 554, 'y': 160, 'w': 124, 'h': 32, 'confidence': '0.9999904479274938', 'text': 'purpose'}, {'x': 721, 'y': 159, 'w': 92, 'h': 32, 'confidence': '0.999993602555785', 'text': 'messy'}, {'x': 824, 'y': 156, 'w': 74, 'h': 32, 'confidence': '0.9968363536070731', 'text': 'data'}, {'x': 39, 'y': 195, 'w': 18, 'h': 28, 'confidence': '0.9999945163801982', 'text': '6'}, {'x': 133, 'y': 193, 'w': 877, 'h': 40, 'confidence': '0.46126454454755744', 'text': 'PyPDFLoader (\"/content MachineLearning_Lecture0l pdf\"'}, {'x': 41, 'y': 235, 'w': 14, 'h': 24, 'confidence': '0.9999940395444042', 'text': '7'}, {'x': 132, 'y': 227, 'w': 901, 'h': 42, 'confidence': '0.6130664585138361', 'text': 'PyPDFLoader (\"/content /MachineLearning_Lecture02_pdf\")'}, {'x': 39, 'y': 271, 'w': 18, 'h': 28, 'confidence': '0.5112871449474305', 'text': '8'}, {'x': 132, 'y': 265, 'w': 903, 'h': 43, 'confidence': '0.6813138453031891', 'text': 'PyPDFLoader (\"/content /MachineLearning_Lecture03_pdf\" )'}, {'x': 39, 'y': 311, 'w': 18, 'h': 26, 'confidence': '0.9999979734431044', 'text': '9'}, {'x': 132, 'y': 303, 'w': 209, 'h': 42, 'confidence': '0.9983129738754423', 'text': 'PyPDFLoader('}, {'x': 351, 'y': 306, 'w': 666, 'h': 39, 'confidence': '0.7405197426525103', 'text': 'Lcontent /MachineLearning_Lecture04_pdf\"'}, {'x': 22, 'y': 348, 'w': 38, 'h': 30, 'confidence': '0.9999996628252286', 'text': '10'}, {'x': 69, 'y': 349, 'w': 14, 'h': 26, 'confidence': '0.2274409546056413', 'text': 'J'}, {'x': 20, 'y': 384, 'w': 118, 'h': 32, 'confidence': '0.999863204302455', 'text': '11 docs'}, {'x': 188, 'y': 384, 'w': 32, 'h': 34, 'confidence': '0.9828637636643445', 'text': '[]'}, {'x': 22, 'y': 422, 'w': 102, 'h': 32, 'confidence': '0.9916074879561975', 'text': '12 for'}, {'x': 136, 'y': 422, 'w': 106, 'h': 32, 'confidence': '0.9937698580672609', 'text': 'loader'}, {'x': 252, 'y': 422, 'w': 38, 'h': 32, 'confidence': '0.9981025707920556', 'text': 'in'}, {'x': 304, 'y': 422, 'w': 134, 'h': 32, 'confidence': '0.9816724942479285', 'text': 'loaders:'}, {'x': 20, 'y': 462, 'w': 40, 'h': 30, 'confidence': '0.9979533411606685', 'text': '13'}, {'x': 134, 'y': 460, 'w': 440, 'h': 32, 'confidence': '0.7562162309730811', 'text': 'docs. extend ( loader. load ( ) )'}, {'x': 37, 'y': 561, 'w': 154, 'h': 38, 'confidence': '0.9960971143908153', 'text': '1 # Split'}, {'x': 36, 'y': 600, 'w': 104, 'h': 32, 'confidence': '0.9957683383046027', 'text': '2 from'}, {'x': 151, 'y': 597, 'w': 1034, 'h': 43, 'confidence': '0.6251884368844953', 'text': 'Langchain.text_splitter import RecursiveCharacterTextSplitter'}, {'x': 35, 'y': 635, 'w': 258, 'h': 43, 'confidence': '0.7482850534088618', 'text': '3 text_splitter'}, {'x': 335, 'y': 637, 'w': 528, 'h': 40, 'confidence': '0.9467243128976975', 'text': 'RecursiveCharacterTextSplitter('}, {'x': 132, 'y': 674, 'w': 177, 'h': 40, 'confidence': '0.9544172987972892', 'text': 'chunk_size'}, {'x': 352, 'y': 673, 'w': 79, 'h': 38, 'confidence': '0.7793181753727383', 'text': '1500_'}, {'x': 36, 'y': 678, 'w': 24, 'h': 66, 'confidence': '0.9959462323897696', 'text': '5'}, {'x': 132, 'y': 711, 'w': 227, 'h': 42, 'confidence': '0.9271349989945761', 'text': 'chunk_overlap'}, {'x': 404, 'y': 714, 'w': 56, 'h': 32, 'confidence': '0.9999989676173402', 'text': '150'}, {'x': 39, 'y': 755, 'w': 18, 'h': 26, 'confidence': '0.9999818802700702', 'text': '6'}, {'x': 41, 'y': 859, 'w': 16, 'h': 24, 'confidence': '0.9999511247884953', 'text': '1'}, {'x': 62, 'y': 846, 'w': 113, 'h': 50, 'confidence': '0.999867672490043', 'text': 'splits'}, {'x': 216, 'y': 850, 'w': 496, 'h': 43, 'confidence': '0.7100217771349865', 'text': 'text_splitter. split_documents'}, {'x': 721, 'y': 853, 'w': 90, 'h': 36, 'confidence': '0.9999858189921423', 'text': 'docs)'}, {'x': 37, 'y': 895, 'w': 20, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 67, 'y': 891, 'w': 174, 'h': 38, 'confidence': '0.7628053280510644', 'text': 'len( splits'}]}]\n",
      "> Image for page 181: [{'name': 'img_p180_1.png', 'height': 290, 'width': 1490, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1490, 'original_height': 290, 'ocr': [{'x': 27, 'y': 49, 'w': 14, 'h': 24, 'confidence': '0.9999647143615675', 'text': '1'}, {'x': 51, 'y': 42, 'w': 396, 'h': 40, 'confidence': '0.7290590848213565', 'text': 'from Langchain.document_'}, {'x': 457, 'y': 42, 'w': 242, 'h': 40, 'confidence': '0.9228785273734994', 'text': 'loaders import'}, {'x': 710, 'y': 44, 'w': 158, 'h': 32, 'confidence': '0.9991173385644204', 'text': 'CSVLoader'}, {'x': 23, 'y': 85, 'w': 20, 'h': 24, 'confidence': '1.0', 'text': '2'}, {'x': 23, 'y': 119, 'w': 138, 'h': 36, 'confidence': '0.6543991669054058', 'text': '3 Loader'}, {'x': 203, 'y': 119, 'w': 482, 'h': 38, 'confidence': '0.7410003275047333', 'text': \"CSVLoader( ' [content [penguins_\"}, {'x': 692, 'y': 124, 'w': 58, 'h': 28, 'confidence': '0.8254640704299133', 'text': 'CSV'}, {'x': 26, 'y': 158, 'w': 98, 'h': 32, 'confidence': '0.9999385818364058', 'text': '4 data'}, {'x': 172, 'y': 158, 'w': 188, 'h': 32, 'confidence': '0.5656698069691617', 'text': 'loader. load'}, {'x': 23, 'y': 193, 'w': 254, 'h': 38, 'confidence': '0.7159061328521961', 'text': '5 embedded_docs'}, {'x': 320, 'y': 190, 'w': 429, 'h': 43, 'confidence': '0.8395951402533469', 'text': 'embedding.embed_documents'}, {'x': 762, 'y': 195, 'w': 307, 'h': 40, 'confidence': '0.8785145997138383', 'text': '[text.page_content'}, {'x': 1080, 'y': 196, 'w': 58, 'h': 32, 'confidence': '0.9999891255764863', 'text': 'for'}, {'x': 1148, 'y': 198, 'w': 72, 'h': 30, 'confidence': '0.9999979734420776', 'text': 'text'}, {'x': 1231, 'y': 193, 'w': 156, 'h': 36, 'confidence': '0.8976483627950907', 'text': 'in data] )'}, {'x': 23, 'y': 235, 'w': 20, 'h': 28, 'confidence': '0.9999814034372889', 'text': '6'}, {'x': 53, 'y': 233, 'w': 292, 'h': 40, 'confidence': '0.5784838003720655', 'text': 'Zen (embedded_docs'}]}]\n",
      "> Image for page 182: []\n",
      "> Image for page 183: [{'name': 'img_p182_1.png', 'height': 544, 'width': 1196, 'x': 12.000000384, 'y': 78.24212848799999, 'original_width': 1196, 'original_height': 544, 'ocr': [{'x': 782, 'y': 82, 'w': 192, 'h': 26, 'confidence': '0.44449267466714587', 'text': '(~0.003530,-0.010379,'}, {'x': 1000, 'y': 82, 'w': 94, 'h': 26, 'confidence': '0.7383236994040405', 'text': '0.005863 ]'}, {'x': 496, 'y': 87, 'w': 171, 'h': 44, 'confidence': '0.8923043873644183', 'text': 'Embedding'}, {'x': 114, 'y': 299, 'w': 958, 'h': 72, 'confidence': '0.7367696794963923', 'text': 'Embedding vector captures content/meaning'}, {'x': 119, 'y': 360, 'w': 996, 'h': 45, 'confidence': '0.9376121094755201', 'text': 'Text with similar content will have similar vectors'}]}]\n",
      "> Image for page 184: [{'name': 'img_p183_1.png', 'height': 482, 'width': 1192, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1192, 'original_height': 482, 'ocr': [{'x': 45, 'y': 47, 'w': 578, 'h': 45, 'confidence': '0.7278167485433551', 'text': '1) My dog Rover likes to chase squirrels:'}, {'x': 43, 'y': 91, 'w': 604, 'h': 40, 'confidence': '0.521177776466334', 'text': '2) Fluffy, my cat, refuses to eat from a can.'}, {'x': 43, 'y': 124, 'w': 804, 'h': 44, 'confidence': '0.8272447436193382', 'text': '3) The Chevy Bolt accelerates to 60 mph in 6.7 seconds:'}, {'x': 69, 'y': 227, 'w': 90, 'h': 36, 'confidence': '0.9999756664391282', 'text': 'My dog'}, {'x': 492, 'y': 222, 'w': 192, 'h': 26, 'confidence': '0.47451631361776475', 'text': '[-0.003530,-0.310379,'}, {'x': 708, 'y': 222, 'w': 94, 'h': 24, 'confidence': '0.9901302780390253', 'text': '0.005863 ]'}, {'x': 1021, 'y': 247, 'w': 152, 'h': 36, 'confidence': '0.9990355180254052', 'text': 'Very similar'}, {'x': 68, 'y': 296, 'w': 116, 'h': 32, 'confidence': '0.7197499734996653', 'text': 'Fluffy, my_'}, {'x': 492, 'y': 292, 'w': 192, 'h': 28, 'confidence': '0.5440149665948454', 'text': '[-0.003540,-0.010369,'}, {'x': 708, 'y': 294, 'w': 94, 'h': 26, 'confidence': '0.5668178043272568', 'text': '0.005265 ]'}, {'x': 1032, 'y': 330, 'w': 134, 'h': 28, 'confidence': '0.9761538793027665', 'text': 'Not similar'}, {'x': 69, 'y': 364, 'w': 131, 'h': 40, 'confidence': '0.589747212241212', 'text': 'The Chevy.'}, {'x': 492, 'y': 364, 'w': 192, 'h': 28, 'confidence': '0.43378877337998445', 'text': '[~0.603530,-0.040329,'}, {'x': 708, 'y': 366, 'w': 94, 'h': 24, 'confidence': '0.8578374570507145', 'text': '0.7058633'}, {'x': 822, 'y': 424, 'w': 134, 'h': 32, 'confidence': '0.6987324174170118', 'text': 'compare'}]}]\n",
      "> Image for page 185: [{'name': 'img_p184_1.png', 'height': 920, 'width': 1320, 'x': 119.02461010799999, 'y': 51.120080375999976, 'original_width': 1320, 'original_height': 920, 'ocr': [{'x': 14, 'y': 17, 'w': 1072, 'h': 50, 'confidence': '0.585479272946087', 'text': 'from Langchain_google_genai import GoogleGenerativeAIEmbeddings'}, {'x': 13, 'y': 94, 'w': 162, 'h': 48, 'confidence': '0.9999915361225326', 'text': 'embedding'}, {'x': 215, 'y': 97, 'w': 986, 'h': 45, 'confidence': '0.7747685448274908', 'text': 'Goog LeGenerativeAIEmbeddings (model-\"models/embedding-001\")'}, {'x': 16, 'y': 204, 'w': 156, 'h': 32, 'confidence': '0.9963590741739372', 'text': 'sentencel'}, {'x': 218, 'y': 204, 'w': 38, 'h': 30, 'confidence': '0.5056605847890944', 'text': '\"i'}, {'x': 269, 'y': 203, 'w': 173, 'h': 38, 'confidence': '0.8669432260878931', 'text': 'like dogs\"'}, {'x': 14, 'y': 240, 'w': 161, 'h': 39, 'confidence': '0.7027594836692457', 'text': 'sentence2'}, {'x': 218, 'y': 242, 'w': 38, 'h': 30, 'confidence': '0.5232606056361774', 'text': '\"i'}, {'x': 269, 'y': 241, 'w': 224, 'h': 36, 'confidence': '0.9679021147600129', 'text': 'like canines\"'}, {'x': 16, 'y': 279, 'w': 157, 'h': 32, 'confidence': '0.9989893266535829', 'text': 'sentence3'}, {'x': 216, 'y': 280, 'w': 76, 'h': 32, 'confidence': '0.999988317489624', 'text': '\"the'}, {'x': 302, 'y': 280, 'w': 124, 'h': 32, 'confidence': '0.9499461892053689', 'text': 'weather'}, {'x': 437, 'y': 277, 'w': 276, 'h': 42, 'confidence': '0.9010583764988485', 'text': 'is ugly outside\"'}, {'x': 16, 'y': 318, 'w': 158, 'h': 32, 'confidence': '0.9982521444047849', 'text': 'sentence4'}, {'x': 304, 'y': 320, 'w': 38, 'h': 30, 'confidence': '0.9916512599808817', 'text': 'is'}, {'x': 353, 'y': 325, 'w': 20, 'h': 22, 'confidence': '0.9999427803595609', 'text': 'a'}, {'x': 470, 'y': 314, 'w': 176, 'h': 45, 'confidence': '0.8543457819519615', 'text': 'companion\"'}, {'x': 15, 'y': 419, 'w': 176, 'h': 40, 'confidence': '0.87237608153381', 'text': 'embedding1'}, {'x': 235, 'y': 418, 'w': 161, 'h': 41, 'confidence': '0.9651062185784348', 'text': 'embedding.'}, {'x': 403, 'y': 419, 'w': 192, 'h': 40, 'confidence': '0.996709859127943', 'text': 'embed_query'}, {'x': 605, 'y': 419, 'w': 172, 'h': 36, 'confidence': '0.986690960981004', 'text': 'sentencel)'}, {'x': 15, 'y': 457, 'w': 176, 'h': 38, 'confidence': '0.8675190601450496', 'text': 'embedding2'}, {'x': 233, 'y': 450, 'w': 164, 'h': 48, 'confidence': '0.9968998084597841', 'text': 'embedding_'}, {'x': 402, 'y': 454, 'w': 193, 'h': 45, 'confidence': '0.9978173818731538', 'text': 'embed_query'}, {'x': 605, 'y': 457, 'w': 172, 'h': 36, 'confidence': '0.682741465662486', 'text': 'sentencez)'}, {'x': 15, 'y': 493, 'w': 176, 'h': 40, 'confidence': '0.9173800036303831', 'text': 'embedding3'}, {'x': 233, 'y': 489, 'w': 533, 'h': 49, 'confidence': '0.6952145957183405', 'text': 'embedding.embed_query (sentence3 _'}, {'x': 15, 'y': 533, 'w': 176, 'h': 38, 'confidence': '0.9598010715649897', 'text': 'embedding4'}, {'x': 236, 'y': 534, 'w': 108, 'h': 32, 'confidence': '0.7735877821125946', 'text': 'embedd_'}, {'x': 401, 'y': 528, 'w': 195, 'h': 49, 'confidence': '0.660525604816128', 'text': 'embed_query'}, {'x': 605, 'y': 533, 'w': 170, 'h': 32, 'confidence': '0.9870627265128268', 'text': 'sentence4)'}, {'x': 15, 'y': 634, 'w': 107, 'h': 38, 'confidence': '0.999300405696274', 'text': 'import'}, {'x': 133, 'y': 639, 'w': 92, 'h': 36, 'confidence': '0.9999825136410351', 'text': 'numpy'}, {'x': 234, 'y': 640, 'w': 38, 'h': 26, 'confidence': '0.9998548493393633', 'text': 'as'}, {'x': 286, 'y': 640, 'w': 40, 'h': 32, 'confidence': '0.9999727732444236', 'text': 'np'}, {'x': 12, 'y': 666, 'w': 413, 'h': 49, 'confidence': '0.7358635088093859', 'text': 'print(np.dot (embeddingl,'}, {'x': 437, 'y': 673, 'w': 190, 'h': 38, 'confidence': '0.7096821701924264', 'text': 'embedding2)'}, {'x': 13, 'y': 707, 'w': 400, 'h': 42, 'confidence': '0.9650800053256722', 'text': 'print(np.dot (embeddingl_'}, {'x': 434, 'y': 706, 'w': 179, 'h': 43, 'confidence': '0.9917230452754636', 'text': 'embedding3'}, {'x': 13, 'y': 746, 'w': 212, 'h': 43, 'confidence': '0.9941868725808529', 'text': 'print(np.dot'}, {'x': 234, 'y': 743, 'w': 396, 'h': 48, 'confidence': '0.6156486457739264', 'text': 'embedding1, embedding4)'}, {'x': 13, 'y': 784, 'w': 410, 'h': 43, 'confidence': '0.8074047616907291', 'text': 'print(np.dot (embedding2 ,'}, {'x': 437, 'y': 787, 'w': 176, 'h': 40, 'confidence': '0.9803109582865981', 'text': 'embedding3'}, {'x': 13, 'y': 821, 'w': 402, 'h': 44, 'confidence': '0.6463085337902976', 'text': 'print(np.dot (embedding2_'}, {'x': 436, 'y': 821, 'w': 179, 'h': 42, 'confidence': '0.9343226174585829', 'text': 'embedding4_'}, {'x': 11, 'y': 857, 'w': 405, 'h': 48, 'confidence': '0.5723527218532298', 'text': 'print(np.dot (embedding3 _'}, {'x': 436, 'y': 859, 'w': 191, 'h': 42, 'confidence': '0.9892172918426694', 'text': 'embedding4)'}, {'x': 219, 'y': 312, 'w': 69, 'h': 46, 'confidence': '0.9990794658660889', 'text': '\"Dog'}, {'x': 383, 'y': 322, 'w': 78, 'h': 28, 'confidence': '0.9999914169311523', 'text': 'good'}, {'x': 338, 'y': 530, 'w': 54, 'h': 44, 'confidence': '0.7122513055801392', 'text': 'ing_'}]}]\n",
      "> Image for page 186: [{'name': 'img_p185_1.png', 'height': 484, 'width': 1094, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1094, 'original_height': 484, 'ocr': [{'x': 153, 'y': 23, 'w': 128, 'h': 38, 'confidence': '0.9999781484684318', 'text': 'create'}, {'x': 655, 'y': 54, 'w': 237, 'h': 30, 'confidence': '0.9995235857983541', 'text': 'Vector Database'}, {'x': 562, 'y': 112, 'w': 186, 'h': 26, 'confidence': '0.40602196413681735', 'text': '(-0.003530,-0.0109,'}, {'x': 782, 'y': 112, 'w': 88, 'h': 26, 'confidence': '0.9960524198688614', 'text': '0.00633]'}, {'x': 562, 'y': 148, 'w': 184, 'h': 28, 'confidence': '0.79954455292311', 'text': '[0.003530,-0.8187'}, {'x': 782, 'y': 148, 'w': 88, 'h': 26, 'confidence': '0.70026146923974', 'text': '0.09633]'}, {'x': 564, 'y': 302, 'w': 186, 'h': 28, 'confidence': '0.7854879837242574', 'text': '[0.472409, -0.4287'}, {'x': 786, 'y': 298, 'w': 89, 'h': 32, 'confidence': '0.741876537265981', 'text': '0.09731]'}, {'x': 260, 'y': 366, 'w': 86, 'h': 26, 'confidence': '0.9999823825152249', 'text': 'chunks'}, {'x': 390, 'y': 366, 'w': 88, 'h': 26, 'confidence': '0.9978810211465401', 'text': 'embed'}, {'x': 598, 'y': 389, 'w': 143, 'h': 36, 'confidence': '0.9999918937518827', 'text': 'embedding'}, {'x': 902, 'y': 394, 'w': 92, 'h': 30, 'confidence': '0.9995841012192015', 'text': 'original'}, {'x': 630, 'y': 422, 'w': 80, 'h': 24, 'confidence': '0.9993542395265045', 'text': 'vector'}, {'x': 903, 'y': 418, 'w': 89, 'h': 30, 'confidence': '0.680914930339034', 'text': 'chunks'}]}]\n",
      "> Image for page 187: []\n",
      "> Image for page 188: [{'name': 'img_p187_1.png', 'height': 354, 'width': 1270, 'x': 12.000000384, 'y': 63.84449023199997, 'original_width': 1270, 'original_height': 354, 'ocr': [{'x': 9, 'y': 33, 'w': 16, 'h': 26, 'confidence': '0.9999918937847383', 'text': '1'}, {'x': 49, 'y': 29, 'w': 60, 'h': 38, 'confidence': '0.9999927733243802', 'text': 'pip'}, {'x': 120, 'y': 30, 'w': 122, 'h': 32, 'confidence': '0.9998147656420702', 'text': 'install'}, {'x': 254, 'y': 30, 'w': 140, 'h': 32, 'confidence': '0.9999497604338294', 'text': 'chromadb'}, {'x': 7, 'y': 127, 'w': 488, 'h': 43, 'confidence': '0.8678187641093592', 'text': '1 from langchain.vectorstores'}, {'x': 505, 'y': 131, 'w': 108, 'h': 38, 'confidence': '0.9563892790321734', 'text': 'import'}, {'x': 624, 'y': 132, 'w': 106, 'h': 32, 'confidence': '0.7880331300414486', 'text': 'Chroma'}, {'x': 7, 'y': 231, 'w': 319, 'h': 40, 'confidence': '0.9678848275584216', 'text': '1 persist_directory'}, {'x': 385, 'y': 231, 'w': 314, 'h': 36, 'confidence': '0.8105735695115832', 'text': 'docs/chroma-demo1/'}, {'x': 7, 'y': 271, 'w': 18, 'h': 28, 'confidence': '0.6788013752850888', 'text': '2'}, {'x': 54, 'y': 276, 'w': 36, 'h': 28, 'confidence': '0.9997025405027827', 'text': 'rm'}, {'x': 185, 'y': 267, 'w': 310, 'h': 40, 'confidence': '0.7618397790740512', 'text': 'Idocs/chroma-demol'}, {'x': 522, 'y': 272, 'w': 24, 'h': 28, 'confidence': '1.0', 'text': '#'}, {'x': 557, 'y': 273, 'w': 106, 'h': 30, 'confidence': '0.9999890012469673', 'text': 'remove'}, {'x': 673, 'y': 269, 'w': 294, 'h': 36, 'confidence': '0.7084874552861176', 'text': 'old database files'}, {'x': 978, 'y': 270, 'w': 40, 'h': 32, 'confidence': '0.9897672501060989', 'text': 'if'}, {'x': 1028, 'y': 276, 'w': 58, 'h': 32, 'confidence': '0.9999971781544015', 'text': 'any'}, {'x': 100, 'y': 275, 'w': 57, 'h': 24, 'confidence': '0.6424973576392066', 'text': '~rf'}]}]\n",
      "> Image for page 189: [{'name': 'img_p188_1.png', 'height': 612, 'width': 1112, 'x': 60.96358462799999, 'y': 62.58858468, 'original_width': 1112, 'original_height': 612, 'ocr': [{'x': 30, 'y': 20, 'w': 100, 'h': 32, 'confidence': '0.9995621702262942', 'text': '1 from'}, {'x': 141, 'y': 15, 'w': 444, 'h': 42, 'confidence': '0.9013525747132648', 'text': 'Langchain.document_loaders'}, {'x': 595, 'y': 19, 'w': 108, 'h': 38, 'confidence': '0.9993220171856309', 'text': 'import'}, {'x': 713, 'y': 17, 'w': 158, 'h': 36, 'confidence': '0.9992673246960427', 'text': 'CSVLoader'}, {'x': 25, 'y': 55, 'w': 88, 'h': 36, 'confidence': '0.9995679194707854', 'text': '2 file'}, {'x': 173, 'y': 55, 'w': 531, 'h': 40, 'confidence': '0.8710477776056327', 'text': 'Lcontent/OutdoorClothingCatalog'}, {'x': 713, 'y': 55, 'w': 78, 'h': 36, 'confidence': '0.9999940395355225', 'text': '1000'}, {'x': 798, 'y': 62, 'w': 58, 'h': 28, 'confidence': '0.45070996210181735', 'text': 'CSV'}, {'x': 29, 'y': 97, 'w': 18, 'h': 26, 'confidence': '0.9999997615814351', 'text': '3'}, {'x': 58, 'y': 96, 'w': 105, 'h': 32, 'confidence': '0.811211083451912', 'text': 'loader'}, {'x': 207, 'y': 90, 'w': 392, 'h': 44, 'confidence': '0.6049555209243439', 'text': 'CSVLoader (file_path-file)'}, {'x': 30, 'y': 198, 'w': 182, 'h': 32, 'confidence': '0.919085950485541', 'text': '1 documents'}, {'x': 260, 'y': 198, 'w': 220, 'h': 32, 'confidence': '0.5200836299487462', 'text': 'loader. load ( )'}, {'x': 29, 'y': 237, 'w': 18, 'h': 26, 'confidence': '0.9999997615814351', 'text': '2'}, {'x': 28, 'y': 274, 'w': 168, 'h': 32, 'confidence': '0.9833730585022828', 'text': '3 vectordb'}, {'x': 241, 'y': 269, 'w': 362, 'h': 42, 'confidence': '0.931140814131112', 'text': 'Chroma. from_documents'}, {'x': 31, 'y': 315, 'w': 16, 'h': 26, 'confidence': '0.999999880790714', 'text': '4'}, {'x': 124, 'y': 312, 'w': 324, 'h': 32, 'confidence': '0.9966024903038523', 'text': 'documents-documents'}, {'x': 29, 'y': 349, 'w': 18, 'h': 28, 'confidence': '0.9999995231628986', 'text': '5'}, {'x': 123, 'y': 347, 'w': 330, 'h': 40, 'confidence': '0.9992106834639168', 'text': 'embedding-embedding'}, {'x': 29, 'y': 389, 'w': 18, 'h': 26, 'confidence': '0.9999814034372889', 'text': '6'}, {'x': 120, 'y': 384, 'w': 601, 'h': 41, 'confidence': '0.8488563791942151', 'text': 'persist_directory-persist_directory'}, {'x': 27, 'y': 425, 'w': 20, 'h': 26, 'confidence': '0.9999996423721633', 'text': '7'}, {'x': 25, 'y': 463, 'w': 122, 'h': 38, 'confidence': '0.8390481215835578', 'text': '8 query'}, {'x': 187, 'y': 459, 'w': 262, 'h': 44, 'confidence': '0.76719766922634', 'text': '\"Please suggest'}, {'x': 461, 'y': 469, 'w': 18, 'h': 24, 'confidence': '0.9999592308385132', 'text': 'a'}, {'x': 493, 'y': 461, 'w': 394, 'h': 40, 'confidence': '0.8166335488149651', 'text': 'shirt with sunblocking\"'}, {'x': 26, 'y': 502, 'w': 102, 'h': 32, 'confidence': '0.97875673099945', 'text': '9 docs'}, {'x': 172, 'y': 499, 'w': 561, 'h': 42, 'confidence': '0.6912197907853719', 'text': 'vectordb. Similarity_search(query)'}, {'x': 11, 'y': 536, 'w': 504, 'h': 44, 'confidence': '0.5760746190327625', 'text': '10 print(docs [0] . page_content)'}]}]\n",
      "> Image for page 190: [{'name': 'img_p189_1.png', 'height': 594, 'width': 1990, 'x': 12.000000384, 'y': 63.84447054695997, 'original_width': 1990, 'original_height': 594, 'ocr': [{'x': 19, 'y': 23, 'w': 86, 'h': 36, 'confidence': '0.9927971841040836', 'text': '1 file'}, {'x': 163, 'y': 23, 'w': 480, 'h': 36, 'confidence': '0.7347386801036729', 'text': 'Icontent/customer_review.CSV'}, {'x': 17, 'y': 61, 'w': 138, 'h': 36, 'confidence': '0.7198418616129644', 'text': '2 loader'}, {'x': 197, 'y': 60, 'w': 392, 'h': 42, 'confidence': '0.6863877609474461', 'text': 'CSVLoader(file_path-file)'}, {'x': 19, 'y': 163, 'w': 118, 'h': 36, 'confidence': '0.8956941072207957', 'text': '1 index'}, {'x': 19, 'y': 269, 'w': 118, 'h': 36, 'confidence': '0.9998377459382041', 'text': '1 query'}, {'x': 146, 'y': 268, 'w': 142, 'h': 32, 'confidence': '0.9496864897814206', 'text': '=\"Please'}, {'x': 299, 'y': 265, 'w': 142, 'h': 36, 'confidence': '0.9908950984062465', 'text': 'list all'}, {'x': 449, 'y': 262, 'w': 210, 'h': 43, 'confidence': '0.9971507028064802', 'text': 'the products'}, {'x': 667, 'y': 264, 'w': 230, 'h': 42, 'confidence': '0.983133763214435', 'text': 'with negative'}, {'x': 907, 'y': 265, 'w': 108, 'h': 36, 'confidence': '0.9999438379406311', 'text': 'review'}, {'x': 1023, 'y': 265, 'w': 144, 'h': 36, 'confidence': '0.9937059283164716', 'text': 'in table'}, {'x': 1175, 'y': 265, 'w': 192, 'h': 36, 'confidence': '0.9980465393191741', 'text': 'format with'}, {'x': 1377, 'y': 262, 'w': 193, 'h': 43, 'confidence': '0.8402258533444498', 'text': 'the product'}, {'x': 1579, 'y': 264, 'w': 143, 'h': 37, 'confidence': '0.7070949996271251', 'text': 'name and'}, {'x': 1731, 'y': 265, 'w': 124, 'h': 36, 'confidence': '0.6539787766669276', 'text': 'review\"'}, {'x': 15, 'y': 305, 'w': 174, 'h': 38, 'confidence': '0.9992701467561236', 'text': '2 response'}, {'x': 19, 'y': 345, 'w': 18, 'h': 26, 'confidence': '0.999999880790714', 'text': '3'}, {'x': 44, 'y': 340, 'w': 459, 'h': 42, 'confidence': '0.5133942244712835', 'text': 'display (Markdown ( response) )'}, {'x': 19, 'y': 447, 'w': 118, 'h': 36, 'confidence': '0.9998295451462128', 'text': '1 query'}, {'x': 147, 'y': 451, 'w': 22, 'h': 20, 'confidence': '0.9976559325035375', 'text': '='}, {'x': 159, 'y': 441, 'w': 131, 'h': 41, 'confidence': '0.9690468659118108', 'text': '\"Please'}, {'x': 299, 'y': 443, 'w': 74, 'h': 36, 'confidence': '0.997524082660675', 'text': 'list'}, {'x': 381, 'y': 440, 'w': 278, 'h': 43, 'confidence': '0.9839925249910109', 'text': 'all the products'}, {'x': 667, 'y': 440, 'w': 230, 'h': 43, 'confidence': '0.8802081002115336', 'text': 'with positive'}, {'x': 907, 'y': 443, 'w': 108, 'h': 36, 'confidence': '0.9998798395824396', 'text': 'review'}, {'x': 1023, 'y': 443, 'w': 144, 'h': 36, 'confidence': '0.9927886496983978', 'text': 'in table'}, {'x': 1175, 'y': 439, 'w': 395, 'h': 44, 'confidence': '0.49777228550932656', 'text': 'format with the product'}, {'x': 1580, 'y': 448, 'w': 74, 'h': 30, 'confidence': '0.9997792840003967', 'text': 'name'}, {'x': 1664, 'y': 444, 'w': 56, 'h': 32, 'confidence': '0.85929936170578', 'text': 'and'}, {'x': 1734, 'y': 446, 'w': 120, 'h': 32, 'confidence': '0.9849446354955684', 'text': 'review\"'}, {'x': 17, 'y': 483, 'w': 172, 'h': 38, 'confidence': '0.999237602396202', 'text': '2 response'}, {'x': 17, 'y': 518, 'w': 306, 'h': 41, 'confidence': '0.623061859827783', 'text': '3 display (Markdown'}, {'x': 333, 'y': 523, 'w': 170, 'h': 36, 'confidence': '0.9820939137943163', 'text': 'response) )'}]}]\n",
      "> Image for page 191: [{'name': 'img_p190_1.png', 'height': 845, 'width': 2048, 'x': 12.000000384, 'y': 78.86811275999997, 'original_width': 2048, 'original_height': 845, 'ocr': [{'x': 57, 'y': 2, 'w': 170, 'h': 61, 'confidence': '0.9981439891053994', 'text': 'Images'}, {'x': 616, 'y': 40, 'w': 150, 'h': 48, 'confidence': '0.672219379424395', 'text': 'Vector'}, {'x': 913, 'y': 19, 'w': 382, 'h': 62, 'confidence': '0.61437959089755', 'text': 'Nearest neighbor'}, {'x': 1444, 'y': 58, 'w': 148, 'h': 48, 'confidence': '0.9999135179206705', 'text': 'Vector'}, {'x': 524, 'y': 94, 'w': 329, 'h': 64, 'confidence': '0.9999909835781579', 'text': 'representation'}, {'x': 1350, 'y': 112, 'w': 329, 'h': 65, 'confidence': '0.9999975149155348', 'text': 'representation'}, {'x': 645, 'y': 191, 'w': 100, 'h': 44, 'confidence': '0.20037336449676688', 'text': '[\"]'}, {'x': 15, 'y': 231, 'w': 257, 'h': 53, 'confidence': '0.991316787730089', 'text': 'Documents'}, {'x': 1457, 'y': 223, 'w': 109, 'h': 57, 'confidence': '0.8871696097845133', 'text': '[-]'}, {'x': 1825, 'y': 206, 'w': 145, 'h': 61, 'confidence': '0.9944669141960721', 'text': 'Query'}, {'x': 638, 'y': 288, 'w': 110, 'h': 60, 'confidence': '0.9169701547640108', 'text': '[-]'}, {'x': 567, 'y': 365, 'w': 250, 'h': 40, 'confidence': '0.9991518597107459', 'text': 'Dense vectors'}, {'x': 228, 'y': 410, 'w': 326, 'h': 52, 'confidence': '0.998911012726621', 'text': 'Transform into'}, {'x': 1487, 'y': 436, 'w': 327, 'h': 55, 'confidence': '0.9879352192176114', 'text': 'Transform into'}, {'x': 76, 'y': 510, 'w': 134, 'h': 50, 'confidence': '0.5824179922177858', 'text': 'Audio'}, {'x': 258, 'y': 457, 'w': 267, 'h': 76, 'confidence': '0.9999955495149051', 'text': 'embedding'}, {'x': 1518, 'y': 485, 'w': 267, 'h': 76, 'confidence': '0.9999957879340005', 'text': 'embedding'}, {'x': 1020, 'y': 622, 'w': 164, 'h': 50, 'confidence': '0.9999955844229748', 'text': 'Results'}, {'x': 915, 'y': 741, 'w': 106, 'h': 66, 'confidence': '0.24266333394522496', 'text': 'FL'}]}]\n",
      "> Image for page 192: [{'name': 'img_p191_1.png', 'height': 1030, 'width': 1142, 'x': 161.606304384, 'y': 61.34055314400001, 'original_width': 1142, 'original_height': 1030, 'ocr': [{'x': 501, 'y': 44, 'w': 279, 'h': 73, 'confidence': '0.9999968608195782', 'text': 'Relevant'}, {'x': 477, 'y': 131, 'w': 328, 'h': 66, 'confidence': '0.9202100263110556', 'text': 'Document'}, {'x': 829, 'y': 267, 'w': 203, 'h': 86, 'confidence': '0.9843827413025606', 'text': 'Query'}]}]\n",
      "> Image for page 193: [{'name': 'img_p192_1.png', 'height': 592, 'width': 1958, 'x': 12.000000384, 'y': 63.84448038947997, 'original_width': 1958, 'original_height': 592, 'ocr': [{'x': 28, 'y': 16, 'w': 84, 'h': 32, 'confidence': '0.9800808926553302', 'text': '1 file'}, {'x': 172, 'y': 16, 'w': 294, 'h': 32, 'confidence': '0.9145072971275002', 'text': 'Icontent/customer'}, {'x': 476, 'y': 16, 'w': 174, 'h': 32, 'confidence': '0.9686645923112757', 'text': 'review. CSV'}, {'x': 25, 'y': 51, 'w': 138, 'h': 36, 'confidence': '0.6024863305274005', 'text': '2 loader'}, {'x': 205, 'y': 53, 'w': 392, 'h': 38, 'confidence': '0.7594108752467009', 'text': 'CSVLoader(file_path-file)'}, {'x': 28, 'y': 156, 'w': 182, 'h': 32, 'confidence': '0.941877543200755', 'text': '1 documents'}, {'x': 257, 'y': 153, 'w': 192, 'h': 36, 'confidence': '0.46817789436478824', 'text': 'Loader. load'}, {'x': 25, 'y': 195, 'w': 20, 'h': 26, 'confidence': '1.0', 'text': '2'}, {'x': 26, 'y': 232, 'w': 168, 'h': 32, 'confidence': '0.981229711749311', 'text': '3 vectordb'}, {'x': 240, 'y': 232, 'w': 358, 'h': 32, 'confidence': '0.9897336668758677', 'text': 'Chroma. from_documents'}, {'x': 27, 'y': 271, 'w': 18, 'h': 26, 'confidence': '0.9999995231628986', 'text': '4'}, {'x': 122, 'y': 270, 'w': 326, 'h': 32, 'confidence': '0.9982573961679223', 'text': 'documents-documents'}, {'x': 25, 'y': 309, 'w': 20, 'h': 28, 'confidence': '0.9999997615814351', 'text': '5'}, {'x': 121, 'y': 305, 'w': 332, 'h': 40, 'confidence': '0.9692230172606832', 'text': 'embedding-embedding_'}, {'x': 25, 'y': 345, 'w': 20, 'h': 28, 'confidence': '0.6067380228501089', 'text': '6'}, {'x': 121, 'y': 342, 'w': 597, 'h': 41, 'confidence': '0.7881986650526905', 'text': 'persist_directory-persist_directory'}, {'x': 27, 'y': 385, 'w': 18, 'h': 26, 'confidence': '0.9826213938082542', 'text': '7'}, {'x': 27, 'y': 423, 'w': 18, 'h': 26, 'confidence': '1.0', 'text': '8'}, {'x': 23, 'y': 459, 'w': 122, 'h': 38, 'confidence': '0.999938451695404', 'text': '9 query'}, {'x': 189, 'y': 457, 'w': 124, 'h': 36, 'confidence': '0.8907536347303994', 'text': '\"Please'}, {'x': 323, 'y': 457, 'w': 74, 'h': 36, 'confidence': '0.9981220364570618', 'text': 'list'}, {'x': 407, 'y': 457, 'w': 58, 'h': 36, 'confidence': '0.999507432041895', 'text': 'all'}, {'x': 475, 'y': 454, 'w': 208, 'h': 43, 'confidence': '0.7641309870069936', 'text': 'the products'}, {'x': 691, 'y': 456, 'w': 230, 'h': 42, 'confidence': '0.7860587955876778', 'text': 'with negative'}, {'x': 931, 'y': 457, 'w': 108, 'h': 36, 'confidence': '0.9307717496234476', 'text': 'review'}, {'x': 1049, 'y': 457, 'w': 142, 'h': 36, 'confidence': '0.884138846393571', 'text': 'in table'}, {'x': 1199, 'y': 454, 'w': 396, 'h': 43, 'confidence': '0.9907035549100458', 'text': 'format with the product'}, {'x': 1603, 'y': 457, 'w': 145, 'h': 37, 'confidence': '0.9893953089175593', 'text': 'name and'}, {'x': 1757, 'y': 457, 'w': 124, 'h': 36, 'confidence': '0.6910215635486583', 'text': 'review\"'}, {'x': 8, 'y': 498, 'w': 118, 'h': 32, 'confidence': '0.9889518738128699', 'text': '10 docs'}, {'x': 171, 'y': 495, 'w': 142, 'h': 36, 'confidence': '0.7979450113603651', 'text': 'vectordb'}, {'x': 338, 'y': 494, 'w': 410, 'h': 44, 'confidence': '0.7798599955049925', 'text': 'similarity_search(query)'}, {'x': 7, 'y': 531, 'w': 506, 'h': 44, 'confidence': '0.8394408616074502', 'text': '11 print(docs [0] . page_content)'}]}]\n",
      "> Image for page 194: [{'name': 'img_p193_1.png', 'height': 662, 'width': 2048, 'x': 12.000000384, 'y': 63.84449023200003, 'original_width': 2048, 'original_height': 662, 'ocr': [{'x': 34, 'y': 8, 'w': 114, 'h': 30, 'confidence': '0.9512864221718516', 'text': '1 texts'}, {'x': 197, 'y': 11, 'w': 14, 'h': 24, 'confidence': '0.8117087807611121', 'text': 'L'}, {'x': 33, 'y': 45, 'w': 18, 'h': 28, 'confidence': '1.0', 'text': '2'}, {'x': 176, 'y': 44, 'w': 54, 'h': 32, 'confidence': '0.9997687339782715', 'text': 'The'}, {'x': 239, 'y': 40, 'w': 302, 'h': 39, 'confidence': '0.7943470524449932', 'text': 'Amanita phalloides'}, {'x': 550, 'y': 44, 'w': 56, 'h': 32, 'confidence': '0.9997933886625265', 'text': 'has'}, {'x': 617, 'y': 49, 'w': 18, 'h': 22, 'confidence': '0.9999618533911416', 'text': 'a'}, {'x': 648, 'y': 38, 'w': 1135, 'h': 45, 'confidence': '0.6942318371638376', 'text': 'large and imposing epigeous (aboveground) fruiting body (basidiocarp)'}, {'x': 31, 'y': 81, 'w': 20, 'h': 28, 'confidence': '0.9999995231628986', 'text': '3'}, {'x': 175, 'y': 81, 'w': 18, 'h': 26, 'confidence': '0.9999470717758072', 'text': 'A'}, {'x': 206, 'y': 80, 'w': 220, 'h': 32, 'confidence': '0.9844586124557423', 'text': 'mushroom with'}, {'x': 437, 'y': 87, 'w': 18, 'h': 22, 'confidence': '0.9999542241566814', 'text': 'a'}, {'x': 467, 'y': 75, 'w': 320, 'h': 44, 'confidence': '0.9115032945414064', 'text': 'large fruiting body'}, {'x': 798, 'y': 82, 'w': 36, 'h': 30, 'confidence': '0.9834757206031103', 'text': 'is'}, {'x': 846, 'y': 80, 'w': 184, 'h': 32, 'confidence': '0.999984149074947', 'text': 'the Amanita'}, {'x': 1041, 'y': 79, 'w': 184, 'h': 38, 'confidence': '0.688231696235645', 'text': 'phalloides.'}, {'x': 1238, 'y': 80, 'w': 72, 'h': 32, 'confidence': '0.9999247789382935', 'text': 'Some'}, {'x': 1320, 'y': 80, 'w': 152, 'h': 32, 'confidence': '0.9993147073201646', 'text': 'varieties'}, {'x': 1484, 'y': 79, 'w': 222, 'h': 33, 'confidence': '0.7997644062634761', 'text': 'are all-white_'}, {'x': 33, 'y': 119, 'w': 20, 'h': 28, 'confidence': '0.9999997615814351', 'text': '4'}, {'x': 156, 'y': 118, 'w': 38, 'h': 28, 'confidence': '0.9982661820435227', 'text': '\"A'}, {'x': 206, 'y': 118, 'w': 220, 'h': 32, 'confidence': '0.7469646669507288', 'text': 'mushroom with'}, {'x': 437, 'y': 123, 'w': 18, 'h': 22, 'confidence': '0.9999226346674881', 'text': 'a'}, {'x': 468, 'y': 111, 'w': 319, 'h': 44, 'confidence': '0.9133627819069018', 'text': 'large fruiting body'}, {'x': 798, 'y': 118, 'w': 36, 'h': 32, 'confidence': '0.9694136217986797', 'text': 'is'}, {'x': 845, 'y': 113, 'w': 380, 'h': 40, 'confidence': '0.8479662778449157', 'text': 'the Amanita phalloides.'}, {'x': 1237, 'y': 117, 'w': 73, 'h': 33, 'confidence': '0.999937891960144', 'text': 'Some'}, {'x': 1320, 'y': 118, 'w': 154, 'h': 32, 'confidence': '0.998587864680635', 'text': 'varieties'}, {'x': 1483, 'y': 115, 'w': 224, 'h': 36, 'confidence': '0.8497201737613939', 'text': 'are all-white'}, {'x': 33, 'y': 157, 'w': 20, 'h': 26, 'confidence': '0.9999997615814351', 'text': '5'}, {'x': 156, 'y': 154, 'w': 38, 'h': 28, 'confidence': '0.998459459006235', 'text': '\"A'}, {'x': 206, 'y': 154, 'w': 220, 'h': 32, 'confidence': '0.7539567288117008', 'text': 'mushroom with'}, {'x': 437, 'y': 161, 'w': 18, 'h': 22, 'confidence': '0.9999543433632461', 'text': 'a'}, {'x': 468, 'y': 149, 'w': 319, 'h': 43, 'confidence': '0.7289037850806149', 'text': 'large fruiting body'}, {'x': 798, 'y': 154, 'w': 36, 'h': 32, 'confidence': '0.9872269776597332', 'text': 'is'}, {'x': 846, 'y': 154, 'w': 54, 'h': 32, 'confidence': '0.9999985546643163', 'text': 'the'}, {'x': 909, 'y': 148, 'w': 316, 'h': 43, 'confidence': '0.9948816424468399', 'text': 'Amanita phalloides.'}, {'x': 1238, 'y': 154, 'w': 72, 'h': 32, 'confidence': '0.9999449253082275', 'text': 'Some'}, {'x': 1320, 'y': 154, 'w': 152, 'h': 32, 'confidence': '0.745384870481909', 'text': 'varieties'}, {'x': 1484, 'y': 153, 'w': 220, 'h': 33, 'confidence': '0.9212482250387111', 'text': 'are all-white'}, {'x': 175, 'y': 193, 'w': 18, 'h': 24, 'confidence': '0.9999023699748797', 'text': 'A'}, {'x': 206, 'y': 192, 'w': 220, 'h': 32, 'confidence': '0.7656263993771242', 'text': 'mushroom with'}, {'x': 437, 'y': 197, 'w': 18, 'h': 22, 'confidence': '0.9947091160503161', 'text': 'a'}, {'x': 468, 'y': 185, 'w': 320, 'h': 45, 'confidence': '0.7030398827194393', 'text': 'large fruiting body'}, {'x': 798, 'y': 192, 'w': 36, 'h': 30, 'confidence': '0.968450574803684', 'text': 'is'}, {'x': 846, 'y': 192, 'w': 54, 'h': 30, 'confidence': '0.9236176609992981', 'text': 'the'}, {'x': 909, 'y': 185, 'w': 316, 'h': 42, 'confidence': '0.9985224144774028', 'text': 'Amanita phalloides.'}, {'x': 1237, 'y': 188, 'w': 235, 'h': 36, 'confidence': '0.9983973907823648', 'text': 'Some varieties'}, {'x': 1484, 'y': 194, 'w': 52, 'h': 26, 'confidence': '0.9999991740938607', 'text': 'are'}, {'x': 1548, 'y': 190, 'w': 156, 'h': 32, 'confidence': '0.9997316418843963', 'text': 'all-white'}, {'x': 30, 'y': 190, 'w': 24, 'h': 66, 'confidence': '0.9399918618055949', 'text': '6'}, {'x': 174, 'y': 228, 'w': 34, 'h': 30, 'confidence': '0.9760976746077947', 'text': 'A.'}, {'x': 220, 'y': 225, 'w': 187, 'h': 40, 'confidence': '0.8903087552302823', 'text': 'phalloides ,'}, {'x': 420, 'y': 228, 'w': 86, 'h': 30, 'confidence': '0.897057921531686', 'text': 'a.k.a'}, {'x': 518, 'y': 228, 'w': 88, 'h': 32, 'confidence': '0.9506013493784318', 'text': 'Death'}, {'x': 700, 'y': 228, 'w': 36, 'h': 32, 'confidence': '0.985419271995664', 'text': 'is'}, {'x': 746, 'y': 232, 'w': 56, 'h': 28, 'confidence': '0.9997249094846751', 'text': 'one'}, {'x': 812, 'y': 228, 'w': 40, 'h': 32, 'confidence': '0.9241913500753962', 'text': 'of'}, {'x': 861, 'y': 223, 'w': 302, 'h': 42, 'confidence': '0.8630190710252359', 'text': 'the most poisonous'}, {'x': 1172, 'y': 228, 'w': 40, 'h': 32, 'confidence': '0.9273410862021367', 'text': 'of'}, {'x': 1222, 'y': 228, 'w': 152, 'h': 32, 'confidence': '0.9903569312658467', 'text': 'all known'}, {'x': 1384, 'y': 228, 'w': 156, 'h': 32, 'confidence': '0.9895487422911008', 'text': 'mushrooms'}, {'x': 1553, 'y': 231, 'w': 48, 'h': 14, 'confidence': '0.4356473214602943', 'text': 'M'}, {'x': 33, 'y': 267, 'w': 18, 'h': 26, 'confidence': '1.0', 'text': '8'}, {'x': 61, 'y': 269, 'w': 14, 'h': 24, 'confidence': '0.16940412833864915', 'text': 'J'}, {'x': 34, 'y': 364, 'w': 164, 'h': 32, 'confidence': '0.765585430673313', 'text': '1 vectordb'}, {'x': 239, 'y': 361, 'w': 398, 'h': 40, 'confidence': '0.5684036404528398', 'text': 'Chroma. from_texts(texts ,'}, {'x': 646, 'y': 359, 'w': 939, 'h': 44, 'confidence': '0.915466330146876', 'text': 'embedding-embedding, persist_directory-persist_directory)'}, {'x': 31, 'y': 397, 'w': 166, 'h': 40, 'confidence': '0.9954148787006947', 'text': '2 question'}, {'x': 238, 'y': 400, 'w': 90, 'h': 32, 'confidence': '0.6064017832539873', 'text': '\"Tell'}, {'x': 338, 'y': 404, 'w': 38, 'h': 26, 'confidence': '0.9999207648442535', 'text': 'me'}, {'x': 388, 'y': 402, 'w': 86, 'h': 30, 'confidence': '0.9999964814062795', 'text': 'about'}, {'x': 484, 'y': 400, 'w': 152, 'h': 30, 'confidence': '0.9997234681768278', 'text': 'mushroom\"'}, {'x': 31, 'y': 437, 'w': 622, 'h': 38, 'confidence': '0.7014578740564373', 'text': '3 vectordb. similarity_search(question,'}, {'x': 666, 'y': 438, 'w': 68, 'h': 32, 'confidence': '0.9677324891090393', 'text': 'k=3)'}, {'x': 13, 'y': 505, 'w': 410, 'h': 40, 'confidence': '0.8974728369868297', 'text': \"[Document (page_content='A\"}, {'x': 434, 'y': 508, 'w': 220, 'h': 32, 'confidence': '0.847133663050977', 'text': 'mushroom with'}, {'x': 667, 'y': 515, 'w': 16, 'h': 22, 'confidence': '0.9998644636306189', 'text': 'a'}, {'x': 695, 'y': 502, 'w': 320, 'h': 44, 'confidence': '0.9413050403787971', 'text': 'large fruiting body'}, {'x': 1026, 'y': 508, 'w': 36, 'h': 32, 'confidence': '0.9764467156922638', 'text': 'is'}, {'x': 1073, 'y': 503, 'w': 380, 'h': 42, 'confidence': '0.9935668835118394', 'text': 'the Amanita phalloides.'}, {'x': 1466, 'y': 508, 'w': 72, 'h': 32, 'confidence': '0.9998433589935303', 'text': 'Some'}, {'x': 1548, 'y': 508, 'w': 152, 'h': 32, 'confidence': '0.999729932987869', 'text': 'varieties'}, {'x': 1710, 'y': 512, 'w': 56, 'h': 28, 'confidence': '0.9999991052683532', 'text': 'are'}, {'x': 1776, 'y': 508, 'w': 202, 'h': 32, 'confidence': '0.8776444733879867', 'text': \"all-white.' \"}, {'x': 25, 'y': 540, 'w': 398, 'h': 39, 'confidence': '0.9518955733774671', 'text': \"Document (page_content='A\"}, {'x': 434, 'y': 542, 'w': 138, 'h': 32, 'confidence': '0.9999368631953398', 'text': 'mushroom'}, {'x': 582, 'y': 542, 'w': 72, 'h': 32, 'confidence': '0.9998719692230225', 'text': 'with'}, {'x': 665, 'y': 547, 'w': 18, 'h': 22, 'confidence': '0.999870185296917', 'text': 'a'}, {'x': 695, 'y': 536, 'w': 320, 'h': 45, 'confidence': '0.9621317464346155', 'text': 'large fruiting body'}, {'x': 1026, 'y': 542, 'w': 36, 'h': 32, 'confidence': '0.9735796364352052', 'text': 'is'}, {'x': 1073, 'y': 537, 'w': 380, 'h': 42, 'confidence': '0.9928933657907972', 'text': 'the Amanita phalloides.'}, {'x': 1466, 'y': 542, 'w': 72, 'h': 32, 'confidence': '0.9999005198478699', 'text': 'Some'}, {'x': 1548, 'y': 542, 'w': 152, 'h': 32, 'confidence': '0.9997245678381181', 'text': 'varieties'}, {'x': 1710, 'y': 546, 'w': 54, 'h': 26, 'confidence': '0.7769407629966736', 'text': 'are'}, {'x': 1776, 'y': 541, 'w': 202, 'h': 33, 'confidence': '0.7849941040759735', 'text': \"all-white.' \"}, {'x': 25, 'y': 574, 'w': 398, 'h': 41, 'confidence': '0.6297558422332638', 'text': \"Document (page_content='A\"}, {'x': 434, 'y': 576, 'w': 220, 'h': 32, 'confidence': '0.8881694835416611', 'text': 'mushroom with'}, {'x': 667, 'y': 583, 'w': 16, 'h': 22, 'confidence': '0.9998945025613217', 'text': 'a'}, {'x': 695, 'y': 571, 'w': 320, 'h': 43, 'confidence': '0.9077566846489599', 'text': 'large fruiting body'}, {'x': 1026, 'y': 576, 'w': 36, 'h': 30, 'confidence': '0.9713327001693934', 'text': 'is'}, {'x': 1074, 'y': 576, 'w': 54, 'h': 30, 'confidence': '0.9999932050704956', 'text': 'the'}, {'x': 1137, 'y': 571, 'w': 306, 'h': 42, 'confidence': '0.7614110499858666', 'text': 'Amanita phalloides_'}, {'x': 1466, 'y': 576, 'w': 72, 'h': 32, 'confidence': '0.9998863339424133', 'text': 'Some'}, {'x': 1548, 'y': 576, 'w': 152, 'h': 32, 'confidence': '0.9997413785925556', 'text': 'varieties'}, {'x': 1710, 'y': 580, 'w': 54, 'h': 26, 'confidence': '0.9995785355567932', 'text': 'are'}, {'x': 1775, 'y': 571, 'w': 218, 'h': 38, 'confidence': '0.7019601404003663', 'text': \"all-white:' ]\"}, {'x': 616, 'y': 224, 'w': 66, 'h': 44, 'confidence': '0.7395939287764345', 'text': 'Cap ,'}]}]\n",
      "> Image for page 195: [{'name': 'img_p194_1.png', 'height': 628, 'width': 1036, 'x': 112.77953116799999, 'y': 61.34055314400001, 'original_width': 1036, 'original_height': 628, 'ocr': [{'x': 106, 'y': 42, 'w': 139, 'h': 55, 'confidence': '0.7359750240287712', 'text': 'Query'}, {'x': 791, 'y': 53, 'w': 108, 'h': 42, 'confidence': '0.9999920725822449', 'text': 'Most'}, {'x': 464, 'y': 92, 'w': 175, 'h': 57, 'confidence': '0.763690907253325', 'text': 'fetch_k'}, {'x': 791, 'y': 101, 'w': 158, 'h': 44, 'confidence': '0.7783801145162341', 'text': 'Diverse'}, {'x': 466, 'y': 152, 'w': 224, 'h': 48, 'confidence': '0.8196749412057961', 'text': 'responses'}, {'x': 471, 'y': 46, 'w': 77, 'h': 60, 'confidence': '0.999394084761213', 'text': 'Top'}]}]\n",
      "> Image for page 196: [{'name': 'img_p195_1.png', 'height': 1452, 'width': 1634, 'x': 163.768706028, 'y': 53.72244266399997, 'original_width': 1634, 'original_height': 1452, 'ocr': [{'x': 260, 'y': 766, 'w': 196, 'h': 350, 'confidence': '0.9527503190857125', 'text': '0'}, {'x': 0, 'y': 972, 'w': 184, 'h': 364, 'confidence': '0.17085691993894342', 'text': '5)'}, {'x': 532, 'y': 934, 'w': 216, 'h': 332, 'confidence': '0.8272247717261769', 'text': '0)'}, {'x': 1177, 'y': 1045, 'w': 276, 'h': 212, 'confidence': '0.37757411959388776', 'text': '6'}]}]\n",
      "> Image for page 197: [{'name': 'img_p196_1.png', 'height': 263, 'width': 2048, 'x': 12.000000384, 'y': 63.84450204302398, 'original_width': 2048, 'original_height': 263, 'ocr': [{'x': 33, 'y': 31, 'w': 16, 'h': 22, 'confidence': '0.9999972581882197', 'text': '1'}, {'x': 58, 'y': 28, 'w': 196, 'h': 28, 'confidence': '0.9032682905869996', 'text': 'vectordb. max'}, {'x': 261, 'y': 23, 'w': 624, 'h': 40, 'confidence': '0.7455796723327713', 'text': 'marginal_relevance_search(question,k-3)'}, {'x': 7, 'y': 90, 'w': 846, 'h': 42, 'confidence': '0.6386195621956868', 'text': 'WARNING: chromadb. segment. impl.vector. local_persistent'}, {'x': 861, 'y': 92, 'w': 388, 'h': 38, 'confidence': '0.747196719498167', 'text': 'hnsw:Number of requested'}, {'x': 1260, 'y': 94, 'w': 114, 'h': 32, 'confidence': '0.9999785979098093', 'text': 'results'}, {'x': 1384, 'y': 94, 'w': 38, 'h': 32, 'confidence': '0.9999938465656626', 'text': '20'}, {'x': 1431, 'y': 92, 'w': 165, 'h': 37, 'confidence': '0.9706404950173022', 'text': 'is greater'}, {'x': 1606, 'y': 94, 'w': 68, 'h': 32, 'confidence': '0.6745187717425782', 'text': 'than'}, {'x': 1684, 'y': 94, 'w': 148, 'h': 32, 'confidence': '0.9382306287021869', 'text': 'number of'}, {'x': 1842, 'y': 93, 'w': 134, 'h': 32, 'confidence': '0.9998617122293207', 'text': 'elements'}, {'x': 1986, 'y': 96, 'w': 36, 'h': 30, 'confidence': '0.9994977308121679', 'text': 'in'}, {'x': 11, 'y': 125, 'w': 370, 'h': 40, 'confidence': '0.777062575061781', 'text': '[Document (page_content='}, {'x': 389, 'y': 131, 'w': 18, 'h': 24, 'confidence': '0.9999116678671705', 'text': 'A'}, {'x': 420, 'y': 128, 'w': 212, 'h': 30, 'confidence': '0.9954109503575161', 'text': 'mushroom with'}, {'x': 641, 'y': 133, 'w': 18, 'h': 22, 'confidence': '0.9999380121300874', 'text': 'a'}, {'x': 671, 'y': 126, 'w': 184, 'h': 38, 'confidence': '0.8897503972295574', 'text': 'large fruit-'}, {'x': 909, 'y': 127, 'w': 72, 'h': 36, 'confidence': '0.9999655485153198', 'text': 'body'}, {'x': 990, 'y': 128, 'w': 36, 'h': 30, 'confidence': '0.9725609483884655', 'text': 'is'}, {'x': 1038, 'y': 128, 'w': 52, 'h': 30, 'confidence': '0.9999949069135972', 'text': 'the'}, {'x': 1099, 'y': 123, 'w': 304, 'h': 40, 'confidence': '0.990569249362973', 'text': 'Amanita phalloides.'}, {'x': 1416, 'y': 128, 'w': 228, 'h': 30, 'confidence': '0.6542375452272253', 'text': 'Some varieties'}, {'x': 1654, 'y': 132, 'w': 50, 'h': 24, 'confidence': '0.999999449395897', 'text': 'are'}, {'x': 1716, 'y': 128, 'w': 198, 'h': 32, 'confidence': '0.45390400844946266', 'text': \"all-white.' _\"}, {'x': 24, 'y': 161, 'w': 131, 'h': 30, 'confidence': '0.9999677574455833', 'text': 'Document'}, {'x': 165, 'y': 159, 'w': 278, 'h': 38, 'confidence': '0.7955044609351211', 'text': \"page_content=' The\"}, {'x': 451, 'y': 155, 'w': 292, 'h': 42, 'confidence': '0.9982719205890405', 'text': 'Amanita phalloides'}, {'x': 752, 'y': 162, 'w': 52, 'h': 30, 'confidence': '0.9999289724060494', 'text': 'has'}, {'x': 846, 'y': 160, 'w': 87, 'h': 38, 'confidence': '0.7254040772192323', 'text': 'large'}, {'x': 941, 'y': 159, 'w': 150, 'h': 38, 'confidence': '0.8284851754075676', 'text': 'and impos'}, {'x': 1145, 'y': 161, 'w': 136, 'h': 36, 'confidence': '0.9998402929116735', 'text': 'epigeous'}, {'x': 1291, 'y': 155, 'w': 432, 'h': 42, 'confidence': '0.9987061232891502', 'text': '(aboveground) fruiting body'}, {'x': 1733, 'y': 158, 'w': 260, 'h': 39, 'confidence': '0.5072894893116402', 'text': \"(basidiocarp . '  _\"}, {'x': 23, 'y': 191, 'w': 358, 'h': 40, 'confidence': '0.9962893155905616', 'text': 'Document (page_content='}, {'x': 388, 'y': 194, 'w': 32, 'h': 28, 'confidence': '0.8640582384125212', 'text': 'A.'}, {'x': 434, 'y': 189, 'w': 179, 'h': 40, 'confidence': '0.9480281994958762', 'text': 'phalloides ,'}, {'x': 626, 'y': 194, 'w': 82, 'h': 28, 'confidence': '0.4713232011914446', 'text': 'a.k.a'}, {'x': 720, 'y': 194, 'w': 86, 'h': 30, 'confidence': '0.5143375401926491', 'text': 'Death'}, {'x': 894, 'y': 196, 'w': 38, 'h': 28, 'confidence': '0.9912156334549659', 'text': 'is'}, {'x': 942, 'y': 196, 'w': 52, 'h': 26, 'confidence': '0.999793732780585', 'text': 'one'}, {'x': 1004, 'y': 194, 'w': 38, 'h': 30, 'confidence': '0.9164486684555866', 'text': 'of'}, {'x': 1052, 'y': 194, 'w': 54, 'h': 30, 'confidence': '0.9999991740938607', 'text': 'the'}, {'x': 1113, 'y': 189, 'w': 230, 'h': 40, 'confidence': '0.9960688430619883', 'text': 'most poisonous'}, {'x': 1352, 'y': 194, 'w': 38, 'h': 30, 'confidence': '0.9099716037928365', 'text': 'of'}, {'x': 1400, 'y': 194, 'w': 54, 'h': 30, 'confidence': '0.9987083673477173', 'text': 'all'}, {'x': 1464, 'y': 194, 'w': 82, 'h': 28, 'confidence': '0.999484137235235', 'text': 'known'}, {'x': 1558, 'y': 194, 'w': 160, 'h': 28, 'confidence': '0.6680251514696212', 'text': 'mushrooms .'}, {'x': 1730, 'y': 194, 'w': 36, 'h': 30, 'confidence': '0.46868517008206995', 'text': '2]'}, {'x': 848, 'y': 124, 'w': 50, 'h': 42, 'confidence': '0.9999867855127385', 'text': 'ing'}, {'x': 1084, 'y': 156, 'w': 52, 'h': 42, 'confidence': '0.9999768058373436', 'text': 'ing'}, {'x': 815, 'y': 189, 'w': 65, 'h': 43, 'confidence': '0.9376560791841599', 'text': 'Cap,'}]}]\n",
      "> Image for page 198: []\n",
      "> Image for page 199: [{'name': 'img_p198_1.png', 'height': 528, 'width': 1278, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1278, 'original_height': 528, 'ocr': [{'x': 273, 'y': 124, 'w': 126, 'h': 40, 'confidence': '0.7154144058183745', 'text': 'Storage'}, {'x': 548, 'y': 126, 'w': 138, 'h': 32, 'confidence': '0.9999613360800286', 'text': 'Retrieval'}, {'x': 910, 'y': 124, 'w': 115, 'h': 40, 'confidence': '0.9968697079638096', 'text': 'Output'}, {'x': 12, 'y': 180, 'w': 128, 'h': 32, 'confidence': '0.9483362500362441', 'text': 'Retrieval'}, {'x': 826, 'y': 202, 'w': 115, 'h': 39, 'confidence': '0.994651134461328', 'text': 'Prompt'}, {'x': 36, 'y': 262, 'w': 132, 'h': 30, 'confidence': '0.9362582303485795', 'text': 'Question'}, {'x': 294, 'y': 270, 'w': 100, 'h': 32, 'confidence': '0.9997405000487375', 'text': 'Vector'}, {'x': 1010, 'y': 272, 'w': 56, 'h': 30, 'confidence': '0.9993122583169569', 'text': 'LLM'}, {'x': 1184, 'y': 260, 'w': 94, 'h': 28, 'confidence': '0.9999327732823603', 'text': 'Answe'}, {'x': 44, 'y': 300, 'w': 107, 'h': 39, 'confidence': '0.722379370628397', 'text': \"'Query'\"}, {'x': 302, 'y': 302, 'w': 82, 'h': 32, 'confidence': '0.9980089886481002', 'text': 'Store'}, {'x': 548, 'y': 330, 'w': 130, 'h': 30, 'confidence': '0.9937769214045165', 'text': 'Relevant'}, {'x': 573, 'y': 363, 'w': 84, 'h': 38, 'confidence': '0.9996595127186276', 'text': 'Splits'}]}]\n",
      "> Image for page 200: [{'name': 'img_p199_1.png', 'height': 466, 'width': 1088, 'x': 12.000000384, 'y': 63.844490232, 'original_width': 1088, 'original_height': 466, 'ocr': [{'x': 30, 'y': 40, 'w': 52, 'h': 28, 'confidence': '0.823085615074684', 'text': '1 #'}, {'x': 90, 'y': 35, 'w': 145, 'h': 42, 'confidence': '0.9999789686309856', 'text': 'question'}, {'x': 277, 'y': 37, 'w': 110, 'h': 36, 'confidence': '0.9999945492939307', 'text': '\"where'}, {'x': 398, 'y': 40, 'w': 38, 'h': 32, 'confidence': '0.9756560268125115', 'text': 'is'}, {'x': 447, 'y': 35, 'w': 161, 'h': 40, 'confidence': '0.8116843398939658', 'text': 'the email'}, {'x': 616, 'y': 35, 'w': 211, 'h': 48, 'confidence': '0.9787083996599619', 'text': 'for support\"'}, {'x': 29, 'y': 74, 'w': 172, 'h': 41, 'confidence': '0.9100990626274715', 'text': '2 question'}, {'x': 243, 'y': 75, 'w': 92, 'h': 36, 'confidence': '0.8873075992730118', 'text': '\"what'}, {'x': 347, 'y': 75, 'w': 242, 'h': 40, 'confidence': '0.9295928650462378', 'text': 'is regression\"'}, {'x': 35, 'y': 183, 'w': 14, 'h': 24, 'confidence': '0.9999721052207775', 'text': '1'}, {'x': 60, 'y': 180, 'w': 72, 'h': 32, 'confidence': '0.9999876618385315', 'text': 'docs'}, {'x': 176, 'y': 176, 'w': 681, 'h': 42, 'confidence': '0.919251806496716', 'text': 'vectordb. Similarity_search(question,k-3)'}, {'x': 35, 'y': 285, 'w': 14, 'h': 24, 'confidence': '0.9999635222900594', 'text': '1'}, {'x': 61, 'y': 279, 'w': 56, 'h': 36, 'confidence': '0.5185659131582359', 'text': 'Len'}, {'x': 127, 'y': 279, 'w': 74, 'h': 36, 'confidence': '0.9998759031295776', 'text': 'docs'}, {'x': 33, 'y': 387, 'w': 16, 'h': 24, 'confidence': '0.999993562708724', 'text': '1'}, {'x': 56, 'y': 377, 'w': 462, 'h': 48, 'confidence': '0.9220729396992546', 'text': 'print(docs [0] . page_content)'}]}]\n",
      "> Image for page 201: []\n",
      "> Image for page 202: [{'name': 'img_p201_1.png', 'height': 772, 'width': 1400, 'x': 58.320868008, 'y': 63.844490232, 'original_width': 1400, 'original_height': 772, 'ocr': [{'x': 674, 'y': 160, 'w': 74, 'h': 26, 'confidence': '0.9999930694352156', 'text': 'Model'}, {'x': 929, 'y': 147, 'w': 80, 'h': 40, 'confidence': '0.999997040503424', 'text': 'LLM'}, {'x': 312, 'y': 193, 'w': 300, 'h': 48, 'confidence': '0.8067169436542819', 'text': 'User Input Context'}, {'x': 638, 'y': 188, 'w': 144, 'h': 28, 'confidence': '0.8913814989286577', 'text': 'Hallucination'}, {'x': 872, 'y': 181, 'w': 193, 'h': 56, 'confidence': '0.9999779858967073', 'text': 'Knowledge'}, {'x': 373, 'y': 239, 'w': 176, 'h': 36, 'confidence': '0.9922168800176222', 'text': 'User Intent'}, {'x': 559, 'y': 373, 'w': 16, 'h': 22, 'confidence': '1.0', 'text': '2'}, {'x': 684, 'y': 360, 'w': 56, 'h': 28, 'confidence': '0.5613725185394287', 'text': 'RAG'}, {'x': 845, 'y': 371, 'w': 18, 'h': 22, 'confidence': '0.9999997615814351', 'text': '3'}, {'x': 494, 'y': 407, 'w': 133, 'h': 31, 'confidence': '0.7400037764077225', 'text': 'Lacks NLG,'}, {'x': 443, 'y': 433, 'w': 228, 'h': 39, 'confidence': '0.8507704190202144', 'text': 'Dialog Management;'}, {'x': 764, 'y': 452, 'w': 182, 'h': 28, 'confidence': '0.9878704635357859', 'text': 'Fine-Tuned LLM'}, {'x': 464, 'y': 466, 'w': 192, 'h': 26, 'confidence': '0.7366752937451237', 'text': 'LLM Backbone &'}, {'x': 501, 'y': 493, 'w': 117, 'h': 29, 'confidence': '0.9999931013825913', 'text': 'Resilience'}, {'x': 540, 'y': 575, 'w': 324, 'h': 48, 'confidence': '0.9944623829291168', 'text': 'External Contextual'}, {'x': 574, 'y': 621, 'w': 255, 'h': 43, 'confidence': '0.7796163645002', 'text': 'Reference Data'}, {'x': 1213, 'y': 747, 'w': 42, 'h': 14, 'confidence': '0.5894631147384644', 'text': 'WWW:'}, {'x': 1250, 'y': 742, 'w': 143, 'h': 20, 'confidence': '0.9334530333458363', 'text': 'cobusgreyling.com'}]}]\n",
      "> Image for page 203: [{'name': 'img_p202_1.png', 'height': 433, 'width': 828, 'x': 59.09449007999999, 'y': 62.58858468, 'original_width': 828, 'original_height': 433, 'ocr': [{'x': 589, 'y': 43, 'w': 62, 'h': 14, 'confidence': '0.9999797694279506', 'text': 'Generate'}, {'x': 169, 'y': 57, 'w': 28, 'h': 16, 'confidence': '0.9999930486261803', 'text': 'Ask'}, {'x': 595, 'y': 61, 'w': 50, 'h': 14, 'confidence': '0.9939550294784327', 'text': 'answer'}, {'x': 359, 'y': 91, 'w': 60, 'h': 16, 'confidence': '0.9999885360299865', 'text': 'Question'}, {'x': 431, 'y': 93, 'w': 56, 'h': 14, 'confidence': '0.9997610903137124', 'text': 'relevant'}, {'x': 387, 'y': 109, 'w': 72, 'h': 14, 'confidence': '0.9999902645509919', 'text': 'documents'}, {'x': 678, 'y': 136, 'w': 129, 'h': 16, 'confidence': '0.8103563696916789', 'text': 'Generated answer based'}, {'x': 41, 'y': 147, 'w': 50, 'h': 14, 'confidence': '0.9938898832805585', 'text': 'Question'}, {'x': 265, 'y': 147, 'w': 70, 'h': 12, 'confidence': '0.9866684689489991', 'text': 'Smart search'}, {'x': 511, 'y': 147, 'w': 28, 'h': 12, 'confidence': '0.9996695760150942', 'text': 'LLM'}, {'x': 681, 'y': 151, 'w': 122, 'h': 12, 'confidence': '0.9848836143413666', 'text': 'on provided documents'}, {'x': 191, 'y': 205, 'w': 42, 'h': 14, 'confidence': '0.3853742984511808', 'text': 'Smart'}, {'x': 325, 'y': 211, 'w': 60, 'h': 16, 'confidence': '0.8735196890946016', 'text': 'Relevant'}, {'x': 187, 'y': 221, 'w': 46, 'h': 16, 'confidence': '0.9903759375042362', 'text': 'lookup'}, {'x': 317, 'y': 229, 'w': 74, 'h': 14, 'confidence': '0.7075116888744468', 'text': 'dlocuments'}, {'x': 227, 'y': 391, 'w': 148, 'h': 14, 'confidence': '0.4569315925646331', 'text': 'Specilic (private) Knowledge'}, {'x': 287, 'y': 405, 'w': 28, 'h': 12, 'confidence': '0.9998250007629395', 'text': 'Base'}]}]\n",
      "> Image for page 204: []\n",
      "> Image for page 205: [{'name': 'img_p204_1.png', 'height': 1112, 'width': 1212, 'x': 180.622053024, 'y': 62.59252168799998, 'original_width': 1212, 'original_height': 1112, 'ocr': [{'x': 105, 'y': 63, 'w': 268, 'h': 36, 'confidence': '0.7366558529490222', 'text': 'RetrievalQA.from'}, {'x': 383, 'y': 61, 'w': 508, 'h': 41, 'confidence': '0.5091758389554379', 'text': 'chain_typel, chain_type=\"stuff\" _)'}, {'x': 196, 'y': 172, 'w': 190, 'h': 48, 'confidence': '0.9999785050115686', 'text': 'Question'}, {'x': 666, 'y': 156, 'w': 524, 'h': 67, 'confidence': '0.7861602160260868', 'text': 'Question is applied to the'}, {'x': 668, 'y': 209, 'w': 478, 'h': 55, 'confidence': '0.5819820516589339', 'text': 'Vector Store as 4 query'}, {'x': 245, 'y': 311, 'w': 84, 'h': 36, 'confidence': '0.9999876849155851', 'text': 'Store'}, {'x': 3, 'y': 429, 'w': 186, 'h': 44, 'confidence': '0.9999923308543349', 'text': 'Relevant'}, {'x': 666, 'y': 404, 'w': 471, 'h': 62, 'confidence': '0.9793294035650109', 'text': 'Vector store provides k'}, {'x': 667, 'y': 459, 'w': 414, 'h': 44, 'confidence': '0.9980764229040366', 'text': 'relevant documents'}, {'x': 670, 'y': 700, 'w': 360, 'h': 56, 'confidence': '0.9302649945419401', 'text': 'Docs and original'}, {'x': 244, 'y': 725, 'w': 126, 'h': 48, 'confidence': '0.9997507803896344', 'text': 'System:'}, {'x': 464, 'y': 730, 'w': 116, 'h': 32, 'confidence': '0.9982014378588548', 'text': 'Human:'}, {'x': 253, 'y': 767, 'w': 110, 'h': 38, 'confidence': '0.9625859173140452', 'text': 'Prompt'}, {'x': 454, 'y': 764, 'w': 135, 'h': 41, 'confidence': '0.6793320733768379', 'text': 'Question'}, {'x': 666, 'y': 745, 'w': 476, 'h': 56, 'confidence': '0.7905743426030065', 'text': 'question are sent to an'}, {'x': 669, 'y': 799, 'w': 78, 'h': 42, 'confidence': '0.999954506472956', 'text': 'LLM'}, {'x': 379, 'y': 943, 'w': 70, 'h': 36, 'confidence': '0.9999857531319064', 'text': 'LLM'}, {'x': 339, 'y': 1073, 'w': 150, 'h': 39, 'confidence': '0.9999731357411576', 'text': 'Answer'}, {'x': 40, 'y': 479, 'w': 118, 'h': 42, 'confidence': '0.9999791218128788', 'text': 'splits'}]}]\n",
      "> Image for page 206: [{'name': 'img_p205_1.png', 'height': 1236, 'width': 1426, 'x': 161.383863432, 'y': 54.438978119999945, 'original_width': 1426, 'original_height': 1236, 'ocr': [{'x': 0, 'y': 19, 'w': 329, 'h': 40, 'confidence': '0.9855851686454556', 'text': '7] persist_directory'}, {'x': 372, 'y': 17, 'w': 295, 'h': 40, 'confidence': '0.9994399718924104', 'text': \"'docs/chroma-rag/\"}, {'x': 52, 'y': 62, 'w': 40, 'h': 28, 'confidence': '0.9996011455271413', 'text': 'rm'}, {'x': 102, 'y': 58, 'w': 54, 'h': 30, 'confidence': '0.9151035063662785', 'text': '~rf'}, {'x': 185, 'y': 57, 'w': 278, 'h': 40, 'confidence': '0.930136564133914', 'text': '[docs/chroma-rag'}, {'x': 524, 'y': 60, 'w': 106, 'h': 30, 'confidence': '0.6591486962341153', 'text': 'remove'}, {'x': 640, 'y': 58, 'w': 209, 'h': 32, 'confidence': '0.9938268012091309', 'text': 'old database'}, {'x': 860, 'y': 58, 'w': 90, 'h': 32, 'confidence': '0.9999731840140172', 'text': 'files'}, {'x': 962, 'y': 58, 'w': 38, 'h': 32, 'confidence': '0.9929167528911742', 'text': 'if'}, {'x': 1011, 'y': 61, 'w': 58, 'h': 36, 'confidence': '0.9999337792396545', 'text': 'any'}, {'x': 0, 'y': 160, 'w': 108, 'h': 32, 'confidence': '0.992355041025494', 'text': '3] from'}, {'x': 119, 'y': 158, 'w': 561, 'h': 40, 'confidence': '0.803929817248264', 'text': 'Langchain.document_loaders import'}, {'x': 692, 'y': 160, 'w': 158, 'h': 32, 'confidence': '0.9991834880895426', 'text': 'CSVLoader'}, {'x': 34, 'y': 198, 'w': 74, 'h': 32, 'confidence': '0.9999752640724182', 'text': 'file'}, {'x': 166, 'y': 193, 'w': 533, 'h': 43, 'confidence': '0.686468816541977', 'text': 'Lcontent/OutdoorClothingCatalog'}, {'x': 710, 'y': 198, 'w': 138, 'h': 32, 'confidence': '0.829654624456595', 'text': '1000.CSV'}, {'x': 36, 'y': 236, 'w': 106, 'h': 32, 'confidence': '0.5893277188086136', 'text': 'loader'}, {'x': 185, 'y': 235, 'w': 425, 'h': 40, 'confidence': '0.6374160702213637', 'text': 'CSVLoader( file_path-file)'}, {'x': 34, 'y': 338, 'w': 156, 'h': 32, 'confidence': '0.9991512484202526', 'text': 'documents'}, {'x': 236, 'y': 335, 'w': 223, 'h': 38, 'confidence': '0.6361332817580724', 'text': 'Loader. Load ( )'}, {'x': 34, 'y': 414, 'w': 142, 'h': 32, 'confidence': '0.9799815935997265', 'text': 'vectordb'}, {'x': 219, 'y': 413, 'w': 362, 'h': 36, 'confidence': '0.8087642271886671', 'text': 'Chroma. from_documents'}, {'x': 101, 'y': 451, 'w': 328, 'h': 36, 'confidence': '0.9951194854430153', 'text': 'documents-documents'}, {'x': 100, 'y': 484, 'w': 159, 'h': 43, 'confidence': '0.9999546204822819', 'text': 'embedding'}, {'x': 301, 'y': 485, 'w': 480, 'h': 44, 'confidence': '0.63589626462844', 'text': 'Goog LeGenerativeAIEmbeddings'}, {'x': 792, 'y': 490, 'w': 110, 'h': 32, 'confidence': '0.813714821482328', 'text': \"model='\"}, {'x': 908, 'y': 483, 'w': 391, 'h': 45, 'confidence': '0.992251968329397', 'text': 'models/embedding-001\") ,'}, {'x': 101, 'y': 527, 'w': 596, 'h': 40, 'confidence': '0.8528003506959713', 'text': 'persist_directory-persist_directory'}, {'x': 33, 'y': 666, 'w': 480, 'h': 41, 'confidence': '0.5351340034260433', 'text': 'from Langchain. chains import'}, {'x': 521, 'y': 667, 'w': 194, 'h': 36, 'confidence': '0.9971517972153576', 'text': 'RetrievalQA'}, {'x': 32, 'y': 703, 'w': 279, 'h': 43, 'confidence': '0.7834750279296006', 'text': 'import Langchain'}, {'x': 0, 'y': 805, 'w': 309, 'h': 42, 'confidence': '0.9624809321249993', 'text': 'L] qa_chain_default'}, {'x': 353, 'y': 807, 'w': 280, 'h': 36, 'confidence': '0.8888296701604795', 'text': 'RetrievalQA. from_'}, {'x': 639, 'y': 803, 'w': 179, 'h': 48, 'confidence': '0.6937487028527569', 'text': 'chain_type'}, {'x': 101, 'y': 843, 'w': 73, 'h': 38, 'confidence': '0.3591162417133285', 'text': '1Lm,'}, {'x': 103, 'y': 883, 'w': 360, 'h': 36, 'confidence': '0.994627380087718', 'text': 'retriever-vectordb.as'}, {'x': 473, 'y': 880, 'w': 559, 'h': 44, 'confidence': '0.8985630879495606', 'text': 'retriever(search_kwargs-{\"k\":3}) ,'}, {'x': 101, 'y': 921, 'w': 308, 'h': 40, 'confidence': '0.7925772418893879', 'text': 'chain_type-\"stuff\"'}, {'x': 102, 'y': 957, 'w': 479, 'h': 44, 'confidence': '0.8505525456756855', 'text': 'return_source_documents-True'}, {'x': 0, 'y': 1096, 'w': 175, 'h': 41, 'confidence': '0.8569412263980911', 'text': '2] question'}, {'x': 217, 'y': 1099, 'w': 262, 'h': 41, 'confidence': '0.763051761854879', 'text': '\"Please suggest'}, {'x': 489, 'y': 1105, 'w': 20, 'h': 24, 'confidence': '0.9999263300159242', 'text': 'a'}, {'x': 521, 'y': 1099, 'w': 90, 'h': 32, 'confidence': '0.9998340380717086', 'text': 'shirt'}, {'x': 621, 'y': 1099, 'w': 296, 'h': 38, 'confidence': '0.8005878302688738', 'text': 'with sunblocking\"'}, {'x': 36, 'y': 1176, 'w': 104, 'h': 32, 'confidence': '0.999958389530123', 'text': 'result'}, {'x': 184, 'y': 1172, 'w': 431, 'h': 44, 'confidence': '0.7631961111189918', 'text': 'qa_chain_default ( {\"query\"'}, {'x': 638, 'y': 1173, 'w': 175, 'h': 40, 'confidence': '0.9999804349966521', 'text': 'question})'}, {'x': 39, 'y': 1219, 'w': 68, 'h': 17, 'confidence': '0.4796186089515686', 'text': 'recu'}]}]\n",
      "> Image for page 207: [{'name': 'img_p206_1.png', 'height': 1216, 'width': 1172, 'x': 184.18898227199998, 'y': 32.017166378880006, 'original_width': 1172, 'original_height': 1216, 'ocr': [{'x': 16, 'y': 10, 'w': 38, 'h': 26, 'confidence': '0.9997237807296394', 'text': 'qa'}, {'x': 91, 'y': 5, 'w': 965, 'h': 37, 'confidence': '0.5332918312641723', 'text': 'ConversationalRetrievalChain from_Ilm( ChatOpenAI(temperature=0) ,'}, {'x': 16, 'y': 40, 'w': 202, 'h': 28, 'confidence': '0.9510832800360802', 'text': 'vectorstore.as'}, {'x': 229, 'y': 37, 'w': 432, 'h': 38, 'confidence': '0.8929889754379998', 'text': 'retriever() , memory=memory)'}, {'x': 222, 'y': 118, 'w': 78, 'h': 32, 'confidence': '0.9999584555625916', 'text': 'Chat'}, {'x': 397, 'y': 129, 'w': 188, 'h': 44, 'confidence': '0.9999187770880734', 'text': 'Question'}, {'x': 202, 'y': 149, 'w': 113, 'h': 48, 'confidence': '0.9091448104508977', 'text': 'History'}, {'x': 244, 'y': 268, 'w': 225, 'h': 40, 'confidence': '0.9999585812234341', 'text': 'Condense LLM'}, {'x': 107, 'y': 321, 'w': 266, 'h': 44, 'confidence': '0.9924158137362676', 'text': 'Stand-alone'}, {'x': 105, 'y': 367, 'w': 193, 'h': 51, 'confidence': '0.5137043828827107', 'text': 'Question'}, {'x': 391, 'y': 411, 'w': 140, 'h': 36, 'confidence': '0.9999968608195782', 'text': 'Retriever'}, {'x': 171, 'y': 525, 'w': 188, 'h': 42, 'confidence': '0.8006834867626673', 'text': 'Relevant'}, {'x': 419, 'y': 827, 'w': 122, 'h': 42, 'confidence': '0.9924157359338182', 'text': 'System:'}, {'x': 640, 'y': 830, 'w': 116, 'h': 32, 'confidence': '0.9991439626385932', 'text': 'Human:'}, {'x': 424, 'y': 866, 'w': 113, 'h': 39, 'confidence': '0.9999388251747016', 'text': 'Prompt'}, {'x': 628, 'y': 865, 'w': 136, 'h': 36, 'confidence': '0.9999978926566547', 'text': 'Question'}, {'x': 553, 'y': 1047, 'w': 70, 'h': 36, 'confidence': '0.9999730204467188', 'text': 'LLM'}, {'x': 511, 'y': 1181, 'w': 154, 'h': 35, 'confidence': '0.9999781484684318', 'text': 'Answer'}, {'x': 208, 'y': 576, 'w': 120, 'h': 41, 'confidence': '0.999991191266332', 'text': 'splits'}]}]\n",
      "> Image for page 208: [{'name': 'img_p207_1.png', 'height': 966, 'width': 1306, 'x': 122.21260233599999, 'y': 45.094489632000034, 'original_width': 1306, 'original_height': 966, 'ocr': [{'x': 19, 'y': 23, 'w': 396, 'h': 43, 'confidence': '0.6330991814678295', 'text': 'from Langchain.document'}, {'x': 425, 'y': 24, 'w': 242, 'h': 40, 'confidence': '0.9145055170054428', 'text': 'loaders import'}, {'x': 677, 'y': 25, 'w': 194, 'h': 38, 'confidence': '0.9323856317939428', 'text': 'PyPDFLoader'}, {'x': 18, 'y': 106, 'w': 24, 'h': 26, 'confidence': '0.9999960660973137', 'text': '#'}, {'x': 54, 'y': 102, 'w': 74, 'h': 32, 'confidence': '0.9999892711639404', 'text': 'Load'}, {'x': 138, 'y': 102, 'w': 56, 'h': 32, 'confidence': '0.9997123148902317', 'text': 'PDF'}, {'x': 22, 'y': 140, 'w': 122, 'h': 32, 'confidence': '0.9933941399231861', 'text': 'loaders'}, {'x': 85, 'y': 176, 'w': 362, 'h': 39, 'confidence': '0.9260704944724465', 'text': '# Duplicate documents'}, {'x': 458, 'y': 182, 'w': 40, 'h': 28, 'confidence': '0.999113682568476', 'text': 'on'}, {'x': 508, 'y': 182, 'w': 124, 'h': 32, 'confidence': '0.9999894116159693', 'text': 'purpose'}, {'x': 676, 'y': 182, 'w': 92, 'h': 32, 'confidence': '0.9999194451623643', 'text': 'messy'}, {'x': 778, 'y': 178, 'w': 74, 'h': 32, 'confidence': '0.9999973343988308', 'text': 'data'}, {'x': 86, 'y': 215, 'w': 903, 'h': 38, 'confidence': '0.29420220075576975', 'text': 'PyPDFLoader( \" [content MachineLearning_Lecture01_pdf\" ) _'}, {'x': 86, 'y': 250, 'w': 904, 'h': 41, 'confidence': '0.7496520953783443', 'text': 'PyPDFLoader (\" /content /MachineLearning_Lecture02_pdf\")'}, {'x': 86, 'y': 290, 'w': 903, 'h': 39, 'confidence': '0.5942004997720277', 'text': 'PyPDFLoader( \"[content /MachineLearning_Lecture03_pdf\") _'}, {'x': 86, 'y': 328, 'w': 898, 'h': 39, 'confidence': '0.6908580558785107', 'text': 'PyPDFLoader( \"[content /MachineLearning_Lecture04_pdf\" )'}, {'x': 23, 'y': 371, 'w': 12, 'h': 26, 'confidence': '0.1819055993332066', 'text': 'J'}, {'x': 20, 'y': 406, 'w': 72, 'h': 32, 'confidence': '0.9999896287918091', 'text': 'docs'}, {'x': 142, 'y': 406, 'w': 32, 'h': 34, 'confidence': '0.9844025075120795', 'text': '[]'}, {'x': 90, 'y': 444, 'w': 106, 'h': 32, 'confidence': '0.993464032899362', 'text': 'loader'}, {'x': 206, 'y': 444, 'w': 38, 'h': 32, 'confidence': '0.9981230428307675', 'text': 'in'}, {'x': 258, 'y': 444, 'w': 134, 'h': 32, 'confidence': '0.9879664743404436', 'text': 'loaders:'}, {'x': 87, 'y': 481, 'w': 428, 'h': 36, 'confidence': '0.501497566020524', 'text': 'docs.extend ( Loader. load ( )'}, {'x': 17, 'y': 583, 'w': 128, 'h': 38, 'confidence': '0.999637000530322', 'text': '# Split'}, {'x': 19, 'y': 619, 'w': 1122, 'h': 43, 'confidence': '0.7143219710431513', 'text': 'from Langchain.text_splitter import RecursiveCharacterTextSplitter'}, {'x': 19, 'y': 654, 'w': 228, 'h': 45, 'confidence': '0.9990977201268239', 'text': 'text_splitter'}, {'x': 289, 'y': 659, 'w': 530, 'h': 38, 'confidence': '0.9321335280169287', 'text': 'RecursiveCharacterTextSplitter('}, {'x': 87, 'y': 697, 'w': 176, 'h': 38, 'confidence': '0.9999457970595533', 'text': 'chunk_size'}, {'x': 307, 'y': 697, 'w': 78, 'h': 36, 'confidence': '0.9460331763428054', 'text': '1500_'}, {'x': 86, 'y': 734, 'w': 226, 'h': 40, 'confidence': '0.931584386507672', 'text': 'chunk_overlap'}, {'x': 358, 'y': 736, 'w': 56, 'h': 32, 'confidence': '0.9999991740938607', 'text': '150'}, {'x': 19, 'y': 875, 'w': 294, 'h': 40, 'confidence': '0.7784742585475173', 'text': 'persist_directory'}, {'x': 371, 'y': 875, 'w': 298, 'h': 38, 'confidence': '0.8043963302848159', 'text': 'docs/chroma-rag2/'}, {'x': 38, 'y': 918, 'w': 40, 'h': 28, 'confidence': '0.9996299707249862', 'text': 'rm'}, {'x': 88, 'y': 914, 'w': 54, 'h': 30, 'confidence': '0.9053580670635997', 'text': '~rf'}, {'x': 171, 'y': 912, 'w': 294, 'h': 39, 'confidence': '0.5504798183920983', 'text': '[docs/chroma-rag2'}, {'x': 490, 'y': 916, 'w': 24, 'h': 28, 'confidence': '0.9999988079074598', 'text': '#'}, {'x': 525, 'y': 911, 'w': 327, 'h': 38, 'confidence': '0.9824336221882877', 'text': 'remove old database'}, {'x': 862, 'y': 914, 'w': 90, 'h': 32, 'confidence': '0.9999675329206558', 'text': 'files'}, {'x': 964, 'y': 914, 'w': 40, 'h': 32, 'confidence': '0.9917943790170219', 'text': 'if'}, {'x': 1014, 'y': 918, 'w': 58, 'h': 32, 'confidence': '0.999995182215476', 'text': 'any'}, {'x': 21, 'y': 441, 'w': 51, 'h': 36, 'confidence': '0.7163252234458923', 'text': 'for'}]}]\n",
      "> Image for page 209: []\n",
      "> Image for page 210: []\n",
      "> Image for page 211: [{'name': 'img_p210_1.png', 'height': 505, 'width': 421, 'x': 485.61025176, 'y': 71.41141960799996, 'original_width': 421, 'original_height': 505, 'ocr': [{'x': 74, 'y': 70, 'w': 268, 'h': 33, 'confidence': '0.8455006782784441', 'text': 'Scan with Singpass app'}, {'x': 170, 'y': 100, 'w': 76, 'h': 26, 'confidence': '0.73178623639161', 'text': 'to log in'}, {'x': 138, 'y': 404, 'w': 140, 'h': 32, 'confidence': '0.6167544165091849', 'text': 'Singpass'}]}]\n",
      "> Image for page 212: []\n",
      "> Image for page 213: [{'name': 'img_p212_2.png', 'height': 343, 'width': 346, 'x': 241.360243944, 'y': 144.83070542198402, 'original_width': 346, 'original_height': 343}]\n",
      "> Image for page 214: [{'name': 'img_p213_2.png', 'height': 200, 'width': 200, 'x': 253.52758685303996, 'y': 136.32287837808, 'original_width': 200, 'original_height': 200}]\n",
      "> Image for page 215: []\n",
      "> Image for page 216: []\n"
     ]
    }
   ],
   "source": [
    "image_dicts = parser.get_images(md_json_objs, download_path=\"data_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pages loaded through llamaparse\n",
    "import re\n",
    "\n",
    "def get_page_number(file_name):\n",
    "    match = re.search(r\"-page-(\\d+)\\.jpg$\", str(file_name))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _get_sorted_image_files(image_dir):\n",
    "    \"\"\"Get image files sorted by page.\"\"\"\n",
    "    raw_files = [f for f in list(Path(image_dir).iterdir()) if f.is_file()]\n",
    "    sorted_files = sorted(raw_files, key=get_page_number)\n",
    "    return sorted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# attach image metadata to the text nodes\n",
    "def get_text_nodes(json_dicts, image_dir=None):\n",
    "    \"\"\"Split docs into nodes, by separator.\"\"\"\n",
    "    nodes = []\n",
    "\n",
    "    image_files = _get_sorted_image_files(image_dir) if image_dir is not None else None\n",
    "    md_texts = [d[\"text\"] for d in json_dicts]\n",
    "\n",
    "    for idx, md_text in enumerate(md_texts):\n",
    "        chunk_metadata = {\"page_num\": idx + 1}\n",
    "        # Check if an image exists for the current index\n",
    "        if idx < len(image_files):\n",
    "            chunk_metadata[\"image_path\"] = str(image_files[idx])\n",
    "        else:\n",
    "            chunk_metadata[\"image_path\"] = None  # No image available for this page\n",
    "        \n",
    "        # if image_files is not None:\n",
    "        #     image_file = image_files[idx]\n",
    "        #     chunk_metadata[\"image_path\"] = str(image_file)\n",
    "        chunk_metadata[\"parsed_text_markdown\"] = md_text\n",
    "        node = TextNode(\n",
    "            text=\"\",\n",
    "            metadata=chunk_metadata,\n",
    "        )\n",
    "        nodes.append(node)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will split into pages\n",
    "text_nodes = get_text_nodes(md_json_list, image_dir=\"data_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_num: 11\n",
      "image_path: data_images\\af26f91b-a611-44b3-91e9-f0684926e6c1-img_p103_1.png\n",
      "parsed_text_markdown:                             Final Assessment\n",
      "  Written Assessment (SAQ) - 1 hr\n",
      "  Practical Performance (PP) - 1 hr\n",
      "\n",
      "                                                                                                            11\n",
      "                        This material belongs to Tertiary Infotech Pte Ltd (UEN: 20120096W). All Rights Reserved\n"
     ]
    }
   ],
   "source": [
    "print(text_nodes[10].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    SummaryIndex,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"storage_nodes_summary\"):\n",
    "    index = SummaryIndex(text_nodes)\n",
    "    # save index to disk\n",
    "    index.set_index_id(\"summary_index\")\n",
    "    index.storage_context.persist(\"./storage_nodes_summary\")\n",
    "else:\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"storage_nodes_summary\")\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context, index_id=\"summary_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of FG Document Data\n",
    "\n",
    "In this section, we focus on extracting structured data from the Facilitator Guide (FG) document. The process involves several key steps:\n",
    "\n",
    "1. **Parsing the FG Document**: We utilize the `LlamaParse` tool to preprocess the content of the FG document. This involves reading the document and converting it into a structured format that can be easily processed.\n",
    "\n",
    "2. **Loading Document Content**: The content of the FG document is loaded using the `Document` class from the `docx` module. This allows us to read the text content of the document and prepare it for further processing.\n",
    "\n",
    "3. **Extracting Structured Data**: Using the OpenAI model, we extract relevant information from the preprocessed content. This includes details such as the course title, TSC proficiency level, learning units, topics, knowledge statements, ability statements, and assessment methods. The extracted data is validated against the `FacilitatorGuideExtraction` Pydantic model to ensure it adheres to the expected schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id a0f4455d-9be6-4f9a-ba62-7f3ccc88d9ba\n",
      "Preprocessed Content:\n",
      "[\n",
      "    {\n",
      "        \"pages\": [\n",
      "            {\n",
      "                \"page\": 1,\n",
      "                \"text\": \"                                    T\\n                              Facilitator Guide\\n                                         For\\n\\nDevelop Artificial Intelligence and Large Language Model (LLM) Applications\\n                                with Google Gemini\\n\\n                           TGS Ref No: TGS-2024042961\\n\\n                                   Conducted by\\n                         TERTIARY INFOTECH PTE. LTD\\n\\n                                 UEN: 201200696W\\n\\n                                     Version 2.0\",\n",
      "                \"images\": [\n",
      "                    {\n",
      "                        \"name\": \"img_p0_1.png\",\n",
      "                        \"height\": 500,\n",
      "                        \"width\": 500,\n",
      "                        \"x\": 225,\n",
      "                        \"y\": 158.30076377952798,\n",
      "                        \"original_width\": 500,\n",
      "                        \"original_height\": 500,\n",
      "                        \"ocr\": [\n",
      "                            {\n",
      "                                \"x\": 121,\n",
      "                                \"y\": 85,\n",
      "                                \"w\": 270,\n",
      "                                \"h\": 335,\n",
      "                                \"confidence\": \"0.8993932957970721\",\n",
      "                                \"text\": \"T\"\n",
      "                            }\n",
      "                        ]\n",
      "                    }\n",
      "                ],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 2,\n",
      "                \"text\": \"Table of Content\\n\\n1. DOCUMENT VERSION CONTROL RECORD\\n2. Course Overview\\n3. Learning Outcomes\\n4. Lesson Plan and Instructional Methods\\n     Instructional methods\\n     Lesson Plan\\n           Day 1\\n           Day 2\\n           Total Hours\\n5. Structure & Duration of Training & Assessment\\n6. Reference\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 2 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.8d83w1huun1u\",\n",
      "                        \"text\": \"1. DOCUMENT VERSION CONTROL RECORD\\t3\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.gjdgxs\",\n",
      "                        \"text\": \"2. Course Overview\\t4\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.30j0zll\",\n",
      "                        \"text\": \"3. Learning Outcomes\\t5\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.3exqfsvu99j6\",\n",
      "                        \"text\": \"4. Lesson Plan and Instructional Methods\\t7\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.vtxrde1pbe1\",\n",
      "                        \"text\": \"Instructional methods\\t7\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.cubmti6uhwb5\",\n",
      "                        \"text\": \"Lesson Plan\\t7\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.188hfdn52qzz\",\n",
      "                        \"text\": \"Day 1\\t7\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.9jl1181qdo4q\",\n",
      "                        \"text\": \"Day 2\\t8\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.jd9t8g9qs0cp\",\n",
      "                        \"text\": \"Total Hours\\t10\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"url\": \"https://docs.google.com/document/d/1Be6mvOZnQtPNsXWxBI8Fa0nVQGxipp-L/edit#heading=h.1fob9te\",\n",
      "                        \"text\": \"5. Structure & Duration of Training & Assessment\\t11\"\n",
      "                    }\n",
      "                ],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 3,\n",
      "                \"text\": \"     1. DOCUMENT VERSION CONTROL RECORD\\n\\n    Version Number                      Effective Date of                       Summary of Included                               Author\\n                                               Release                                    Changes\\n 1.0                               2 Feb 2023                              First version                                   Dr. Alfred Ang\\n                                                                           Added table of content\\n 2.0                               11 Sep 2024                             Added Lesson Plan and                           Tertiary Infotech\\n                                                                           Instructional Methods in\\n                                                                           Section 4\\n\\n     2. Course Overview\\n Skills Framework                                    AER\\n TSC Category                                        Technology Management\\n TSC Code                                            AER-TEM-4026-1.1\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 3 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 4,\n",
      "                \"text\": \" TSC Title                                          Artificial Intelligence Application\\n TSC Description                                    Evaluate the effectiveness and sustainability of artificial\\n                                                    intelligence (AI) workflows for process improvements\\n TSC Proficiency Level                              3\\n Recommended Class Size                             20\\n TSC Abilities and Knowledge\\n TSC Abilities:\\n A1: Analyse algorithms in the AI applications\\n A2: Establish the correlation between design of algorithms and efficiency\\n A3: Identify strengths and limitations of the AI applications\\n A4: Evaluate various AI applications to compare strengths and limitations of the AI applications\\n A5: Assess feasibility of AI applications to the engineering processes\\n A6: Assess improvements on the engineering and maintenance processes\\n\\n TSC Knowledge:\\n K1: Range of AI applications\\n K2: Concepts pertaining to performance effectiveness and analysis\\n K3: Methods of evaluating effectiveness of AI applications\\n K4: Algorithm design and implementation\\n K5: Methods of evaluating process improvements to the engineering processes using AI\\n K6: Applicability of AI in the industry\\n\\n Resources Required\\n    \\u25cf Standard training equipment \\u2013 computer, overhead projector, etc.\\n    \\u25cf Flip chart papers and markers\\n    \\u25cf Paper tape / Blu Tac\\n\\n Abbreviations\\n    \\u25cf Learner\\u2019s Guide (LG)\\n    \\u25cf Facilitator\\u2019s Guide (FG)\\n    \\u25cf Assessment Plan (AP)\\n    \\u25cf Lesson Plan (LP)\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 4 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 5,\n",
      "                \"text\": \"               3. Learning Outcomes\\n              Learning Units (LUs)                            Mapping of Knowledge and Abilities Statements\\n\\n          LU1: Overview of Large                       Topics:\\n          Language Model (LLM)                         Topic 1 Overview of Large Language Model (LLM) (K1, K6, A1,\\n                                                       A3)\\n                                                       \\u25cf What is Large Language Model (LLM)? (A1)\\n                                                       \\u25cf Opportunities LLM applications (K1, A3)\\n                                                       \\u25cf Industrial use cases of LLM applications (K6)\\n\\n                                                       LO1 \\u2013 Analyze the range of LLM applications using Generative AI\\n                                                       (GAI) and identify their industrial use cases.\\n\\n\\n\\n\\n\\nLU2: Multimodal Prompting\\nwith Google Gemini LLM\\n\\n\\n\\n\\n\\n\\nK1: Range of AI applications\\nK6: Applicability of AI in the industry\\nA1: Analyse algorithms in the AI applications\\nA3: Identify strengths and limitations of the AI applications\\nTopics:\\nTopic 2 Multimodal Prompting with Google Gemini LLM (K4,\\nK5, A2, A6)\\n\\u25cf What is Multimodal Prompting ? (A2)\\n\\u25cf Overview of Google Gemini LLM (K4)\\n\\u25cf Testing Google Gemini in Google Bard (K5)\\n\\u25cf Getting Gemini API (A6)\\n\\u25cf Building LLM applications with Gemini (A6)\\n\\n                                                       LO2 \\u2013 Establish Google Gemini GAI designs and assess\\n                                                       improvements on engineering processes.\\n\\n\\n\\n\\n\\n\\n\\n\\nLU3: Building LLM Applications\\nwith Google Gemini LLM\\n\\n\\n\\n\\nK4: Algorithm design and implementation\\nK5: Methods of evaluating process improvements to the\\nengineering processes using AI\\nA2: Establish the correlation between design of algorithms and\\nefficiency\\nA6: Assess improvements on the engineering and maintenance\\nprocesses\\nTopics:\\nTopic 3 Building LLM Applications with Google Gemini LLM\\n(K3, A5)\\n\\u25cf Using Langchain to access Google Gemini API\\n\\u25cf Image Recognition\\n\\u25cf Chat Conversation\\n\\n          Copyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\n          approved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\n          publication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\n          otherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\n          prohibited.\\n\\n          Page 5 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 6,\n",
      "                \"text\": \"                                                           LO3 - Develop LLM applications and assess its feasibility\\n\\n\\n\\n\\nLU4: Implementing Retrieval\\nAugmented Generation (RAG)\\n\\n\\n\\n\\n\\n\\n\\nK3: Methods of evaluating effectiveness of AI applications\\nA5: Assess feasibility of AI applications to the engineering\\nprocesses\\nTopics:\\nTopic 4 Implementing Retrieval Augmented Generation (RAG)\\n(K2, A4)\\n      \\u25cf Overview of LLM driven RAG technology\\n      \\u25cf Document Loading and Splitting\\n      \\u25cf Embedding\\n      \\u25cf Vector Databases\\n      \\u25cf Retrieval\\n      \\u25cf Questioning/Answering\\n\\n                                                           LO4 \\u2013 Evaluate the performance effectiveness of Retrieval\\n                                                           Augmented Generation (RAG)\\n\\n                                                           K2: Concepts pertaining to performance effectiveness and analysis\\n                                                           A4: Evaluate various AI applications to compare strengths and\\n                                                           limitations of the AI applications\\n\\n          Copyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\n          approved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\n          publication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\n          otherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\n          prohibited.\\n\\n          Page 6 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 7,\n",
      "                \"text\": \"     4. Lesson Plan and Instructional Methods\\n\\nInstructional methods\\n     \\u25cf     Lecture\\n     \\u25cf     Didactic Questioning\\n     \\u25cf     Demonstration\\n     \\u25cf     Hands-On Practical\\n\\nLesson Plan\\n\\nDay 1\\n\\n      Time                    Instructions for Facilitator                           Instructional                 Resources\\n                                                                                        Methods\\n\\n  0930hrs \\u2013          AM Digital Attendance\\n  0940hrs\\n  (10 mins)\\n\\n  0940hrs \\u2013          Trainer and Learner Introduction.\\n  1000hrs            Overview of the course structure\\n  (20 mins)\\n\\n  1000hrs \\u2013          Topic 1: Overview of Large Language                          Lecture                      Slide page #,\\n  1110hrs            Models (LLM): What is LLM?                                                                TV, Whiteboard,\\n  (70 mins)                                                                                                    Wi-Fi\\n\\n  1100hrs \\u2013          Morning Break\\n  1110hrs\\n  (10 mins)\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 7 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 8,\n",
      "                \"text\": \" 1120hrs \\u2013           Topic 1: Overview of Large Language                         Lecture, Didactic            Slide page #,\\n 1220hrs             Models (LLM): Opportunities for LLM                         Questioning                  TV, Whiteboard,\\n (60 mins)           applications                                                                             Wi-Fi\\n\\n 1220hrs \\u2013           Topic 1: Overview of Large Language                         Lecture,                     Slide page #,\\n 1300hrs             Models (LLM): Industrial use cases of                       Demonstration                TV, Whiteboard,\\n (40 mins)           LLM applications                                                                         Wi-Fi\\n\\n 1300hrs \\u2013           Lunch Break\\n 1330hrs\\n (30 mins)\\n\\n 1330hrs \\u2013           PM Digital Attendance\\n 1340hrs\\n (10 mins)\\n\\n 1340hrs \\u2013           Topic 2: Multimodal Prompting with                          Lecture,                     Slide page #,\\n 1440hrs             Google Gemini LLM: What is                                  Demonstration                TV, Whiteboard,\\n (60 mins)           Multimodal Prompting?                                                                    Wi-Fi\\n\\n 1440hrs \\u2013           Activity: Group discussion on the                           Peer Sharing\\n 1450hrs             efficiency of multimodal prompting\\n (10 mins)           Facilitator's Guidance:\\n                          \\u25cf     Facilitator will explain and\\n                                demonstrate the activities to\\n                                learners.\\n                          \\u25cf     Facilitators are encouraged to\\n                                invite the learners to share their\\n                                own answers with the class.\\n                          \\u25cf     Facilitators are encouraged to\\n                                share their own personal\\n                                experiences to incorporate real-\\n                                life experiences.\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 8 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 9,\n",
      "                \"text\": \"  1450hrs \\u2013           Topic 2: Multimodal Prompting with                            Lecture, Practical            Slide page #,\\n  1600hrs             Google Gemini LLM: Overview of                                                              TV, Whiteboard,\\n  (70 mins)           Google Gemini LLM                                                                           Wi-Fi\\n\\n  1600hrs \\u2013           Afternoon Break\\n  1610hrs\\n  (10 mins)\\n\\n  1610hrs \\u2013           Topic 2: Multimodal Prompting with                            Demonstration,                Slide page #,\\n  1710hrs             Google Gemini LLM: Testing Google                             Practical                     TV, Whiteboard,\\n  (60 mins)           Gemini in Google Bard                                                                       Wi-Fi\\n\\n  1710hrs \\u2013           Topic 2: Multimodal Prompting with                            Lecture, Practical            Slide page #,\\n  1830hrs             Google Gemini LLM: Getting Gemini                                                           TV, Whiteboard,\\n  (80 mins)           API and building applications                                                               Wi-Fi\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 9 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 10,\n",
      "                \"text\": \"Day 2\\n\\n      Time                    Instructions for Facilitator                           Instructional                 Resources\\n                                                                                         Methods\\n\\n  0930hrs \\u2013           AM Digital Attendance\\n  0940hrs\\n  (10 mins)\\n\\n  0940hrs \\u2013           Topic 3: Building LLM Applications:                         Lecture,                     Slide page #,\\n  1100hrs             Using Langchain to access Google                            Demonstration                TV, Whiteboard,\\n  (80 mins)           Gemini API                                                                               Wi-Fi\\n\\n  1100hrs \\u2013           Morning Break\\n  1110hrs\\n  (10 mins)\\n\\n  1110hrs \\u2013           Topic 3: Building LLM Applications:                         Lecture, Practical           Slide page #,\\n  1220hrs             Image Recognition and Chat                                                               TV, Whiteboard,\\n  (70 mins)           Conversation in LLM applications                                                         Wi-Fi\\n\\n  1220hrs \\u2013           Activity: Group discussion on                               Peer Sharing\\n  1300hrs             feasibility of AI applications\\n  (40 mins)           Facilitator's Guidance:\\n                           \\u25cf    Facilitator will explain and\\n                                demonstrate the activities to\\n                                learners.\\n                           \\u25cf    Facilitators are encouraged to\\n                                invite the learners to share their\\n                                own answers with the class.\\n                           \\u25cf    Facilitators are encouraged to\\n                                share their own personal\\n                                experiences to incorporate real-\\n                                life experiences.\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 10 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 11,\n",
      "                \"text\": \" 1300hrs \\u2013           Lunch Break\\n 1330hrs\\n (30 mins)\\n\\n 1330hrs \\u2013           PM Digital Attendance\\n 1340hrs\\n (10 mins)\\n\\n 1340hrs \\u2013           Topic 4: Implementing Retrieval                             Lecture,                     Slide page #,\\n 1450hrs             Augmented Generation (RAG):                                 Demonstration                TV, Whiteboard,\\n (70 mins)           Overview and technology                                                                  Wi-Fi\\n\\n 1450hrs \\u2013           Activity: Discuss strengths and                             Peer Sharing\\n 1500hrs             limitations of RAG technology\\n (10 mins)           Facilitator's Guidance:\\n                           \\u25cf    Facilitator will explain and\\n                                demonstrate the activities to\\n                                learners.\\n                           \\u25cf    Facilitators are encouraged to\\n                                invite the learners to share their\\n                                own answers with the class.\\n                           \\u25cf    Facilitators are encouraged to\\n                                share their own personal\\n                                experiences to incorporate real-\\n                                life experiences.\\n 1500hrs \\u2013           Topic 4: Implementing Retrieval                             Lecture, Practical           Slide page #,\\n 1530hrs             Augmented Generation (RAG):                                                              TV, Whiteboard,\\n (30 mins)           Document Loading, Embedding, and                                                         Wi-Fi\\n                     Vector Databases\\n\\n 1530hrs \\u2013           Assessment Attendance\\n 1540hrs\\n (10 mins)\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 11 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 12,\n",
      "                \"text\": \" 1540hrs -           Recap & Content Clarification\\n 1610hrs\\n (30 mins)\\n\\n 1610hrs \\u2013           Written Assessment - Short Answer                           WA-SAQ                       Assessment\\n 1710hrs             Questions (WA-SAQ): Assess                                                               Question,\\n (60 mins)           learners' understanding of Linux                                                         Assessment\\n                     concepts. Facilitator's Guidance: Refer                                                  Plan\\n                     to the Assessment Plan Specification to\\n                     conduct the assessment.\\n\\n 1710hrs \\u2013           Practical Performance (PP): Evaluate                        PP                           Assessment\\n 1810hrs             learners' ability to apply Linux concepts                                                Question,\\n (60 mins)           in practical tasks.                                                                      Assessment\\n                                                                                                              Plan\\n\\n 1810hrs \\u2013           Feedback and TRAQOM: Gather\\n 1830hrs             feedback from learners and administer\\n (20 mins)           the TRAQOM survey.\\n\\n     \\u25cf Total Training Hours: 14 hrs\\n     \\u25cf Total Assessment Hours: 2 hrs\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 12 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 13,\n",
      "                \"text\": \"     5. Structure & Duration of Training & Assessment\\n\\n                                                                 Assessment Contact Time\\n          Training Contact Time                           Written                  Written\\n           (inclusive tea breaks)                     Assessment              Assessment                   Total\\n                                                           (Short                    (PP)\\n                                                         Answer)\\n                       14 hrs                                1 hr                    1 hr                 16 hrs\\n\\n     Classroom Training\\n     \\u25cf 0930 hrs to 1800 hrs\\n\\n     Assessment\\n     \\u25cf 1645 hrs to 1745 hrs\\n\\n     Summary of Assessment Requirement:\\n\\n        Learning Outcomes                                                                                       AssessmentMethods\\n        LO1: Analyze the range of LLM applications using Generative AI (GAI)                                 WA(SAQ), PP\\n        and identify their industrial use cases.\\n        LO2: Establish Google Gemini GAI designs and assess improvements                                     WA(SAQ), PP\\n        on engineering processes.\\n        LO3: Develop LLM applications and assess its feasibility                                             WA(SAQ), PP\\n\\n        LO4: Evaluate the performance effectiveness of Retrieval Augmented                                   WA(SAQ), PP\\n        Generation (RAG)\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 13 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            },\n",
      "            {\n",
      "                \"page\": 14,\n",
      "                \"text\": \"      Assessment duration and ratio\\n\\n                                                                                           Ratio\\n                            Method                              Duration              (Assessor :              Remarks\\n                                                                                       Candidate)\\n         Written Assessment, WA-SAQ                                 1 hr          Min: 1:3\\n                                                                                  Max: 1:20\\n         Written Assessment (Practical                              1 hr          Min: 1:3\\n         Performance), WA-PP                                                      Max: 1:20\\n                                                     Total         2 hrs                                                      --\\n\\n      6. Reference\\n           1. Trainer Slides\\n           2. Lesson Plan (LP)\\n           3. Assessment Plan (AP)\\n           4. Assessment Questions and Answers\\n           5. Facilitator Guide (FG)\\n           6. Learner Guide (LG)\\n           7. Course Proposal (CP)\\n\\nCopyright 2024, TERTIARY INFOTECH PTE. LTD. All rights reserved. This document is provided for the explicit use and guidance of trainers\\napproved by Tertiary Infotech Pte Ltd as information resource only. Any other use of this document or parts thereof, including reproduction,\\npublication, distribution, transmission, re-transmission or public showing, or storage in a retrieval system in any form, electronic or\\notherwise, for purposes other than that expressly stated above without the express permission of Tertiary Infotech Pte Ltd is strictly\\nprohibited.\\n\\nPage 14 of 14\",\n",
      "                \"images\": [],\n",
      "                \"charts\": [],\n",
      "                \"items\": [],\n",
      "                \"status\": \"OK\",\n",
      "                \"links\": [],\n",
      "                \"width\": 595.303937007874,\n",
      "                \"height\": 841.889763779528,\n",
      "                \"triggeredAutoMode\": false,\n",
      "                \"structuredData\": null,\n",
      "                \"noStructuredContent\": false,\n",
      "                \"noTextContent\": false\n",
      "            }\n",
      "        ],\n",
      "        \"job_metadata\": {\n",
      "            \"credits_used\": 72.0,\n",
      "            \"job_credits_usage\": 0,\n",
      "            \"job_pages\": 0,\n",
      "            \"job_auto_mode_triggered_pages\": 0,\n",
      "            \"job_is_cache_hit\": true\n",
      "        },\n",
      "        \"job_id\": \"a0f4455d-9be6-4f9a-ba62-7f3ccc88d9ba\",\n",
      "        \"file_path\": \"../input/FG_TGS-2024042961_Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini_v2.docx\"\n",
      "    }\n",
      "]\n",
      "Structured Data:\n",
      "course_title='Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini' tsc_proficiency_level='3' learning_units=[LearningUnit(name='Overview of Large Language Model (LLM)', topics=[Topic(name='Overview of Large Language Model (LLM)', subtopics=['What is Large Language Model (LLM)?', 'Opportunities LLM applications', 'Industrial use cases of LLM applications'], tsc_knowledges=[KnowledgeStatement(id='K1', text='Range of AI applications'), KnowledgeStatement(id='K6', text='Applicability of AI in the industry')], tsc_abilities=[AbilityStatement(id='A1', text='Analyse algorithms in the AI applications'), AbilityStatement(id='A3', text='Identify strengths and limitations of the AI applications')])], learning_outcome='Analyze the range of LLM applications using Generative AI (GAI) and identify their industrial use cases.'), LearningUnit(name='Multimodal Prompting with Google Gemini LLM', topics=[Topic(name='Multimodal Prompting with Google Gemini LLM', subtopics=['What is Multimodal Prompting?', 'Overview of Google Gemini LLM', 'Testing Google Gemini in Google Bard', 'Getting Gemini API', 'Building LLM applications with Gemini'], tsc_knowledges=[KnowledgeStatement(id='K4', text='Algorithm design and implementation'), KnowledgeStatement(id='K5', text='Methods of evaluating process improvements to the engineering processes using AI')], tsc_abilities=[AbilityStatement(id='A2', text='Establish the correlation between design of algorithms and efficiency'), AbilityStatement(id='A6', text='Assess improvements on the engineering and maintenance processes')])], learning_outcome='Establish Google Gemini GAI designs and assess improvements on engineering processes.'), LearningUnit(name='Building LLM Applications with Google Gemini LLM', topics=[Topic(name='Building LLM Applications with Google Gemini LLM', subtopics=['Using Langchain to access Google Gemini API', 'Image Recognition', 'Chat Conversation'], tsc_knowledges=[KnowledgeStatement(id='K3', text='Methods of evaluating effectiveness of AI applications')], tsc_abilities=[AbilityStatement(id='A5', text='Assess feasibility of AI applications to the engineering processes')])], learning_outcome='Develop LLM applications and assess its feasibility.'), LearningUnit(name='Implementing Retrieval Augmented Generation (RAG)', topics=[Topic(name='Implementing Retrieval Augmented Generation (RAG)', subtopics=['Overview of LLM driven RAG technology', 'Document Loading and Splitting', 'Embedding', 'Vector Databases', 'Retrieval', 'Questioning/Answering'], tsc_knowledges=[KnowledgeStatement(id='K2', text='Concepts pertaining to performance effectiveness and analysis')], tsc_abilities=[AbilityStatement(id='A4', text='Evaluate various AI applications to compare strengths and limitations of the AI applications')])], learning_outcome='Evaluate the performance effectiveness of Retrieval Augmented Generation (RAG).')] assessments=[AssessmentMethod(code='WA-SAQ', duration='1 hr'), AssessmentMethod(code='PP', duration='1 hr')]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from docx import Document\n",
    "from typing import Dict, List\n",
    "from llama_parse import LlamaParse\n",
    "import nest_asyncio\n",
    "import os\n",
    "import json\n",
    "\n",
    "# API access to llama-cloud\n",
    "LLAMA_API_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "\n",
    "# Using OpenAI API for embeddings/llms\n",
    "OPENAI_API_KEY = os.getenv(\"TERTIARY_INFOTECH_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "class KnowledgeStatement(BaseModel):\n",
    "    id: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "class AbilityStatement(BaseModel):\n",
    "    id: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "class Topic(BaseModel):\n",
    "    name: str\n",
    "    subtopics: List[str]\n",
    "    tsc_knowledges: List[KnowledgeStatement]\n",
    "    tsc_abilities: List[AbilityStatement]\n",
    "\n",
    "\n",
    "class LearningUnit(BaseModel):\n",
    "    name: str\n",
    "    topics: List[Topic]\n",
    "    learning_outcome: str\n",
    "\n",
    "\n",
    "class AssessmentMethod(BaseModel):\n",
    "    code: str\n",
    "    duration: str\n",
    "    \n",
    "class FacilitatorGuideExtraction(BaseModel):\n",
    "    course_title: str\n",
    "    tsc_proficiency_level: str\n",
    "    learning_units: List[LearningUnit]\n",
    "    assessments: List[AssessmentMethod]  # New field for assessments\n",
    "\n",
    "\n",
    "# Function to load FG document content using LlamaParse\n",
    "def parse_with_llamaparse(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Parses the FG document using LlamaParse to preprocess its content.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the document.\n",
    "\n",
    "    Returns:\n",
    "        str: Preprocessed content of the document as text.\n",
    "    \"\"\"\n",
    "\n",
    "    parser = LlamaParse(\n",
    "        api_key=LLAMA_API_KEY,\n",
    "        result_type=\"markdown\",\n",
    "        show_progress=True,\n",
    "        verbose=True,\n",
    "        num_workers=8,\n",
    "        fast_mode=True,\n",
    "    )\n",
    "\n",
    "    result = parser.get_json_result(file_path)\n",
    "    return result\n",
    "\n",
    "# Function to load FG document content\n",
    "def load_fg_document(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads the content of a Word document.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the document.\n",
    "\n",
    "    Returns:\n",
    "        str: The document's text content.\n",
    "    \"\"\"\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Function to extract structured data from FG document\n",
    "def extract_fg_data(preprocessed_content: str) -> FacilitatorGuideExtraction:\n",
    "    \"\"\"\n",
    "    Extracts relevant information from the FG document using GPT and Pydantic.\n",
    "\n",
    "    Args:\n",
    "        preprocessed_content (str): Preprocessed text content of the FG document.\n",
    "\n",
    "    Returns:\n",
    "        FacilitatorGuideExtraction: Extracted and validated data.\n",
    "    \"\"\"\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"\"\"You are an expert at structured data extraction. Extract the following details from the FG Document:\n",
    "                    - Course Title\n",
    "                    - TSC Proficiency Level\n",
    "                    - Learning Units (LUs):\n",
    "                        * Name of the Learning Unit\n",
    "                        * Topics in the Learning Unit:\n",
    "                            - Name of the Topic\n",
    "                            - Description of the Topic (bullet points or sub-topics)\n",
    "                            - Full Knowledge Statements associated with the topic, including their identifiers and text (e.g., K1: Range of AI applications)\n",
    "                            - Full Ability Statements associated with the topic, including their identifiers and text (e.g., A1: Analyze algorithms in the AI applications)\n",
    "                        * Learning Outcome (LO) for each Learning Unit\n",
    "                    - Assessment Types and Durations:\n",
    "                        * Extract assessment types and their durations in the format:\n",
    "                          {\"code\": \"WA-SAQ\", \"duration\": \"1 hr\"}\n",
    "                          {\"code\": \"PP\", \"duration\": \"0.5 hr\"}\n",
    "                          {\"code\": \"CS\", \"duration\": \"30 mins\"}\n",
    "                        * Interpret abbreviations of assessment methods to their correct types (e.g., \"WA-SAQ,\" \"PP,\" \"CS\").\n",
    "                        * Include total durations if mentioned.\n",
    "\n",
    "                    Return the output in a JSON format that matches the schema provided:\n",
    "                    {\n",
    "                        \"course_title\": \"string\",\n",
    "                        \"tsc_proficiency_level\": \"string\",\n",
    "                        \"learning_units\": [\n",
    "                            {\n",
    "                                \"name\": \"string\",\n",
    "                                \"topics\": [\n",
    "                                    {\n",
    "                                        \"name\": \"string\",\n",
    "                                        \"subtopics\": [\"string\"],\n",
    "                                        \"tsc_knowledges\": [\n",
    "                                            {\"id\": \"string\", \"text\": \"string\"}\n",
    "                                        ],\n",
    "                                        \"tsc_abilities\": [\n",
    "                                            {\"id\": \"string\", \"text\": \"string\"}\n",
    "                                        ]\n",
    "                                    }\n",
    "                                ],\n",
    "                                \"learning_outcome\": \"string\"\n",
    "                            }\n",
    "                        ],\n",
    "                        \"assessments\": [\n",
    "                            {\"code\": \"string\", \"duration\": \"string\"}\n",
    "                        ]\n",
    "                    }\n",
    "                    \"\"\"\n",
    "                ),\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": preprocessed_content},\n",
    "        ],\n",
    "        response_format=FacilitatorGuideExtraction,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the FG document\n",
    "    file_path = r\"../input/FG_TGS-2024042961_Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini_v2.docx\"\n",
    "    \n",
    "    # Parse document content using LlamaParse\n",
    "    try:\n",
    "        parsed_content = parse_with_llamaparse(file_path)\n",
    "        print(\"Preprocessed Content:\")\n",
    "        print(json.dumps(parsed_content, indent=4))\n",
    "    except Exception as e:\n",
    "        print(f\"Error during LlamaParse parsing: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Extract and validate structured data using OpenAI and Pydantic\n",
    "    try:\n",
    "        extracted_data = extract_fg_data(json.dumps(parsed_content))\n",
    "        print(\"Structured Data:\")\n",
    "        print(extracted_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI extraction: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_title='Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini' tsc_proficiency_level='3' learning_units=[LearningUnit(name='Overview of Large Language Model (LLM)', topics=[Topic(name='Overview of Large Language Model (LLM)', subtopics=['What is Large Language Model (LLM)?', 'Opportunities LLM applications', 'Industrial use cases of LLM applications'], tsc_knowledges=[KnowledgeStatement(id='K1', text='Range of AI applications'), KnowledgeStatement(id='K6', text='Applicability of AI in the industry')], tsc_abilities=[AbilityStatement(id='A1', text='Analyse algorithms in the AI applications'), AbilityStatement(id='A3', text='Identify strengths and limitations of the AI applications')])], learning_outcome='Analyze the range of LLM applications using Generative AI (GAI) and identify their industrial use cases.'), LearningUnit(name='Multimodal Prompting with Google Gemini LLM', topics=[Topic(name='Multimodal Prompting with Google Gemini LLM', subtopics=['What is Multimodal Prompting?', 'Overview of Google Gemini LLM', 'Testing Google Gemini in Google Bard', 'Getting Gemini API', 'Building LLM applications with Gemini'], tsc_knowledges=[KnowledgeStatement(id='K4', text='Algorithm design and implementation'), KnowledgeStatement(id='K5', text='Methods of evaluating process improvements to the engineering processes using AI')], tsc_abilities=[AbilityStatement(id='A2', text='Establish the correlation between design of algorithms and efficiency'), AbilityStatement(id='A6', text='Assess improvements on the engineering and maintenance processes')])], learning_outcome='Establish Google Gemini GAI designs and assess improvements on engineering processes.'), LearningUnit(name='Building LLM Applications with Google Gemini LLM', topics=[Topic(name='Building LLM Applications with Google Gemini LLM', subtopics=['Using Langchain to access Google Gemini API', 'Image Recognition', 'Chat Conversation'], tsc_knowledges=[KnowledgeStatement(id='K3', text='Methods of evaluating effectiveness of AI applications')], tsc_abilities=[AbilityStatement(id='A5', text='Assess feasibility of AI applications to the engineering processes')])], learning_outcome='Develop LLM applications and assess its feasibility.'), LearningUnit(name='Implementing Retrieval Augmented Generation (RAG)', topics=[Topic(name='Implementing Retrieval Augmented Generation (RAG)', subtopics=['Overview of LLM driven RAG technology', 'Document Loading and Splitting', 'Embedding', 'Vector Databases', 'Retrieval', 'Questioning/Answering'], tsc_knowledges=[KnowledgeStatement(id='K2', text='Concepts pertaining to performance effectiveness and analysis')], tsc_abilities=[AbilityStatement(id='A4', text='Evaluate various AI applications to compare strengths and limitations of the AI applications')])], learning_outcome='Evaluate the performance effectiveness of Retrieval Augmented Generation (RAG).')] assessments=[AssessmentMethod(code='WA-SAQ', duration='1 hr'), AssessmentMethod(code='PP', duration='1 hr')]\n"
     ]
    }
   ],
   "source": [
    "print(extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Practical Performance Scenario-based Questions (PP)\n",
    "\n",
    "In this section, we focus on generating Practical Performance (PP) scenario-based questions. These questions are designed to assess learners ability to apply their knowledge and skills in realistic, practical situations. The process involves several key steps:## Generating Practical Performance Scenario-based Questions (PP)\n",
    "In this section, we focus on generating Practical Performance (PP) scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario Generation Agent for Practical Performance Assessment\n",
    "\n",
    "The Scenario Generation Agent is designed to create detailed, realistic scenarios specifically for practical performance assessments. By leveraging the provided Learning Outcomes, Course Title, and TSC Proficiency Level, the agent generates comprehensive scenarios that align with the educational goals and proficiency requirements. These scenarios serve as practical contexts for learners to apply their knowledge and skills, ensuring that the learning experience is both relevant and engaging.\n",
    "\n",
    "The agent uses advanced language models to craft scenarios that are approximately 500 words in length, providing sufficient detail to cover the complexities and nuances of real-world situations. These scenarios are tailored to highlight specific organizational challenges, data points, and objectives, making them highly applicable to the learners' future professional environments.\n",
    "\n",
    "Key features of the Scenario Generation Agent include:\n",
    "- **Alignment with Learning Outcomes**: Ensures that the generated scenario directly supports the specified learning outcomes, helping learners achieve the desired educational objectives.\n",
    "- **Relevance to Course Title**: Incorporates elements related to the course title, ensuring that the scenario is contextually appropriate and enhances the overall learning experience.\n",
    "- **TSC Proficiency Level**: Adjusts the complexity and depth of the scenario based on the specified TSC proficiency level, catering to the learners' current skill set and knowledge base.\n",
    "- **Realistic and Practical**: Focuses on creating scenarios that are realistic and practical, providing learners with opportunities to apply their skills in situations that mirror real-world challenges.\n",
    "- **Detailed and Comprehensive**: Generates scenarios that are approximately 500 words long, offering a thorough exploration of the context and challenges, and providing ample material for learners to engage with.\n",
    "\n",
    "By integrating these features, the Scenario Generation Agent ensures that learners are well-prepared to tackle real-world problems, enhancing their ability to apply theoretical knowledge in practical settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "# System prompt tailored for content retrieval and question-answer generation\n",
    "system_prompt = \"\"\"\\\n",
    "You are an instructional design assistant tasked with generating realistic, scenario-based practical performance assessment (PPA) tasks for educational purposes. Your output must focus on hands-on application and skill demonstration in a real-world context.\n",
    "\n",
    "Your Role:\n",
    "1. Develop a realistic and concise scenario for the given Course Title, Learning Outcome (LO), and associated abilities (As). Each scenario must:\n",
    "   - Be relevant to the LO and abilities while addressing specific organizational or practical challenges.\n",
    "   - Provide clear context (e.g., organization type, objectives, and challenges) in 1 paragraph.\n",
    "   - Be hands-on and action-oriented, directly connecting to the skills or abilities being assessed.\n",
    "   - Align with the Bloom's Taxonomy level specified for the LO.\n",
    "\n",
    "2. Highlight Practical Application: The scenario must clearly depict how learners will:\n",
    "   - Apply the targeted skills.\n",
    "   - Solve real-world challenges or meet organizational needs.\n",
    "   - Demonstrate performance relevant to the given abilities.\n",
    "\n",
    "3. If insufficient information is available, create a general but realistic scenario tied to the broader course theme, ensuring it remains educationally valuable.\n",
    "\n",
    "Output Format:\n",
    "[Provide a single paragraph description of the situation, including organization type, objectives, challenges, and the specific task learners must complete. The task should be action-oriented and tied directly to the LO and abilities.]\n",
    "\n",
    "Example Scenario 1:\n",
    "TechRobotics, a company specializing in developing intelligent robots for industrial automation, is conducting a training program to ensure their engineers are proficient in using the Robot Operating System (ROS). The training covers essential skills such as installing ROS, creating simulations, diagnosing communication issues, and controlling robots with ROS packages. As part of the training team, you are responsible for overseeing the use of ROS, diagnosing issues, interpreting specifications, applying corrective actions, and incorporating feedback into operational procedures.\n",
    "\n",
    "Example Scenario 2:\n",
    "GreenEarth Innovations, a sustainable lifestyle brand, is launching a new line of eco-friendly skincare products. The company aims to leverage XiaoHongShu (Little Red Book) to reach a younger, environmentally-conscious audience. The marketing team is tasked with creating an engaging social e-commerce campaign that aligns with the companys strategic goals, monitors campaign performance, analyzes sales and feedback, identifies trends, and engages with customer feedback on social media and forums.\n",
    "\n",
    "Restrictions:\n",
    "- Focus exclusively on the given LO and abilities.\n",
    "- Avoid using unrelated topics or assumptions.\n",
    "- Do not invent abilities or knowledge outside the provided scope.\n",
    "\"\"\"\n",
    "\n",
    "scenario_llm = OpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    llm=scenario_llm,\n",
    "    response_mode=\"compact\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a detailed scenario for the case study\n",
    "def generate_pp_scenario(data: FacilitatorGuideExtraction) -> str:\n",
    "    \"\"\"\n",
    "    Generates a concise, realistic scenario for the practical performance.\n",
    "    Args:\n",
    "        course_title (str): The title of the course.\n",
    "        learning_outcomes (List[str]): A list of learning outcomes.\n",
    "\n",
    "    Returns:\n",
    "        str: A concise scenario for the case study.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the course title and bloom taxonomy level\n",
    "    course_title = data.course_title\n",
    "    bloom_taxonomy_level = data.tsc_proficiency_level\n",
    "\n",
    "    # Extract the learning outcomes as a list of strings\n",
    "    learning_outcomes = [lu.learning_outcome for lu in data.learning_units]\n",
    "    abilities = [ability.text for lu in data.learning_units for topic in lu.topics for ability in topic.tsc_abilities]\n",
    "    \n",
    "    outcomes_text = \"\\n\".join([f\"- {lo}\" for lo in learning_outcomes])\n",
    "    abilities_text = \"\\n\".join([f\"- {ability}\" for ability in abilities])\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are tasked with designing a realistic practical performance assessment scenario for the course '{course_title}'.\\n\\n\"\n",
    "        f\"The scenario should align with the following:\\n\\n\"\n",
    "        f\"Learning Outcomes:\\n{outcomes_text}\\n\\n\"\n",
    "        f\"Abilities:\\n{abilities_text}\\n\\n\"\n",
    "        f\"Bloom's Taxonomy Level:\\n{bloom_taxonomy_level}\\n\\n\"\n",
    "        \"The scenario should describe a company or organization facing practical challenges and provide context for the learners to apply their skills.\\n\"\n",
    "        \"Ensure the scenario is concise (1 paragraph), realistic, and action-oriented, focusing on the summary of tasks learners must perform without requiring extensive deliverables.\"\n",
    "    )\n",
    "    response = scenario_query_engine.query(prompt)\n",
    "    return response.response.strip()\n",
    "\n",
    "# Generate the shared scenario\n",
    "scenario = generate_pp_scenario(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In a rapidly evolving tech landscape, InnovateAI, a mid-sized company specializing in AI-driven solutions for the healthcare sector, is facing challenges in optimizing its patient management system. The company has recently integrated Google Gemini's Generative AI capabilities to enhance its application for real-time patient data analysis and decision support. As part of a project team, you are tasked with analyzing the current LLM applications to identify their strengths and limitations, establishing the design of algorithms that improve efficiency in processing patient data, and assessing the feasibility of these AI applications in streamlining engineering processes. Additionally, you will evaluate the performance effectiveness of the Retrieval Augmented Generation (RAG) model implemented in the system, ensuring that the solutions align with industry standards and enhance overall operational efficiency. Your role will involve hands-on analysis, algorithm design, and performance evaluation to provide actionable insights that drive improvements in the company's healthcare solutions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(scenario))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and Answer Generation Agent\n",
    "\n",
    "The Question and Answer Generation Agent is designed to facilitate the creation of educational content by generating scenario-based questions and answers. This agent operates by taking in a specified Learning Outcome (LO) and its associated abilities, retrieving relevant content, and then generating questions and answers that align with the given scenario and Bloom's Taxonomy level.\n",
    "\n",
    "#### Key Features:\n",
    "1. **Input Handling**:\n",
    "    - **Learning Outcome (LO)**: The specific educational goal that the learners are expected to achieve.\n",
    "    - **Associated Abilities**: The skills or competencies that are linked to the Learning Outcome.\n",
    "\n",
    "2. **Content Retrieval**:\n",
    "    - The agent retrieves content that is relevant to the specified Learning Outcome and its associated abilities. This ensures that the generated questions and answers are contextually appropriate and aligned with the educational objectives.\n",
    "\n",
    "3. **Scenario Alignment**:\n",
    "    - The agent generates a realistic and practical scenario that aligns with the Learning Outcome. This scenario provides a context for the questions and answers, making them more engaging and applicable to real-world situations.\n",
    "\n",
    "4. **Question and Answer Generation**:\n",
    "    - Based on the retrieved content and the generated scenario, the agent formulates questions that require learners to demonstrate their understanding and mastery of the Learning Outcome and associated abilities.\n",
    "    - The answers are crafted to align with Bloom's Taxonomy level, ensuring that they meet the desired cognitive complexity and educational standards.\n",
    "\n",
    "5. **Output**:\n",
    "    - The final output includes the scenario, the question, and the answer, all structured in a clear and concise format. This output can be used directly in educational assessments or as part of instructional materials.\n",
    "\n",
    "By integrating these features, the Question and Answer Generation Agent ensures that the generated educational content is both relevant and effective in achieving the specified learning objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Case Study Scenario-based Questions (CS Scenario-based Questions)\n",
    "\n",
    "In this section, we generate the Case Study assessment questions and answers. Each question is linked to a specific learning outcome and includes a question, an answer, and its associated ability statements, which are structured in a JSON format. The results are then saved to a file for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Learning Outcomes and its associated Ability Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Title: Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini\n",
      "Bloom's Taxonomy Level: 3\n",
      "\n",
      "Learning Outcomes with Abilities:\n",
      "\n",
      "Learning Outcome: Analyze the range of LLM applications using Generative AI (GAI) and identify their industrial use cases.\n",
      "Associated Ability Statements:\n",
      "  - [A1] Analyse algorithms in the AI applications\n",
      "  - [A3] Identify strengths and limitations of the AI applications\n",
      "--------------------\n",
      "Learning Outcome: Establish Google Gemini GAI designs and assess improvements on engineering processes.\n",
      "Associated Ability Statements:\n",
      "  - [A2] Establish the correlation between design of algorithms and efficiency\n",
      "  - [A6] Assess improvements on the engineering and maintenance processes\n",
      "--------------------\n",
      "Learning Outcome: Develop LLM applications and assess its feasibility.\n",
      "Associated Ability Statements:\n",
      "  - [A5] Assess feasibility of AI applications to the engineering processes\n",
      "--------------------\n",
      "Learning Outcome: Evaluate the performance effectiveness of Retrieval Augmented Generation (RAG).\n",
      "Associated Ability Statements:\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the details\n",
    "print(\"Course Title:\", extracted_data.course_title)\n",
    "print(\"Bloom's Taxonomy Level:\", extracted_data.tsc_proficiency_level)\n",
    "print(\"\\nLearning Outcomes with Abilities:\\n\")\n",
    "\n",
    "for learning_unit in extracted_data.learning_units:\n",
    "    print(f\"Learning Outcome: {learning_unit.learning_outcome}\")\n",
    "    print(\"Associated Ability Statements:\")\n",
    "    \n",
    "    # Loop through topics to gather abilities\n",
    "    for topic in learning_unit.topics:\n",
    "        for ability in topic.tsc_abilities:\n",
    "            print(f\"  - [{ability.id}] {ability.text}\")\n",
    "    \n",
    "    print(\"-\" * 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario Generation Agent for Case Study\n",
    "The Scenario Generation Agent is designed to create detailed, realistic scenarios based on specific educational inputs. By leveraging the provided Learning Outcomes, Course Title, and TSC Proficiency Level, the agent generates a comprehensive scenario that aligns with the educational goals and proficiency requirements. This scenario serves as a practical context for learners to apply their knowledge and skills, ensuring that the learning experience is both relevant and engaging.\n",
    "\n",
    "The agent uses advanced language models to craft scenarios that are approximately 500 words in length, providing sufficient detail to cover the complexities and nuances of real-world situations. These scenarios are tailored to highlight specific organizational challenges, data points, and objectives, making them highly applicable to the learners' future professional environments.\n",
    "\n",
    "Key features of the Scenario Generation Agent include:\n",
    "- **Alignment with Learning Outcomes**: Ensures that the generated scenario directly supports the specified learning outcomes, helping learners achieve the desired educational objectives.\n",
    "- **Relevance to Course Title**: Incorporates elements related to the course title, ensuring that the scenario is contextually appropriate and enhances the overall learning experience.\n",
    "- **TSC Proficiency Level**: Adjusts the complexity and depth of the scenario based on the specified TSC proficiency level, catering to the learners' current skill set and knowledge base.\n",
    "- **Realistic and Practical**: Focuses on creating scenarios that are realistic and practical, providing learners with opportunities to apply their skills in situations that mirror real-world challenges.\n",
    "- **Detailed and Comprehensive**: Generates scenarios that are 1-2 paragraphs long, offering a thorough exploration of the context and challenges, and providing ample material for learners to engage with.\n",
    "\n",
    "By integrating these features, the Scenario Generation Agent ensures that learners are well-prepared to tackle real-world problems, enhancing their ability to apply theoretical knowledge in practical settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "# System prompt tailored for content retrieval and question-answer generation\n",
    "system_prompt = \"\"\"\\\n",
    "You are an instructional design assistant tasked with generating concise, realistic, and practical scenario-based question-answer pairs for educational purposes.\n",
    "\n",
    "Your role:\n",
    "1. **Generate a real-world scenario** for the given Course Title and Learning Outcome (LO). The scenario must:\n",
    "   - Be concise (1-2 paragraphs) while clearly describing the organizational challenges or context.\n",
    "   - Align directly with the Learning Outcome and be applicable to the associated abilities.\n",
    "   - Highlight specific organizational data, challenges, and objectives to ensure relevance and practicality.\n",
    "\n",
    "2. Use only the information relevant to the specified Learning Unit, Learning Outcome, and its abilities. Do not include information from unrelated topics.\n",
    "\n",
    "3. Ensure that:\n",
    "   - Each scenario and question-answer pair is realistic, aligned to Bloom's Taxonomy level for the LO, and practically applicable.\n",
    "   - If no relevant content exists, create a general scenario that remains educationally valuable and tied to the broader course theme.\n",
    "\n",
    "**Output Format:**\n",
    "- Tase study scenario have to be at least 500 words long.\n",
    "- You will output your response in the following format. For example:\n",
    "TechFusion, a leading software solutions provider, has been approached by a global bank to develop a new mobile banking application. The bank wants to offer its customers a seamless, secure, and intuitive banking experience on their smartphones. Given the competitive landscape, the bank emphasizes the need for rapid delivery without compromising on quality. TechFusion has recently adopted Agile methodologies with Scrum and DevOps practices and sees this project as an opportunity to showcase its capabilities in these areas.\n",
    "\n",
    "**Restrictions:**\n",
    "- Do not include content from other topics or unrelated slides.\n",
    "- Do not invent abilities or knowledge outside the scope of the LO and its associated abilities.\n",
    "\"\"\"\n",
    "\n",
    "scenario_llm = OpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"PERSONAL_OAI_API_KEY\"), system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    llm=scenario_llm,\n",
    "    response_mode=\"compact\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.9756561110559212 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.006215702531275014 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Generate the shared scenario\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m scenario \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_case_study_scenario\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[86], line 33\u001b[0m, in \u001b[0;36mgenerate_case_study_scenario\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     22\u001b[0m abilities_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mability\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ability \u001b[38;5;129;01min\u001b[39;00m abilities])\n\u001b[0;32m     24\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are tasked with designing a concise, realistic case study scenario for the course \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcourse_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe scenario should align with the following:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsure the scenario is realistic and practical, and keep it to 1-2 paragraphs without markdown elements or formatting.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m )\n\u001b[1;32m---> 33\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mscenario_query_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\base\\base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[1;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:179\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    176\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[0;32m    177\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[0;32m    178\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve(query_bundle)\n\u001b[1;32m--> 179\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_response_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\base.py:241\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[1;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    238\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE,\n\u001b[0;32m    239\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    240\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m--> 241\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    250\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\compact_and_refine.py:43\u001b[0m, in \u001b[0;36mCompactAndRefine.get_response\u001b[1;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m new_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprev_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:179\u001b[0m, in \u001b[0;36mRefine.get_response\u001b[1;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prev_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;66;03m# is an answer, then return it\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_give_response_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;66;03m# refine response if possible\u001b[39;00m\n\u001b[0;32m    184\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refine_response_single(\n\u001b[0;32m    185\u001b[0m             prev_response, query_str, text_chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs\n\u001b[0;32m    186\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:241\u001b[0m, in \u001b[0;36mRefine._give_response_single\u001b[1;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m         structured_response \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m    240\u001b[0m             StructuredRefineResponse,\n\u001b[1;32m--> 241\u001b[0m             \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_text_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    245\u001b[0m         )\n\u001b[0;32m    246\u001b[0m         query_satisfied \u001b[38;5;241m=\u001b[39m structured_response\u001b[38;5;241m.\u001b[39mquery_satisfied\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m query_satisfied:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:85\u001b[0m, in \u001b[0;36mDefaultRefineProgram.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     83\u001b[0m         answer \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mmodel_dump_json()\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StructuredRefineResponse(answer\u001b[38;5;241m=\u001b[39manswer, query_satisfied\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\llms\\llm.py:596\u001b[0m, in \u001b[0;36mLLM.predict\u001b[1;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_chat_model:\n\u001b[0;32m    595\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_messages(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[1;32m--> 596\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:173\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[1;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[0;32m    165\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    166\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m     },\n\u001b[0;32m    171\u001b[0m )\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    175\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[0;32m    176\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    177\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[0;32m    178\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[0;32m    179\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:355\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m     chat_fn \u001b[38;5;241m=\u001b[39m completion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete)\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:106\u001b[0m, in \u001b[0;36mllm_retry_decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     99\u001b[0m retry \u001b[38;5;241m=\u001b[39m create_retry_decorator(\n\u001b[0;32m    100\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[0;32m    101\u001b[0m     random_exponential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m     max_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m    105\u001b[0m )\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:429\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(messages, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse_client:\n\u001b[1;32m--> 429\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m client:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:668\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    667\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1025\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1025\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1025\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1050\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Generate a detailed scenario for the case study\n",
    "def generate_case_study_scenario(data: FacilitatorGuideExtraction) -> str:\n",
    "    \"\"\"\n",
    "    Generates a concise, realistic scenario for the case study.\n",
    "    Args:\n",
    "        course_title (str): The title of the course.\n",
    "        learning_outcomes (List[str]): A list of learning outcomes.\n",
    "\n",
    "    Returns:\n",
    "        str: A concise scenario for the case study.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the course title and bloom taxonomy level\n",
    "    course_title = data.course_title\n",
    "    bloom_taxonomy_level = data.tsc_proficiency_level\n",
    "\n",
    "    # Extract the learning outcomes as a list of strings\n",
    "    learning_outcomes = [lu.learning_outcome for lu in data.learning_units]\n",
    "    abilities = [ability.text for lu in data.learning_units for topic in lu.topics for ability in topic.tsc_abilities]\n",
    "    \n",
    "    outcomes_text = \"\\n\".join([f\"- {lo}\" for lo in learning_outcomes])\n",
    "    abilities_text = \"\\n\".join([f\"- {ability}\" for ability in abilities])\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are tasked with designing a concise, realistic case study scenario for the course '{course_title}'.\\n\\n\"\n",
    "        f\"The scenario should align with the following:\\n\\n\"\n",
    "        f\"Learning Outcomes:\\n{outcomes_text}\\n\\n\"\n",
    "        f\"Abilities:\\n{abilities_text}\\n\\n\"\n",
    "        f\"Bloom's Taxonomy Level:\\n{bloom_taxonomy_level}\\n\\n\"\n",
    "        \"The scenario should describe a company or organization facing challenges related to communication, collaboration, or customer satisfaction. \"\n",
    "        \"Ensure the scenario is realistic and practical, and keep it to 1-2 paragraphs without markdown elements or formatting.\"\n",
    "    )\n",
    "    response = scenario_query_engine.query(prompt)\n",
    "    return response.response.strip()\n",
    "\n",
    "# Generate the shared scenario\n",
    "scenario = generate_case_study_scenario(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TechSolutions Inc., a mid-sized technology consulting firm, has been experiencing significant challenges in managing client communications and project updates. With a growing portfolio of clients, the firm struggles to maintain timely and effective communication, leading to misunderstandings and delays in project deliverables. To address these issues, the management team has decided to explore the implementation of a Large Language Model (LLM) application using Google Gemini. They aim to analyze various LLM applications that can automate client interactions, streamline project updates, and enhance overall customer satisfaction. The team is particularly interested in assessing the feasibility of integrating this technology into their existing workflows and evaluating its potential to improve engineering processes and client engagement.\n",
      "\n",
      "As part of this initiative, the team will analyze the algorithms behind the proposed LLM applications, identify their strengths and limitations, and establish correlations between the design of these algorithms and their efficiency in real-world scenarios. They will also evaluate the performance effectiveness of a Retrieval Augmented Generation (RAG) approach to ensure that the LLM can provide accurate and contextually relevant responses to client inquiries. By the end of the project, TechSolutions Inc. aims to enhance its communication strategies, improve client satisfaction, and ultimately drive better project outcomes.\n"
     ]
    }
   ],
   "source": [
    "print(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "TechSolutions Inc., a mid-sized technology consulting firm, has been experiencing significant challenges in managing client communications and project updates. With a growing portfolio of clients, the firm struggles to maintain timely and effective communication, leading to misunderstandings and delays in project deliverables. To address these issues, the management team has decided to explore the implementation of a Large Language Model (LLM) application using Google Gemini. They aim to analyze various LLM applications that can automate client interactions, streamline project updates, and enhance overall customer satisfaction. The team is particularly interested in assessing the feasibility of integrating this technology into their existing workflows and evaluating its potential to improve engineering processes and client engagement.\n",
       "\n",
       "As part of this initiative, the team will analyze the algorithms behind the proposed LLM applications, identify their strengths and limitations, and establish correlations between the design of these algorithms and their efficiency in real-world scenarios. They will also evaluate the performance effectiveness of a Retrieval Augmented Generation (RAG) approach to ensure that the LLM can provide accurate and contextually relevant responses to client inquiries. By the end of the project, TechSolutions Inc. aims to enhance its communication strategies, improve client satisfaction, and ultimately drive better project outcomes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(scenario))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Content Aligning to Learning Outcomes from the Vector Store\n",
    "\n",
    "In this section, we focus on retrieving content that aligns with specific learning outcomes from the vector store. The process involves querying the vector store using the learning outcomes and associated abilities to extract relevant content. This ensures that the retrieved content is contextually appropriate and supports the educational objectives.\n",
    "\n",
    "#### Steps Involved:\n",
    "\n",
    "1. **Define the Learning Outcomes and Abilities**:\n",
    "    - Identify the learning outcomes and their associated abilities from the extracted data.\n",
    "\n",
    "2. **Formulate the Retrieval Prompt**:\n",
    "    - Create a prompt that specifies the learning outcome and associated abilities.\n",
    "    - The prompt should clearly state the requirement to retrieve content that aligns with the specified learning outcome.\n",
    "\n",
    "3. **Query the Vector Store**:\n",
    "    - Use the formulated prompt to query the vector store.\n",
    "    - The query engine will retrieve the most relevant content based on the learning outcome and abilities.\n",
    "\n",
    "4. **Process and Display the Retrieved Content**:\n",
    "    - Process the retrieved content to ensure it aligns with the learning outcome.\n",
    "    - Display the retrieved content in a structured format for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "# System prompt tailored for content retrieval and question-answer generation\n",
    "system_prompt = \"\"\"\\\n",
    "You are a content retrieval assistant. Your role is to retrieve topic content that aligns strictly with the specified Learning Outcome (LO) and its associated abilities.\n",
    "\n",
    "Your role:\n",
    "1. Restrict your retrieval strictly to the specified topic provided in the query.\n",
    "2. Retrieve content from the topic that directly aligns with the provided Learning Outcome (LO) and its abilities.\n",
    "3. If no specific content directly aligns with the Learning Outcome or abilities, provide a general summary of the topic instead.\n",
    "4. Include any example/usecase code or equations relevant to the topic or subtopics.\n",
    "5. Prioritize retrieving content that are practical.\n",
    "6. Identify and extract the exact inline segments from the provided documents that directly correspond to the content used to generate the summary. The extracted segments must be verbatim snippets from the documents, ensuring a word-for-word match with the text in the provided documents.\n",
    "\n",
    "Ensure that:\n",
    "- (Important) Each retrieved segment is an exact match to a part of the document and is fully contained within the document text.\n",
    "- The relevance of each segment to the Learning Outcome or abilities is clear and directly supports the summary provided.\n",
    "- (Important) If you didn't use the specific document or topic, do not mention it.\n",
    "- If no relevant information is found for the Learning Outcome, clearly state this and provide a general topic summary instead.\n",
    "\n",
    "Restrictions:\n",
    "- Do not include content from other topics or slides outside the specified topic.\n",
    "- Each retrieved segment must explicitly belong to the given topic.\n",
    "- Avoid including assumptions or content outside the scope of the Learning Outcome and abilities.\n",
    "\n",
    "You must always provide:\n",
    "1. The retrieved content aligned with the Learning Outcome and abilities.\n",
    "2. A list of verbatim extracted segments that directly support the retrieved content, each labeled with the topic and document it belongs to.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lo_retriever_llm = OpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY, system_prompt=system_prompt)\n",
    "qa_generation_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    llm=lo_retriever_llm,\n",
    "    response_mode=\"compact\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To evaluate the performance effectiveness of Retrieval Augmented Generation (RAG), the following relevant content has been extracted:\n",
       "\n",
       "1. **Overview of RAG**:\n",
       "   - RAG combines the strengths of language models with external knowledge sources to enhance the quality of generated responses. It utilizes a retrieval mechanism to fetch relevant documents that inform the generation process.\n",
       "\n",
       "2. **Use Cases of RAG**:\n",
       "   - RAG can be applied in various scenarios such as:\n",
       "     - Question Answering\n",
       "     - Information Retrieval\n",
       "     - Content Recommendation\n",
       "     - Data Enrichment\n",
       "     - Knowledge Base Construction\n",
       "     - Academic Research\n",
       "     - Legal Research\n",
       "     - Language Translation\n",
       "     - Customer Support\n",
       "     - Educational Tools\n",
       "\n",
       "3. **RAG Process**:\n",
       "   - The RAG process involves several steps:\n",
       "     - **Document Loading**: Accessing and converting data from various sources.\n",
       "     - **Document Splitting**: Breaking down documents into manageable chunks for processing.\n",
       "     - **Storage**: Storing the processed documents in a vector database.\n",
       "     - **Retrieval**: Fetching relevant document splits based on user queries.\n",
       "     - **Output**: Generating answers based on the retrieved documents.\n",
       "\n",
       "4. **Example of RAG Implementation**:\n",
       "   - The implementation of RAG can be demonstrated through the following code snippet:\n",
       "     ```python\n",
       "     from langchain.chains import RetrievalQA\n",
       "     from langchain.document_loaders import CSVLoader\n",
       "     from langchain.vectorstores import Chroma\n",
       "\n",
       "     # Load documents\n",
       "     loader = CSVLoader(file_path='path/to/documents.csv')\n",
       "     documents = loader.load()\n",
       "\n",
       "     # Create a vector store\n",
       "     vectordb = Chroma.from_documents(documents)\n",
       "\n",
       "     # Set up the RAG chain\n",
       "     qa_chain = RetrievalQA.from_chain_type(\n",
       "         llm=ChatOpenAI(temperature=0),\n",
       "         retriever=vectordb.as_retriever(search_kwargs={\"k\": 3}),\n",
       "         chain_type=\"stuff\"\n",
       "     )\n",
       "\n",
       "     # Query the RAG system\n",
       "     result = qa_chain({\"query\": \"What is the impact of RAG on AI applications?\"})\n",
       "     print(result)\n",
       "     ```\n",
       "\n",
       "### Extracted Segments:\n",
       "- **Document Loading**: \"Loaders deal with the specifics of accessing and converting data.\"\n",
       "- **Use Cases of RAG**: \"Question Answering, Information Retrieval, Content Recommendation, Data Enrichment, Knowledge Base Construction, Academic Research, Legal Research, Language Translation, Customer Support, Educational Tools.\"\n",
       "- **RAG Process**: \"The RAG process involves several steps: Document Loading, Document Splitting, Storage, Retrieval, Output.\"\n",
       "- **Example of RAG Implementation**: \"from langchain.chains import RetrievalQA... result = qa_chain({'query': 'What is the impact of RAG on AI applications?'})\"\n",
       "\n",
       "These segments provide a comprehensive understanding of how to evaluate the performance effectiveness of RAG, aligning with the specified Learning Outcome and associated abilities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the content retrieval prompt\n",
    "retrieval_prompt = (\n",
    "    f\"Retrieve the most relevant inline segments aligned to Learning Outcome: Evaluate the performance effectiveness of Retrieval Augmented Generation (RAG)\\n\"\n",
    "    f\"Associated Abilities:\\n\"\n",
    "    f\"A4: Evaluate various AI applications to compare strengths and limitations of the AI applications\\n\"\n",
    "    f\"from the given Topics: Topic 4 Implementing Retrieval Augmented Generation (RAG)\"\n",
    ")\n",
    "response = qa_generation_query_engine.query(retrieval_prompt)\n",
    "display(Markdown(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_content_for_learning_outcomes(extracted_data):\n",
    "    \"\"\"\n",
    "    Retrieves content related to the learning outcomes and abilities from the provided data.\n",
    "\n",
    "    Args:\n",
    "        extracted_data (FacilitatorGuideExtraction): The extracted data instance containing course details.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries containing retrieved content and associated abilities.\n",
    "    \"\"\"\n",
    "    retrieved_content = []\n",
    "\n",
    "    for learning_unit in extracted_data.learning_units:\n",
    "        learning_outcome = learning_unit.learning_outcome\n",
    "        associated_abilities = []\n",
    "        ability_ids = []\n",
    "        for topic in learning_unit.topics:\n",
    "            associated_abilities.extend(topic.tsc_abilities)\n",
    "            ability_ids.extend([ability.id for ability in topic.tsc_abilities])\n",
    "\n",
    "        # Define the content retrieval prompt\n",
    "        retrieval_prompt = (\n",
    "            f\"Retrieve the most relevant inline segments aligned to Learning Outcome: {learning_outcome}\\n\"\n",
    "            f\"Associated Abilities:\\n\"\n",
    "            + \"\\n\".join([f\"- [{ability.id}] {ability.text}\" for ability in associated_abilities])\n",
    "            + f\"\\nFrom the given Topics: {', '.join([topic.name for topic in learning_unit.topics])}\"\n",
    "        )\n",
    "\n",
    "\n",
    "        response = qa_generation_query_engine.query(retrieval_prompt)\n",
    "        retrieved_content.append({\n",
    "            \"learning_outcome\": learning_outcome,\n",
    "            \"abilities\": ability_ids,\n",
    "            \"retrieved_content\": response.response\n",
    "        })\n",
    "    \n",
    "    return retrieved_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_content = retrieve_content_for_learning_outcomes(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Learning Outcome: Analyze the range of LLM applications using Generative AI (GAI) and identify their industrial use cases.\n",
       "### Associated Abilities:\n",
       "- A1\n",
       "- A3\n",
       "### Retrieved Content:\n",
       "To analyze the range of LLM applications using Generative AI (GAI) and identify their industrial use cases, the following relevant content has been extracted:\n",
       "\n",
       "### Retrieved Content:\n",
       "1. **Opportunities of LLM Applications**:\n",
       "   - Content Creation and Assistance\n",
       "   - Customer Support and Chatbots\n",
       "   - Language Translation and Localization\n",
       "   - Educational Tools\n",
       "   - Business Intelligence and Analytics\n",
       "   - Accessibility for Disabled Persons\n",
       "   - Coding and Development\n",
       "   - Legal and Compliance Assistance\n",
       "   - Healthcare Support\n",
       "   - Art and Design Inspiration\n",
       "   - Enhanced Search Engines\n",
       "   - Crisis Management and Response\n",
       "\n",
       "2. **Use Cases of GAI in Various Industries**:\n",
       "   - **Finance**:\n",
       "     - Automated Financial Reporting\n",
       "     - Risk Assessment and Analysis\n",
       "     - Algorithmic Trading Strategies\n",
       "     - Fraud Detection and Prevention\n",
       "     - Customer Service Chatbots\n",
       "     - Personalized Financial Advice\n",
       "     - Credit Scoring and Lending Analysis\n",
       "     - Regulatory Compliance and Monitoring\n",
       "     - Market Sentiment Analysis\n",
       "     - Contract Review and Analysis\n",
       "   - **Marketing**:\n",
       "     - Content Creation\n",
       "     - Market Research Analysis\n",
       "     - Personalized Marketing\n",
       "     - Email Marketing Automation\n",
       "     - Social Media Management\n",
       "     - SEO Optimization\n",
       "     - Customer Sentiment Analysis\n",
       "     - Chatbots for Customer Engagement\n",
       "     - Predictive Analytics\n",
       "     - Brand Strategy Development\n",
       "   - **Education**:\n",
       "     - Personalized Learning Assistance\n",
       "     - Grading and Feedback Automation\n",
       "     - Curriculum Development and Content Creation\n",
       "     - Language Learning and Translation\n",
       "     - Educational Chatbots\n",
       "     - Research and Writing Assistance\n",
       "     - Interactive Learning Environments\n",
       "     - Special Education Support\n",
       "     - Teacher Training and Professional Development\n",
       "     - Student Engagement and Motivation Tools\n",
       "   - **Healthcare**:\n",
       "     - Drug discovery and development\n",
       "     - Personalized medicine and treatment optimization\n",
       "     - Medical imaging and diagnosis\n",
       "     - Disease prediction and prevention\n",
       "     - Biomarker development\n",
       "     - Synthetic data generation for research\n",
       "     - Robotic surgery\n",
       "     - Virtual health assistants\n",
       "     - Epidemiological research\n",
       "     - Enhanced patient education and engagement\n",
       "     - Genomic sequencing analysis\n",
       "     - Automated clinical documentation\n",
       "\n",
       "### Extracted Segments:\n",
       "- **Opportunities of LLM Applications**:\n",
       "  - \"Content Creation and Assistance\"\n",
       "  - \"Customer Support and Chatbots\"\n",
       "  - \"Language Translation and Localization\"\n",
       "  - \"Educational Tools\"\n",
       "  - \"Business Intelligence and Analytics\"\n",
       "  - \"Accessibility for Disabled Persons\"\n",
       "  - \"Coding and Development\"\n",
       "  - \"Legal and Compliance Assistance\"\n",
       "  - \"Healthcare Support\"\n",
       "  - \"Art and Design Inspiration\"\n",
       "  - \"Enhanced Search Engines\"\n",
       "  - \"Crisis Management and Response\"\n",
       "\n",
       "- **Use Cases of GAI in Finance**:\n",
       "  - \"Automated Financial Reporting\"\n",
       "  - \"Risk Assessment and Analysis\"\n",
       "  - \"Algorithmic Trading Strategies\"\n",
       "  - \"Fraud Detection and Prevention\"\n",
       "  - \"Customer Service Chatbots\"\n",
       "  - \"Personalized Financial Advice\"\n",
       "  - \"Credit Scoring and Lending Analysis\"\n",
       "  - \"Regulatory Compliance and Monitoring\"\n",
       "  - \"Market Sentiment Analysis\"\n",
       "  - \"Contract Review and Analysis\"\n",
       "\n",
       "- **Use Cases of GAI in Marketing**:\n",
       "  - \"Content Creation\"\n",
       "  - \"Market Research Analysis\"\n",
       "  - \"Personalized Marketing\"\n",
       "  - \"Email Marketing Automation\"\n",
       "  - \"Social Media Management\"\n",
       "  - \"SEO Optimization\"\n",
       "  - \"Customer Sentiment Analysis\"\n",
       "  - \"Chatbots for Customer Engagement\"\n",
       "  - \"Predictive Analytics\"\n",
       "  - \"Brand Strategy Development\"\n",
       "\n",
       "- **Use Cases of GAI in Education**:\n",
       "  - \"Personalized Learning Assistance\"\n",
       "  - \"Grading and Feedback Automation\"\n",
       "  - \"Curriculum Development and Content Creation\"\n",
       "  - \"Language Learning and Translation\"\n",
       "  - \"Educational Chatbots\"\n",
       "  - \"Research and Writing Assistance\"\n",
       "  - \"Interactive Learning Environments\"\n",
       "  - \"Special Education Support\"\n",
       "  - \"Teacher Training and Professional Development\"\n",
       "  - \"Student Engagement and Motivation Tools\"\n",
       "\n",
       "- **Use Cases of GAI in Healthcare**:\n",
       "  - \"Drug discovery and development\"\n",
       "  - \"Personalized medicine and treatment optimization\"\n",
       "  - \"Medical imaging and diagnosis\"\n",
       "  - \"Disease prediction and prevention\"\n",
       "  - \"Biomarker development\"\n",
       "  - \"Synthetic data generation for research\"\n",
       "  - \"Robotic surgery\"\n",
       "  - \"Virtual health assistants\"\n",
       "  - \"Epidemiological research\"\n",
       "  - \"Enhanced patient education and engagement\"\n",
       "  - \"Genomic sequencing analysis\"\n",
       "  - \"Automated clinical documentation\"\n",
       "\n",
       "These segments provide a comprehensive overview of the applications and use cases of LLMs in various industries, aligning with the specified Learning Outcome and associated abilities.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Learning Outcome: Establish Google Gemini GAI designs and assess improvements on engineering processes.\n",
       "### Associated Abilities:\n",
       "- A2\n",
       "- A6\n",
       "### Retrieved Content:\n",
       "The content relevant to the Learning Outcome of establishing Google Gemini GAI designs and assessing improvements on engineering processes, particularly aligned with abilities A2 and A6, includes practical insights into the design and implementation of multimodal prompting with Google Gemini. \n",
       "\n",
       "### Retrieved Content:\n",
       "1. **Multimodal Prompting with Google Gemini**:\n",
       "   - This section discusses how to utilize Google Gemini for multimodal prompting, which involves integrating various types of data inputs (text, images, etc.) to enhance the efficiency and effectiveness of AI applications. The design of algorithms in this context is crucial for achieving optimal performance across different tasks.\n",
       "\n",
       "2. **Implementation of Google AI Studio**:\n",
       "   - The Google AI Studio allows for prototyping and testing designs, which can lead to improvements in engineering processes by providing a platform for experimentation and iteration. This aligns with assessing improvements in engineering processes through practical application.\n",
       "\n",
       "3. **Example Code for API Usage**:\n",
       "   - The following example demonstrates how to set up and use the Google Gemini API for generating content, which is a practical application of the design principles discussed:\n",
       "   ```python\n",
       "   import google.generativeai as genai\n",
       "   genai.configure(api_key='YOUR_API_KEY')\n",
       "   response = genai.GenerativeModel(\"gemini-1.5-flash\").generate_content(\"Write a story about magic backpack.\")\n",
       "   print(response.text)\n",
       "   ```\n",
       "\n",
       "### Extracted Segments:\n",
       "- **Topic**: Multimodal Prompting with Google Gemini LLM\n",
       "  - \"This section discusses how to utilize Google Gemini for multimodal prompting, which involves integrating various types of data inputs (text, images, etc.) to enhance the efficiency and effectiveness of AI applications.\"\n",
       "  \n",
       "- **Topic**: Multimodal Prompting with Google Gemini LLM\n",
       "  - \"The Google AI Studio allows for prototyping and testing designs, which can lead to improvements in engineering processes by providing a platform for experimentation and iteration.\"\n",
       "\n",
       "- **Topic**: Multimodal Prompting with Google Gemini LLM\n",
       "  - \"Example code for API usage demonstrates how to set up and use the Google Gemini API for generating content.\"\n",
       "\n",
       "These segments illustrate the correlation between the design of algorithms and their efficiency, as well as the assessment of improvements in engineering processes through practical applications of Google Gemini.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Learning Outcome: Develop LLM applications and assess its feasibility.\n",
       "### Associated Abilities:\n",
       "- A5\n",
       "### Retrieved Content:\n",
       "To align with the Learning Outcome of developing LLM applications and assessing their feasibility, the following relevant content has been extracted from the topic \"Building LLM Applications with Google Gemini LLM\":\n",
       "\n",
       "### Retrieved Content:\n",
       "1. **Overview of LangChain Components**:\n",
       "   - LangChain is a framework for developing applications powered by language models. It enables applications that are context-aware and can reason based on provided context.\n",
       "\n",
       "2. **LangChain Libraries**:\n",
       "   - The Python and JavaScript libraries facilitate the development of LLM applications, allowing for easy integration and deployment.\n",
       "\n",
       "3. **Assessing Feasibility**:\n",
       "   - The framework allows developers to assess the feasibility of integrating LLMs into existing engineering processes by providing tools for context awareness and reasoning capabilities.\n",
       "\n",
       "4. **Example Code for Building LLM Applications**:\n",
       "   ```python\n",
       "   from langchain import ChatGoogleGenerativeAI\n",
       "   llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\")\n",
       "   response = llm.invoke(\"What is the best way to implement an LLM in a customer service application?\")\n",
       "   print(response.content)\n",
       "   ```\n",
       "\n",
       "### Extracted Segments:\n",
       "- **LangChain Overview**: \"LangChain is a framework for developing applications powered by language models. It enables applications that: Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.) Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)\"\n",
       "- **LangChain Libraries**: \"LangChain Libraries: The Python and JavaScript libraries.\"\n",
       "- **Assessing Feasibility**: \"The framework allows developers to assess the feasibility of integrating LLMs into existing engineering processes by providing tools for context awareness and reasoning capabilities.\"\n",
       "- **Example Code**: \"from langchain import ChatGoogleGenerativeAI llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash-001') response = llm.invoke('What is the best way to implement an LLM in a customer service application?') print(response.content)\"\n",
       "\n",
       "These segments provide a clear understanding of how to develop LLM applications using the LangChain framework and assess their feasibility in engineering processes.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Learning Outcome: Evaluate the performance effectiveness of Retrieval Augmented Generation (RAG).\n",
       "### Associated Abilities:\n",
       "- A4\n",
       "### Retrieved Content:\n",
       "To evaluate the performance effectiveness of Retrieval Augmented Generation (RAG), the following relevant content has been extracted:\n",
       "\n",
       "### Summary of Relevant Content:\n",
       "Retrieval Augmented Generation (RAG) combines the strengths of language models with external knowledge sources to enhance the quality of generated responses. It involves several key processes: document loading, splitting, storage, retrieval, and output generation. The effectiveness of RAG can be assessed through its ability to provide accurate and contextually relevant answers based on the retrieved documents. This method is particularly useful in applications such as question answering, information retrieval, and content recommendation.\n",
       "\n",
       "### Example Code Snippets:\n",
       "1. **Document Loading and Retrieval**:\n",
       "   ```python\n",
       "   from langchain.document_loaders import CSVLoader\n",
       "   loader = CSVLoader(file_path='content/OutdoorClothingCatalog.csv')\n",
       "   documents = loader.load()\n",
       "   vectordb = Chroma.from_documents(documents=documents, embedding=embedding)\n",
       "   ```\n",
       "\n",
       "2. **RetrievalQA RAG**:\n",
       "   ```python\n",
       "   from langchain.chains import RetrievalQA\n",
       "   qa_chain = RetrievalQA.from_chain_type(\n",
       "       llm=llm,\n",
       "       retriever=vectordb.as_retriever(search_kwargs={\"k\": 3}),\n",
       "       chain_type=\"stuff\",\n",
       "       return_source_documents=True\n",
       "   )\n",
       "   result = qa_chain({\"query\": \"Please suggest a shirt with sunblocking\"})\n",
       "   ```\n",
       "\n",
       "3. **Conversational Retrieval Chain**:\n",
       "   ```python\n",
       "   from langchain.chains import ConversationalRetrievalChain\n",
       "   memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
       "   qa_chain = ConversationalRetrievalChain.from_llm(\n",
       "       ChatOpenAI(temperature=0),\n",
       "       vectorstore.as_retriever(),\n",
       "       memory=memory\n",
       "   )\n",
       "   ```\n",
       "\n",
       "### Extracted Segments:\n",
       "1. **RAG Overview**:\n",
       "   - \"Retrieval Augmented Generation (RAG) combines the strengths of language models with external knowledge sources to enhance the quality of generated responses.\"\n",
       "   \n",
       "2. **Document Loading**:\n",
       "   - \"Loaders deal with the specifics of accessing and converting data... Returns a list of document objects.\"\n",
       "\n",
       "3. **Use Cases of RAG**:\n",
       "   - \"Use Cases of RAG: Question Answering, Information Retrieval, Content Recommendation, Data Enrichment, Knowledge Base Construction, Academic Research, Legal Research, Language Translation, Customer Support, Educational Tools.\"\n",
       "\n",
       "4. **Retrieval Process**:\n",
       "   - \"Relevant documents are fetched from the vector store based on the user's query, which are then used to generate a more informed response.\"\n",
       "\n",
       "These segments directly support the evaluation of RAG's performance effectiveness by outlining its processes, applications, and the importance of document retrieval in generating accurate responses.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the content in Markdown format\n",
    "for content in retrieved_content:\n",
    "    markdown_output = (\n",
    "        f\"### Learning Outcome: {content['learning_outcome']}\\n\"\n",
    "        f\"### Associated Abilities:\\n\"\n",
    "        + \"\".join([f\"- {ability_id}\\n\" for ability_id in content['abilities']])\n",
    "        + f\"### Retrieved Content:\\n{content['retrieved_content']}\\n\"\n",
    "    )\n",
    "\n",
    "    display(Markdown(markdown_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 12-12 15:05:37] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "\u001b[33muser_proxy\u001b[0m (to Question Answer Generator):\n",
      "\n",
      "\n",
      "        Please generate practical performance assessment questions using the following course title: 'Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini', \n",
      "        assessment duration: '1 hr', scenario: 'In a rapidly evolving tech landscape, InnovateAI, a mid-sized company specializing in AI-driven solutions for the healthcare sector, is facing challenges in optimizing its patient management system. The company has recently integrated Google Gemini's Generative AI capabilities to enhance its application for real-time patient data analysis and decision support. As part of a project team, you are tasked with analyzing the current LLM applications to identify their strengths and limitations, establishing the design of algorithms that improve efficiency in processing patient data, and assessing the feasibility of these AI applications in streamlining engineering processes. Additionally, you will evaluate the performance effectiveness of the Retrieval Augmented Generation (RAG) model implemented in the system, ensuring that the solutions align with industry standards and enhance overall operational efficiency. Your role will involve hands-on analysis, algorithm design, and performance evaluation to provide actionable insights that drive improvements in the company's healthcare solutions.', and topic contents: [{'learning_outcome': 'Analyze the range of LLM applications using Generative AI (GAI) and identify their industrial use cases.', 'abilities': ['A1', 'A3'], 'retrieved_content': 'To analyze the range of LLM applications using Generative AI (GAI) and identify their industrial use cases, the following relevant content has been extracted:\\n\\n### Retrieved Content:\\n1. **Opportunities of LLM Applications**:\\n   - Content Creation and Assistance\\n   - Customer Support and Chatbots\\n   - Language Translation and Localization\\n   - Educational Tools\\n   - Business Intelligence and Analytics\\n   - Accessibility for Disabled Persons\\n   - Coding and Development\\n   - Legal and Compliance Assistance\\n   - Healthcare Support\\n   - Art and Design Inspiration\\n   - Enhanced Search Engines\\n   - Crisis Management and Response\\n\\n2. **Use Cases of GAI in Various Industries**:\\n   - **Finance**:\\n     - Automated Financial Reporting\\n     - Risk Assessment and Analysis\\n     - Algorithmic Trading Strategies\\n     - Fraud Detection and Prevention\\n     - Customer Service Chatbots\\n     - Personalized Financial Advice\\n     - Credit Scoring and Lending Analysis\\n     - Regulatory Compliance and Monitoring\\n     - Market Sentiment Analysis\\n     - Contract Review and Analysis\\n   - **Marketing**:\\n     - Content Creation\\n     - Market Research Analysis\\n     - Personalized Marketing\\n     - Email Marketing Automation\\n     - Social Media Management\\n     - SEO Optimization\\n     - Customer Sentiment Analysis\\n     - Chatbots for Customer Engagement\\n     - Predictive Analytics\\n     - Brand Strategy Development\\n   - **Education**:\\n     - Personalized Learning Assistance\\n     - Grading and Feedback Automation\\n     - Curriculum Development and Content Creation\\n     - Language Learning and Translation\\n     - Educational Chatbots\\n     - Research and Writing Assistance\\n     - Interactive Learning Environments\\n     - Special Education Support\\n     - Teacher Training and Professional Development\\n     - Student Engagement and Motivation Tools\\n   - **Healthcare**:\\n     - Drug discovery and development\\n     - Personalized medicine and treatment optimization\\n     - Medical imaging and diagnosis\\n     - Disease prediction and prevention\\n     - Biomarker development\\n     - Synthetic data generation for research\\n     - Robotic surgery\\n     - Virtual health assistants\\n     - Epidemiological research\\n     - Enhanced patient education and engagement\\n     - Genomic sequencing analysis\\n     - Automated clinical documentation\\n\\n### Extracted Segments:\\n- **Opportunities of LLM Applications**:\\n  - \"Content Creation and Assistance\"\\n  - \"Customer Support and Chatbots\"\\n  - \"Language Translation and Localization\"\\n  - \"Educational Tools\"\\n  - \"Business Intelligence and Analytics\"\\n  - \"Accessibility for Disabled Persons\"\\n  - \"Coding and Development\"\\n  - \"Legal and Compliance Assistance\"\\n  - \"Healthcare Support\"\\n  - \"Art and Design Inspiration\"\\n  - \"Enhanced Search Engines\"\\n  - \"Crisis Management and Response\"\\n\\n- **Use Cases of GAI in Finance**:\\n  - \"Automated Financial Reporting\"\\n  - \"Risk Assessment and Analysis\"\\n  - \"Algorithmic Trading Strategies\"\\n  - \"Fraud Detection and Prevention\"\\n  - \"Customer Service Chatbots\"\\n  - \"Personalized Financial Advice\"\\n  - \"Credit Scoring and Lending Analysis\"\\n  - \"Regulatory Compliance and Monitoring\"\\n  - \"Market Sentiment Analysis\"\\n  - \"Contract Review and Analysis\"\\n\\n- **Use Cases of GAI in Marketing**:\\n  - \"Content Creation\"\\n  - \"Market Research Analysis\"\\n  - \"Personalized Marketing\"\\n  - \"Email Marketing Automation\"\\n  - \"Social Media Management\"\\n  - \"SEO Optimization\"\\n  - \"Customer Sentiment Analysis\"\\n  - \"Chatbots for Customer Engagement\"\\n  - \"Predictive Analytics\"\\n  - \"Brand Strategy Development\"\\n\\n- **Use Cases of GAI in Education**:\\n  - \"Personalized Learning Assistance\"\\n  - \"Grading and Feedback Automation\"\\n  - \"Curriculum Development and Content Creation\"\\n  - \"Language Learning and Translation\"\\n  - \"Educational Chatbots\"\\n  - \"Research and Writing Assistance\"\\n  - \"Interactive Learning Environments\"\\n  - \"Special Education Support\"\\n  - \"Teacher Training and Professional Development\"\\n  - \"Student Engagement and Motivation Tools\"\\n\\n- **Use Cases of GAI in Healthcare**:\\n  - \"Drug discovery and development\"\\n  - \"Personalized medicine and treatment optimization\"\\n  - \"Medical imaging and diagnosis\"\\n  - \"Disease prediction and prevention\"\\n  - \"Biomarker development\"\\n  - \"Synthetic data generation for research\"\\n  - \"Robotic surgery\"\\n  - \"Virtual health assistants\"\\n  - \"Epidemiological research\"\\n  - \"Enhanced patient education and engagement\"\\n  - \"Genomic sequencing analysis\"\\n  - \"Automated clinical documentation\"\\n\\nThese segments provide a comprehensive overview of the applications and use cases of LLMs in various industries, aligning with the specified Learning Outcome and associated abilities.'}, {'learning_outcome': 'Establish Google Gemini GAI designs and assess improvements on engineering processes.', 'abilities': ['A2', 'A6'], 'retrieved_content': 'The content relevant to the Learning Outcome of establishing Google Gemini GAI designs and assessing improvements on engineering processes, particularly aligned with abilities A2 and A6, includes practical insights into the design and implementation of multimodal prompting with Google Gemini. \\n\\n### Retrieved Content:\\n1. **Multimodal Prompting with Google Gemini**:\\n   - This section discusses how to utilize Google Gemini for multimodal prompting, which involves integrating various types of data inputs (text, images, etc.) to enhance the efficiency and effectiveness of AI applications. The design of algorithms in this context is crucial for achieving optimal performance across different tasks.\\n\\n2. **Implementation of Google AI Studio**:\\n   - The Google AI Studio allows for prototyping and testing designs, which can lead to improvements in engineering processes by providing a platform for experimentation and iteration. This aligns with assessing improvements in engineering processes through practical application.\\n\\n3. **Example Code for API Usage**:\\n   - The following example demonstrates how to set up and use the Google Gemini API for generating content, which is a practical application of the design principles discussed:\\n   ```python\\n   import google.generativeai as genai\\n   genai.configure(api_key=\\'YOUR_API_KEY\\')\\n   response = genai.GenerativeModel(\"gemini-1.5-flash\").generate_content(\"Write a story about magic backpack.\")\\n   print(response.text)\\n   ```\\n\\n### Extracted Segments:\\n- **Topic**: Multimodal Prompting with Google Gemini LLM\\n  - \"This section discusses how to utilize Google Gemini for multimodal prompting, which involves integrating various types of data inputs (text, images, etc.) to enhance the efficiency and effectiveness of AI applications.\"\\n  \\n- **Topic**: Multimodal Prompting with Google Gemini LLM\\n  - \"The Google AI Studio allows for prototyping and testing designs, which can lead to improvements in engineering processes by providing a platform for experimentation and iteration.\"\\n\\n- **Topic**: Multimodal Prompting with Google Gemini LLM\\n  - \"Example code for API usage demonstrates how to set up and use the Google Gemini API for generating content.\"\\n\\nThese segments illustrate the correlation between the design of algorithms and their efficiency, as well as the assessment of improvements in engineering processes through practical applications of Google Gemini.'}, {'learning_outcome': 'Develop LLM applications and assess its feasibility.', 'abilities': ['A5'], 'retrieved_content': 'To align with the Learning Outcome of developing LLM applications and assessing their feasibility, the following relevant content has been extracted from the topic \"Building LLM Applications with Google Gemini LLM\":\\n\\n### Retrieved Content:\\n1. **Overview of LangChain Components**:\\n   - LangChain is a framework for developing applications powered by language models. It enables applications that are context-aware and can reason based on provided context.\\n\\n2. **LangChain Libraries**:\\n   - The Python and JavaScript libraries facilitate the development of LLM applications, allowing for easy integration and deployment.\\n\\n3. **Assessing Feasibility**:\\n   - The framework allows developers to assess the feasibility of integrating LLMs into existing engineering processes by providing tools for context awareness and reasoning capabilities.\\n\\n4. **Example Code for Building LLM Applications**:\\n   ```python\\n   from langchain import ChatGoogleGenerativeAI\\n   llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\")\\n   response = llm.invoke(\"What is the best way to implement an LLM in a customer service application?\")\\n   print(response.content)\\n   ```\\n\\n### Extracted Segments:\\n- **LangChain Overview**: \"LangChain is a framework for developing applications powered by language models. It enables applications that: Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.) Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)\"\\n- **LangChain Libraries**: \"LangChain Libraries: The Python and JavaScript libraries.\"\\n- **Assessing Feasibility**: \"The framework allows developers to assess the feasibility of integrating LLMs into existing engineering processes by providing tools for context awareness and reasoning capabilities.\"\\n- **Example Code**: \"from langchain import ChatGoogleGenerativeAI llm = ChatGoogleGenerativeAI(model=\\'gemini-1.5-flash-001\\') response = llm.invoke(\\'What is the best way to implement an LLM in a customer service application?\\') print(response.content)\"\\n\\nThese segments provide a clear understanding of how to develop LLM applications using the LangChain framework and assess their feasibility in engineering processes.'}, {'learning_outcome': 'Evaluate the performance effectiveness of Retrieval Augmented Generation (RAG).', 'abilities': ['A4'], 'retrieved_content': 'To evaluate the performance effectiveness of Retrieval Augmented Generation (RAG), the following relevant content has been extracted:\\n\\n### Summary of Relevant Content:\\nRetrieval Augmented Generation (RAG) combines the strengths of language models with external knowledge sources to enhance the quality of generated responses. It involves several key processes: document loading, splitting, storage, retrieval, and output generation. The effectiveness of RAG can be assessed through its ability to provide accurate and contextually relevant answers based on the retrieved documents. This method is particularly useful in applications such as question answering, information retrieval, and content recommendation.\\n\\n### Example Code Snippets:\\n1. **Document Loading and Retrieval**:\\n   ```python\\n   from langchain.document_loaders import CSVLoader\\n   loader = CSVLoader(file_path=\\'content/OutdoorClothingCatalog.csv\\')\\n   documents = loader.load()\\n   vectordb = Chroma.from_documents(documents=documents, embedding=embedding)\\n   ```\\n\\n2. **RetrievalQA RAG**:\\n   ```python\\n   from langchain.chains import RetrievalQA\\n   qa_chain = RetrievalQA.from_chain_type(\\n       llm=llm,\\n       retriever=vectordb.as_retriever(search_kwargs={\"k\": 3}),\\n       chain_type=\"stuff\",\\n       return_source_documents=True\\n   )\\n   result = qa_chain({\"query\": \"Please suggest a shirt with sunblocking\"})\\n   ```\\n\\n3. **Conversational Retrieval Chain**:\\n   ```python\\n   from langchain.chains import ConversationalRetrievalChain\\n   memory = ConversationBufferMemory(memory_key=\"chat_history\")\\n   qa_chain = ConversationalRetrievalChain.from_llm(\\n       ChatOpenAI(temperature=0),\\n       vectorstore.as_retriever(),\\n       memory=memory\\n   )\\n   ```\\n\\n### Extracted Segments:\\n1. **RAG Overview**:\\n   - \"Retrieval Augmented Generation (RAG) combines the strengths of language models with external knowledge sources to enhance the quality of generated responses.\"\\n   \\n2. **Document Loading**:\\n   - \"Loaders deal with the specifics of accessing and converting data... Returns a list of document objects.\"\\n\\n3. **Use Cases of RAG**:\\n   - \"Use Cases of RAG: Question Answering, Information Retrieval, Content Recommendation, Data Enrichment, Knowledge Base Construction, Academic Research, Legal Research, Language Translation, Customer Support, Educational Tools.\"\\n\\n4. **Retrieval Process**:\\n   - \"Relevant documents are fetched from the vector store based on the user\\'s query, which are then used to generate a more informed response.\"\\n\\nThese segments directly support the evaluation of RAG\\'s performance effectiveness by outlining its processes, applications, and the importance of document retrieval in generating accurate responses.'}].\n",
      "        Phrase your question in alignment with Bloom's Taxonomy Level: 3.\n",
      "        Example Bloom's Taxonomy Levels:\n",
      "            - Level 1: Remembering\n",
      "            - Level 2: Understanding\n",
      "            - Level 3: Applying\n",
      "            - Level 4: Analyzing\n",
      "            - Level 5: Evaluating\n",
      "            - Level 6: Creating\n",
      "        Ensure the question ends with \"Take snapshots of your commands at each step and paste them below.\"\n",
      "        Ensure the answer begins with \"The snapshot should include: \" and specifies only practical steps to test hands-on skills without any writing or documenting.\n",
      "        RETURN 'TERMINATE' once the generation is done.\n",
      "        \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mQuestion Answer Generator\u001b[0m (to user_proxy):\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"course_title\": \"Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini\",\n",
      "    \"duration\": \"1 hr\",\n",
      "    \"scenario\": \"In a rapidly evolving tech landscape, InnovateAI, a mid-sized company specializing in AI-driven solutions for the healthcare sector, is facing challenges in optimizing its patient management system. The company has recently integrated Google Gemini's Generative AI capabilities to enhance its application for real-time patient data analysis and decision support. As part of a project team, you are tasked with analyzing the current LLM applications to identify their strengths and limitations, establishing the design of algorithms that improve efficiency in processing patient data, and assessing the feasibility of these AI applications in streamlining engineering processes. Additionally, you will evaluate the performance effectiveness of the Retrieval Augmented Generation (RAG) model implemented in the system, ensuring that the solutions align with industry standards and enhance overall operational efficiency. Your role will involve hands-on analysis, algorithm design, and performance evaluation to provide actionable insights that drive improvements in the company's healthcare solutions.\",\n",
      "    \"questions\": [\n",
      "        {\n",
      "            \"question_statement\": \"Identify and analyze the various industrial use cases for LLM applications using Google Gemini in the healthcare sector. Take snapshots of your commands at each step and paste them below.\",\n",
      "            \"answer\": \"The snapshot should include: lists of industrial use cases for healthcare LLM applications, including drug discovery, virtual health assistants, and automated clinical documentation. Use commands to create structured data tables to display these findings.\",\n",
      "            \"ability_id\": [\"A1\", \"A3\"]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"Implement a multimodal prompting design using Google Gemini to enhance algorithm performance in patient data processing. Take snapshots of your commands at each step and paste them below.\",\n",
      "            \"answer\": \"The snapshot should include: the setup commands for Google AI Studio, including importing necessary libraries, configuring multimodal input parameters, and testing the initial design for efficiency. Document commands used in the configuration.\",\n",
      "            \"ability_id\": [\"A2\", \"A6\"]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"Build and deploy a simple LLM application using LangChain to automate patient inquiry responses, then assess its feasibility. Take snapshots of your commands at each step and paste them below.\",\n",
      "            \"answer\": \"The snapshot should include: the code for importing LangChain, initializing the LLM with Google Gemini, executing patient inquiry prompts, and analyzing the responses. Include commands used in the setup.\",\n",
      "            \"ability_id\": [\"A5\"]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"Evaluate the implementation of the Retrieval Augmented Generation (RAG) mechanism within the current LLM application and assess its performance. Take snapshots of your commands at each step and paste them below.\",\n",
      "            \"answer\": \"The snapshot should include: the code snippets for document loading using CSVLoader, retrieving documents through the RAG model, and running queries to test response accuracy. Document commands used in loading and retrieval.\",\n",
      "            \"ability_id\": [\"A4\"]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "from autogen.cache import Cache\n",
    "\n",
    "llm_config={\n",
    "        \"config_list\": [\n",
    "            {\n",
    "                'model': \"gpt-4o-mini\",\n",
    "                'api_key': OPENAI_API_KEY,\n",
    "            },\n",
    "        ],\n",
    "        \"timeout\": 120,\n",
    "    }\n",
    "\n",
    "user_proxy_agent = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\", \"\") and \"TERMINATE\" in msg[\"content\"],\n",
    "    code_execution_config={\"work_dir\": \"output\", \"use_docker\": False}\n",
    ")\n",
    "\n",
    "# Autogen setup\n",
    "qa_generation_agent = AssistantAgent(\n",
    "    name=\"Question Answer Generator\",\n",
    "    system_message=f\"\"\"\n",
    "    You are an expert educator in '{extracted_data.course_title}'. You will create scenario-based practical performance assessment (PPA) question-answer pairs based on course data.\n",
    "    The data will include:\n",
    "    - A scenario\n",
    "    - Retrieved content aligned with learning outcomes and abilities\n",
    "\n",
    "    ### Instructions:\n",
    "    1. Use the provided scenario and retrieved content to generate one question-and-answer pair per learning outcome.\n",
    "    2. Each question must:\n",
    "        - Be aligned with the scenario context and practical skills relevant to the abilities.\n",
    "        - End with the statement: \"Take snapshots of your ... at each step and paste them below.\"\n",
    "    3. Each answer must:\n",
    "        - Begin with: \"The snapshot should include: \".\n",
    "        - Specify only practical steps that test the learner's skills (e.g., commands, setups, or tool usage).\n",
    "        - Avoid any form of writing, documenting, or analytical description beyond the practical steps.\n",
    "    4. Ensure all keys and values are double-quoted in the JSON output.\n",
    "    5. Return the output in JSON format with the following structure:\n",
    "        ```json\n",
    "        {{\n",
    "            \"course_title\": \"<course_title_here>\",\n",
    "            \"duration\": \"<assessment_duration_here>\",\n",
    "            \"scenario\": \"<scenario_here>\",\n",
    "            \"questions\": [\n",
    "                {{\n",
    "                    \"question_statement\": \"<question_text>\",\n",
    "                    \"answer\": \"<answer_text>\",\n",
    "                    \"ability_id\": [\"<list_of_ability_ids>\"]\n",
    "                }},\n",
    "                ...\n",
    "            ]\n",
    "        }}\n",
    "        ```\n",
    "    \"\"\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "assessment_duration = \"\"\n",
    "for assessment in extracted_data.assessments:\n",
    "    if \"PP\" in assessment.code:\n",
    "        assessment_duration = assessment.duration\n",
    "\n",
    "with Cache.disk() as cache:\n",
    "    chat_result = user_proxy_agent.initiate_chat(\n",
    "        qa_generation_agent,\n",
    "        message=f\"\"\"\n",
    "        Please generate practical performance assessment questions using the following course title: '{extracted_data.course_title}', \n",
    "        assessment duration: '{assessment_duration}', scenario: '{scenario}', and topic contents: {retrieved_content}.\n",
    "        Phrase your question in alignment with Bloom's Taxonomy Level: {extracted_data.tsc_proficiency_level}.\n",
    "        Example Bloom's Taxonomy Levels:\n",
    "            - Level 1: Remembering\n",
    "            - Level 2: Understanding\n",
    "            - Level 3: Applying\n",
    "            - Level 4: Analyzing\n",
    "            - Level 5: Evaluating\n",
    "            - Level 6: Creating\n",
    "        Ensure the question ends with \"Take snapshots of your commands at each step and paste them below.\"\n",
    "        Ensure the answer begins with \"The snapshot should include: \" and specifies only practical steps to test hands-on skills without any writing or documenting.\n",
    "        RETURN 'TERMINATE' once the generation is done.\n",
    "        \"\"\",\n",
    "        summary_method=\"reflection_with_llm\",\n",
    "        cache=cache,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT JSON MAPPING: \n",
      "\n",
      "{'course_title': 'Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini', 'duration': '1 hr', 'scenario': \"In a rapidly evolving tech landscape, InnovateAI, a mid-sized company specializing in AI-driven solutions for the healthcare sector, is facing challenges in optimizing its patient management system. The company has recently integrated Google Gemini's Generative AI capabilities to enhance its application for real-time patient data analysis and decision support. As part of a project team, you are tasked with analyzing the current LLM applications to identify their strengths and limitations, establishing the design of algorithms that improve efficiency in processing patient data, and assessing the feasibility of these AI applications in streamlining engineering processes. Additionally, you will evaluate the performance effectiveness of the Retrieval Augmented Generation (RAG) model implemented in the system, ensuring that the solutions align with industry standards and enhance overall operational efficiency. Your role will involve hands-on analysis, algorithm design, and performance evaluation to provide actionable insights that drive improvements in the company's healthcare solutions.\", 'questions': [{'question_statement': 'Identify and analyze the various industrial use cases for LLM applications using Google Gemini in the healthcare sector. Take snapshots of your commands at each step and paste them below.', 'answer': 'The snapshot should include: lists of industrial use cases for healthcare LLM applications, including drug discovery, virtual health assistants, and automated clinical documentation. Use commands to create structured data tables to display these findings.', 'ability_id': ['A1', 'A3']}, {'question_statement': 'Implement a multimodal prompting design using Google Gemini to enhance algorithm performance in patient data processing. Take snapshots of your commands at each step and paste them below.', 'answer': 'The snapshot should include: the setup commands for Google AI Studio, including importing necessary libraries, configuring multimodal input parameters, and testing the initial design for efficiency. Document commands used in the configuration.', 'ability_id': ['A2', 'A6']}, {'question_statement': 'Build and deploy a simple LLM application using LangChain to automate patient inquiry responses, then assess its feasibility. Take snapshots of your commands at each step and paste them below.', 'answer': 'The snapshot should include: the code for importing LangChain, initializing the LLM with Google Gemini, executing patient inquiry prompts, and analyzing the responses. Include commands used in the setup.', 'ability_id': ['A5']}, {'question_statement': 'Evaluate the implementation of the Retrieval Augmented Generation (RAG) mechanism within the current LLM application and assess its performance. Take snapshots of your commands at each step and paste them below.', 'answer': 'The snapshot should include: the code snippets for document loading using CSVLoader, retrieving documents through the RAG model, and running queries to test response accuracy. Document commands used in loading and retrieval.', 'ability_id': ['A4']}]}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Extract the content from the last message\n",
    "    last_message_content = chat_result.chat_history[-1].get(\"content\", \"\")\n",
    "    if not last_message_content:\n",
    "        print(\"No content found in the agent's last message.\")\n",
    "\n",
    "    last_message_content = last_message_content.strip()\n",
    "\n",
    "    # Extract JSON context from the message\n",
    "    json_pattern = re.compile(r'```json\\s*(\\{.*?\\})\\s*```', re.DOTALL)\n",
    "    json_match = json_pattern.search(last_message_content)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "        context = json.loads(json_str)  # Parse the extracted JSON\n",
    "        print(f\"CONTEXT JSON MAPPING: \\n\\n{context}\")\n",
    "    else:\n",
    "        print(\"No JSON context found in the agent's last message.\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing context JSON: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"course_title\": \"Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini\",\n",
      "    \"duration\": \"1 hr\",\n",
      "    \"scenario\": \"In a rapidly evolving tech landscape, InnovateAI, a mid-sized company specializing in AI-driven solutions for the healthcare sector, is facing challenges in optimizing its patient management system. The company has recently integrated Google Gemini's Generative AI capabilities to enhance its application for real-time patient data analysis and decision support. As part of a project team, you are tasked with analyzing the current LLM applications to identify their strengths and limitations, establishing the design of algorithms that improve efficiency in processing patient data, and assessing the feasibility of these AI applications in streamlining engineering processes. Additionally, you will evaluate the performance effectiveness of the Retrieval Augmented Generation (RAG) model implemented in the system, ensuring that the solutions align with industry standards and enhance overall operational efficiency. Your role will involve hands-on analysis, algorithm design, and performance evaluation to provide actionable insights that drive improvements in the company's healthcare solutions.\",\n",
      "    \"questions\": [\n",
      "        {\n",
      "            \"question_statement\": \"Identify and analyze the various industrial use cases for LLM applications using Google Gemini in the healthcare sector. Take snapshots of your commands at each step and paste them below.\",\n",
      "            \"answer\": \"The snapshot should include: lists of industrial use cases for healthcare LLM applications, including drug discovery, virtual health assistants, and automated clinical documentation. Use commands to create structured data tables to display these findings.\",\n",
      "            \"ability_id\": [\n",
      "                \"A1\",\n",
      "                \"A3\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"Implement a multimodal prompting design using Google Gemini to enhance algorithm performance in patient data processing. Take snapshots of your commands at each step and paste them below.\",\n",
      "            \"answer\": \"The snapshot should include: the setup commands for Google AI Studio, including importing necessary libraries, configuring multimodal input parameters, and testing the initial design for efficiency. Document commands used in the configuration.\",\n",
      "            \"ability_id\": [\n",
      "                \"A2\",\n",
      "                \"A6\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"Build and deploy a simple LLM application using LangChain to automate patient inquiry responses, then assess its feasibility. Take snapshots of your commands at each step and paste them below.\",\n",
      "            \"answer\": \"The snapshot should include: the code for importing LangChain, initializing the LLM with Google Gemini, executing patient inquiry prompts, and analyzing the responses. Include commands used in the setup.\",\n",
      "            \"ability_id\": [\n",
      "                \"A5\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"Evaluate the implementation of the Retrieval Augmented Generation (RAG) mechanism within the current LLM application and assess its performance. Take snapshots of your commands at each step and paste them below.\",\n",
      "            \"answer\": \"The snapshot should include: the code snippets for document loading using CSVLoader, retrieving documents through the RAG model, and running queries to test response accuracy. Document commands used in loading and retrieval.\",\n",
      "            \"ability_id\": [\n",
      "                \"A4\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pretty_json = json.dumps(context, indent=4, ensure_ascii=False)\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and Answer Generation Agent for Case Study\n",
    "\n",
    "The Question and Answer Generation Agent is designed to facilitate the creation of educational content by generating scenario-based questions and answers. This agent operates by taking in a specified Learning Outcome (LO) and its associated abilities, retrieving relevant content, and then generating questions and answers that align with the given scenario and Bloom's Taxonomy level.\n",
    "\n",
    "#### Key Features:\n",
    "1. **Input Handling**:\n",
    "    - **Learning Outcome (LO)**: The specific educational goal that the learners are expected to achieve.\n",
    "    - **Associated Abilities**: The skills or competencies that are linked to the Learning Outcome.\n",
    "\n",
    "2. **Content Retrieval**:\n",
    "    - The agent retrieves content that is relevant to the specified Learning Outcome and its associated abilities. This ensures that the generated questions and answers are contextually appropriate and aligned with the educational objectives.\n",
    "\n",
    "3. **Scenario Alignment**:\n",
    "    - The agent generates a realistic and practical scenario that aligns with the Learning Outcome. This scenario provides a context for the questions and answers, making them more engaging and applicable to real-world situations.\n",
    "\n",
    "4. **Question and Answer Generation**:\n",
    "    - Based on the retrieved content and the generated scenario, the agent formulates questions that require learners to demonstrate their understanding and mastery of the Learning Outcome and associated abilities.\n",
    "    - The answers are crafted to align with Bloom's Taxonomy level, ensuring that they meet the desired cognitive complexity and educational standards.\n",
    "\n",
    "5. **Output**:\n",
    "    - The final output includes the scenario, the question, and the answer, all structured in a clear and concise format. This output can be used directly in educational assessments or as part of instructional materials.\n",
    "\n",
    "By integrating these features, the Question and Answer Generation Agent ensures that the generated educational content is both relevant and effective in achieving the specified learning objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.openai import OpenAI\n",
    "# from pydantic.v1 import BaseModel, Field\n",
    "# from typing import List\n",
    "# from IPython.display import display, Markdown, Image\n",
    "\n",
    "# # System prompt tailored for content retrieval and question-answer generation\n",
    "# system_prompt = \"\"\"\\\n",
    "# You are a content retrieval assistant. Your role is to retrieve and summarize topic content that aligns strictly with the specified Learning Outcome (LO) and its associated abilities.\n",
    "\n",
    "# Your role:\n",
    "# 1. Restrict your retrieval strictly to the specified topic provided in the query.\n",
    "# 2. Retrieve and summarize the content from the topic that directly aligns with the provided Learning Outcome (LO) and its abilities.\n",
    "# 3. If no specific content directly aligns with the Learning Outcome or abilities, provide a general summary of the topic instead.\n",
    "# 4. Identify and extract the exact inline segments from the provided documents that directly correspond to the content used to generate the summary. The extracted segments must be verbatim snippets from the documents, ensuring a word-for-word match with the text in the provided documents.\n",
    "\n",
    "# Ensure that:\n",
    "# - (Important) Each retrieved segment is an exact match to a part of the document and is fully contained within the document text.\n",
    "# - The relevance of each segment to the Learning Outcome or abilities is clear and directly supports the summary provided.\n",
    "# - (Important) If you didn't use the specific document or topic, do not mention it.\n",
    "# - If no relevant information is found for the Learning Outcome, clearly state this and provide a general topic summary instead.\n",
    "\n",
    "# Restrictions:\n",
    "# - Do not include content from other topics or slides outside the specified topic.\n",
    "# - Each retrieved segment must explicitly belong to the given topic.\n",
    "# - Avoid including assumptions or content outside the scope of the Learning Outcome and abilities.\n",
    "\n",
    "# You must always provide:\n",
    "# 1. A detailed summary of the retrieved content aligned with the Learning Outcome and abilities.\n",
    "# 2. A list of verbatim extracted segments that directly support the summary, each labeled with the topic and document it belongs to.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.openai import OpenAI\n",
    "# from typing import List\n",
    "# from IPython.display import display, Markdown\n",
    "\n",
    "# lo_retriever_llm = OpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_generation_query_engine = index.as_query_engine(\n",
    "#     similarity_top_k=10,\n",
    "#     llm=lo_retriever_llm,\n",
    "#     response_mode=\"compact\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 12-11 15:31:47] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "\u001b[33muser_proxy\u001b[0m (to Question Answer Generator):\n",
      "\n",
      "\n",
      "        Please generate the questions and answer using the following course title:'Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini', assessment_duration:'1 hr', scenario: 'TechSolutions Inc., a mid-sized technology consulting firm, has been experiencing significant challenges in managing client communications and project updates. With a growing portfolio of clients, the firm struggles to maintain timely and effective communication, leading to misunderstandings and delays in project deliverables. To address these issues, the management team has decided to explore the implementation of a Large Language Model (LLM) application using Google Gemini. They aim to analyze various LLM applications that can automate client interactions, streamline project updates, and enhance overall customer satisfaction. The team is particularly interested in assessing the feasibility of integrating this technology into their existing workflows and evaluating its potential to improve engineering processes and client engagement.\n",
      "\n",
      "As part of this initiative, the team will analyze the algorithms behind the proposed LLM applications, identify their strengths and limitations, and establish correlations between the design of these algorithms and their efficiency in real-world scenarios. They will also evaluate the performance effectiveness of a Retrieval Augmented Generation (RAG) approach to ensure that the LLM can provide accurate and contextually relevant responses to client inquiries. By the end of the project, TechSolutions Inc. aims to enhance its communication strategies, improve client satisfaction, and ultimately drive better project outcomes.' and topic contents:[{'learning_outcome': 'LO1  Analyze the range of LLM applications using Generative AI (GAI) and identify their industrial use cases.', 'abilities': ['A1', 'A3'], 'retrieved_content': 'To align with Learning Outcome LO1, which focuses on analyzing the range of LLM applications using Generative AI (GAI) and identifying their industrial use cases, the following relevant content has been retrieved:\\n\\n### Summary of Relevant Content:\\nLarge Language Models (LLMs) such as OpenAI\\'s GPT-4 and Google Gemini have a wide range of applications across various industries. These applications include content creation, customer support, language translation, educational tools, business intelligence, coding assistance, legal compliance, healthcare support, and more. Each application showcases the strengths of LLMs in understanding and generating human-like text, while also highlighting potential limitations such as context understanding and accuracy in specific domains.\\n\\n### Example Use Cases:\\n1. **Content Creation and Assistance**: LLMs can generate articles, blogs, and marketing content, enhancing productivity in creative industries.\\n2. **Customer Support and Chatbots**: They can automate responses to customer inquiries, improving service efficiency.\\n3. **Language Translation and Localization**: LLMs facilitate real-time translation, making global communication seamless.\\n4. **Educational Tools**: They provide personalized learning experiences and tutoring, adapting to individual student needs.\\n5. **Business Intelligence and Analytics**: LLMs analyze data trends and generate insights, aiding decision-making processes.\\n\\n### Extracted Segments:\\n1. **Opportunities of LLM Applications**:\\n   - \"Content Creation and Assistance\"\\n   - \"Customer Support and Chatbots\"\\n   - \"Language Translation and Localization\"\\n   - \"Educational Tools\"\\n   - \"Business Intelligence and Analytics\"\\n   - \"Legal and Compliance Assistance\"\\n   - \"Healthcare Support\"\\n   - \"Crisis Management and Response\"\\n\\n2. **Use Cases of GAI in Various Industries**:\\n   - **Finance**: \"Automated Financial Reporting\", \"Risk Assessment and Analysis\", \"Fraud Detection and Prevention\".\\n   - **Marketing**: \"Content Creation\", \"Market Research Analysis\", \"Personalized Marketing\".\\n   - **Education**: \"Personalized Learning Assistance\", \"Grading and Feedback Automation\".\\n   - **Healthcare**: \"Drug discovery and development\", \"Personalized medicine and treatment optimization\".\\n\\nThese segments illustrate the diverse applications of LLMs and their relevance in various sectors, fulfilling the requirements of LO1 and its associated abilities.\\n\\n### Document References:\\n- **Topic**: Overview of Large Language Model (LLM)\\n- **Segments**:\\n   - \"Opportunities of LLM Applications\"\\n   - \"Use Cases of GAI in Finance\"\\n   - \"Use Cases of GAI in Marketing\"\\n   - \"Use Cases of GAI in Education\"\\n   - \"Use Cases of GAI in Healthcare\"'}, {'learning_outcome': 'LO2  Establish Google Gemini GAI designs and assess improvements on engineering processes.', 'abilities': ['A2', 'A6'], 'retrieved_content': 'The content relevant to Learning Outcome LO2, which focuses on establishing Google Gemini GAI designs and assessing improvements on engineering processes, includes practical insights into the design and implementation of multimodal prompting with Google Gemini. This aligns with the associated abilities A2 and A6.\\n\\n### Retrieved Content:\\n1. **Multimodal Prompting with Google Gemini**:\\n   - The design of algorithms in multimodal prompting is crucial for enhancing efficiency in processing various types of inputs (text, images, etc.). This directly relates to establishing the correlation between algorithm design and efficiency.\\n   - The implementation of multimodal prompting allows for improved engineering processes by integrating different data types, which can lead to more effective and efficient AI applications.\\n\\n### Example Code Snippet:\\n```python\\n# Example of using Google Gemini for multimodal prompting\\nfrom google.generativeai import ChatGoogleGenerativeAI\\n\\n# Initialize the model\\nllm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\")\\n\\n# Define a multimodal prompt\\nresponse = llm.generate_content(\"Describe the image and provide a summary of the text.\")\\nprint(response.text)\\n```\\n\\n### Extracted Segments:\\n- **Topic**: Multimodal Prompting with Google Gemini LLM\\n  - \"The design of algorithms in multimodal prompting is crucial for enhancing efficiency in processing various types of inputs.\"\\n  - \"The implementation of multimodal prompting allows for improved engineering processes by integrating different data types.\"\\n\\nThese segments illustrate the connection between the design of algorithms and their efficiency, as well as the assessment of improvements in engineering processes through the use of multimodal prompting with Google Gemini.'}, {'learning_outcome': 'LO3 - Develop LLM applications and assess its feasibility.', 'abilities': ['A5'], 'retrieved_content': 'To align with Learning Outcome LO3, which focuses on developing LLM applications and assessing their feasibility, the following relevant content has been extracted:\\n\\n### Retrieved Content:\\n1. **Building LLM Applications with Google Gemini LLM**:\\n   - Overview of Langchain Components\\n   - Automate Workflow with Langchain and Gemini Model\\n   - Create AI Agent Using Langchain and Gemini LLM Model\\n\\n### Example Code:\\n```python\\nfrom langchain import LangChain\\nfrom langchain_google_genai import ChatGoogleGenerativeAI\\n\\n# Initialize the model\\nllm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\")\\n\\n# Define a prompt\\nprompt = \"What is the best name to describe a company that makes {product}?\"\\n\\n# Create a chain\\nchain = LangChain(llm=llm, prompt=prompt)\\n\\n# Run the chain with a specific product\\nresponse = chain.run(product=\"Queen Size Sheet Set\")\\nprint(response)\\n```\\n\\n### Verbatim Extracted Segments:\\n- **Topic**: Building LLM Applications with Google Gemini LLM\\n  - \"Overview of Langchain Components\"\\n  - \"Automate Workflow with Langchain and Gemini Model\"\\n  - \"Create AI Agent Using Langchain and Gemini LLM Model\"\\n\\nThese segments directly support the development of LLM applications and the assessment of their feasibility in engineering processes, as outlined in the associated abilities.'}, {'learning_outcome': 'LO4  Evaluate the performance effectiveness of Retrieval Augmented Generation (RAG).', 'abilities': ['A4'], 'retrieved_content': 'To address Learning Outcome LO4, which focuses on evaluating the performance effectiveness of Retrieval Augmented Generation (RAG), the following relevant content has been retrieved:\\n\\n### Summary of Relevant Content:\\nRetrieval Augmented Generation (RAG) combines the capabilities of language models with external knowledge sources to enhance the quality and relevance of generated responses. This approach allows for improved performance in various applications, such as question answering, information retrieval, and content recommendation. The effectiveness of RAG can be evaluated by examining how well it retrieves relevant documents and integrates them into the generation process, thus reducing hallucinations and improving the accuracy of the output.\\n\\n### Example Code Snippet:\\n```python\\nfrom langchain.chains import RetrievalQA\\n\\n# Initialize the RAG chain\\nqa_chain = RetrievalQA.from_chain_type(\\n    llm=ChatOpenAI(temperature=0),\\n    chain_type=\"stuff\"\\n)\\n\\n# Example query\\nquery = \"Please suggest a shirt with sunblocking\"\\nresult = qa_chain({\"query\": query})\\nprint(result)\\n```\\n\\n### Extracted Segments:\\n1. **RAG Overview**:\\n   - \"Retrieval Augmented Generation (RAG) combines the capabilities of language models with external knowledge sources to enhance the quality and relevance of generated responses.\"\\n   \\n2. **Performance Evaluation**:\\n   - \"The effectiveness of RAG can be evaluated by examining how well it retrieves relevant documents and integrates them into the generation process, thus reducing hallucinations and improving the accuracy of the output.\"\\n\\n3. **Use Cases of RAG**:\\n   - \"Use Cases of RAG include: Question Answering, Information Retrieval, Content Recommendation, Data Enrichment, Knowledge Base Construction, Academic Research, Legal Research, Language Translation, Customer Support, Educational Tools.\"\\n\\n4. **RetrievalQA Implementation**:\\n   - \"RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature=0), chain_type=\\'stuff\\')\"\\n\\nThese segments directly support the evaluation of RAG\\'s performance effectiveness and align with the specified Learning Outcome and associated abilities.'}]\n",
      "        Phrase your question in accordance with the Bloom's Taxonomy Level: 3\n",
      "        Bloom's Taxonomy Level Information:\n",
      "            Level 1: Remembering\n",
      "            Level 2: Understanding\n",
      "            Level 3: Applying\n",
      "            Level 4: Analyzing\n",
      "            Level 5: Evaluating\n",
      "            Level 6: Creating\n",
      "        Return the question and answer as a complete JSON dictionary containing the specified fields.\n",
      "        RETURN 'TERMINATE' once the generation is done.\n",
      "        \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mQuestion Answer Generator\u001b[0m (to user_proxy):\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"course_title\": \"Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini\",\n",
      "    \"duration\": \"1 hr\",\n",
      "    \"scenario\": \"TechSolutions Inc., a mid-sized technology consulting firm, has been experiencing significant challenges in managing client communications and project updates. With a growing portfolio of clients, the firm struggles to maintain timely and effective communication, leading to misunderstandings and delays in project deliverables. To address these issues, the management team has decided to explore the implementation of a Large Language Model (LLM) application using Google Gemini. They aim to analyze various LLM applications that can automate client interactions, streamline project updates, and enhance overall customer satisfaction. The team is particularly interested in assessing the feasibility of integrating this technology into their existing workflows and evaluating its potential to improve engineering processes and client engagement.\\n\\nAs part of this initiative, the team will analyze the algorithms behind the proposed LLM applications, identify their strengths and limitations, and establish correlations between the design of these algorithms and their efficiency in real-world scenarios. They will also evaluate the performance effectiveness of a Retrieval Augmented Generation (RAG) approach to ensure that the LLM can provide accurate and contextually relevant responses to client inquiries. By the end of the project, TechSolutions Inc. aims to enhance its communication strategies, improve client satisfaction, and ultimately drive better project outcomes.\",\n",
      "    \"questions\": [\n",
      "        {\n",
      "            \"question_statement\": \"How can TechSolutions Inc. leverage the capabilities of Generative AI applications to streamline project updates and improve client engagement within their engineering processes?\",\n",
      "            \"answer\": \"TechSolutions Inc. can leverage Generative AI applications by implementing LLMs for automating client communications, such as providing real-time updates about project progress and using chatbots to respond quickly to client inquiries. This technology enables the company to personalize interactions, ensuring timely responses and reducing misunderstandings, which ultimately enhances client satisfaction. By analyzing various industrial use cases, they can tailor these applications specifically to their workflows, maximizing efficiency and effectiveness.\",\n",
      "            \"ability_id\": [\"A1\", \"A3\"]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"What advantages does the multimodal prompting feature of Google Gemini provide for enhancing TechSolutions Inc.'s engineering processes?\",\n",
      "            \"answer\": \"The multimodal prompting feature of Google Gemini allows TechSolutions Inc. to process and understand multiple types of input, such as text and images, simultaneously. This capability can significantly enhance engineering processes by integrating various data types needed for project updates and client communications. By utilizing multimodal prompts, the firm can automate complex queries that involve visual data and text, leading to more efficient workflows and improved decision-making.\",\n",
      "            \"ability_id\": [\"A2\", \"A6\"]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"In developing an LLM application with Google Gemini, how can TechSolutions Inc. assess the feasibility of incorporating Generative AI into their current workflow?\",\n",
      "            \"answer\": \"To assess the feasibility of incorporating Generative AI into their current workflow, TechSolutions Inc. can start by analyzing existing processes to identify areas where automation could bring value. They should map out the potential LLM applications, such as automating report generation and client interactions. Conducting pilot tests using Langchain components to automate workflows can provide insights into the integration's effectiveness, enabling the team to determine how well it aligns with their operational needs.\",\n",
      "            \"ability_id\": [\"A5\"]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"What metrics should TechSolutions Inc. consider when evaluating the performance effectiveness of their Retrieval Augmented Generation (RAG) approach for client inquiries?\",\n",
      "            \"answer\": \"When evaluating the performance effectiveness of their RAG approach, TechSolutions Inc. should consider metrics such as retrieval accuracy, response relevance, and client satisfaction scores. They should analyze how well RAG retrieves pertinent documents to support the generative responses and the reduction of inaccuracies, or 'hallucinations,' in the output. Additionally, feedback from clients on the relevance and helpfulness of the responses generated can provide valuable insights into the RAG's effectiveness.\",\n",
      "            \"ability_id\": [\"A4\"]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1258: UserWarning: Cannot extract summary using reflection_with_llm: Error code: 400 - {'error': {'message': \"Invalid 'messages[1].name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': 'messages[1].name', 'code': 'invalid_value'}}. Using an empty str as summary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "from autogen.cache import Cache\n",
    "\n",
    "class CaseStudyQuestion(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    ability_id: List[str]\n",
    "\n",
    "class CaseStudy(BaseModel):\n",
    "    scenario: str\n",
    "    questions: List[CaseStudyQuestion]\n",
    "\n",
    "user_proxy_agent = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\", \"\") and \"TERMINATE\" in msg[\"content\"],\n",
    "    code_execution_config={\"work_dir\": \"output\", \"use_docker\": False}\n",
    ")\n",
    "\n",
    "# Autogen setup\n",
    "qa_generation_agent = AssistantAgent(\n",
    "    name=\"Question Answer Generator\",\n",
    "    system_message=f\"\"\"\n",
    "    You are an expert educator in '{extracted_data.course_title}'. You will create scenario-based case study question-answer pairs based on course data.\n",
    "    The data will include:\n",
    "    - A scenario\n",
    "    - Retrieved content aligned with learning outcomes and abilities\n",
    "\n",
    "    ### Instructions:\n",
    "    1. Use the provided scenario and retrieved content to generate one question-and-answer pairs per one learning outcome.\n",
    "    2. Each question should be aligned with the learning outcome and abilities implied by the retrieved content and the Bloom's Taxonomy Level.\n",
    "    3. The answer should demonstrate mastery of the abilities and address the scenario context.\n",
    "    4. Ensure all keys and values are double-quoted in the JSON output.\n",
    "    5. Return the output in JSON format with the following structure:\n",
    "        import\n",
    "        ```json\n",
    "        {{\n",
    "            \"course_title\": \"<course_title_here>\",\n",
    "            \"duration\": \"<assessment_duration_here>\",\n",
    "            \"scenario\": \"<scenario_here>\",\n",
    "            \"questions\": [\n",
    "            {{\n",
    "                \"question_statement\": \"<question_text>\",\n",
    "                \"answer\": \"<answer_text>\",\n",
    "                \"ability_id\": [\"<list_of_ability_ids>\"]\n",
    "            }},\n",
    "            ...\n",
    "            ]\n",
    "        }}\n",
    "        ```\n",
    "    \"\"\",\n",
    "    llm_config={\n",
    "        \"config_list\": [\n",
    "            {\n",
    "                'model': \"gpt-4o-mini\",\n",
    "                'api_key': OPENAI_API_KEY,\n",
    "            },\n",
    "        ],\n",
    "        \"timeout\": 120,\n",
    "    },\n",
    ")\n",
    "assessment_duration = \"\"\n",
    "for assessment in extracted_data.assessments:\n",
    "    if \"PP\" in assessment.code:\n",
    "        assessment_duration = assessment.duration\n",
    "\n",
    "with Cache.disk() as cache:\n",
    "    chat_result = user_proxy_agent.initiate_chat(\n",
    "        qa_generation_agent,\n",
    "        message=f\"\"\"\n",
    "        Please generate the questions and answer using the following course title:'{extracted_data.course_title}', assessment_duration:'{assessment_duration}', scenario: '{scenario}' and topic contents:{retrieved_content}\n",
    "        Phrase your question in accordance with the Bloom's Taxonomy Level: {extracted_data.tsc_proficiency_level}\n",
    "        Bloom's Taxonomy Level Information:\n",
    "            Level 1: Remembering\n",
    "            Level 2: Understanding\n",
    "            Level 3: Applying\n",
    "            Level 4: Analyzing\n",
    "            Level 5: Evaluating\n",
    "            Level 6: Creating\n",
    "        Return the question and answer as a complete JSON dictionary containing the specified fields.\n",
    "        RETURN 'TERMINATE' once the generation is done.\n",
    "        \"\"\",\n",
    "        summary_method=\"reflection_with_llm\",\n",
    "        cache=cache,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT JSON MAPPING: \n",
      "\n",
      "{'course_title': 'Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini', 'duration': '1 hr', 'scenario': 'TechSolutions Inc., a mid-sized technology consulting firm, has been experiencing significant challenges in managing client communications and project updates. With a growing portfolio of clients, the firm struggles to maintain timely and effective communication, leading to misunderstandings and delays in project deliverables. To address these issues, the management team has decided to explore the implementation of a Large Language Model (LLM) application using Google Gemini. They aim to analyze various LLM applications that can automate client interactions, streamline project updates, and enhance overall customer satisfaction. The team is particularly interested in assessing the feasibility of integrating this technology into their existing workflows and evaluating its potential to improve engineering processes and client engagement.\\n\\nAs part of this initiative, the team will analyze the algorithms behind the proposed LLM applications, identify their strengths and limitations, and establish correlations between the design of these algorithms and their efficiency in real-world scenarios. They will also evaluate the performance effectiveness of a Retrieval Augmented Generation (RAG) approach to ensure that the LLM can provide accurate and contextually relevant responses to client inquiries. By the end of the project, TechSolutions Inc. aims to enhance its communication strategies, improve client satisfaction, and ultimately drive better project outcomes.', 'questions': [{'question_statement': 'How can TechSolutions Inc. leverage the capabilities of Generative AI applications to streamline project updates and improve client engagement within their engineering processes?', 'answer': 'TechSolutions Inc. can leverage Generative AI applications by implementing LLMs for automating client communications, such as providing real-time updates about project progress and using chatbots to respond quickly to client inquiries. This technology enables the company to personalize interactions, ensuring timely responses and reducing misunderstandings, which ultimately enhances client satisfaction. By analyzing various industrial use cases, they can tailor these applications specifically to their workflows, maximizing efficiency and effectiveness.', 'ability_id': ['A1', 'A3']}, {'question_statement': \"What advantages does the multimodal prompting feature of Google Gemini provide for enhancing TechSolutions Inc.'s engineering processes?\", 'answer': 'The multimodal prompting feature of Google Gemini allows TechSolutions Inc. to process and understand multiple types of input, such as text and images, simultaneously. This capability can significantly enhance engineering processes by integrating various data types needed for project updates and client communications. By utilizing multimodal prompts, the firm can automate complex queries that involve visual data and text, leading to more efficient workflows and improved decision-making.', 'ability_id': ['A2', 'A6']}, {'question_statement': 'In developing an LLM application with Google Gemini, how can TechSolutions Inc. assess the feasibility of incorporating Generative AI into their current workflow?', 'answer': \"To assess the feasibility of incorporating Generative AI into their current workflow, TechSolutions Inc. can start by analyzing existing processes to identify areas where automation could bring value. They should map out the potential LLM applications, such as automating report generation and client interactions. Conducting pilot tests using Langchain components to automate workflows can provide insights into the integration's effectiveness, enabling the team to determine how well it aligns with their operational needs.\", 'ability_id': ['A5']}, {'question_statement': 'What metrics should TechSolutions Inc. consider when evaluating the performance effectiveness of their Retrieval Augmented Generation (RAG) approach for client inquiries?', 'answer': \"When evaluating the performance effectiveness of their RAG approach, TechSolutions Inc. should consider metrics such as retrieval accuracy, response relevance, and client satisfaction scores. They should analyze how well RAG retrieves pertinent documents to support the generative responses and the reduction of inaccuracies, or 'hallucinations,' in the output. Additionally, feedback from clients on the relevance and helpfulness of the responses generated can provide valuable insights into the RAG's effectiveness.\", 'ability_id': ['A4']}]}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    last_message_content = chat_result.chat_history[-1].get(\"content\", \"\")\n",
    "    if not last_message_content:\n",
    "        print(\"No content found in the agent's last message.\")\n",
    "    last_message_content = last_message_content.strip()\n",
    "    json_pattern = re.compile(r'```json\\s*(\\{.*?\\})\\s*```', re.DOTALL)\n",
    "    json_match = json_pattern.search(last_message_content)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "        context = json.loads(json_str)\n",
    "        print(f\"CONTEXT JSON MAPPING: \\n\\n{context}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing context JSON: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 12-11 15:32:59] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 12-11 15:32:59] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "\u001b[33muser_proxy\u001b[0m (to Question Answer Generator):\n",
      "\n",
      "\n",
      "        Please generate assessment documents with the context: {'course_title': 'Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini', 'duration': '1 hr', 'scenario': 'TechSolutions Inc., a mid-sized technology consulting firm, has been experiencing significant challenges in managing client communications and project updates. With a growing portfolio of clients, the firm struggles to maintain timely and effective communication, leading to misunderstandings and delays in project deliverables. To address these issues, the management team has decided to explore the implementation of a Large Language Model (LLM) application using Google Gemini. They aim to analyze various LLM applications that can automate client interactions, streamline project updates, and enhance overall customer satisfaction. The team is particularly interested in assessing the feasibility of integrating this technology into their existing workflows and evaluating its potential to improve engineering processes and client engagement.\\n\\nAs part of this initiative, the team will analyze the algorithms behind the proposed LLM applications, identify their strengths and limitations, and establish correlations between the design of these algorithms and their efficiency in real-world scenarios. They will also evaluate the performance effectiveness of a Retrieval Augmented Generation (RAG) approach to ensure that the LLM can provide accurate and contextually relevant responses to client inquiries. By the end of the project, TechSolutions Inc. aims to enhance its communication strategies, improve client satisfaction, and ultimately drive better project outcomes.', 'questions': [{'question_statement': 'How can TechSolutions Inc. leverage the capabilities of Generative AI applications to streamline project updates and improve client engagement within their engineering processes?', 'answer': 'TechSolutions Inc. can leverage Generative AI applications by implementing LLMs for automating client communications, such as providing real-time updates about project progress and using chatbots to respond quickly to client inquiries. This technology enables the company to personalize interactions, ensuring timely responses and reducing misunderstandings, which ultimately enhances client satisfaction. By analyzing various industrial use cases, they can tailor these applications specifically to their workflows, maximizing efficiency and effectiveness.', 'ability_id': ['A1', 'A3']}, {'question_statement': \"What advantages does the multimodal prompting feature of Google Gemini provide for enhancing TechSolutions Inc.'s engineering processes?\", 'answer': 'The multimodal prompting feature of Google Gemini allows TechSolutions Inc. to process and understand multiple types of input, such as text and images, simultaneously. This capability can significantly enhance engineering processes by integrating various data types needed for project updates and client communications. By utilizing multimodal prompts, the firm can automate complex queries that involve visual data and text, leading to more efficient workflows and improved decision-making.', 'ability_id': ['A2', 'A6']}, {'question_statement': 'In developing an LLM application with Google Gemini, how can TechSolutions Inc. assess the feasibility of incorporating Generative AI into their current workflow?', 'answer': \"To assess the feasibility of incorporating Generative AI into their current workflow, TechSolutions Inc. can start by analyzing existing processes to identify areas where automation could bring value. They should map out the potential LLM applications, such as automating report generation and client interactions. Conducting pilot tests using Langchain components to automate workflows can provide insights into the integration's effectiveness, enabling the team to determine how well it aligns with their operational needs.\", 'ability_id': ['A5']}, {'question_statement': 'What metrics should TechSolutions Inc. consider when evaluating the performance effectiveness of their Retrieval Augmented Generation (RAG) approach for client inquiries?', 'answer': \"When evaluating the performance effectiveness of their RAG approach, TechSolutions Inc. should consider metrics such as retrieval accuracy, response relevance, and client satisfaction scores. They should analyze how well RAG retrieves pertinent documents to support the generative responses and the reduction of inaccuracies, or 'hallucinations,' in the output. Additionally, feedback from clients on the relevance and helpfulness of the responses generated can provide valuable insights into the RAG's effectiveness.\", 'ability_id': ['A4']}]}\n",
      "        RETURN 'TERMINATE' once the document generation is done.\n",
      "        \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mQuestion Answer Generator\u001b[0m (to user_proxy):\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"course_title\": \"Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini\",\n",
      "    \"duration\": \"1 hr\",\n",
      "    \"scenario\": \"TechSolutions Inc., a mid-sized technology consulting firm, has been experiencing significant challenges in managing client communications and project updates. With a growing portfolio of clients, the firm struggles to maintain timely and effective communication, leading to misunderstandings and delays in project deliverables. To address these issues, the management team has decided to explore the implementation of a Large Language Model (LLM) application using Google Gemini. They aim to analyze various LLM applications that can automate client interactions, streamline project updates, and enhance overall customer satisfaction. The team is particularly interested in assessing the feasibility of integrating this technology into their existing workflows and evaluating its potential to improve engineering processes and client engagement. As part of this initiative, the team will analyze the algorithms behind the proposed LLM applications, identify their strengths and limitations, and establish correlations between the design of these algorithms and their efficiency in real-world scenarios. They will also evaluate the performance effectiveness of a Retrieval Augmented Generation (RAG) approach to ensure that the LLM can provide accurate and contextually relevant responses to client inquiries. By the end of the project, TechSolutions Inc. aims to enhance its communication strategies, improve client satisfaction, and ultimately drive better project outcomes.\",\n",
      "    \"questions\": [\n",
      "        {\n",
      "            \"question_statement\": \"How can TechSolutions Inc. leverage the capabilities of Generative AI applications to streamline project updates and improve client engagement within their engineering processes?\",\n",
      "            \"answer\": \"TechSolutions Inc. can leverage Generative AI applications by implementing LLMs for automating client communications, such as providing real-time updates about project progress and using chatbots to respond quickly to client inquiries. This technology enables the company to personalize interactions, ensuring timely responses and reducing misunderstandings, which ultimately enhances client satisfaction. By analyzing various industrial use cases, they can tailor these applications specifically to their workflows, maximizing efficiency and effectiveness.\",\n",
      "            \"ability_id\": [\"A1\", \"A3\"]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"What advantages does the multimodal prompting feature of Google Gemini provide for enhancing TechSolutions Inc.'s engineering processes?\",\n",
      "            \"answer\": \"The multimodal prompting feature of Google Gemini allows TechSolutions Inc. to process and understand multiple types of input, such as text and images, simultaneously. This capability can significantly enhance engineering processes by integrating various data types needed for project updates and client communications. By utilizing multimodal prompts, the firm can automate complex queries that involve visual data and text, leading to more efficient workflows and improved decision-making.\",\n",
      "            \"ability_id\": [\"A2\", \"A6\"]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"In developing an LLM application with Google Gemini, how can TechSolutions Inc. assess the feasibility of incorporating Generative AI into their current workflow?\",\n",
      "            \"answer\": \"To assess the feasibility of incorporating Generative AI into their current workflow, TechSolutions Inc. can start by analyzing existing processes to identify areas where automation could bring value. They should map out the potential LLM applications, such as automating report generation and client interactions. Conducting pilot tests using Langchain components to automate workflows can provide insights into the integration's effectiveness, enabling the team to determine how well it aligns with their operational needs.\",\n",
      "            \"ability_id\": [\"A5\"]\n",
      "        },\n",
      "        {\n",
      "            \"question_statement\": \"What metrics should TechSolutions Inc. consider when evaluating the performance effectiveness of their Retrieval Augmented Generation (RAG) approach for client inquiries?\",\n",
      "            \"answer\": \"When evaluating the performance effectiveness of their RAG approach, TechSolutions Inc. should consider metrics such as retrieval accuracy, response relevance, and client satisfaction scores. They should analyze how well RAG retrieves pertinent documents to support the generative responses and the reduction of inaccuracies, or 'hallucinations,' in the output. Additionally, feedback from clients on the relevance and helpfulness of the responses generated can provide valuable insights into the RAG's effectiveness.\",\n",
      "            \"ability_id\": [\"A4\"]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Autogen setup\n",
    "user_proxy_agent = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\", \"\") and \"TERMINATE\" in msg[\"content\"],\n",
    "    code_execution_config={\"work_dir\": \"output\", \"use_docker\": False}\n",
    ")\n",
    "\n",
    "cs_writer_agent = AssistantAgent(\n",
    "    name=\"Question Answer Generator\",\n",
    "    system_message=\"\"\"\n",
    "    You are an assistant that generates scenario-based question-answer pairs based on course data.\n",
    "\n",
    "    Your Task:\n",
    "    1. You have received the assessment information JSON dictionary.\n",
    "    2. Call the `generate_documents` function with the arguments: context=context.\n",
    "    **Example function call:**\n",
    "    ```python\n",
    "    generate_document(context=json context)\n",
    "    ```\n",
    "    3. Ensure that you only pass 'context' as arguments.\n",
    "    4. After the function call, include the output path returned by the function in your final message, starting with `Output Paths: ` followed by the path.\n",
    "    5. Return 'TERMINATE' when the task is done.\n",
    "    \"\"\",\n",
    "    llm_config={\n",
    "        \"config_list\": [\n",
    "            {\n",
    "                'model': \"gpt-4o-mini\",\n",
    "                'api_key': OPENAI_API_KEY,\n",
    "            },\n",
    "        ],\n",
    "        \"timeout\": 120,\n",
    "    },\n",
    ")\n",
    "\n",
    "@user_proxy_agent.register_for_execution()\n",
    "@cs_writer_agent.register_for_llm(name=\"generate_document\", description=\"Generate the Facilitator Guide document\")\n",
    "def generate_documents(context: dict, output_dir: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate the question paper and answer paper for the given context and type.\n",
    "\n",
    "    Parameters:\n",
    "    - context (dict): The data for the assessment (course title, type, questions, etc.).\n",
    "    - type (int): The assessment type (1 for Ability-based, 2 for Knowledge-based).\n",
    "    - output_dir (str): Directory where the generated documents will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Paths to the generated documents (question and answer papers).\n",
    "    \"\"\"\n",
    "    # Define template paths\n",
    "    TEMPLATES = {\n",
    "        1: { # PP\n",
    "            \"ANSWER\": \"../Templates/(Template) Answer to A Assessment - Course Title - v1.docx\",\n",
    "            \"QUESTION\": \"../Templates//(Template) A Assessment - Course Title - v1.docx\"\n",
    "        },\n",
    "        2: { # SAQ\n",
    "            \"ANSWER\": \"../Templates/(Template) Answer to WA (SAQ) - Course Title - v1.docx\",\n",
    "            \"QUESTION\": \"../Templates/(Template) WA (SAQ) - Course Title - v1.docx\"\n",
    "        },\n",
    "        3: { # CS\n",
    "            \"ANSWER\": \"../Templates/(Template) Answers to CS - Course Title - v1.docx\",\n",
    "            \"QUESTION\": \"../Templates/(Template) CS - Course Title - v1.docx\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Validate type\n",
    "    if type not in TEMPLATES:\n",
    "        raise ValueError(\"Invalid type. Must be 1 (Ability-based) or 2 (Knowledge-based).\")\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load templates\n",
    "    answer_template_path = TEMPLATES[3][\"ANSWER\"]\n",
    "    question_template_path = TEMPLATES[3][\"QUESTION\"]\n",
    "    answer_doc = DocxTemplate(answer_template_path)\n",
    "    question_doc = DocxTemplate(question_template_path)\n",
    "\n",
    "    # Prepare context for the question paper by creating a copy of the context without answers\n",
    "    question_context = {\n",
    "        **context,\n",
    "        \"questions\": [\n",
    "            {\n",
    "                **question,\n",
    "                \"answer\": None,  # Remove answers for the question document\n",
    "            }\n",
    "            for question in context.get(\"questions\", [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Render both templates\n",
    "    answer_doc.render(context)  # Render with answers\n",
    "    question_doc.render(question_context)  # Render without answers\n",
    "\n",
    "    # Save the documents to the output directory\n",
    "    files = {\n",
    "        \"ANSWER\": os.path.join(output_dir, f\"Answers to CS - {context['course_title']} - v1.docx\"),\n",
    "        \"QUESTION\": os.path.join(output_dir, f\"CS - {context['course_title']} - v1.docx\")\n",
    "    }\n",
    "    answer_doc.save(files[\"ANSWER\"])\n",
    "    question_doc.save(files[\"QUESTION\"])\n",
    "\n",
    "    return files  # Return paths to the generated documents\n",
    "\n",
    "with Cache.disk() as cache:\n",
    "    chat_result = user_proxy_agent.initiate_chat(\n",
    "        qa_generation_agent,\n",
    "        message=f\"\"\"\n",
    "        Please generate assessment documents with the context: {context}\n",
    "        RETURN 'TERMINATE' once the document generation is done.\n",
    "        \"\"\",\n",
    "        summary_method=\"reflection_with_llm\",\n",
    "        cache=cache,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents generated: {'ANSWER': 'output\\\\Answer to CS - Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini - v1.docx', 'QUESTION': 'output\\\\CS - Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini - v1.docx'}\n"
     ]
    }
   ],
   "source": [
    "from docxtpl import DocxTemplate\n",
    "\n",
    "def generate_documents(context: dict, type: int, output_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generate the question paper and answer paper for the given context and type.\n",
    "\n",
    "    Parameters:\n",
    "    - context (dict): The data for the assessment (course title, type, questions, etc.).\n",
    "    - type (int): The assessment type (1 for Ability-based, 2 for Knowledge-based).\n",
    "    - output_dir (str): Directory where the generated documents will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Paths to the generated documents (question and answer papers).\n",
    "    \"\"\"\n",
    "    # Define template paths\n",
    "    TEMPLATES = {\n",
    "        1: { # PP\n",
    "            \"ANSWER\": \"../Templates/(Template) Answer to A Assessment - Course Title - v1.docx\",\n",
    "            \"QUESTION\": \"../Templates//(Template) A Assessment - Course Title - v1.docx\"\n",
    "        },\n",
    "        2: { # SAQ\n",
    "            \"ANSWER\": \"../Templates/(Template) Answer to WA (SAQ) - Course Title - v1.docx\",\n",
    "            \"QUESTION\": \"../Templates/(Template) WA (SAQ) - Course Title - v1.docx\"\n",
    "        },\n",
    "        3: { # CS\n",
    "            \"ANSWER\": \"../Templates/(Template) Answer to CS - Course Title - v1.docx\",\n",
    "            \"QUESTION\": \"../Templates/(Template) CS - Course Title - v1.docx\"\n",
    "        },\n",
    "        # 4: { # OQ\n",
    "        #     \"ANSWER\": None,\n",
    "        #     \"QUESTION\": r\"C:\\Users\\dljh1\\Documents\\courseware_autogen\\Assessment\\Templates\\(Template) WA (SAQ) - Course Title - v1.docx\"\n",
    "        # },\n",
    "    }\n",
    "\n",
    "    # Validate type\n",
    "    if type not in TEMPLATES:\n",
    "        raise ValueError(\"Invalid type. Must be 1 (Ability-based) or 2 (Knowledge-based).\")\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load templates\n",
    "    answer_template_path = TEMPLATES[type][\"ANSWER\"]\n",
    "    question_template_path = TEMPLATES[type][\"QUESTION\"]\n",
    "    answer_doc = DocxTemplate(answer_template_path)\n",
    "    question_doc = DocxTemplate(question_template_path)\n",
    "\n",
    "    # Prepare context for the question paper by creating a copy of the context without answers\n",
    "    question_context = {\n",
    "        **context,\n",
    "        \"questions\": [\n",
    "            {\n",
    "                **question,\n",
    "                \"answer\": None,  # Remove answers for the question document\n",
    "            }\n",
    "            for question in context.get(\"questions\", [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Render both templates\n",
    "    answer_doc.render(context)  # Render with answers\n",
    "    question_doc.render(question_context)  # Render without answers\n",
    "\n",
    "    # Save the documents to the output directory\n",
    "    files = {\n",
    "        \"ANSWER\": os.path.join(output_dir, f\"Answer to CS - {context['course_title']} - v1.docx\"),\n",
    "        \"QUESTION\": os.path.join(output_dir, f\"CS - {context['course_title']} - v1.docx\")\n",
    "    }\n",
    "    answer_doc.save(files[\"ANSWER\"])\n",
    "    question_doc.save(files[\"QUESTION\"])\n",
    "\n",
    "    return files  # Return paths to the generated documents\n",
    "\n",
    "files = generate_documents(context, type=3, output_dir=\"output\")  # 'type=2' as per your code for knowledge-based assessment\n",
    "print(\"Documents generated:\", files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Short Answer Questions (SAQ)\n",
    "\n",
    "In this section, we generate SAQs for each Knowledge Statement using OpenAI. The generated questions include a scenario, a question, and an answer, which are structured in a JSON format. The process involves querying the OpenAI model with the relevant content retrieved for each Knowledge Statement. The results are then saved to a file for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from typing import List\n",
    "\n",
    "# System prompt tailored for content retrieval\n",
    "system_prompt = \"\"\"\\\n",
    "You are a content retrieval assistant tasked with retrieving educational topic content aligned with a given Knowledge Statement.\n",
    "\n",
    "Your role:\n",
    "1. Restrict your retrieval strictly to the specified topic provided in the query.\n",
    "2. Retrieve and summarize the topic content that aligns with the provided Knowledge Statement.\n",
    "3. If no specific content directly aligns with the Knowledge Statement, provide a general summary of the specified topic instead.\n",
    "4. Identify and extract the exact inline segments from the provided documents that directly correspond to the content used to \n",
    "generate the given answer. The extracted segments must be verbatim snippets from the documents, ensuring a word-for-word match with the text \n",
    "in the provided documents.\n",
    "\n",
    "Ensure that:\n",
    "- (Important) Each segment is an exact match to a part of the document and is fully contained within the document text.\n",
    "- The relevance of each segment to the generated answer is clear and directly supports the answer provided.\n",
    "- (Important) If you didn't used the specific document don't mention it.\n",
    "- If no relevant information is found for the Knowledge Statement, clearly state this and provide a general topic summary instead.\n",
    "\n",
    "Restrictions:\n",
    "- Do not include content from other topics or slides outside the specified topic.\n",
    "- Each retrieved segment must explicitly belong to the given topic.\n",
    "\"\"\"\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    llm=llm,\n",
    "    # response_mode=\"tree_summarize\"\n",
    "    response_mode=\"compact\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extracted_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m retrieved_data: List[KnowledgeStatementContent] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate through all learning units and topics to query for all Knowledge Statements\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m learning_unit \u001b[38;5;129;01min\u001b[39;00m \u001b[43mextracted_data\u001b[49m\u001b[38;5;241m.\u001b[39mlearning_units:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m learning_unit\u001b[38;5;241m.\u001b[39mtopics:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m knowledge \u001b[38;5;129;01min\u001b[39;00m topic\u001b[38;5;241m.\u001b[39mtsc_knowledges:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extracted_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store structured outputs\n",
    "retrieved_data: List[KnowledgeStatementContent] = []\n",
    "\n",
    "# Iterate through all learning units and topics to query for all Knowledge Statements\n",
    "for learning_unit in extracted_data.learning_units:\n",
    "    for topic in learning_unit.topics:\n",
    "        for knowledge in topic.tsc_knowledges:\n",
    "            knowledge_id = knowledge.id\n",
    "            knowledge_statement = knowledge.text\n",
    "            topic_name = topic.name\n",
    "\n",
    "            print(f\"\\n--- Retrieving for Knowledge Statement: {knowledge_id}: {knowledge_statement}\")\n",
    "            \n",
    "            # Query the index to retrieve topic content for this Knowledge Statement\n",
    "            response = query_engine.query(\n",
    "                f\"Generate questions and answer content for the following topic: '{topic.name}' aligning to the Knowledge Statement: '{knowledge_statement}'.\"\n",
    "            )\n",
    "            retrieved_content = response.response\n",
    "\n",
    "            # Add the structured data using Pydantic model\n",
    "            try:\n",
    "                knowledge_data = KnowledgeStatementContent(\n",
    "                    knowledge_id=knowledge_id,\n",
    "                    knowledge_statement=knowledge_statement,\n",
    "                    topic_name=topic_name,\n",
    "                    retrieved_content=retrieved_content\n",
    "                )\n",
    "                retrieved_data.append(knowledge_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding structured data for {knowledge_id}: {e}\")\n",
    "\n",
    "# Print structured data for verification\n",
    "for entry in retrieved_data:\n",
    "    print(entry.json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"TERTIARY_INFOTECH_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Function to generate WSQ using OpenAI\n",
    "def generate_wsq_openai(knowledge_id: str, knowledge_statement: str, topic_name: str, retrieved_content: str) -> WSQ:\n",
    "    \"\"\"\n",
    "    Generate a Workplace Scenario Question (WSQ) using OpenAI.\n",
    "\n",
    "    Args:\n",
    "        knowledge_id (str): The ID of the Knowledge Statement.\n",
    "        knowledge_statement (str): The Knowledge Statement.\n",
    "        topic_name (str): The name of the topic.\n",
    "        retrieved_content (str): The content retrieved for the Knowledge Statement.\n",
    "\n",
    "    Returns:\n",
    "        WSQ: A structured WSQ object.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an experienced instructional designer tasked with creating Workplace Scenario Questions (WSQs). Your output must include a Knowledge Statement, Scenario, Question, and Answer in JSON format.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Generate a WSQ for the following inputs:\\n\\n\"\n",
    "                f\"Knowledge ID: {knowledge_id}\\n\"\n",
    "                f\"Knowledge Statement: {knowledge_statement}\\n\"\n",
    "                f\"Topic Name: {topic_name}\\n\"\n",
    "                f\"Retrieved Content: {retrieved_content}\\n\\n\"\n",
    "                f\"Ensure the response adheres to this schema: {{'knowledge_id': 'string', 'knowledge_statement': 'string', 'scenario': 'string', 'question': 'string', 'answer': 'string'}}.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Call OpenAI's structured response API\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        response_format=WSQ\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        wsq_data = response.choices[0].message.parsed\n",
    "        return wsq_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating WSQ: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WSQ for K1: Range of AI applications ---\n",
      "\n",
      "Scenario: As a business analyst, you are tasked with presenting a report on the potential applications of Large Language Models (LLMs) to your team. You have identified several areas where LLMs can be beneficial, such as customer support, content creation, and educational tools.\n",
      "\n",
      "Question: What are some common applications of Large Language Models (LLMs) that you could include in your report to the team?\n",
      "\n",
      "Answer: Common applications of LLMs include content creation and assistance, customer support and chatbots, language translation and localization, educational tools, business intelligence and analytics, accessibility for disabled persons, coding and development, legal and compliance assistance, healthcare support, art and design inspiration, enhanced search engines, and crisis management and response.\n",
      "\n",
      "\n",
      "--- WSQ for K6: Applicability of AI in the industry ---\n",
      "\n",
      "Scenario: A manager at a healthcare organization is exploring new technologies to improve patient care and streamline operations within the hospital. They gather their staff to discuss the potential applications of Large Language Models (LLMs) in their daily processes.\n",
      "\n",
      "Question: What are some specific applications of LLMs in the healthcare industry that could improve patient care and streamline operations?\n",
      "\n",
      "Answer: LLMs can be applied in healthcare for drug discovery, personalized medicine, automated clinical documentation, analyzing medical data for insights, and enhancing patient engagement through virtual health assistants.\n",
      "\n",
      "\n",
      "--- WSQ for K4: Algorithm design and implementation ---\n",
      "\n",
      "Scenario: A team of data scientists at a tech company is working on improving their interactive assistant powered by the Google Gemini LLM. They need to ensure that the assistant can effectively process various types of inputs, including text, images, and audio, to provide accurate and context-aware responses to users.\n",
      "\n",
      "Question: How can the design of algorithms enhance the performance of the interactive assistant in processing multimodal inputs?\n",
      "\n",
      "Answer: The design of algorithms enhances performance by enabling the assistant to accurately process and integrate different input types, ensuring coherent and contextually relevant responses, and improving interaction quality.\n",
      "\n",
      "\n",
      "--- WSQ for K5: Methods of evaluating process improvements to the engineering processes using AI ---\n",
      "\n",
      "Scenario: A team of engineers is looking to leverage AI to assess the effectiveness of recent changes made to their design processes. They want to understand how the integration of both visual design outputs and performance data can help identify further optimizations.\n",
      "\n",
      "Question: How can multimodal prompting enhance the evaluation of the engineering design process improvements made by the team?\n",
      "\n",
      "Answer: Multimodal prompting enables the AI to analyze various inputs like design images and performance metrics simultaneously, offering a holistic view of the design workflow. This leads to more precise evaluations and uncovering of further optimization opportunities.\n",
      "\n",
      "\n",
      "--- WSQ for K3: Methods of evaluating effectiveness of AI applications ---\n",
      "\n",
      "Scenario: A team is developing a customer support AI application using Google Gemini LLM. After deployment, they want to assess how well the AI performs in real interactions with users. They have set up collection systems for both user satisfaction ratings and system response data. During the evaluation phase, they notice a decline in user retention over several weeks, prompting discussions on how to improve the application.\n",
      "\n",
      "Question: What key performance indicators (KPIs) should the team consider evaluating to address the decline in user retention for their AI application?\n",
      "\n",
      "Answer: The team should evaluate KPIs such as accuracy of responses, response time, user satisfaction ratings, and the frequency of user interactions. Additionally, examining metrics like session duration can provide insights into user engagement and help identify areas needing improvement.\n",
      "\n",
      "\n",
      "--- WSQ for K2: Concepts pertaining to performance effectiveness and analysis ---\n",
      "\n",
      "Scenario: A customer support agent is struggling to provide accurate responses to user inquiries due to outdated knowledge. The team decides to implement Retrieval Augmented Generation (RAG) to enhance response quality. During a team meeting, the manager asks for an overview of how RAG operates and its benefits.\n",
      "\n",
      "Question: What is the primary purpose of implementing Retrieval Augmented Generation (RAG) in customer support?\n",
      "\n",
      "Answer: The primary purpose of implementing RAG in customer support is to provide quick and accurate responses by leveraging current and relevant information retrieved from a knowledge base, thereby improving customer satisfaction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate WSQs for each Knowledge Statement in retrieved_data\n",
    "wsq_results = []\n",
    "\n",
    "for entry in retrieved_data:\n",
    "    # Access attributes of the Pydantic model\n",
    "    knowledge_id = entry.knowledge_id\n",
    "    knowledge_statement = entry.knowledge_statement\n",
    "    topic_name = entry.topic_name\n",
    "    retrieved_content = entry.retrieved_content\n",
    "\n",
    "    # Generate WSQ\n",
    "    wsq = generate_wsq_openai(knowledge_id, knowledge_statement, topic_name, retrieved_content)\n",
    "    if wsq:\n",
    "        print(f\"\\n--- WSQ for {knowledge_id}: {knowledge_statement} ---\\n\")\n",
    "        print(f\"Scenario: {wsq.scenario}\\n\")\n",
    "        print(f\"Question: {wsq.question}\\n\")\n",
    "        print(f\"Answer: {wsq.answer}\\n\")\n",
    "        wsq_results.append(wsq)\n",
    "\n",
    "# Save WSQs to a file for further use\n",
    "with open(\"wsq_results.json\", \"w\") as f:\n",
    "    json.dump([wsq.dict() for wsq in wsq_results], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WSQ(knowledge_id='K1', knowledge_statement='Range of AI applications', scenario='As a business analyst, you are tasked with presenting a report on the potential applications of Large Language Models (LLMs) to your team. You have identified several areas where LLMs can be beneficial, such as customer support, content creation, and educational tools.', question='What are some common applications of Large Language Models (LLMs) that you could include in your report to the team?', answer='Common applications of LLMs include content creation and assistance, customer support and chatbots, language translation and localization, educational tools, business intelligence and analytics, accessibility for disabled persons, coding and development, legal and compliance assistance, healthcare support, art and design inspiration, enhanced search engines, and crisis management and response.'), WSQ(knowledge_id='K6', knowledge_statement='Applicability of AI in the industry', scenario='A manager at a healthcare organization is exploring new technologies to improve patient care and streamline operations within the hospital. They gather their staff to discuss the potential applications of Large Language Models (LLMs) in their daily processes.', question='What are some specific applications of LLMs in the healthcare industry that could improve patient care and streamline operations?', answer='LLMs can be applied in healthcare for drug discovery, personalized medicine, automated clinical documentation, analyzing medical data for insights, and enhancing patient engagement through virtual health assistants.'), WSQ(knowledge_id='K4', knowledge_statement='Algorithm design and implementation', scenario='A team of data scientists at a tech company is working on improving their interactive assistant powered by the Google Gemini LLM. They need to ensure that the assistant can effectively process various types of inputs, including text, images, and audio, to provide accurate and context-aware responses to users.', question='How can the design of algorithms enhance the performance of the interactive assistant in processing multimodal inputs?', answer='The design of algorithms enhances performance by enabling the assistant to accurately process and integrate different input types, ensuring coherent and contextually relevant responses, and improving interaction quality.'), WSQ(knowledge_id='K5', knowledge_statement='Methods of evaluating process improvements to the engineering processes using AI', scenario='A team of engineers is looking to leverage AI to assess the effectiveness of recent changes made to their design processes. They want to understand how the integration of both visual design outputs and performance data can help identify further optimizations.', question='How can multimodal prompting enhance the evaluation of the engineering design process improvements made by the team?', answer='Multimodal prompting enables the AI to analyze various inputs like design images and performance metrics simultaneously, offering a holistic view of the design workflow. This leads to more precise evaluations and uncovering of further optimization opportunities.'), WSQ(knowledge_id='K3', knowledge_statement='Methods of evaluating effectiveness of AI applications', scenario='A team is developing a customer support AI application using Google Gemini LLM. After deployment, they want to assess how well the AI performs in real interactions with users. They have set up collection systems for both user satisfaction ratings and system response data. During the evaluation phase, they notice a decline in user retention over several weeks, prompting discussions on how to improve the application.', question='What key performance indicators (KPIs) should the team consider evaluating to address the decline in user retention for their AI application?', answer='The team should evaluate KPIs such as accuracy of responses, response time, user satisfaction ratings, and the frequency of user interactions. Additionally, examining metrics like session duration can provide insights into user engagement and help identify areas needing improvement.'), WSQ(knowledge_id='K2', knowledge_statement='Concepts pertaining to performance effectiveness and analysis', scenario='A customer support agent is struggling to provide accurate responses to user inquiries due to outdated knowledge. The team decides to implement Retrieval Augmented Generation (RAG) to enhance response quality. During a team meeting, the manager asks for an overview of how RAG operates and its benefits.', question='What is the primary purpose of implementing Retrieval Augmented Generation (RAG) in customer support?', answer='The primary purpose of implementing RAG in customer support is to provide quick and accurate responses by leveraging current and relevant information retrieved from a knowledge base, thereby improving customer satisfaction.')]\n"
     ]
    }
   ],
   "source": [
    "print(wsq_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knowledge_id': 'K1', 'knowledge_statement': 'Range of AI applications', 'scenario': 'As a business analyst, you are tasked with presenting a report on the potential applications of Large Language Models (LLMs) to your team. You have identified several areas where LLMs can be beneficial, such as customer support, content creation, and educational tools.', 'question': 'What are some common applications of Large Language Models (LLMs) that you could include in your report to the team?', 'answer': 'Common applications of LLMs include content creation and assistance, customer support and chatbots, language translation and localization, educational tools, business intelligence and analytics, accessibility for disabled persons, coding and development, legal and compliance assistance, healthcare support, art and design inspiration, enhanced search engines, and crisis management and response.'}\n",
      "{'knowledge_id': 'K6', 'knowledge_statement': 'Applicability of AI in the industry', 'scenario': 'A manager at a healthcare organization is exploring new technologies to improve patient care and streamline operations within the hospital. They gather their staff to discuss the potential applications of Large Language Models (LLMs) in their daily processes.', 'question': 'What are some specific applications of LLMs in the healthcare industry that could improve patient care and streamline operations?', 'answer': 'LLMs can be applied in healthcare for drug discovery, personalized medicine, automated clinical documentation, analyzing medical data for insights, and enhancing patient engagement through virtual health assistants.'}\n",
      "{'knowledge_id': 'K4', 'knowledge_statement': 'Algorithm design and implementation', 'scenario': 'A team of data scientists at a tech company is working on improving their interactive assistant powered by the Google Gemini LLM. They need to ensure that the assistant can effectively process various types of inputs, including text, images, and audio, to provide accurate and context-aware responses to users.', 'question': 'How can the design of algorithms enhance the performance of the interactive assistant in processing multimodal inputs?', 'answer': 'The design of algorithms enhances performance by enabling the assistant to accurately process and integrate different input types, ensuring coherent and contextually relevant responses, and improving interaction quality.'}\n",
      "{'knowledge_id': 'K5', 'knowledge_statement': 'Methods of evaluating process improvements to the engineering processes using AI', 'scenario': 'A team of engineers is looking to leverage AI to assess the effectiveness of recent changes made to their design processes. They want to understand how the integration of both visual design outputs and performance data can help identify further optimizations.', 'question': 'How can multimodal prompting enhance the evaluation of the engineering design process improvements made by the team?', 'answer': 'Multimodal prompting enables the AI to analyze various inputs like design images and performance metrics simultaneously, offering a holistic view of the design workflow. This leads to more precise evaluations and uncovering of further optimization opportunities.'}\n",
      "{'knowledge_id': 'K3', 'knowledge_statement': 'Methods of evaluating effectiveness of AI applications', 'scenario': 'A team is developing a customer support AI application using Google Gemini LLM. After deployment, they want to assess how well the AI performs in real interactions with users. They have set up collection systems for both user satisfaction ratings and system response data. During the evaluation phase, they notice a decline in user retention over several weeks, prompting discussions on how to improve the application.', 'question': 'What key performance indicators (KPIs) should the team consider evaluating to address the decline in user retention for their AI application?', 'answer': 'The team should evaluate KPIs such as accuracy of responses, response time, user satisfaction ratings, and the frequency of user interactions. Additionally, examining metrics like session duration can provide insights into user engagement and help identify areas needing improvement.'}\n",
      "{'knowledge_id': 'K2', 'knowledge_statement': 'Concepts pertaining to performance effectiveness and analysis', 'scenario': 'A customer support agent is struggling to provide accurate responses to user inquiries due to outdated knowledge. The team decides to implement Retrieval Augmented Generation (RAG) to enhance response quality. During a team meeting, the manager asks for an overview of how RAG operates and its benefits.', 'question': 'What is the primary purpose of implementing Retrieval Augmented Generation (RAG) in customer support?', 'answer': 'The primary purpose of implementing RAG in customer support is to provide quick and accurate responses by leveraging current and relevant information retrieved from a knowledge base, thereby improving customer satisfaction.'}\n"
     ]
    }
   ],
   "source": [
    "for wsq in wsq_results:\n",
    "    print(wsq.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docxtpl import DocxTemplate\n",
    "import os\n",
    "\n",
    "def generate_documents(context: dict, type: int, output_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generate the question paper and answer paper for the given context and type.\n",
    "\n",
    "    Parameters:\n",
    "    - context (dict): The data for the assessment (course title, type, questions, etc.).\n",
    "    - type (int): The assessment type (1 for Ability-based, 2 for Knowledge-based).\n",
    "    - output_dir (str): Directory where the generated documents will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Paths to the generated documents (question and answer papers).\n",
    "    \"\"\"\n",
    "    # Define template paths\n",
    "    TEMPLATES = {\n",
    "        1: { # PP\n",
    "            \"ANSWER\": \"../Templates/(Template) Answer to A Assessment - Course Title - v1.docx\",\n",
    "            \"QUESTION\": \"../Templates//(Template) A Assessment - Course Title - v1.docx\"\n",
    "        },\n",
    "        2: { # SAQ\n",
    "            \"ANSWER\": \"../Templates/(Template) Answer to WA (SAQ) - Course Title - v1.docx\",\n",
    "            \"QUESTION\": \"../Templates/(Template) WA (SAQ) - Course Title - v1.docx\"\n",
    "        },\n",
    "        3: { # CS\n",
    "            \"ANSWER\": \"../Templates/(Template) Answers to CS - Course Title - v1.docx\",\n",
    "            \"QUESTION\": \"../Templates/(Template) CS - Course Title - v1.docx\"\n",
    "        },\n",
    "        # 4: { # OQ\n",
    "        #     \"ANSWER\": None,\n",
    "        #     \"QUESTION\": r\"C:\\Users\\dljh1\\Documents\\courseware_autogen\\Assessment\\Templates\\(Template) WA (SAQ) - Course Title - v1.docx\"\n",
    "        # },\n",
    "    }\n",
    "\n",
    "    # Validate type\n",
    "    if type not in TEMPLATES:\n",
    "        raise ValueError(\"Invalid type. Must be 1 (Ability-based) or 2 (Knowledge-based).\")\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load templates\n",
    "    answer_template_path = TEMPLATES[type][\"ANSWER\"]\n",
    "    question_template_path = TEMPLATES[type][\"QUESTION\"]\n",
    "    answer_doc = DocxTemplate(answer_template_path)\n",
    "    question_doc = DocxTemplate(question_template_path)\n",
    "\n",
    "    # Prepare context for the question paper by creating a copy of the context without answers\n",
    "    question_context = {\n",
    "        **context,\n",
    "        \"questions\": [\n",
    "            {\n",
    "                **question,\n",
    "                \"answer\": None,  # Remove answers for the question document\n",
    "            }\n",
    "            for question in context.get(\"questions\", [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Render both templates\n",
    "    answer_doc.render(context)  # Render with answers\n",
    "    question_doc.render(question_context)  # Render without answers\n",
    "\n",
    "    # Save the documents to the output directory\n",
    "    files = {\n",
    "        \"ANSWER\": os.path.join(output_dir, f\"Answers to WA(SAQ) - {context['course_title']} - v1.docx\"),\n",
    "        \"QUESTION\": os.path.join(output_dir, f\"WA(SAQ) - {context['course_title']} - v1.docx\")\n",
    "    }\n",
    "    answer_doc.save(files[\"ANSWER\"])\n",
    "    question_doc.save(files[\"QUESTION\"])\n",
    "\n",
    "    return files  # Return paths to the generated documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context prepared for document generation.\n",
      "Documents generated: {'ANSWER': 'output\\\\Answers to WA(SAQ) - Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini - v1.docx', 'QUESTION': 'output\\\\WA(SAQ) - Develop Artificial Intelligence and Large Language Model (LLM) Applications with Google Gemini - v1.docx'}\n"
     ]
    }
   ],
   "source": [
    "for assessment in extracted_data.assessments:\n",
    "    if 'SAQ' in assessment.code:\n",
    "        context = {\n",
    "            \"course_title\": extracted_data.course_title,  # e.g., extracted_data.course_title\n",
    "            \"duration\": assessment.duration,\n",
    "            # The scenario field at the top level can be a general overview or introduction.\n",
    "            # Since each WSQ also has its own scenario, you can choose to put a general scenario here:\n",
    "            \"scenario\": \"Below are scenario-based questions derived from the course content and Knowledge Statements.\",\n",
    "            \"questions\": []\n",
    "        }\n",
    "\n",
    "        # Populate the questions from wsq_results\n",
    "        for wsq in wsq_results:\n",
    "            # Append the WSQ details along with the knowledge ID to the context\n",
    "            context[\"questions\"].append({\n",
    "                \"knowledge_id\": wsq.knowledge_id,\n",
    "                \"scenario\": wsq.scenario,\n",
    "                \"question_statement\": wsq.question,\n",
    "                \"answer\": wsq.answer\n",
    "            })\n",
    "\n",
    "        print(\"Context prepared for document generation.\")\n",
    "\n",
    "        files = generate_documents(context, type=2, output_dir=\"output\")  # 'type=2' as per your code for knowledge-based assessment\n",
    "        print(\"Documents generated:\", files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
