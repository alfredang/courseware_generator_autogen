{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.11.23-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index)\n",
      "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.23 (from llama-index)\n",
      "  Downloading llama_index_core-0.11.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.3.0,>=0.2.10 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.3.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.52.0)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading aiohttp-3.11.0-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.26.4)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting llama-cloud>=0.1.5 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.5-py3-none-any.whl.metadata (763 bytes)\n",
      "Requirement already satisfied: pandas in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index) (4.12.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index)\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index)\n",
      "  Downloading llama_parse-0.5.14-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting click (from nltk>3.8.1->llama-index)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading yarl-1.17.1-cp311-cp311-win_amd64.whl.metadata (66 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.4.0,>=0.3.0->llama-index) (2.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from click->nltk>3.8.1->llama-index) (0.4.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (0.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (2.2.3)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.23->llama-index)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.23->llama-index) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
      "Downloading llama_index-0.11.23-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.6 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.6 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.6 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.4.2-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 335.2 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 335.2 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 335.2 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 0.8/1.2 MB 404.2 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 0.8/1.2 MB 404.2 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 0.8/1.2 MB 404.2 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.0/1.2 MB 412.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 435.1 kB/s eta 0:00:00\n",
      "Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.3.0-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 653.7 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 653.7 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 653.7 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 653.7 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 653.7 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 653.7 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 653.7 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 653.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 377.0 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 377.0 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 377.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 366.8 kB/s eta 0:00:00\n",
      "Downloading aiohttp-3.11.0-cp311-cp311-win_amd64.whl (440 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading llama_cloud-0.1.5-py3-none-any.whl (188 kB)\n",
      "Downloading llama_parse-0.5.14-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 441.3 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.5/1.7 MB 441.3 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.5/1.7 MB 441.3 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 424.5 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 424.5 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 424.5 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 1.0/1.7 MB 426.5 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 426.5 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 456.5 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 456.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 479.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 500.0 kB/s eta 0:00:00\n",
      "Downloading pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.6 MB 882.6 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.5/2.6 MB 882.6 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.5/2.6 MB 882.6 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.8/2.6 MB 645.7 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 709.1 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 709.1 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 1.3/2.6 MB 713.8 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 915.0 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 915.0 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.6 MB 939.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.4/2.6 MB 894.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 910.6 kB/s eta 0:00:00\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.1 MB 780.2 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.1 MB 780.2 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.0/2.1 MB 799.2 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.3/2.1 MB 894.7 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 902.1 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 959.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 974.8 kB/s eta 0:00:00\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.17.1-cp311-cp311-win_amd64.whl (90 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, wrapt, tenacity, PyYAML, pypdf, propcache, pillow, networkx, mypy-extensions, multidict, marshmallow, greenlet, fsspec, frozenlist, click, attrs, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, nltk, deprecated, aiosignal, llama-cloud, dataclasses-json, aiohttp, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.11.0 aiosignal-1.3.1 attrs-24.2.0 click-8.1.7 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 filetype-1.2.0 frozenlist-1.5.0 fsspec-2024.10.0 greenlet-3.1.1 llama-cloud-0.1.5 llama-index-0.11.23 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.23 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.2 llama-index-legacy-0.9.48.post4 llama-index-llms-openai-0.2.16 llama-index-multi-modal-llms-openai-0.2.3 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.3.0 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.14 marshmallow-3.23.1 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 nltk-3.9.1 pillow-11.0.0 propcache-0.2.0 pypdf-5.1.0 striprtf-0.0.26 tenacity-8.5.0 typing-inspect-0.9.0 wrapt-1.16.0 yarl-1.17.1\n",
      "Collecting llama-index-core==0.10.6.post1\n",
      "  Downloading llama_index_core-0.10.6.post1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.6.post1) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (3.11.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (2024.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (0.27.2)\n",
      "Collecting llamaindex-py-client>=0.1.12 (from llama-index-core==0.10.6.post1)\n",
      "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (3.4.2)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (1.52.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (11.0.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core==0.10.6.post1) (0.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.6.post1) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.6.post1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.6.post1) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.6.post1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.6.post1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.6.post1) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.6.post1) (1.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core==0.10.6.post1) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llamaindex-py-client>=0.1.12->llama-index-core==0.10.6.post1) (2.9.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core==0.10.6.post1) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core==0.10.6.post1) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core==0.10.6.post1) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core==0.10.6.post1) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core==0.10.6.post1) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.6.post1) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.6.post1) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.6.post1) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.6.post1) (2024.9.11)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from openai>=1.1.0->llama-index-core==0.10.6.post1) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from openai>=1.1.0->llama-index-core==0.10.6.post1) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.6.post1) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.6.post1) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.6.post1) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core==0.10.6.post1) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.6.post1) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from dataclasses-json->llama-index-core==0.10.6.post1) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pandas->llama-index-core==0.10.6.post1) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pandas->llama-index-core==0.10.6.post1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pandas->llama-index-core==0.10.6.post1) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.6.post1) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client>=0.1.12->llama-index-core==0.10.6.post1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client>=0.1.12->llama-index-core==0.10.6.post1) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.6.post1) (1.16.0)\n",
      "Downloading llama_index_core-0.10.6.post1-py3-none-any.whl (15.4 MB)\n",
      "   ---------------------------------------- 0.0/15.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.4 MB 2.1 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.8/15.4 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/15.4 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.0/15.4 MB 986.7 kB/s eta 0:00:15\n",
      "   -- ------------------------------------- 1.0/15.4 MB 986.7 kB/s eta 0:00:15\n",
      "   --- ------------------------------------ 1.3/15.4 MB 944.7 kB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 1.6/15.4 MB 921.7 kB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 1.6/15.4 MB 921.7 kB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 1.6/15.4 MB 921.7 kB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 1.8/15.4 MB 786.4 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.8/15.4 MB 786.4 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.8/15.4 MB 786.4 kB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 2.1/15.4 MB 703.1 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 2.1/15.4 MB 703.1 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 2.1/15.4 MB 703.1 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 2.1/15.4 MB 703.1 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 2.1/15.4 MB 703.1 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 2.4/15.4 MB 593.9 kB/s eta 0:00:22\n",
      "   ------ --------------------------------- 2.4/15.4 MB 593.9 kB/s eta 0:00:22\n",
      "   ------ --------------------------------- 2.4/15.4 MB 593.9 kB/s eta 0:00:22\n",
      "   ------ --------------------------------- 2.4/15.4 MB 593.9 kB/s eta 0:00:22\n",
      "   ------ --------------------------------- 2.4/15.4 MB 593.9 kB/s eta 0:00:22\n",
      "   ------ --------------------------------- 2.6/15.4 MB 517.0 kB/s eta 0:00:25\n",
      "   ------ --------------------------------- 2.6/15.4 MB 517.0 kB/s eta 0:00:25\n",
      "   ------- -------------------------------- 2.9/15.4 MB 517.8 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.1/15.4 MB 544.4 kB/s eta 0:00:23\n",
      "   -------- ------------------------------- 3.4/15.4 MB 570.3 kB/s eta 0:00:21\n",
      "   --------- ------------------------------ 3.7/15.4 MB 599.1 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 3.9/15.4 MB 628.0 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 4.2/15.4 MB 648.5 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 4.2/15.4 MB 648.5 kB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 4.5/15.4 MB 651.5 kB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 4.5/15.4 MB 651.5 kB/s eta 0:00:17\n",
      "   ------------ --------------------------- 4.7/15.4 MB 654.1 kB/s eta 0:00:17\n",
      "   ------------ --------------------------- 5.0/15.4 MB 671.1 kB/s eta 0:00:16\n",
      "   --------------- ------------------------ 5.8/15.4 MB 743.3 kB/s eta 0:00:13\n",
      "   --------------- ------------------------ 6.0/15.4 MB 762.5 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 6.6/15.4 MB 815.1 kB/s eta 0:00:11\n",
      "   ------------------- -------------------- 7.3/15.4 MB 884.7 kB/s eta 0:00:10\n",
      "   ------------------- -------------------- 7.6/15.4 MB 891.3 kB/s eta 0:00:09\n",
      "   -------------------- ------------------- 7.9/15.4 MB 900.9 kB/s eta 0:00:09\n",
      "   --------------------- ------------------ 8.1/15.4 MB 910.1 kB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 8.7/15.4 MB 951.8 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 9.4/15.4 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 10.2/15.4 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 11.0/15.4 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 11.5/15.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 11.8/15.4 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 12.8/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 13.1/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.6/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.9/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.9/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.2/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.4/15.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.4/15.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.7/15.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.7/15.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.2/15.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.4/15.4 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
      "Installing collected packages: llamaindex-py-client, llama-index-core\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.23\n",
      "    Uninstalling llama-index-core-0.11.23:\n",
      "      Successfully uninstalled llama-index-core-0.11.23\n",
      "Successfully installed llama-index-core-0.10.6.post1 llamaindex-py-client-0.1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.11.23 requires llama-index-core<0.12.0,>=0.11.23, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-embeddings-openai 0.2.5 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.4.2 requires llama-index-core<0.12.0,>=0.11.13.post1, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-llms-openai 0.2.16 requires llama-index-core<0.12.0,>=0.11.7, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.3 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-readers-file 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.10.6.post1 which is incompatible.\n",
      "llama-parse 0.5.14 requires llama-index-core>=0.11.0, but you have llama-index-core 0.10.6.post1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-openai in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (0.2.5)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-embeddings-openai)\n",
      "  Using cached llama_index_core-0.11.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-embeddings-openai) (1.52.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.11.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (11.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.17.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.1)\n",
      "Using cached llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n",
      "Installing collected packages: llama-index-core\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.6.post1\n",
      "    Uninstalling llama-index-core-0.10.6.post1:\n",
      "      Successfully uninstalled llama-index-core-0.10.6.post1\n",
      "Successfully installed llama-index-core-0.11.23\n",
      "Collecting llama-index-postprocessor-flag-embedding-reranker\n",
      "  Downloading llama_index_postprocessor_flag_embedding_reranker-0.2.0-py3-none-any.whl.metadata (714 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-postprocessor-flag-embedding-reranker) (0.11.23)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.11.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2024.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (11.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.17.1)\n",
      "Requirement already satisfied: click in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-postprocessor-flag-embedding-reranker) (24.1)\n",
      "Downloading llama_index_postprocessor_flag_embedding_reranker-0.2.0-py3-none-any.whl (3.0 kB)\n",
      "Installing collected packages: llama-index-postprocessor-flag-embedding-reranker\n",
      "Successfully installed llama-index-postprocessor-flag-embedding-reranker-0.2.0\n",
      "Collecting git+https://github.com/FlagOpen/FlagEmbedding.git\n",
      "  Cloning https://github.com/FlagOpen/FlagEmbedding.git to c:\\users\\dljh1\\appdata\\local\\temp\\pip-req-build-3xp9kjao\n",
      "  Resolved https://github.com/FlagOpen/FlagEmbedding.git to commit 1b971d023e53904d2e35d96b6a99721715e063ed\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch>=1.6.0 (from FlagEmbedding==1.3.2)\n",
      "  Downloading torch-2.5.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting transformers==4.44.2 (from FlagEmbedding==1.3.2)\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets==2.19.0 (from FlagEmbedding==1.3.2)\n",
      "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate>=0.20.1 (from FlagEmbedding==1.3.2)\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentence_transformers (from FlagEmbedding==1.3.2)\n",
      "  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting peft (from FlagEmbedding==1.3.2)\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ir-datasets (from FlagEmbedding==1.3.2)\n",
      "  Downloading ir_datasets-0.5.9-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sentencepiece (from FlagEmbedding==1.3.2)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting protobuf (from FlagEmbedding==1.3.2)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting filelock (from datasets==2.19.0->FlagEmbedding==1.3.2)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from datasets==2.19.0->FlagEmbedding==1.3.2) (1.26.4)\n",
      "Collecting pyarrow>=12.0.0 (from datasets==2.19.0->FlagEmbedding==1.3.2)\n",
      "  Downloading pyarrow-18.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pyarrow-hotfix (from datasets==2.19.0->FlagEmbedding==1.3.2)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.19.0->FlagEmbedding==1.3.2)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from datasets==2.19.0->FlagEmbedding==1.3.2) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from datasets==2.19.0->FlagEmbedding==1.3.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from datasets==2.19.0->FlagEmbedding==1.3.2) (4.66.5)\n",
      "Collecting xxhash (from datasets==2.19.0->FlagEmbedding==1.3.2)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from datasets==2.19.0->FlagEmbedding==1.3.2)\n",
      "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.0->FlagEmbedding==1.3.2)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from datasets==2.19.0->FlagEmbedding==1.3.2) (3.11.0)\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets==2.19.0->FlagEmbedding==1.3.2)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from datasets==2.19.0->FlagEmbedding==1.3.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from datasets==2.19.0->FlagEmbedding==1.3.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from transformers==4.44.2->FlagEmbedding==1.3.2) (2024.9.11)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.44.2->FlagEmbedding==1.3.2)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2->FlagEmbedding==1.3.2)\n",
      "  Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from accelerate>=0.20.1->FlagEmbedding==1.3.2) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from torch>=1.6.0->FlagEmbedding==1.3.2) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from torch>=1.6.0->FlagEmbedding==1.3.2) (3.4.2)\n",
      "Collecting jinja2 (from torch>=1.6.0->FlagEmbedding==1.3.2)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.6.0->FlagEmbedding==1.3.2)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.6.0->FlagEmbedding==1.3.2)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from ir-datasets->FlagEmbedding==1.3.2) (4.12.3)\n",
      "Collecting inscriptis>=2.2.0 (from ir-datasets->FlagEmbedding==1.3.2)\n",
      "  Downloading inscriptis-2.5.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: lxml>=4.5.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from ir-datasets->FlagEmbedding==1.3.2) (5.3.0)\n",
      "Collecting trec-car-tools>=2.5.4 (from ir-datasets->FlagEmbedding==1.3.2)\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
      "Collecting lz4>=3.1.10 (from ir-datasets->FlagEmbedding==1.3.2)\n",
      "  Downloading lz4-4.3.3-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting warc3-wet>=0.2.3 (from ir-datasets->FlagEmbedding==1.3.2)\n",
      "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->FlagEmbedding==1.3.2)\n",
      "  Using cached warc3_wet_clueweb09-0.2.5-py3-none-any.whl\n",
      "Collecting zlib-state>=0.1.3 (from ir-datasets->FlagEmbedding==1.3.2)\n",
      "  Downloading zlib_state-0.1.9-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting ijson>=3.1.3 (from ir-datasets->FlagEmbedding==1.3.2)\n",
      "  Downloading ijson-3.3.0-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting unlzw3>=0.2.1 (from ir-datasets->FlagEmbedding==1.3.2)\n",
      "  Downloading unlzw3-0.2.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from sentence_transformers->FlagEmbedding==1.3.2) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from sentence_transformers->FlagEmbedding==1.3.2) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from sentence_transformers->FlagEmbedding==1.3.2) (11.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding==1.3.2) (2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.2) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.2) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.2) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.2) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.2) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.2) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.2) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.19.0->datasets==2.19.0->FlagEmbedding==1.3.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.19.0->datasets==2.19.0->FlagEmbedding==1.3.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.19.0->datasets==2.19.0->FlagEmbedding==1.3.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.19.0->datasets==2.19.0->FlagEmbedding==1.3.2) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from tqdm>=4.62.1->datasets==2.19.0->FlagEmbedding==1.3.2) (0.4.6)\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding==1.3.2)\n",
      "  Using cached cbor-1.0.0-py3-none-any.whl\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.6.0->FlagEmbedding==1.3.2)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.19.0->FlagEmbedding==1.3.2)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pandas->datasets==2.19.0->FlagEmbedding==1.3.2) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pandas->datasets==2.19.0->FlagEmbedding==1.3.2) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pandas->datasets==2.19.0->FlagEmbedding==1.3.2) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from scikit-learn->sentence_transformers->FlagEmbedding==1.3.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from scikit-learn->sentence_transformers->FlagEmbedding==1.3.2) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.0->FlagEmbedding==1.3.2) (1.16.0)\n",
      "Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "   ---------------------------------------- 0.0/542.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 542.0/542.0 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/9.5 MB 6.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.3/9.5 MB 6.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.1/9.5 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.9/9.5 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.9/9.5 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.5 MB 2.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.7/9.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.9/9.5 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.5/9.5 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.0/9.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.2/9.5 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.5/9.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.8/9.5 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.0/9.5 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.3/9.5 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.6/9.5 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.6/9.5 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.1/9.5 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.3/9.5 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.3/9.5 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.6/9.5 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.6/9.5 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.9/9.5 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.5 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.1/9.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "Downloading torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/203.1 MB 356.7 kB/s eta 0:09:28\n",
      "   ---------------------------------------- 0.5/203.1 MB 356.7 kB/s eta 0:09:28\n",
      "   ---------------------------------------- 0.5/203.1 MB 356.7 kB/s eta 0:09:28\n",
      "   ---------------------------------------- 0.5/203.1 MB 356.7 kB/s eta 0:09:28\n",
      "   ---------------------------------------- 0.5/203.1 MB 356.7 kB/s eta 0:09:28\n",
      "   ---------------------------------------- 0.8/203.1 MB 319.5 kB/s eta 0:10:34\n",
      "   ---------------------------------------- 0.8/203.1 MB 319.5 kB/s eta 0:10:34\n",
      "   ---------------------------------------- 0.8/203.1 MB 319.5 kB/s eta 0:10:34\n",
      "   ---------------------------------------- 0.8/203.1 MB 319.5 kB/s eta 0:10:34\n",
      "   ---------------------------------------- 0.8/203.1 MB 319.5 kB/s eta 0:10:34\n",
      "   ---------------------------------------- 0.8/203.1 MB 319.5 kB/s eta 0:10:34\n",
      "   ---------------------------------------- 0.8/203.1 MB 319.5 kB/s eta 0:10:34\n",
      "   ---------------------------------------- 1.0/203.1 MB 247.9 kB/s eta 0:13:35\n",
      "   ---------------------------------------- 1.0/203.1 MB 247.9 kB/s eta 0:13:35\n",
      "   ---------------------------------------- 1.0/203.1 MB 247.9 kB/s eta 0:13:35\n",
      "   ---------------------------------------- 1.0/203.1 MB 247.9 kB/s eta 0:13:35\n",
      "   ---------------------------------------- 1.0/203.1 MB 247.9 kB/s eta 0:13:35\n",
      "   ---------------------------------------- 1.3/203.1 MB 252.2 kB/s eta 0:13:20\n",
      "   ---------------------------------------- 1.6/203.1 MB 293.3 kB/s eta 0:11:28\n",
      "   ---------------------------------------- 1.6/203.1 MB 293.3 kB/s eta 0:11:28\n",
      "   ---------------------------------------- 1.6/203.1 MB 293.3 kB/s eta 0:11:28\n",
      "   ---------------------------------------- 1.8/203.1 MB 315.5 kB/s eta 0:10:38\n",
      "   ---------------------------------------- 2.1/203.1 MB 346.4 kB/s eta 0:09:41\n",
      "   ---------------------------------------- 2.4/203.1 MB 382.3 kB/s eta 0:08:46\n",
      "   ---------------------------------------- 2.4/203.1 MB 382.3 kB/s eta 0:08:46\n",
      "    --------------------------------------- 2.6/203.1 MB 401.6 kB/s eta 0:08:20\n",
      "    --------------------------------------- 2.9/203.1 MB 429.0 kB/s eta 0:07:47\n",
      "    --------------------------------------- 2.9/203.1 MB 429.0 kB/s eta 0:07:47\n",
      "    --------------------------------------- 3.4/203.1 MB 480.5 kB/s eta 0:06:56\n",
      "    --------------------------------------- 3.4/203.1 MB 480.5 kB/s eta 0:06:56\n",
      "    --------------------------------------- 3.7/203.1 MB 490.1 kB/s eta 0:06:47\n",
      "    --------------------------------------- 3.7/203.1 MB 490.1 kB/s eta 0:06:47\n",
      "    --------------------------------------- 4.2/203.1 MB 535.4 kB/s eta 0:06:12\n",
      "    --------------------------------------- 4.5/203.1 MB 558.0 kB/s eta 0:05:56\n",
      "    --------------------------------------- 4.5/203.1 MB 558.0 kB/s eta 0:05:56\n",
      "    --------------------------------------- 4.7/203.1 MB 565.9 kB/s eta 0:05:51\n",
      "    --------------------------------------- 5.0/203.1 MB 580.7 kB/s eta 0:05:42\n",
      "   - -------------------------------------- 5.2/203.1 MB 594.7 kB/s eta 0:05:33\n",
      "   - -------------------------------------- 5.2/203.1 MB 594.7 kB/s eta 0:05:33\n",
      "   - -------------------------------------- 5.5/203.1 MB 603.5 kB/s eta 0:05:28\n",
      "   - -------------------------------------- 5.5/203.1 MB 603.5 kB/s eta 0:05:28\n",
      "   - -------------------------------------- 5.8/203.1 MB 605.3 kB/s eta 0:05:26\n",
      "   - -------------------------------------- 6.0/203.1 MB 613.1 kB/s eta 0:05:22\n",
      "   - -------------------------------------- 6.0/203.1 MB 613.1 kB/s eta 0:05:22\n",
      "   - -------------------------------------- 6.8/203.1 MB 667.8 kB/s eta 0:04:54\n",
      "   - -------------------------------------- 7.3/203.1 MB 706.7 kB/s eta 0:04:38\n",
      "   - -------------------------------------- 7.6/203.1 MB 716.1 kB/s eta 0:04:34\n",
      "   - -------------------------------------- 7.9/203.1 MB 733.8 kB/s eta 0:04:27\n",
      "   - -------------------------------------- 8.1/203.1 MB 739.1 kB/s eta 0:04:24\n",
      "   - -------------------------------------- 8.1/203.1 MB 739.1 kB/s eta 0:04:24\n",
      "   - -------------------------------------- 8.4/203.1 MB 743.0 kB/s eta 0:04:23\n",
      "   - -------------------------------------- 8.4/203.1 MB 743.0 kB/s eta 0:04:23\n",
      "   - -------------------------------------- 8.7/203.1 MB 744.6 kB/s eta 0:04:22\n",
      "   - -------------------------------------- 8.7/203.1 MB 744.6 kB/s eta 0:04:22\n",
      "   - -------------------------------------- 8.9/203.1 MB 735.2 kB/s eta 0:04:25\n",
      "   - -------------------------------------- 8.9/203.1 MB 735.2 kB/s eta 0:04:25\n",
      "   - -------------------------------------- 9.2/203.1 MB 732.2 kB/s eta 0:04:25\n",
      "   - -------------------------------------- 9.2/203.1 MB 732.2 kB/s eta 0:04:25\n",
      "   - -------------------------------------- 9.2/203.1 MB 732.2 kB/s eta 0:04:25\n",
      "   - -------------------------------------- 9.4/203.1 MB 722.3 kB/s eta 0:04:29\n",
      "   - -------------------------------------- 9.4/203.1 MB 722.3 kB/s eta 0:04:29\n",
      "   - -------------------------------------- 9.7/203.1 MB 714.8 kB/s eta 0:04:31\n",
      "   - ------------------------------------- 10.0/203.1 MB 722.6 kB/s eta 0:04:28\n",
      "   - ------------------------------------- 10.0/203.1 MB 722.6 kB/s eta 0:04:28\n",
      "   - ------------------------------------- 10.2/203.1 MB 724.5 kB/s eta 0:04:27\n",
      "   -- ------------------------------------ 10.5/203.1 MB 728.6 kB/s eta 0:04:25\n",
      "   -- ------------------------------------ 10.5/203.1 MB 728.6 kB/s eta 0:04:25\n",
      "   -- ------------------------------------ 10.7/203.1 MB 731.0 kB/s eta 0:04:24\n",
      "   -- ------------------------------------ 11.0/203.1 MB 733.3 kB/s eta 0:04:22\n",
      "   -- ------------------------------------ 11.8/203.1 MB 773.0 kB/s eta 0:04:08\n",
      "   -- ------------------------------------ 12.6/203.1 MB 817.1 kB/s eta 0:03:54\n",
      "   -- ------------------------------------ 13.1/203.1 MB 838.0 kB/s eta 0:03:47\n",
      "   -- ------------------------------------ 13.6/203.1 MB 861.6 kB/s eta 0:03:40\n",
      "   -- ------------------------------------ 14.4/203.1 MB 898.8 kB/s eta 0:03:30\n",
      "   -- ------------------------------------ 15.5/203.1 MB 954.0 kB/s eta 0:03:17\n",
      "   --- ------------------------------------ 16.8/203.1 MB 1.0 MB/s eta 0:03:03\n",
      "   --- ------------------------------------ 17.6/203.1 MB 1.1 MB/s eta 0:02:56\n",
      "   --- ------------------------------------ 18.6/203.1 MB 1.1 MB/s eta 0:02:47\n",
      "   --- ------------------------------------ 19.7/203.1 MB 1.2 MB/s eta 0:02:39\n",
      "   --- ------------------------------------ 20.2/203.1 MB 1.2 MB/s eta 0:02:36\n",
      "   ---- ----------------------------------- 20.7/203.1 MB 1.2 MB/s eta 0:02:34\n",
      "   ---- ----------------------------------- 21.2/203.1 MB 1.2 MB/s eta 0:02:31\n",
      "   ---- ----------------------------------- 21.8/203.1 MB 1.2 MB/s eta 0:02:29\n",
      "   ---- ----------------------------------- 22.0/203.1 MB 1.2 MB/s eta 0:02:28\n",
      "   ---- ----------------------------------- 22.5/203.1 MB 1.2 MB/s eta 0:02:26\n",
      "   ---- ----------------------------------- 23.3/203.1 MB 1.3 MB/s eta 0:02:22\n",
      "   ---- ----------------------------------- 23.9/203.1 MB 1.3 MB/s eta 0:02:19\n",
      "   ---- ----------------------------------- 24.6/203.1 MB 1.3 MB/s eta 0:02:17\n",
      "   ---- ----------------------------------- 25.2/203.1 MB 1.3 MB/s eta 0:02:15\n",
      "   ----- ---------------------------------- 26.2/203.1 MB 1.4 MB/s eta 0:02:10\n",
      "   ----- ---------------------------------- 27.5/203.1 MB 1.4 MB/s eta 0:02:04\n",
      "   ----- ---------------------------------- 28.6/203.1 MB 1.5 MB/s eta 0:02:00\n",
      "   ----- ---------------------------------- 29.4/203.1 MB 1.5 MB/s eta 0:01:58\n",
      "   ------ --------------------------------- 30.7/203.1 MB 1.5 MB/s eta 0:01:53\n",
      "   ------ --------------------------------- 32.2/203.1 MB 1.6 MB/s eta 0:01:48\n",
      "   ------ --------------------------------- 33.6/203.1 MB 1.6 MB/s eta 0:01:44\n",
      "   ------ --------------------------------- 35.1/203.1 MB 1.7 MB/s eta 0:01:39\n",
      "   ------- -------------------------------- 37.2/203.1 MB 1.8 MB/s eta 0:01:33\n",
      "   ------- -------------------------------- 39.6/203.1 MB 1.9 MB/s eta 0:01:27\n",
      "   -------- ------------------------------- 41.7/203.1 MB 2.0 MB/s eta 0:01:23\n",
      "   -------- ------------------------------- 44.3/203.1 MB 2.1 MB/s eta 0:01:17\n",
      "   -------- ------------------------------- 45.4/203.1 MB 2.1 MB/s eta 0:01:16\n",
      "   --------- ------------------------------ 46.9/203.1 MB 2.1 MB/s eta 0:01:13\n",
      "   --------- ------------------------------ 48.8/203.1 MB 2.2 MB/s eta 0:01:10\n",
      "   --------- ------------------------------ 50.1/203.1 MB 2.3 MB/s eta 0:01:08\n",
      "   ---------- ----------------------------- 51.1/203.1 MB 2.3 MB/s eta 0:01:07\n",
      "   ---------- ----------------------------- 52.2/203.1 MB 2.3 MB/s eta 0:01:06\n",
      "   ---------- ----------------------------- 53.7/203.1 MB 2.4 MB/s eta 0:01:04\n",
      "   ---------- ----------------------------- 55.1/203.1 MB 2.4 MB/s eta 0:01:03\n",
      "   ----------- ---------------------------- 57.1/203.1 MB 2.5 MB/s eta 0:01:00\n",
      "   ----------- ---------------------------- 59.0/203.1 MB 2.5 MB/s eta 0:00:58\n",
      "   ------------ --------------------------- 61.1/203.1 MB 2.6 MB/s eta 0:00:55\n",
      "   ------------ --------------------------- 63.2/203.1 MB 2.6 MB/s eta 0:00:53\n",
      "   ------------ --------------------------- 64.7/203.1 MB 2.7 MB/s eta 0:00:52\n",
      "   ------------- -------------------------- 66.1/203.1 MB 2.7 MB/s eta 0:00:51\n",
      "   ------------- -------------------------- 67.9/203.1 MB 2.8 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 68.7/203.1 MB 2.8 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 69.2/203.1 MB 2.8 MB/s eta 0:00:48\n",
      "   ------------- -------------------------- 69.7/203.1 MB 2.8 MB/s eta 0:00:48\n",
      "   ------------- -------------------------- 70.0/203.1 MB 2.8 MB/s eta 0:00:48\n",
      "   ------------- -------------------------- 70.0/203.1 MB 2.8 MB/s eta 0:00:48\n",
      "   ------------- -------------------------- 70.3/203.1 MB 2.7 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 70.3/203.1 MB 2.7 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 70.3/203.1 MB 2.7 MB/s eta 0:00:49\n",
      "   ------------- -------------------------- 70.5/203.1 MB 2.7 MB/s eta 0:00:50\n",
      "   ------------- -------------------------- 70.5/203.1 MB 2.7 MB/s eta 0:00:50\n",
      "   ------------- -------------------------- 70.8/203.1 MB 2.7 MB/s eta 0:00:50\n",
      "   ------------- -------------------------- 70.8/203.1 MB 2.7 MB/s eta 0:00:50\n",
      "   ------------- -------------------------- 70.8/203.1 MB 2.7 MB/s eta 0:00:50\n",
      "   ------------- -------------------------- 70.8/203.1 MB 2.7 MB/s eta 0:00:50\n",
      "   ------------- -------------------------- 70.8/203.1 MB 2.7 MB/s eta 0:00:50\n",
      "   ------------- -------------------------- 71.0/203.1 MB 2.6 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 71.3/203.1 MB 2.6 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 71.8/203.1 MB 2.6 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 72.1/203.1 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 72.4/203.1 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 72.6/203.1 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 72.6/203.1 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 72.6/203.1 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 72.6/203.1 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 72.6/203.1 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 72.6/203.1 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------- ------------------------- 72.9/203.1 MB 2.4 MB/s eta 0:00:54\n",
      "   -------------- ------------------------- 72.9/203.1 MB 2.4 MB/s eta 0:00:54\n",
      "   -------------- ------------------------- 72.9/203.1 MB 2.4 MB/s eta 0:00:54\n",
      "   -------------- ------------------------- 73.1/203.1 MB 2.4 MB/s eta 0:00:54\n",
      "   -------------- ------------------------- 73.1/203.1 MB 2.4 MB/s eta 0:00:54\n",
      "   -------------- ------------------------- 73.1/203.1 MB 2.4 MB/s eta 0:00:54\n",
      "   -------------- ------------------------- 73.4/203.1 MB 2.5 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 73.4/203.1 MB 2.5 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 73.7/203.1 MB 2.4 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 73.7/203.1 MB 2.4 MB/s eta 0:00:53\n",
      "   -------------- ------------------------- 73.9/203.1 MB 2.5 MB/s eta 0:00:51\n",
      "   -------------- ------------------------- 74.2/203.1 MB 2.5 MB/s eta 0:00:51\n",
      "   -------------- ------------------------- 75.0/203.1 MB 2.5 MB/s eta 0:00:51\n",
      "   -------------- ------------------------- 75.5/203.1 MB 2.5 MB/s eta 0:00:51\n",
      "   -------------- ------------------------- 76.0/203.1 MB 2.5 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 76.3/203.1 MB 2.5 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 77.1/203.1 MB 2.5 MB/s eta 0:00:50\n",
      "   --------------- ------------------------ 77.9/203.1 MB 2.6 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 78.4/203.1 MB 2.6 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 78.9/203.1 MB 2.6 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 79.4/203.1 MB 2.6 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 80.0/203.1 MB 2.6 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 80.5/203.1 MB 2.6 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 81.0/203.1 MB 2.7 MB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 81.8/203.1 MB 2.7 MB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 82.1/203.1 MB 2.7 MB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 82.6/203.1 MB 2.7 MB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 83.4/203.1 MB 2.7 MB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 84.1/203.1 MB 2.7 MB/s eta 0:00:44\n",
      "   ---------------- ----------------------- 84.4/203.1 MB 2.7 MB/s eta 0:00:44\n",
      "   ---------------- ----------------------- 85.2/203.1 MB 2.7 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 85.5/203.1 MB 2.8 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 85.5/203.1 MB 2.8 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 85.7/203.1 MB 2.7 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 86.0/203.1 MB 2.8 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 86.5/203.1 MB 2.8 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 87.3/203.1 MB 2.8 MB/s eta 0:00:42\n",
      "   ----------------- ---------------------- 87.6/203.1 MB 2.8 MB/s eta 0:00:42\n",
      "   ----------------- ---------------------- 88.1/203.1 MB 2.8 MB/s eta 0:00:42\n",
      "   ----------------- ---------------------- 88.6/203.1 MB 2.8 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 88.9/203.1 MB 2.8 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 89.1/203.1 MB 2.8 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 89.4/203.1 MB 2.8 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 89.7/203.1 MB 2.8 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 90.2/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 90.4/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 90.4/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 90.4/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 91.0/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 91.5/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 91.8/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.0/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.3/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.5/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.5/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.5/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.5/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.8/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.8/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.8/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 92.8/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 93.1/203.1 MB 2.8 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 93.3/203.1 MB 2.8 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 93.6/203.1 MB 2.8 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 93.8/203.1 MB 2.8 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 94.1/203.1 MB 2.8 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 94.4/203.1 MB 2.8 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 94.9/203.1 MB 2.8 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 95.4/203.1 MB 2.8 MB/s eta 0:00:38\n",
      "   ------------------ --------------------- 95.9/203.1 MB 2.8 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 96.7/203.1 MB 2.9 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 97.8/203.1 MB 2.9 MB/s eta 0:00:37\n",
      "   ------------------- -------------------- 98.3/203.1 MB 2.9 MB/s eta 0:00:37\n",
      "   ------------------- -------------------- 99.1/203.1 MB 2.9 MB/s eta 0:00:36\n",
      "   ------------------- -------------------- 99.6/203.1 MB 2.9 MB/s eta 0:00:36\n",
      "   ------------------- -------------------- 99.6/203.1 MB 2.9 MB/s eta 0:00:36\n",
      "   ------------------- -------------------- 99.9/203.1 MB 2.9 MB/s eta 0:00:36\n",
      "   ------------------- -------------------- 99.9/203.1 MB 2.9 MB/s eta 0:00:36\n",
      "   ------------------- -------------------- 100.1/203.1 MB 2.8 MB/s eta 0:00:37\n",
      "   ------------------- -------------------- 100.1/203.1 MB 2.8 MB/s eta 0:00:37\n",
      "   ------------------- -------------------- 100.4/203.1 MB 2.8 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 100.4/203.1 MB 2.8 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 100.4/203.1 MB 2.8 MB/s eta 0:00:38\n",
      "   ------------------- -------------------- 100.7/203.1 MB 2.7 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 100.7/203.1 MB 2.7 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 100.9/203.1 MB 2.7 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 100.9/203.1 MB 2.7 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 101.2/203.1 MB 2.6 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 101.4/203.1 MB 2.6 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 101.7/203.1 MB 2.6 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 101.7/203.1 MB 2.6 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 102.0/203.1 MB 2.6 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 102.2/203.1 MB 2.6 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 102.8/203.1 MB 2.5 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 103.0/203.1 MB 2.5 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 103.0/203.1 MB 2.5 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 103.0/203.1 MB 2.5 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 103.3/203.1 MB 2.5 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 103.3/203.1 MB 2.5 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 103.5/203.1 MB 2.3 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 103.5/203.1 MB 2.3 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 103.8/203.1 MB 2.2 MB/s eta 0:00:45\n",
      "   -------------------- ------------------- 104.1/203.1 MB 2.2 MB/s eta 0:00:46\n",
      "   -------------------- ------------------- 104.3/203.1 MB 2.1 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 104.9/203.1 MB 2.0 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 104.9/203.1 MB 2.0 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 105.4/203.1 MB 2.0 MB/s eta 0:00:50\n",
      "   -------------------- ------------------- 105.9/203.1 MB 1.9 MB/s eta 0:00:51\n",
      "   -------------------- ------------------- 106.4/203.1 MB 1.9 MB/s eta 0:00:51\n",
      "   --------------------- ------------------ 107.0/203.1 MB 1.9 MB/s eta 0:00:52\n",
      "   --------------------- ------------------ 107.2/203.1 MB 1.8 MB/s eta 0:00:52\n",
      "   --------------------- ------------------ 107.7/203.1 MB 1.8 MB/s eta 0:00:53\n",
      "   --------------------- ------------------ 108.3/203.1 MB 1.8 MB/s eta 0:00:53\n",
      "   --------------------- ------------------ 109.6/203.1 MB 1.8 MB/s eta 0:00:53\n",
      "   --------------------- ------------------ 110.1/203.1 MB 1.7 MB/s eta 0:00:54\n",
      "   --------------------- ------------------ 110.6/203.1 MB 1.7 MB/s eta 0:00:56\n",
      "   --------------------- ------------------ 110.9/203.1 MB 1.6 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 111.4/203.1 MB 1.6 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 111.4/203.1 MB 1.6 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 111.7/203.1 MB 1.5 MB/s eta 0:01:03\n",
      "   --------------------- ------------------ 111.7/203.1 MB 1.5 MB/s eta 0:01:03\n",
      "   ---------------------- ----------------- 111.9/203.1 MB 1.4 MB/s eta 0:01:05\n",
      "   ---------------------- ----------------- 112.2/203.1 MB 1.4 MB/s eta 0:01:05\n",
      "   ---------------------- ----------------- 112.5/203.1 MB 1.4 MB/s eta 0:01:04\n",
      "   ---------------------- ----------------- 112.7/203.1 MB 1.4 MB/s eta 0:01:04\n",
      "   ---------------------- ----------------- 113.0/203.1 MB 1.4 MB/s eta 0:01:04\n",
      "   ---------------------- ----------------- 113.2/203.1 MB 1.4 MB/s eta 0:01:03\n",
      "   ---------------------- ----------------- 113.5/203.1 MB 1.4 MB/s eta 0:01:03\n",
      "   ---------------------- ----------------- 113.8/203.1 MB 1.4 MB/s eta 0:01:02\n",
      "   ---------------------- ----------------- 114.0/203.1 MB 1.5 MB/s eta 0:01:02\n",
      "   ---------------------- ----------------- 114.0/203.1 MB 1.5 MB/s eta 0:01:02\n",
      "   ---------------------- ----------------- 114.3/203.1 MB 1.5 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 114.3/203.1 MB 1.5 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 114.6/203.1 MB 1.5 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 114.6/203.1 MB 1.5 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 115.1/203.1 MB 1.5 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 115.1/203.1 MB 1.5 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 115.3/203.1 MB 1.5 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 115.3/203.1 MB 1.5 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 115.9/203.1 MB 1.4 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 116.1/203.1 MB 1.5 MB/s eta 0:00:58\n",
      "   ---------------------- ----------------- 116.1/203.1 MB 1.5 MB/s eta 0:00:58\n",
      "   ----------------------- ---------------- 116.9/203.1 MB 1.5 MB/s eta 0:00:58\n",
      "   ----------------------- ---------------- 116.9/203.1 MB 1.5 MB/s eta 0:00:58\n",
      "   ----------------------- ---------------- 117.2/203.1 MB 1.5 MB/s eta 0:00:58\n",
      "   ----------------------- ---------------- 117.4/203.1 MB 1.5 MB/s eta 0:00:58\n",
      "   ----------------------- ---------------- 117.4/203.1 MB 1.5 MB/s eta 0:00:58\n",
      "   ----------------------- ---------------- 117.7/203.1 MB 1.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 117.7/203.1 MB 1.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 118.0/203.1 MB 1.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 118.0/203.1 MB 1.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 118.2/203.1 MB 1.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 118.2/203.1 MB 1.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 118.5/203.1 MB 1.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 119.0/203.1 MB 1.5 MB/s eta 0:00:56\n",
      "   ----------------------- ---------------- 120.1/203.1 MB 1.5 MB/s eta 0:00:55\n",
      "   ----------------------- ---------------- 120.3/203.1 MB 1.5 MB/s eta 0:00:54\n",
      "   ----------------------- ---------------- 120.6/203.1 MB 1.5 MB/s eta 0:00:54\n",
      "   ----------------------- ---------------- 120.8/203.1 MB 1.5 MB/s eta 0:00:55\n",
      "   ----------------------- ---------------- 121.4/203.1 MB 1.5 MB/s eta 0:00:54\n",
      "   ----------------------- ---------------- 121.4/203.1 MB 1.5 MB/s eta 0:00:54\n",
      "   ----------------------- ---------------- 121.6/203.1 MB 1.5 MB/s eta 0:00:55\n",
      "   ------------------------ --------------- 121.9/203.1 MB 1.5 MB/s eta 0:00:55\n",
      "   ------------------------ --------------- 122.2/203.1 MB 1.5 MB/s eta 0:00:56\n",
      "   ------------------------ --------------- 122.7/203.1 MB 1.5 MB/s eta 0:00:56\n",
      "   ------------------------ --------------- 122.9/203.1 MB 1.5 MB/s eta 0:00:56\n",
      "   ------------------------ --------------- 123.5/203.1 MB 1.5 MB/s eta 0:00:55\n",
      "   ------------------------ --------------- 123.7/203.1 MB 1.5 MB/s eta 0:00:55\n",
      "   ------------------------ --------------- 124.0/203.1 MB 1.4 MB/s eta 0:00:55\n",
      "   ------------------------ --------------- 124.5/203.1 MB 1.4 MB/s eta 0:00:56\n",
      "   ------------------------ --------------- 125.3/203.1 MB 1.4 MB/s eta 0:00:55\n",
      "   ------------------------ --------------- 125.8/203.1 MB 1.4 MB/s eta 0:00:54\n",
      "   ------------------------ --------------- 126.4/203.1 MB 1.5 MB/s eta 0:00:53\n",
      "   ------------------------ --------------- 126.9/203.1 MB 1.4 MB/s eta 0:00:54\n",
      "   ------------------------- -------------- 127.1/203.1 MB 1.4 MB/s eta 0:00:54\n",
      "   ------------------------- -------------- 127.4/203.1 MB 1.4 MB/s eta 0:00:54\n",
      "   ------------------------- -------------- 127.9/203.1 MB 1.4 MB/s eta 0:00:53\n",
      "   ------------------------- -------------- 128.2/203.1 MB 1.4 MB/s eta 0:00:53\n",
      "   ------------------------- -------------- 128.5/203.1 MB 1.4 MB/s eta 0:00:53\n",
      "   ------------------------- -------------- 128.5/203.1 MB 1.4 MB/s eta 0:00:53\n",
      "   ------------------------- -------------- 128.5/203.1 MB 1.4 MB/s eta 0:00:53\n",
      "   ------------------------- -------------- 128.7/203.1 MB 1.4 MB/s eta 0:00:54\n",
      "   ------------------------- -------------- 128.7/203.1 MB 1.4 MB/s eta 0:00:54\n",
      "   ------------------------- -------------- 129.0/203.1 MB 1.4 MB/s eta 0:00:55\n",
      "   ------------------------- -------------- 129.0/203.1 MB 1.4 MB/s eta 0:00:55\n",
      "   ------------------------- -------------- 129.0/203.1 MB 1.4 MB/s eta 0:00:55\n",
      "   ------------------------- -------------- 129.2/203.1 MB 1.3 MB/s eta 0:00:56\n",
      "   ------------------------- -------------- 129.2/203.1 MB 1.3 MB/s eta 0:00:56\n",
      "   ------------------------- -------------- 129.2/203.1 MB 1.3 MB/s eta 0:00:56\n",
      "   ------------------------- -------------- 129.2/203.1 MB 1.3 MB/s eta 0:00:56\n",
      "   ------------------------- -------------- 129.2/203.1 MB 1.3 MB/s eta 0:00:56\n",
      "   ------------------------- -------------- 129.5/203.1 MB 1.3 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 129.5/203.1 MB 1.3 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 129.8/203.1 MB 1.3 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 129.8/203.1 MB 1.3 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 129.8/203.1 MB 1.3 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 130.0/203.1 MB 1.3 MB/s eta 0:00:58\n",
      "   ------------------------- -------------- 130.0/203.1 MB 1.3 MB/s eta 0:00:58\n",
      "   ------------------------- -------------- 130.3/203.1 MB 1.3 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 130.5/203.1 MB 1.3 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 130.8/203.1 MB 1.3 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 131.3/203.1 MB 1.3 MB/s eta 0:00:56\n",
      "   ------------------------- -------------- 131.9/203.1 MB 1.3 MB/s eta 0:00:54\n",
      "   -------------------------- ------------- 132.4/203.1 MB 1.3 MB/s eta 0:00:54\n",
      "   -------------------------- ------------- 132.4/203.1 MB 1.3 MB/s eta 0:00:54\n",
      "   -------------------------- ------------- 132.6/203.1 MB 1.3 MB/s eta 0:00:54\n",
      "   -------------------------- ------------- 132.9/203.1 MB 1.3 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 133.2/203.1 MB 1.3 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 133.7/203.1 MB 1.3 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 133.7/203.1 MB 1.3 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 133.7/203.1 MB 1.3 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 134.0/203.1 MB 1.3 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 134.0/203.1 MB 1.3 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 134.0/203.1 MB 1.3 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 134.0/203.1 MB 1.3 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 134.2/203.1 MB 1.3 MB/s eta 0:00:56\n",
      "   -------------------------- ------------- 134.2/203.1 MB 1.3 MB/s eta 0:00:56\n",
      "   -------------------------- ------------- 134.5/203.1 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 134.7/203.1 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 134.7/203.1 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 135.0/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 135.0/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 135.0/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 135.3/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 135.5/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 135.8/203.1 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 135.8/203.1 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 135.8/203.1 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 135.8/203.1 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 135.8/203.1 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 135.8/203.1 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 136.1/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 136.1/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 136.1/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 136.1/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 136.3/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 136.3/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 136.3/203.1 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 136.6/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   -------------------------- ------------- 136.6/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   -------------------------- ------------- 136.8/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   -------------------------- ------------- 136.8/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 137.1/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 137.1/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 137.1/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 137.4/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 137.6/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 137.9/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 138.4/203.1 MB 1.1 MB/s eta 0:00:58\n",
      "   --------------------------- ------------ 138.7/203.1 MB 1.1 MB/s eta 0:00:58\n",
      "   --------------------------- ------------ 138.7/203.1 MB 1.1 MB/s eta 0:00:58\n",
      "   --------------------------- ------------ 138.9/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 138.9/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 138.9/203.1 MB 1.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 139.2/203.1 MB 1.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 139.2/203.1 MB 1.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 139.2/203.1 MB 1.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 139.7/203.1 MB 1.0 MB/s eta 0:01:01\n",
      "   --------------------------- ------------ 140.0/203.1 MB 1.0 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 140.8/203.1 MB 1.0 MB/s eta 0:01:02\n",
      "   --------------------------- ------------ 141.3/203.1 MB 1.0 MB/s eta 0:01:01\n",
      "   --------------------------- ------------ 142.1/203.1 MB 1.0 MB/s eta 0:01:00\n",
      "   ---------------------------- ----------- 142.3/203.1 MB 1.0 MB/s eta 0:00:59\n",
      "   ---------------------------- ----------- 142.9/203.1 MB 1.0 MB/s eta 0:00:58\n",
      "   ---------------------------- ----------- 142.9/203.1 MB 1.0 MB/s eta 0:00:58\n",
      "   ---------------------------- ----------- 143.1/203.1 MB 1.0 MB/s eta 0:00:58\n",
      "   ---------------------------- ----------- 143.4/203.1 MB 1.0 MB/s eta 0:00:58\n",
      "   ---------------------------- ----------- 143.4/203.1 MB 1.0 MB/s eta 0:00:58\n",
      "   ---------------------------- ----------- 143.9/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 144.2/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 144.2/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 144.4/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 144.4/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 144.7/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 144.7/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 145.0/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 145.0/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 145.2/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 145.5/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ---------------------------- ----------- 145.8/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ---------------------------- ----------- 145.8/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ---------------------------- ----------- 145.8/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ---------------------------- ----------- 145.8/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ---------------------------- ----------- 146.0/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 146.0/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 146.3/203.1 MB 1.0 MB/s eta 0:00:57\n",
      "   --------------------------- ---------- 146.5/203.1 MB 997.7 kB/s eta 0:00:57\n",
      "   ---------------------------- ----------- 147.1/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.3/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.3/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.3/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.6/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.6/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.6/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.8/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.8/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.8/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.8/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   ----------------------------- ---------- 147.8/203.1 MB 1.0 MB/s eta 0:00:56\n",
      "   --------------------------- ---------- 148.1/203.1 MB 970.9 kB/s eta 0:00:57\n",
      "   --------------------------- ---------- 148.1/203.1 MB 970.9 kB/s eta 0:00:57\n",
      "   --------------------------- ---------- 148.4/203.1 MB 931.1 kB/s eta 0:00:59\n",
      "   --------------------------- ---------- 148.4/203.1 MB 931.1 kB/s eta 0:00:59\n",
      "   --------------------------- ---------- 148.6/203.1 MB 920.8 kB/s eta 0:01:00\n",
      "   --------------------------- ---------- 148.9/203.1 MB 915.9 kB/s eta 0:01:00\n",
      "   --------------------------- ---------- 148.9/203.1 MB 915.9 kB/s eta 0:01:00\n",
      "   --------------------------- ---------- 149.2/203.1 MB 917.5 kB/s eta 0:00:59\n",
      "   --------------------------- ---------- 149.2/203.1 MB 917.5 kB/s eta 0:00:59\n",
      "   --------------------------- ---------- 149.4/203.1 MB 901.4 kB/s eta 0:01:00\n",
      "   ---------------------------- --------- 149.7/203.1 MB 901.0 kB/s eta 0:01:00\n",
      "   ---------------------------- --------- 149.9/203.1 MB 902.4 kB/s eta 0:00:59\n",
      "   ---------------------------- --------- 150.2/203.1 MB 901.0 kB/s eta 0:00:59\n",
      "   ---------------------------- --------- 150.5/203.1 MB 887.2 kB/s eta 0:01:00\n",
      "   ---------------------------- --------- 150.7/203.1 MB 883.9 kB/s eta 0:01:00\n",
      "   ---------------------------- --------- 151.3/203.1 MB 875.2 kB/s eta 0:01:00\n",
      "   ---------------------------- --------- 151.5/203.1 MB 874.2 kB/s eta 0:00:59\n",
      "   ---------------------------- --------- 151.8/203.1 MB 848.9 kB/s eta 0:01:01\n",
      "   ---------------------------- --------- 152.3/203.1 MB 856.8 kB/s eta 0:01:00\n",
      "   ---------------------------- --------- 152.3/203.1 MB 856.8 kB/s eta 0:01:00\n",
      "   ---------------------------- --------- 152.3/203.1 MB 856.8 kB/s eta 0:01:00\n",
      "   ---------------------------- --------- 152.6/203.1 MB 833.1 kB/s eta 0:01:01\n",
      "   ---------------------------- --------- 152.6/203.1 MB 833.1 kB/s eta 0:01:01\n",
      "   ---------------------------- --------- 152.6/203.1 MB 833.1 kB/s eta 0:01:01\n",
      "   ---------------------------- --------- 152.8/203.1 MB 817.1 kB/s eta 0:01:02\n",
      "   ---------------------------- --------- 152.8/203.1 MB 817.1 kB/s eta 0:01:02\n",
      "   ---------------------------- --------- 153.1/203.1 MB 818.2 kB/s eta 0:01:02\n",
      "   ---------------------------- --------- 153.4/203.1 MB 823.4 kB/s eta 0:01:01\n",
      "   ---------------------------- --------- 153.6/203.1 MB 826.1 kB/s eta 0:01:00\n",
      "   ---------------------------- --------- 154.1/203.1 MB 845.5 kB/s eta 0:00:58\n",
      "   ---------------------------- --------- 154.4/203.1 MB 852.2 kB/s eta 0:00:58\n",
      "   ---------------------------- --------- 154.7/203.1 MB 854.7 kB/s eta 0:00:57\n",
      "   ----------------------------- -------- 155.2/203.1 MB 882.5 kB/s eta 0:00:55\n",
      "   ----------------------------- -------- 155.2/203.1 MB 882.5 kB/s eta 0:00:55\n",
      "   ----------------------------- -------- 155.5/203.1 MB 883.0 kB/s eta 0:00:54\n",
      "   ----------------------------- -------- 155.7/203.1 MB 881.2 kB/s eta 0:00:54\n",
      "   ----------------------------- -------- 156.0/203.1 MB 884.9 kB/s eta 0:00:54\n",
      "   ----------------------------- -------- 156.5/203.1 MB 897.8 kB/s eta 0:00:52\n",
      "   ----------------------------- -------- 157.0/203.1 MB 909.2 kB/s eta 0:00:51\n",
      "   ----------------------------- -------- 157.3/203.1 MB 926.1 kB/s eta 0:00:50\n",
      "   ----------------------------- -------- 157.8/203.1 MB 936.5 kB/s eta 0:00:49\n",
      "   ----------------------------- -------- 158.1/203.1 MB 938.9 kB/s eta 0:00:48\n",
      "   ----------------------------- -------- 158.1/203.1 MB 938.9 kB/s eta 0:00:48\n",
      "   ----------------------------- -------- 158.3/203.1 MB 942.3 kB/s eta 0:00:48\n",
      "   ----------------------------- -------- 158.3/203.1 MB 942.3 kB/s eta 0:00:48\n",
      "   ----------------------------- -------- 158.9/203.1 MB 936.9 kB/s eta 0:00:48\n",
      "   ----------------------------- -------- 159.1/203.1 MB 938.9 kB/s eta 0:00:47\n",
      "   ----------------------------- -------- 159.6/203.1 MB 935.0 kB/s eta 0:00:47\n",
      "   ----------------------------- -------- 159.9/203.1 MB 926.2 kB/s eta 0:00:47\n",
      "   ------------------------------ ------- 160.4/203.1 MB 931.6 kB/s eta 0:00:46\n",
      "   ------------------------------ ------- 160.7/203.1 MB 935.0 kB/s eta 0:00:46\n",
      "   ------------------------------ ------- 161.0/203.1 MB 936.9 kB/s eta 0:00:45\n",
      "   ------------------------------ ------- 161.2/203.1 MB 940.8 kB/s eta 0:00:45\n",
      "   ------------------------------ ------- 161.5/203.1 MB 936.9 kB/s eta 0:00:45\n",
      "   ------------------------------ ------- 161.7/203.1 MB 935.0 kB/s eta 0:00:45\n",
      "   ------------------------------ ------- 162.3/203.1 MB 954.1 kB/s eta 0:00:43\n",
      "   ------------------------------ ------- 162.5/203.1 MB 959.4 kB/s eta 0:00:43\n",
      "   ------------------------------ ------- 163.3/203.1 MB 992.2 kB/s eta 0:00:41\n",
      "   -------------------------------- ------- 164.1/203.1 MB 1.0 MB/s eta 0:00:39\n",
      "   -------------------------------- ------- 164.4/203.1 MB 1.0 MB/s eta 0:00:39\n",
      "   -------------------------------- ------- 164.9/203.1 MB 1.0 MB/s eta 0:00:38\n",
      "   -------------------------------- ------- 166.2/203.1 MB 1.1 MB/s eta 0:00:35\n",
      "   -------------------------------- ------- 167.0/203.1 MB 1.1 MB/s eta 0:00:34\n",
      "   --------------------------------- ------ 168.0/203.1 MB 1.1 MB/s eta 0:00:32\n",
      "   --------------------------------- ------ 168.8/203.1 MB 1.1 MB/s eta 0:00:31\n",
      "   --------------------------------- ------ 169.1/203.1 MB 1.1 MB/s eta 0:00:30\n",
      "   --------------------------------- ------ 169.3/203.1 MB 1.2 MB/s eta 0:00:30\n",
      "   --------------------------------- ------ 169.9/203.1 MB 1.2 MB/s eta 0:00:29\n",
      "   --------------------------------- ------ 170.1/203.1 MB 1.2 MB/s eta 0:00:29\n",
      "   --------------------------------- ------ 170.9/203.1 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------------- ------ 171.2/203.1 MB 1.2 MB/s eta 0:00:27\n",
      "   --------------------------------- ------ 171.4/203.1 MB 1.2 MB/s eta 0:00:27\n",
      "   --------------------------------- ------ 171.7/203.1 MB 1.2 MB/s eta 0:00:26\n",
      "   --------------------------------- ------ 171.7/203.1 MB 1.2 MB/s eta 0:00:26\n",
      "   --------------------------------- ------ 172.0/203.1 MB 1.2 MB/s eta 0:00:26\n",
      "   --------------------------------- ------ 172.5/203.1 MB 1.2 MB/s eta 0:00:26\n",
      "   ---------------------------------- ----- 173.0/203.1 MB 1.3 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 173.3/203.1 MB 1.3 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 173.5/203.1 MB 1.3 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 173.5/203.1 MB 1.3 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 173.5/203.1 MB 1.3 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 173.8/203.1 MB 1.3 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 174.1/203.1 MB 1.3 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 174.1/203.1 MB 1.3 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 174.6/203.1 MB 1.3 MB/s eta 0:00:23\n",
      "   ---------------------------------- ----- 174.9/203.1 MB 1.3 MB/s eta 0:00:23\n",
      "   ---------------------------------- ----- 175.1/203.1 MB 1.3 MB/s eta 0:00:22\n",
      "   ---------------------------------- ----- 175.4/203.1 MB 1.3 MB/s eta 0:00:22\n",
      "   ---------------------------------- ----- 175.9/203.1 MB 1.3 MB/s eta 0:00:21\n",
      "   ---------------------------------- ----- 176.2/203.1 MB 1.3 MB/s eta 0:00:21\n",
      "   ---------------------------------- ----- 176.4/203.1 MB 1.3 MB/s eta 0:00:21\n",
      "   ---------------------------------- ----- 176.7/203.1 MB 1.3 MB/s eta 0:00:21\n",
      "   ---------------------------------- ----- 177.5/203.1 MB 1.3 MB/s eta 0:00:20\n",
      "   ----------------------------------- ---- 177.7/203.1 MB 1.3 MB/s eta 0:00:20\n",
      "   ----------------------------------- ---- 178.3/203.1 MB 1.3 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 179.0/203.1 MB 1.4 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 180.1/203.1 MB 1.4 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 180.9/203.1 MB 1.4 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 181.4/203.1 MB 1.4 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 181.7/203.1 MB 1.4 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 181.9/203.1 MB 1.4 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 181.9/203.1 MB 1.4 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 182.2/203.1 MB 1.4 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 182.2/203.1 MB 1.4 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 182.5/203.1 MB 1.4 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 182.7/203.1 MB 1.4 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 183.2/203.1 MB 1.4 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 183.8/203.1 MB 1.4 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 184.5/203.1 MB 1.4 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 185.1/203.1 MB 1.4 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 185.6/203.1 MB 1.4 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 186.4/203.1 MB 1.4 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 187.2/203.1 MB 1.5 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 188.0/203.1 MB 1.5 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 189.5/203.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ------------------------------------- -- 189.8/203.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ------------------------------------- -- 190.6/203.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ------------------------------------- -- 191.1/203.1 MB 1.6 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 191.9/203.1 MB 1.6 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 192.4/203.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 192.7/203.1 MB 1.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 193.7/203.1 MB 1.6 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 194.5/203.1 MB 1.6 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 195.0/203.1 MB 1.7 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 195.6/203.1 MB 1.7 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 195.8/203.1 MB 1.7 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 196.1/203.1 MB 1.7 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 196.3/203.1 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 196.6/203.1 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 196.9/203.1 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 196.9/203.1 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 197.4/203.1 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 197.9/203.1 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------------------------  198.7/203.1 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------------------  199.0/203.1 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------------------  199.8/203.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  200.5/203.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  201.9/203.1 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 203.1/203.1 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/6.2 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.1/6.2 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.9/6.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading ir_datasets-0.5.9-py3-none-any.whl (347 kB)\n",
      "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading sentence_transformers-3.3.0-py3-none-any.whl (268 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 786.4/991.5 kB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 3.3 MB/s eta 0:00:00\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading ijson-3.3.0-cp311-cp311-win_amd64.whl (50 kB)\n",
      "Downloading inscriptis-2.5.0-py3-none-any.whl (45 kB)\n",
      "Downloading lz4-4.3.3-cp311-cp311-win_amd64.whl (99 kB)\n",
      "Downloading pyarrow-18.0.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/25.1 MB 7.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.1/25.1 MB 7.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.5/25.1 MB 7.2 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.6/25.1 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.1/25.1 MB 7.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.7/25.1 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.5/25.1 MB 7.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.2/25.1 MB 8.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.8/25.1 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.7/25.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.0/25.1 MB 9.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.1/25.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Downloading unlzw3-0.2.2-py3-none-any.whl (6.1 kB)\n",
      "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
      "Downloading zlib_state-0.1.9-cp311-cp311-win_amd64.whl (12 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Building wheels for collected packages: FlagEmbedding\n",
      "  Building wheel for FlagEmbedding (setup.py): started\n",
      "  Building wheel for FlagEmbedding (setup.py): finished with status 'done'\n",
      "  Created wheel for FlagEmbedding: filename=FlagEmbedding-1.3.2-py3-none-any.whl size=264097 sha256=39bf5269c2b731b70e2ddb47e2cfda8ef8e14135bb4aed0586a4af9d800d9ce3\n",
      "  Stored in directory: C:\\Users\\dljh1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-gbh2efr8\\wheels\\58\\38\\6c\\d261654a2708b9eb15d23c611cfa576b70268fc08c8f075430\n",
      "Successfully built FlagEmbedding\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, sentencepiece, mpmath, ijson, cbor, zlib-state, xxhash, unlzw3, trec-car-tools, sympy, safetensors, pyarrow-hotfix, pyarrow, protobuf, MarkupSafe, lz4, fsspec, filelock, dill, multiprocess, jinja2, inscriptis, huggingface-hub, torch, tokenizers, ir-datasets, transformers, datasets, accelerate, sentence_transformers, peft, FlagEmbedding\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "Successfully installed FlagEmbedding-1.3.2 MarkupSafe-3.0.2 accelerate-1.1.1 cbor-1.0.0 datasets-2.19.0 dill-0.3.8 filelock-3.16.1 fsspec-2024.3.1 huggingface-hub-0.26.2 ijson-3.3.0 inscriptis-2.5.0 ir-datasets-0.5.9 jinja2-3.1.4 lz4-4.3.3 mpmath-1.3.0 multiprocess-0.70.16 peft-0.13.2 protobuf-5.28.3 pyarrow-18.0.0 pyarrow-hotfix-0.6 safetensors-0.4.5 sentence_transformers-3.3.0 sentencepiece-0.2.0 sympy-1.13.1 tokenizers-0.19.1 torch-2.5.1 transformers-4.44.2 trec-car-tools-2.6 unlzw3-0.2.2 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 xxhash-3.5.0 zlib-state-0.1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/FlagOpen/FlagEmbedding.git 'C:\\Users\\dljh1\\AppData\\Local\\Temp\\pip-req-build-3xp9kjao'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-parse in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (0.5.14)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-parse) (8.1.7)\n",
      "Requirement already satisfied: llama-index-core>=0.11.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-parse) (0.11.23)\n",
      "Requirement already satisfied: colorama in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from click<9.0.0,>=8.1.7->llama-parse) (0.4.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (3.11.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (2024.3.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (11.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from llama-index-core>=0.11.0->llama-parse) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.17.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core>=0.11.0->llama-parse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core>=0.11.0->llama-parse) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-parse) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from dataclasses-json->llama-index-core>=0.11.0->llama-parse) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core>=0.11.0->llama-parse) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\dljh1\\anaconda3\\envs\\autogen02\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-parse) (24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-core==0.10.6.post1\n",
    "!pip install llama-index-embeddings-openai\n",
    "!pip install llama-index-postprocessor-flag-embedding-reranker\n",
    "!pip install git+https://github.com/FlagOpen/FlagEmbedding.git\n",
    "!pip install llama-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "\n",
    "# API access to llama-cloud\n",
    "os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "\n",
    "# Using OpenAI API for embeddings/llms\n",
    "os.getenv(\"TERTIARY_INFOTECH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 86dcb703-21d6-4020-bf30-aa4e2babb151\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_parse import LlamaParse\n",
    "parsingInstructions= \"\"\"\n",
    "The provided document is a textbook.\n",
    "If page contains code, then Output code in markdown (between ```).\n",
    "If page contains math equations, then Output math equation in LATEX markdown (between $$)\"\"\"\n",
    "\n",
    "parser = LlamaParse(\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    "    result_type=\"markdown\",\n",
    "    parsing_instruction=parsingInstructions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id dec12851-0cb8-4324-bf46-5395a5091766\n"
     ]
    }
   ],
   "source": [
    "json_objs = parser.get_json_result(\"docs/Mastering Java A Beginners Guide (Sufyan bin Uzayr).pdf\")\n",
    "json_list = json_objs[0][\"pages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.schema import ImageDocument, TextNode\n",
    "\n",
    "def get_text_nodes(json_list: List[dict]) -> List[TextNode]:\n",
    "    return [TextNode(text=page[\"text\"], metadata={\"page\": page[\"page\"]}) for page in json_list]\n",
    "\n",
    "text_nodes = get_text_nodes(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Image for page 1: [{'name': 'img_p0_1.png', 'height': 2340, 'width': 1524, 'x': 0, 'y': 2.4400000029345392e-05, 'original_width': 1524, 'original_height': 2340, 'ocr': [{'x': 129, 'y': 89, 'w': 625, 'h': 55, 'confidence': '0.996777644665082', 'text': 'MASTERING COMPUTER SCIENCE'}, {'x': 114, 'y': 247, 'w': 1180, 'h': 314, 'confidence': '0.9906991623997096', 'text': 'Mastering Java'}, {'x': 201, 'y': 531, 'w': 623, 'h': 122, 'confidence': '0.8749674105092146', 'text': \"Beginner's Guide\"}, {'x': 130, 'y': 1848, 'w': 168, 'h': 48, 'confidence': '0.9824436784324095', 'text': 'EDITED'}, {'x': 313, 'y': 1849, 'w': 60, 'h': 44, 'confidence': '0.9525965078461694', 'text': 'BY'}, {'x': 117, 'y': 1912, 'w': 351, 'h': 129, 'confidence': '0.8887067004374768', 'text': 'Sufyan bin'}, {'x': 1097, 'y': 2123, 'w': 275, 'h': 67, 'confidence': '0.9918120829674356', 'text': 'CRC Press'}, {'x': 1097, 'y': 2187, 'w': 299, 'h': 43, 'confidence': '0.788739499955709', 'text': 'Taylor & Francis Group'}, {'x': 473, 'y': 1908, 'w': 172, 'h': 140, 'confidence': '0.9992954524204587', 'text': 'Uzayr'}, {'x': 934, 'y': 2168, 'w': 147, 'h': 16, 'confidence': '0.999724290077894', 'text': 'CRC'}]}]\n",
      "> Image for page 2: []\n",
      "> Image for page 3: []\n",
      "> Image for page 4: []\n",
      "> Image for page 5: []\n",
      "> Image for page 6: []\n",
      "> Image for page 7: []\n",
      "> Image for page 8: []\n",
      "> Image for page 9: []\n",
      "> Image for page 10: []\n",
      "> Image for page 11: []\n",
      "> Image for page 12: []\n",
      "> Image for page 13: []\n",
      "> Image for page 14: []\n",
      "> Image for page 15: []\n",
      "> Image for page 16: []\n",
      "> Image for page 17: []\n",
      "> Image for page 18: []\n",
      "> Image for page 19: []\n",
      "> Image for page 20: []\n",
      "> Image for page 21: []\n",
      "> Image for page 22: []\n",
      "> Image for page 23: []\n",
      "> Image for page 24: []\n",
      "> Image for page 25: []\n",
      "> Image for page 26: []\n",
      "> Image for page 27: [{'name': 'img_p26_1.png', 'height': 298, 'width': 1127, 'x': 47.6399994, 'y': 245.04000240000005, 'original_width': 1127, 'original_height': 298, 'ocr': [{'x': 294, 'y': 24, 'w': 833, 'h': 153, 'confidence': '0.905813563860693', 'text': 'Taylor & Francis'}, {'x': 303, 'y': 165, 'w': 623, 'h': 81, 'confidence': '0.7421902011683379', 'text': 'Taylor & Francis Group'}, {'x': 306, 'y': 248, 'w': 518, 'h': 50, 'confidence': '0.6145183118283511', 'text': 'http:/ /taylorandfrancis.com'}]}]\n",
      "> Image for page 28: []\n",
      "> Image for page 29: []\n",
      "> Image for page 30: []\n",
      "> Image for page 31: []\n",
      "> Image for page 32: []\n",
      "> Image for page 33: []\n",
      "> Image for page 34: []\n",
      "> Image for page 35: [{'name': 'img_p34_1.png', 'height': 379, 'width': 1074, 'x': 54, 'y': 408.5407159, 'original_width': 1074, 'original_height': 379, 'ocr': [{'x': 397, 'y': 0, 'w': 215, 'h': 30, 'confidence': '0.8423395730836534', 'text': 'Working of JVM'}, {'x': 611, 'y': 116, 'w': 114, 'h': 28, 'confidence': '0.8536404942360258', 'text': 'Interpreted'}, {'x': 650, 'y': 186, 'w': 52, 'h': 26, 'confidence': '0.7188986030984761', 'text': 'Java'}, {'x': 772, 'y': 184, 'w': 56, 'h': 26, 'confidence': '0.9999538660049438', 'text': '0101'}, {'x': 226, 'y': 214, 'w': 100, 'h': 30, 'confidence': '0.6700197250873127', 'text': 'Compiler'}, {'x': 654, 'y': 240, 'w': 44, 'h': 26, 'confidence': '0.999672197550845', 'text': 'VM'}, {'x': 0, 'y': 338, 'w': 108, 'h': 30, 'confidence': '0.9954321846757052', 'text': 'Hello java'}, {'x': 453, 'y': 336, 'w': 117, 'h': 32, 'confidence': '0.6698065813500383', 'text': 'Hello.class'}, {'x': 966, 'y': 358, 'w': 62, 'h': 21, 'confidence': '0.9959913905752361', 'text': 'Hello'}]}]\n",
      "> Image for page 36: [{'name': 'img_p35_1.png', 'height': 738, 'width': 1017, 'x': 60.799408, 'y': 322.1783654, 'original_width': 1017, 'original_height': 738, 'ocr': [{'x': 680, 'y': 34, 'w': 68, 'h': 24, 'confidence': '0.9999902972077144', 'text': 'Windo'}, {'x': 882, 'y': 34, 'w': 94, 'h': 26, 'confidence': '0.9999912589536624', 'text': 'Windows'}, {'x': 701, 'y': 71, 'w': 28, 'h': 18, 'confidence': '0.3962076814796058', 'text': 'wS'}, {'x': 910, 'y': 66, 'w': 36, 'h': 24, 'confidence': '0.8027565170324192', 'text': 'OS'}, {'x': 687, 'y': 97, 'w': 50, 'h': 20, 'confidence': '0.8944414693109728', 'text': 'JVM'}, {'x': 40, 'y': 162, 'w': 50, 'h': 24, 'confidence': '0.9828174042745548', 'text': 'Java'}, {'x': 230, 'y': 178, 'w': 82, 'h': 26, 'confidence': '0.9997372210024761', 'text': 'JAVAc'}, {'x': 418, 'y': 178, 'w': 106, 'h': 28, 'confidence': '0.9998795152515718', 'text': 'Byte Code'}, {'x': 38, 'y': 192, 'w': 56, 'h': 26, 'confidence': '0.9999774694442749', 'text': 'Code'}, {'x': 224, 'y': 208, 'w': 96, 'h': 28, 'confidence': '0.9999784628643444', 'text': 'Compiler'}, {'x': 692, 'y': 212, 'w': 62, 'h': 24, 'confidence': '0.6546739884263894', 'text': 'Linux'}, {'x': 888, 'y': 214, 'w': 100, 'h': 24, 'confidence': '0.9896376994586256', 'text': 'Linux OS'}, {'x': 696, 'y': 242, 'w': 52, 'h': 24, 'confidence': '0.9999469357162452', 'text': 'JVM'}, {'x': 692, 'y': 390, 'w': 72, 'h': 26, 'confidence': '0.993027511140389', 'text': 'Solaris'}, {'x': 886, 'y': 400, 'w': 104, 'h': 26, 'confidence': '0.9980170626143458', 'text': 'Solaris OS'}, {'x': 700, 'y': 422, 'w': 52, 'h': 24, 'confidence': '0.99992608176247', 'text': 'JVM'}, {'x': 708, 'y': 576, 'w': 46, 'h': 24, 'confidence': '0.9999990364428464', 'text': 'Mac'}, {'x': 704, 'y': 606, 'w': 52, 'h': 24, 'confidence': '0.9998679938287938', 'text': 'JVM'}, {'x': 904, 'y': 594, 'w': 84, 'h': 28, 'confidence': '0.9977117518223987', 'text': 'Mac OS'}, {'x': 308, 'y': 709, 'w': 336, 'h': 29, 'confidence': '0.8802054726760387', 'text': 'Java platform independence'}]}]\n",
      "> Image for page 37: []\n",
      "> Image for page 38: []\n",
      "> Image for page 39: []\n",
      "> Image for page 40: []\n",
      "> Image for page 41: []\n",
      "> Image for page 42: []\n",
      "> Image for page 43: []\n",
      "> Image for page 44: []\n",
      "> Image for page 45: []\n",
      "> Image for page 46: []\n",
      "> Image for page 47: []\n",
      "> Image for page 48: []\n",
      "> Image for page 49: []\n",
      "> Image for page 50: []\n",
      "> Image for page 51: []\n",
      "> Image for page 52: []\n",
      "> Image for page 53: []\n",
      "> Image for page 54: []\n",
      "> Image for page 55: [{'name': 'img_p54_1.png', 'height': 298, 'width': 1127, 'x': 47.5946198, 'y': 244.87007689999996, 'original_width': 1127, 'original_height': 298, 'ocr': [{'x': 293, 'y': 23, 'w': 834, 'h': 157, 'confidence': '0.5809515606665815', 'text': 'Taylor & Francis'}, {'x': 303, 'y': 165, 'w': 623, 'h': 80, 'confidence': '0.9433500479004513', 'text': 'Taylor & Francis Group'}, {'x': 303, 'y': 241, 'w': 522, 'h': 57, 'confidence': '0.8278818549052219', 'text': 'http:/ /taylorandfrancis.com'}]}]\n",
      "> Image for page 56: []\n",
      "> Image for page 57: []\n",
      "> Image for page 58: []\n",
      "> Image for page 59: []\n",
      "> Image for page 60: []\n",
      "> Image for page 61: [{'name': 'img_p60_1.png', 'height': 312, 'width': 1068, 'x': 54.6746368, 'y': 208.5630091, 'original_width': 1068, 'original_height': 312, 'ocr': [{'x': 76, 'y': 70, 'w': 124, 'h': 30, 'confidence': '0.9997373052494284', 'text': 'Java Code'}, {'x': 478, 'y': 69, 'w': 112, 'h': 30, 'confidence': '0.9238232798969509', 'text': 'Compiler'}, {'x': 928, 'y': 70, 'w': 64, 'h': 28, 'confidence': '0.7670715463347033', 'text': 'Code'}, {'x': 880, 'y': 246, 'w': 116, 'h': 30, 'confidence': '0.7857887593430466', 'text': 'First class'}, {'x': 86, 'y': 258, 'w': 113, 'h': 36, 'confidence': '0.8228765733780739', 'text': 'First-java'}, {'x': 869, 'y': 67, 'w': 55, 'h': 36, 'confidence': '0.9998350143432617', 'text': 'Byte'}]}, {'name': 'img_p60_2.png', 'height': 651, 'width': 300, 'x': 146.8346558, 'y': 342.290365, 'original_width': 300, 'original_height': 651, 'ocr': [{'x': 77, 'y': 17, 'w': 146, 'h': 38, 'confidence': '0.9945209609549094', 'text': 'Class file'}, {'x': 57, 'y': 133, 'w': 190, 'h': 38, 'confidence': '0.9999792607744404', 'text': 'Classloader'}, {'x': 9, 'y': 247, 'w': 284, 'h': 44, 'confidence': '0.9992618712393131', 'text': 'Bytecode verified'}, {'x': 57, 'y': 363, 'w': 187, 'h': 48, 'confidence': '0.9549093136077583', 'text': 'Interpreter'}, {'x': 84, 'y': 481, 'w': 132, 'h': 38, 'confidence': '0.8429653652728082', 'text': 'Runtine'}, {'x': 69, 'y': 595, 'w': 164, 'h': 40, 'confidence': '0.6520759161199293', 'text': 'Hardware'}]}]\n",
      "> Image for page 62: []\n",
      "> Image for page 63: []\n",
      "> Image for page 64: []\n",
      "> Image for page 65: []\n",
      "> Image for page 66: []\n",
      "> Image for page 67: []\n",
      "> Image for page 68: []\n",
      "> Image for page 69: []\n",
      "> Image for page 70: []\n",
      "> Image for page 71: []\n",
      "> Image for page 72: []\n",
      "> Image for page 73: []\n",
      "> Image for page 74: []\n",
      "> Image for page 75: []\n",
      "> Image for page 76: []\n",
      "> Image for page 77: []\n",
      "> Image for page 78: []\n",
      "> Image for page 79: []\n",
      "> Image for page 80: []\n",
      "> Image for page 81: []\n",
      "> Image for page 82: []\n",
      "> Image for page 83: []\n",
      "> Image for page 84: []\n",
      "> Image for page 85: []\n",
      "> Image for page 86: []\n",
      "> Image for page 87: []\n",
      "> Image for page 88: []\n",
      "> Image for page 89: []\n",
      "> Image for page 90: []\n",
      "> Image for page 91: []\n",
      "> Image for page 92: []\n",
      "> Image for page 93: []\n",
      "> Image for page 94: []\n",
      "> Image for page 95: []\n",
      "> Image for page 96: []\n",
      "> Image for page 97: []\n",
      "> Image for page 98: []\n",
      "> Image for page 99: []\n",
      "> Image for page 100: []\n",
      "> Image for page 101: []\n",
      "> Image for page 102: []\n",
      "> Image for page 103: []\n",
      "> Image for page 104: []\n",
      "> Image for page 105: []\n",
      "> Image for page 106: []\n",
      "> Image for page 107: []\n",
      "> Image for page 108: []\n",
      "> Image for page 109: []\n",
      "> Image for page 110: []\n",
      "> Image for page 111: []\n",
      "> Image for page 112: []\n",
      "> Image for page 113: []\n",
      "> Image for page 114: []\n",
      "> Image for page 115: []\n",
      "> Image for page 116: []\n",
      "> Image for page 117: []\n",
      "> Image for page 118: []\n",
      "> Image for page 119: []\n",
      "> Image for page 120: []\n",
      "> Image for page 121: []\n",
      "> Image for page 122: []\n",
      "> Image for page 123: []\n",
      "> Image for page 124: []\n",
      "> Image for page 125: []\n",
      "> Image for page 126: []\n",
      "> Image for page 127: []\n",
      "> Image for page 128: []\n",
      "> Image for page 129: []\n",
      "> Image for page 130: []\n",
      "> Image for page 131: [{'name': 'img_p130_1.png', 'height': 508, 'width': 1050, 'x': 56.8346405, 'y': 269.99706059999994, 'original_width': 1050, 'original_height': 508, 'ocr': [{'x': 461, 'y': 69, 'w': 136, 'h': 42, 'confidence': '0.8888185233373987', 'text': 'Types of'}, {'x': 429, 'y': 121, 'w': 198, 'h': 36, 'confidence': '0.7243937802268995', 'text': 'Constructor:'}, {'x': 750, 'y': 314, 'w': 230, 'h': 36, 'confidence': '0.9999792364462314', 'text': 'Parameterized'}, {'x': 37, 'y': 339, 'w': 302, 'h': 38, 'confidence': '0.7527914533267593', 'text': 'Default constructor'}, {'x': 774, 'y': 370, 'w': 186, 'h': 32, 'confidence': '0.8220834837381521', 'text': 'constructor'}]}]\n",
      "> Image for page 132: []\n",
      "> Image for page 133: []\n",
      "> Image for page 134: []\n",
      "> Image for page 135: []\n",
      "> Image for page 136: []\n",
      "> Image for page 137: []\n",
      "> Image for page 138: []\n",
      "> Image for page 139: []\n",
      "> Image for page 140: []\n",
      "> Image for page 141: []\n",
      "> Image for page 142: []\n",
      "> Image for page 143: []\n",
      "> Image for page 144: []\n",
      "> Image for page 145: []\n",
      "> Image for page 146: []\n",
      "> Image for page 147: []\n",
      "> Image for page 148: []\n",
      "> Image for page 149: []\n",
      "> Image for page 150: []\n",
      "> Image for page 151: []\n",
      "> Image for page 152: []\n",
      "> Image for page 153: []\n",
      "> Image for page 154: []\n",
      "> Image for page 155: []\n",
      "> Image for page 156: []\n",
      "> Image for page 157: []\n",
      "> Image for page 158: []\n",
      "> Image for page 159: []\n",
      "> Image for page 160: []\n",
      "> Image for page 161: []\n",
      "> Image for page 162: []\n",
      "> Image for page 163: []\n",
      "> Image for page 164: []\n",
      "> Image for page 165: []\n",
      "> Image for page 166: []\n",
      "> Image for page 167: [{'name': 'page_167.jpg', 'height': 561.26, 'width': 365.669, 'x': 0, 'y': 0, 'type': 'full_page_screenshot', 'ocr': [{'x': 338, 'y': 718, 'w': 584, 'h': 102, 'confidence': '0.9671692745181713', 'text': 'Taylor & Francis'}, {'x': 341, 'y': 807, 'w': 430, 'h': 62, 'confidence': '0.8117147014503838', 'text': 'Taylor & Francis Group'}, {'x': 343, 'y': 865, 'w': 356, 'h': 44, 'confidence': '0.7718617644330281', 'text': 'http:/ /taylorandfranciscom'}]}]\n",
      "> Image for page 168: []\n",
      "> Image for page 169: [{'name': 'img_p168_1.png', 'height': 267, 'width': 600, 'x': 110.8346252, 'y': 324.2050378, 'original_width': 600, 'original_height': 267, 'ocr': [{'x': 0, 'y': 1, 'w': 141, 'h': 36, 'confidence': '0.911753303320664', 'text': 'Serializable'}, {'x': 428, 'y': 0, 'w': 172, 'h': 33, 'confidence': '0.9971323107868496', 'text': 'CharSequence'}, {'x': 205, 'y': 27, 'w': 152, 'h': 38, 'confidence': '0.992679844899714', 'text': 'Comparable'}, {'x': 239, 'y': 233, 'w': 83, 'h': 34, 'confidence': '0.7282088394138293', 'text': 'String'}]}]\n",
      "> Image for page 170: [{'name': 'img_p169_1.png', 'height': 398, 'width': 600, 'x': 110.8346405, 'y': 66.0001123, 'original_width': 600, 'original_height': 398, 'ocr': [{'x': 155, 'y': 0, 'w': 209, 'h': 41, 'confidence': '0.9999823117280188', 'text': 'CharSequence'}, {'x': 0, 'y': 309, 'w': 90, 'h': 50, 'confidence': '0.9999920186067003', 'text': 'String'}, {'x': 411, 'y': 319, 'w': 189, 'h': 42, 'confidence': '0.7696640001912284', 'text': 'StringBuilder'}, {'x': 161, 'y': 363, 'w': 182, 'h': 35, 'confidence': '0.9998963440971815', 'text': 'StringBuffer'}]}]\n",
      "> Image for page 171: []\n",
      "> Image for page 172: []\n",
      "> Image for page 173: []\n",
      "> Image for page 174: []\n",
      "> Image for page 175: []\n",
      "> Image for page 176: []\n",
      "> Image for page 177: []\n",
      "> Image for page 178: []\n",
      "> Image for page 179: []\n",
      "> Image for page 180: []\n",
      "> Image for page 181: []\n",
      "> Image for page 182: []\n",
      "> Image for page 183: []\n",
      "> Image for page 184: []\n",
      "> Image for page 185: []\n",
      "> Image for page 186: []\n",
      "> Image for page 187: []\n",
      "> Image for page 188: []\n",
      "> Image for page 189: []\n",
      "> Image for page 190: []\n",
      "> Image for page 191: []\n",
      "> Image for page 192: []\n",
      "> Image for page 193: []\n",
      "> Image for page 194: []\n",
      "> Image for page 195: []\n",
      "> Image for page 196: []\n",
      "> Image for page 197: []\n",
      "> Image for page 198: []\n",
      "> Image for page 199: []\n",
      "> Image for page 200: []\n",
      "> Image for page 201: []\n",
      "> Image for page 202: []\n",
      "> Image for page 203: []\n",
      "> Image for page 204: []\n",
      "> Image for page 205: []\n",
      "> Image for page 206: []\n",
      "> Image for page 207: []\n",
      "> Image for page 208: []\n",
      "> Image for page 209: []\n",
      "> Image for page 210: []\n",
      "> Image for page 211: []\n",
      "> Image for page 212: []\n",
      "> Image for page 213: []\n",
      "> Image for page 214: []\n",
      "> Image for page 215: []\n",
      "> Image for page 216: [{'name': 'img_p215_1.png', 'height': 439, 'width': 601, 'x': 110.8346405, 'y': 208.1965235, 'original_width': 601, 'original_height': 439, 'ocr': [{'x': 342, 'y': 2, 'w': 246, 'h': 30, 'confidence': '0.9991362351526387', 'text': 'Hello welcome to java'}, {'x': 81, 'y': 12, 'w': 69, 'h': 37, 'confidence': '0.9999857656800379', 'text': 'Input'}, {'x': 308, 'y': 117, 'w': 193, 'h': 41, 'confidence': '0.7386906267046589', 'text': 'String Tokenizer'}, {'x': 362, 'y': 252, 'w': 86, 'h': 26, 'confidence': '0.9999851565436978', 'text': 'Tokens'}, {'x': 182, 'y': 412, 'w': 66, 'h': 27, 'confidence': '0.9997903212501642', 'text': 'Hello'}, {'x': 294, 'y': 412, 'w': 100, 'h': 27, 'confidence': '0.9998392328926677', 'text': 'welcome'}, {'x': 450, 'y': 414, 'w': 28, 'h': 24, 'confidence': '0.999845746019275', 'text': 'to'}, {'x': 550, 'y': 411, 'w': 51, 'h': 28, 'confidence': '0.9998356103897095', 'text': 'java'}]}]\n",
      "> Image for page 217: [{'name': 'img_p216_1.png', 'height': 751, 'width': 675, 'x': 101.8346405, 'y': 112.19652339999996, 'original_width': 675, 'original_height': 751, 'ocr': [{'x': 288, 'y': 46, 'w': 100, 'h': 32, 'confidence': '0.9992913995468784', 'text': 'boolean'}, {'x': 274, 'y': 76, 'w': 130, 'h': 32, 'confidence': '0.999821627947441', 'text': 'hasMoreT'}, {'x': 289, 'y': 107, 'w': 95, 'h': 33, 'confidence': '0.8048487623519079', 'text': 'okenso)'}, {'x': 72, 'y': 190, 'w': 40, 'h': 28, 'confidence': '0.9997229136185645', 'text': 'int'}, {'x': 541, 'y': 183, 'w': 85, 'h': 43, 'confidence': '0.9623765369271485', 'text': 'String '}, {'x': 26, 'y': 218, 'w': 131, 'h': 30, 'confidence': '0.9990258228105354', 'text': 'countToke'}, {'x': 516, 'y': 218, 'w': 132, 'h': 30, 'confidence': '0.9959070894737525', 'text': 'nextToken'}, {'x': 64, 'y': 252, 'w': 52, 'h': 28, 'confidence': '0.4911058278003065', 'text': 'ns()'}, {'x': 50, 'y': 472, 'w': 88, 'h': 32, 'confidence': '0.9998208937377141', 'text': 'Object'}, {'x': 515, 'y': 488, 'w': 132, 'h': 28, 'confidence': '0.9933847811967479', 'text': 'nextToken'}, {'x': 26, 'y': 502, 'w': 132, 'h': 30, 'confidence': '0.9976313387348315', 'text': 'nextEleme'}, {'x': 66, 'y': 534, 'w': 52, 'h': 32, 'confidence': '0.6866426467895508', 'text': 'nto)'}, {'x': 535, 'y': 513, 'w': 95, 'h': 42, 'confidence': '0.999990357813462', 'text': '(String'}, {'x': 538, 'y': 545, 'w': 89, 'h': 36, 'confidence': '0.7717005286557631', 'text': 'delim)'}, {'x': 288, 'y': 614, 'w': 98, 'h': 30, 'confidence': '0.9999729657562306', 'text': 'boolean'}, {'x': 272, 'y': 644, 'w': 130, 'h': 32, 'confidence': '0.9997823438623559', 'text': 'hasMoreE'}, {'x': 275, 'y': 673, 'w': 121, 'h': 33, 'confidence': '0.6252350757994962', 'text': 'lementso)'}, {'x': 545, 'y': 449, 'w': 76, 'h': 47, 'confidence': '0.9999963986413812', 'text': 'String'}]}]\n",
      "> Image for page 218: []\n",
      "> Image for page 219: [{'name': 'page_219.jpg', 'height': 561.26, 'width': 365.669, 'x': 0, 'y': 0, 'type': 'full_page_screenshot', 'ocr': [{'x': 338, 'y': 718, 'w': 584, 'h': 102, 'confidence': '0.9671692745181713', 'text': 'Taylor & Francis'}, {'x': 341, 'y': 807, 'w': 430, 'h': 62, 'confidence': '0.8117147014503838', 'text': 'Taylor & Francis Group'}, {'x': 343, 'y': 865, 'w': 356, 'h': 44, 'confidence': '0.7718617644330281', 'text': 'http:/ /taylorandfranciscom'}]}]\n",
      "> Image for page 220: []\n",
      "> Image for page 221: []\n",
      "> Image for page 222: []\n",
      "> Image for page 223: []\n",
      "> Image for page 224: []\n",
      "> Image for page 225: []\n",
      "> Image for page 226: []\n",
      "> Image for page 227: []\n",
      "> Image for page 228: []\n",
      "> Image for page 229: []\n",
      "> Image for page 230: []\n",
      "> Image for page 231: []\n",
      "> Image for page 232: []\n",
      "> Image for page 233: []\n",
      "> Image for page 234: []\n",
      "> Image for page 235: []\n",
      "> Image for page 236: []\n",
      "> Image for page 237: []\n",
      "> Image for page 238: []\n",
      "> Image for page 239: []\n",
      "> Image for page 240: []\n",
      "> Image for page 241: []\n",
      "> Image for page 242: []\n",
      "> Image for page 243: []\n",
      "> Image for page 244: []\n",
      "> Image for page 245: []\n",
      "> Image for page 246: []\n",
      "> Image for page 247: []\n",
      "> Image for page 248: []\n",
      "> Image for page 249: []\n",
      "> Image for page 250: []\n",
      "> Image for page 251: []\n",
      "> Image for page 252: []\n",
      "> Image for page 253: []\n",
      "> Image for page 254: []\n",
      "> Image for page 255: []\n",
      "> Image for page 256: []\n",
      "> Image for page 257: []\n",
      "> Image for page 258: []\n",
      "> Image for page 259: []\n",
      "> Image for page 260: []\n",
      "> Image for page 261: []\n",
      "> Image for page 262: []\n",
      "> Image for page 263: []\n",
      "> Image for page 264: []\n",
      "> Image for page 265: []\n",
      "> Image for page 266: []\n",
      "> Image for page 267: []\n",
      "> Image for page 268: [{'name': 'img_p267_1.png', 'height': 938, 'width': 1057, 'x': 56.0966339, 'y': 233.29601069999995, 'original_width': 1057, 'original_height': 938, 'ocr': [{'x': 908, 'y': 42, 'w': 124, 'h': 32, 'confidence': '0.9999888737686936', 'text': 'Interface'}, {'x': 909, 'y': 105, 'w': 78, 'h': 36, 'confidence': '0.9999300010351283', 'text': 'Class'}, {'x': 903, 'y': 173, 'w': 154, 'h': 36, 'confidence': '0.9999464313208887', 'text': 'Implements'}, {'x': 910, 'y': 234, 'w': 112, 'h': 32, 'confidence': '0.9999987384072065', 'text': 'Extends'}, {'x': 82, 'y': 577, 'w': 153, 'h': 42, 'confidence': '0.9999864498315192', 'text': 'SortedMap'}, {'x': 573, 'y': 576, 'w': 137, 'h': 43, 'confidence': '0.999986708192969', 'text': 'HashMap'}, {'x': 80, 'y': 811, 'w': 135, 'h': 48, 'confidence': '0.9999443542578758', 'text': 'TreeMap'}, {'x': 527, 'y': 820, 'w': 229, 'h': 48, 'confidence': '0.983865247154613', 'text': 'LinkedHashMap'}, {'x': 128, 'y': 342, 'w': 60, 'h': 47, 'confidence': '0.999995182215476', 'text': 'Map'}]}]\n",
      "> Image for page 269: []\n",
      "> Image for page 270: []\n",
      "> Image for page 271: []\n",
      "> Image for page 272: []\n",
      "> Image for page 273: []\n",
      "> Image for page 274: []\n",
      "> Image for page 275: []\n",
      "> Image for page 276: []\n",
      "> Image for page 277: []\n",
      "> Image for page 278: []\n",
      "> Image for page 279: []\n",
      "> Image for page 280: []\n",
      "> Image for page 281: []\n",
      "> Image for page 282: []\n",
      "> Image for page 283: []\n",
      "> Image for page 284: []\n",
      "> Image for page 285: []\n",
      "> Image for page 286: []\n",
      "> Image for page 287: []\n",
      "> Image for page 288: []\n",
      "> Image for page 289: []\n",
      "> Image for page 290: []\n",
      "> Image for page 291: [{'name': 'img_p290_1.png', 'height': 431, 'width': 991, 'x': 63.9650421, 'y': 395.9970606, 'original_width': 991, 'original_height': 431, 'ocr': [{'x': 0, 'y': 15, 'w': 116, 'h': 29, 'confidence': '0.8835063382256515', 'text': 'Java package'}, {'x': 462, 'y': 24, 'w': 56, 'h': 32, 'confidence': '0.9998252391815186', 'text': 'java'}, {'x': 0, 'y': 186, 'w': 106, 'h': 30, 'confidence': '0.9999917442742718', 'text': 'subpackage'}, {'x': 468, 'y': 198, 'w': 46, 'h': 28, 'confidence': '0.9324709664511641', 'text': 'util'}, {'x': 702, 'y': 200, 'w': 52, 'h': 26, 'confidence': '0.999998279362313', 'text': 'awt'}, {'x': 4, 'y': 318, 'w': 66, 'h': 24, 'confidence': '0.6136187545906086', 'text': 'classes'}, {'x': 48, 'y': 384, 'w': 118, 'h': 26, 'confidence': '0.9188202573535862', 'text': 'System class'}, {'x': 306, 'y': 384, 'w': 50, 'h': 24, 'confidence': '0.9999348524671888', 'text': 'class'}, {'x': 436, 'y': 384, 'w': 136, 'h': 26, 'confidence': '0.9931940909306948', 'text': 'ArrayList class'}, {'x': 658, 'y': 383, 'w': 96, 'h': 27, 'confidence': '0.6972174405889399', 'text': 'Map class'}, {'x': 848, 'y': 384, 'w': 114, 'h': 24, 'confidence': '0.9954821491308539', 'text': 'Button class'}, {'x': 207, 'y': 195, 'w': 54, 'h': 38, 'confidence': '0.9973005652427673', 'text': 'lang'}, {'x': 249, 'y': 379, 'w': 56, 'h': 34, 'confidence': '0.9999559074897968', 'text': 'String'}]}]\n",
      "> Image for page 292: []\n",
      "> Image for page 293: []\n",
      "> Image for page 294: []\n",
      "> Image for page 295: []\n",
      "> Image for page 296: []\n",
      "> Image for page 297: []\n",
      "> Image for page 298: []\n",
      "> Image for page 299: []\n",
      "> Image for page 300: []\n",
      "> Image for page 301: []\n",
      "> Image for page 302: []\n",
      "> Image for page 303: []\n",
      "> Image for page 304: []\n",
      "> Image for page 305: []\n",
      "> Image for page 306: []\n",
      "> Image for page 307: []\n",
      "> Image for page 308: []\n",
      "> Image for page 309: []\n",
      "> Image for page 310: []\n",
      "> Image for page 311: []\n",
      "> Image for page 312: []\n",
      "> Image for page 313: []\n",
      "> Image for page 314: []\n",
      "> Image for page 315: []\n",
      "> Image for page 316: []\n",
      "> Image for page 317: []\n",
      "> Image for page 318: []\n",
      "> Image for page 319: []\n",
      "> Image for page 320: []\n",
      "> Image for page 321: []\n",
      "> Image for page 322: []\n",
      "> Image for page 323: []\n",
      "> Image for page 324: []\n",
      "> Image for page 325: []\n",
      "> Image for page 326: []\n",
      "> Image for page 327: []\n",
      "> Image for page 328: []\n",
      "> Image for page 329: []\n",
      "> Image for page 330: []\n",
      "> Image for page 331: [{'name': 'img_p330_1.png', 'height': 392, 'width': 901, 'x': 74.8346252, 'y': 282.2959497, 'original_width': 901, 'original_height': 392, 'ocr': [{'x': 64, 'y': 32, 'w': 74, 'h': 30, 'confidence': '0.9999294281005859', 'text': 'JDBC'}, {'x': 78, 'y': 70, 'w': 48, 'h': 28, 'confidence': '0.9410313535316704', 'text': 'API'}, {'x': 76, 'y': 260, 'w': 56, 'h': 28, 'confidence': '0.9999983310699463', 'text': 'Java'}, {'x': 384, 'y': 276, 'w': 76, 'h': 28, 'confidence': '0.6077877978529922', 'text': 'JDBC'}, {'x': 748, 'y': 282, 'w': 106, 'h': 28, 'confidence': '0.6706610617814358', 'text': 'Database'}, {'x': 37, 'y': 295, 'w': 136, 'h': 36, 'confidence': '0.999989756223804', 'text': 'Application'}, {'x': 386, 'y': 310, 'w': 72, 'h': 28, 'confidence': '0.9999984426560902', 'text': 'driver'}]}]\n",
      "> Image for page 332: []\n",
      "> Image for page 333: []\n",
      "> Image for page 334: []\n",
      "> Image for page 335: []\n",
      "> Image for page 336: []\n",
      "> Image for page 337: []\n",
      "> Image for page 338: []\n",
      "> Image for page 339: []\n",
      "> Image for page 340: []\n",
      "> Image for page 341: []\n",
      "> Image for page 342: []\n",
      "> Image for page 343: []\n",
      "> Image for page 344: []\n",
      "> Image for page 345: []\n",
      "> Image for page 346: []\n",
      "> Image for page 347: []\n",
      "> Image for page 348: []\n",
      "> Image for page 349: []\n",
      "> Image for page 350: []\n",
      "> Image for page 351: []\n",
      "> Image for page 352: []\n",
      "> Image for page 353: []\n",
      "> Image for page 354: [{'name': 'img_p353_1.png', 'height': 648, 'width': 1069, 'x': 54.6746368, 'y': 287.99709110000003, 'original_width': 1069, 'original_height': 648, 'ocr': [{'x': 518, 'y': 33, 'w': 101, 'h': 31, 'confidence': '0.6522028448456749', 'text': 'Company'}, {'x': 204, 'y': 212, 'w': 62, 'h': 24, 'confidence': '0.9999627348195597', 'text': 'Users'}, {'x': 542, 'y': 212, 'w': 86, 'h': 24, 'confidence': '0.9999602145226849', 'text': 'Devices'}, {'x': 860, 'y': 204, 'w': 128, 'h': 30, 'confidence': '0.7133539990425705', 'text': 'Applications'}, {'x': 67, 'y': 467, 'w': 111, 'h': 33, 'confidence': '0.879061425089346', 'text': 'Marketing'}, {'x': 366, 'y': 470, 'w': 90, 'h': 26, 'confidence': '0.9620758026234022', 'text': 'Personal'}]}]\n",
      "> Image for page 355: []\n",
      "> Image for page 356: []\n",
      "> Image for page 357: []\n",
      "> Image for page 358: []\n",
      "> Image for page 359: []\n",
      "> Image for page 360: []\n",
      "> Image for page 361: []\n",
      "> Image for page 362: []\n",
      "> Image for page 363: []\n",
      "> Image for page 364: []\n",
      "> Image for page 365: []\n",
      "> Image for page 366: []\n",
      "> Image for page 367: []\n",
      "> Image for page 368: []\n",
      "> Image for page 369: []\n",
      "> Image for page 370: [{'name': 'img_p369_1.png', 'height': 473, 'width': 826, 'x': 83.8346558, 'y': 376.9970605, 'original_width': 826, 'original_height': 473, 'ocr': [{'x': 343, 'y': 22, 'w': 207, 'h': 43, 'confidence': '0.997716519913186', 'text': 'DBMS language'}, {'x': 54, 'y': 366, 'w': 66, 'h': 30, 'confidence': '0.6955507397651672', 'text': 'DDL'}, {'x': 266, 'y': 378, 'w': 64, 'h': 30, 'confidence': '0.9999825871649118', 'text': 'DCL'}, {'x': 478, 'y': 386, 'w': 72, 'h': 30, 'confidence': '0.999950308143286', 'text': 'DML'}, {'x': 710, 'y': 378, 'w': 60, 'h': 30, 'confidence': '0.9999375066936251', 'text': 'TCL'}]}]\n",
      "> Image for page 371: []\n",
      "> Image for page 372: []\n",
      "> Image for page 373: []\n",
      "> Image for page 374: []\n",
      "> Image for page 375: []\n",
      "> Image for page 376: []\n",
      "> Image for page 377: []\n",
      "> Image for page 378: []\n",
      "> Image for page 379: []\n",
      "> Image for page 380: []\n",
      "> Image for page 381: []\n",
      "> Image for page 382: []\n",
      "> Image for page 383: []\n",
      "> Image for page 384: []\n",
      "> Image for page 385: []\n",
      "> Image for page 386: []\n",
      "> Image for page 387: []\n",
      "> Image for page 388: []\n",
      "> Image for page 389: []\n",
      "> Image for page 390: []\n",
      "> Image for page 391: []\n",
      "> Image for page 392: []\n",
      "> Image for page 393: []\n",
      "> Image for page 394: []\n",
      "> Image for page 395: []\n",
      "> Image for page 396: []\n",
      "> Image for page 397: []\n",
      "> Image for page 398: []\n",
      "> Image for page 399: []\n",
      "> Image for page 400: []\n",
      "> Image for page 401: []\n",
      "> Image for page 402: []\n",
      "> Image for page 403: []\n",
      "> Image for page 404: []\n",
      "> Image for page 405: []\n",
      "> Image for page 406: []\n",
      "> Image for page 407: []\n",
      "> Image for page 408: []\n",
      "> Image for page 409: []\n",
      "> Image for page 410: []\n",
      "> Image for page 411: []\n",
      "> Image for page 412: []\n",
      "> Image for page 413: []\n",
      "> Image for page 414: []\n",
      "> Image for page 415: []\n",
      "> Image for page 416: []\n",
      "> Image for page 417: []\n",
      "> Image for page 418: []\n",
      "> Image for page 419: []\n",
      "> Image for page 420: []\n",
      "> Image for page 421: []\n",
      "> Image for page 422: []\n",
      "> Image for page 423: []\n",
      "> Image for page 424: []\n",
      "> Image for page 425: []\n",
      "> Image for page 426: []\n",
      "> Image for page 427: []\n",
      "> Image for page 428: []\n",
      "> Image for page 429: []\n",
      "> Image for page 430: []\n",
      "> Image for page 431: []\n",
      "> Image for page 432: []\n",
      "> Image for page 433: []\n",
      "> Image for page 434: []\n",
      "> Image for page 435: []\n",
      "> Image for page 436: []\n",
      "> Image for page 437: []\n",
      "> Image for page 438: []\n",
      "> Image for page 439: []\n",
      "> Image for page 440: []\n",
      "> Image for page 441: []\n",
      "> Image for page 442: []\n",
      "> Image for page 443: []\n",
      "> Image for page 444: []\n",
      "> Image for page 445: []\n",
      "> Image for page 446: []\n",
      "> Image for page 447: []\n",
      "> Image for page 448: []\n",
      "> Image for page 449: []\n",
      "> Image for page 450: []\n",
      "> Image for page 451: []\n",
      "> Image for page 452: []\n",
      "> Image for page 453: []\n",
      "> Image for page 454: []\n",
      "> Image for page 455: []\n",
      "> Image for page 456: []\n",
      "> Image for page 457: []\n",
      "> Image for page 458: []\n",
      "> Image for page 459: []\n",
      "> Image for page 460: []\n",
      "> Image for page 461: []\n",
      "> Image for page 462: []\n",
      "> Image for page 463: []\n",
      "> Image for page 464: []\n",
      "> Image for page 465: []\n",
      "> Image for page 466: []\n",
      "> Image for page 467: []\n",
      "> Image for page 468: []\n",
      "> Image for page 469: [{'name': 'page_469.jpg', 'height': 561.26, 'width': 365.669, 'x': 0, 'y': 0, 'type': 'full_page_screenshot', 'ocr': [{'x': 338, 'y': 718, 'w': 584, 'h': 102, 'confidence': '0.9671692745181713', 'text': 'Taylor & Francis'}, {'x': 341, 'y': 807, 'w': 430, 'h': 62, 'confidence': '0.8117147014503838', 'text': 'Taylor & Francis Group'}, {'x': 343, 'y': 865, 'w': 356, 'h': 44, 'confidence': '0.7718617644330281', 'text': 'http:/ /taylorandfranciscom'}]}]\n",
      "> Image for page 470: []\n",
      "> Image for page 471: []\n",
      "> Image for page 472: []\n",
      "> Image for page 473: []\n",
      "> Image for page 474: []\n",
      "> Image for page 475: []\n",
      "> Image for page 476: []\n",
      "> Image for page 477: []\n",
      "> Image for page 478: []\n",
      "> Image for page 479: []\n",
      "> Image for page 480: []\n",
      "> Image for page 481: []\n",
      "> Image for page 482: []\n",
      "> Image for page 483: []\n",
      "> Image for page 484: []\n",
      "> Image for page 485: []\n",
      "> Image for page 486: []\n",
      "> Image for page 487: []\n",
      "> Image for page 488: []\n",
      "> Image for page 489: []\n",
      "> Image for page 490: []\n",
      "> Image for page 491: []\n",
      "> Image for page 492: []\n",
      "> Image for page 493: [{'name': 'page_493.jpg', 'height': 561.26, 'width': 365.669, 'x': 0, 'y': 0, 'type': 'full_page_screenshot', 'ocr': [{'x': 338, 'y': 718, 'w': 584, 'h': 102, 'confidence': '0.9671692745181713', 'text': 'Taylor & Francis'}, {'x': 341, 'y': 807, 'w': 430, 'h': 62, 'confidence': '0.8117147014503838', 'text': 'Taylor & Francis Group'}, {'x': 343, 'y': 865, 'w': 356, 'h': 44, 'confidence': '0.7718617644330281', 'text': 'http:/ /taylorandfranciscom'}]}]\n",
      "> Image for page 494: []\n",
      "> Image for page 495: []\n",
      "> Image for page 496: []\n",
      "> Image for page 497: []\n",
      "> Image for page 498: []\n",
      "> Image for page 499: []\n",
      "> Image for page 500: []\n",
      "> Image for page 501: []\n",
      "> Image for page 502: []\n",
      "> Image for page 503: []\n",
      "> Image for page 504: []\n",
      "> Image for page 505: []\n",
      "> Image for page 506: []\n",
      "> Image for page 507: []\n",
      "> Image for page 508: []\n",
      "> Image for page 509: []\n",
      "> Image for page 510: []\n",
      "> Image for page 511: []\n",
      "> Image for page 512: []\n",
      "> Image for page 513: []\n",
      "> Image for page 514: []\n",
      "> Image for page 515: []\n",
      "> Image for page 516: []\n",
      "> Image for page 517: []\n",
      "> Image for page 518: []\n"
     ]
    }
   ],
   "source": [
    "def get_image_nodes(json_objs: List[dict], download_path: str) -> List[ImageDocument]:\n",
    "    image_dicts = parser.get_images(json_objs, download_path=download_path)\n",
    "    return [ImageDocument(image_path=image_dict[\"path\"]) for image_dict in image_dicts]\n",
    "\n",
    "image_documents = get_image_nodes(json_objs, \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74    Mastering Java\n",
      "\n",
      "   1. Break statement:       As its name implies, the break\n",
      "      statement is used to interrupt the programs current\n",
      "      flow and transfer control to the following state-\n",
      "      ment outside of a loop or switch statement. In the\n",
      "      event of a nested loop, however, it just breaks the\n",
      "      inner loop.\n",
      "         In a Java program, the break statement cannot be\n",
      "      used on its own; it must be put inside a loop or switch\n",
      "      statement.\n",
      "\n",
      "      Example:\n",
      "      public class breakex\n",
      "      {\n",
      "      public static void main(String[] args)\n",
      "      {\n",
      "      // Auto-generated method\n",
      "      for(int c = 0; c<= 10; c++)\n",
      "      {\n",
      "      System.out.println(c);\n",
      "      if(c==8)\n",
      "      {\n",
      "      break;\n",
      "      }\n",
      "      }\n",
      "      }\n",
      "      }\n",
      "\n",
      "      Output:\n",
      "      0\n",
      "      1\n",
      "      2\n",
      "      3\n",
      "      4\n"
     ]
    }
   ],
   "source": [
    "print(text_nodes[100].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_format'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m openai_mm_llm \u001b[38;5;241m=\u001b[39m OpenAIMultiModal(\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTERTIARY_INFOTECH_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m), max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_mm_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow does the image relate to the text: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtext_nodes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:431\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[1;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    422\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[0;32m    423\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    424\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    428\u001b[0m     },\n\u001b[0;32m    429\u001b[0m )\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    433\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[0;32m    434\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    435\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[0;32m    436\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[0;32m    437\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\multi_modal_llms\\openai\\base.py:344\u001b[0m, in \u001b[0;36mOpenAIMultiModal.complete\u001b[1;34m(self, prompt, image_documents, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, image_documents: Sequence[ImageNode], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    343\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:431\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[1;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    422\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[0;32m    423\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    424\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    428\u001b[0m     },\n\u001b[0;32m    429\u001b[0m )\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    433\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[0;32m    434\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    435\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[0;32m    436\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[0;32m    437\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\llama_index\\multi_modal_llms\\openai\\base.py:220\u001b[0m, in \u001b[0;36mOpenAIMultiModal._complete\u001b[1;34m(self, prompt, image_documents, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m all_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m message_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_multi_modal_chat_messages(\n\u001b[0;32m    218\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt, role\u001b[38;5;241m=\u001b[39mMessageRole\u001b[38;5;241m.\u001b[39mUSER, image_documents\u001b[38;5;241m=\u001b[39mimage_documents\n\u001b[0;32m    219\u001b[0m )\n\u001b[1;32m--> 220\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletionResponse(\n\u001b[0;32m    227\u001b[0m     text\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[0;32m    228\u001b[0m     raw\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[0;32m    229\u001b[0m     additional_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_response_token_counts(response),\n\u001b[0;32m    230\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:668\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    667\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\openai\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1050\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_format'}}"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "\n",
    "openai_mm_llm = OpenAIMultiModal(\n",
    "    model=\"gpt-4o-mini\", api_key=os.getenv(\"TERTIARY_INFOTECH_API_KEY\"), max_new_tokens=300\n",
    ")\n",
    "\n",
    "# Generate response\n",
    "response = openai_mm_llm.complete(\n",
    "    prompt=f\"How does the image relate to the text: '{text_nodes[100].text}'?\",\n",
    "    image_documents=image_documents,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='df5fc6b2-a391-43fc-81b3-705e90120e80', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='```\\nSpeech and Language Processing\\nAn Introduction to Natural Language Processing,\\nComputational Linguistics, and Speech Recognition\\n\\nThird Edition draft\\n\\nDaniel Jurafsky\\nStanford University\\n\\nJames H. Martin\\nUniversity of Colorado at Boulder\\n\\nCopyright 2023. All rights reserved.\\n\\nDraft of January 7, 2023. Comments and typos welcome!\\n```', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = await parser.aload_data(\"docs/nlp_textbook-1-100.pdf\")\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "\n",
    "def get_page_nodes(docs, separator=\"\\n---\\n\"):\n",
    "    \"\"\"Split each document into page node, by separator.\"\"\"\n",
    "    nodes = []\n",
    "    for doc in docs:\n",
    "        doc_chunks = doc.text.split(separator)\n",
    "        for doc_chunk in doc_chunks:\n",
    "            node = TextNode(\n",
    "                text=doc_chunk,\n",
    "                metadata=deepcopy(doc.metadata),\n",
    "            )\n",
    "            nodes.append(node)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_nodes = get_page_nodes(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 6cbf64e5-59fa-49bb-aa24-f8763b919126\n",
      "Text: ``` Speech and Language Processing An Introduction to Natural\n",
      "Language Processing, Computational Linguistics, and Speech Recognition\n",
      "Third Edition draft  Daniel Jurafsky Stanford University  James H.\n",
      "Martin University of Colorado at Boulder  Copyright 2023. All rights\n",
      "reserved.  Draft of January 7, 2023. Comments and typos welcome! ```\n",
      "Node ID: 3b8568ee-3156-47f1-9566-96a2121ea591\n",
      "Text: ```markdown # Summary of Contents  ## I Fundamental Algorithms\n",
      "for NLP 1. Introduction ..............................................\n",
      "................................... 3 2. Regular Expressions, Text\n",
      "Normalization, Edit Distance .......... 4 3. N-gram Language Models\n",
      ".......................................................... 31 4. Naive\n",
      "Bayes, T...\n",
      "Node ID: 24bdb408-c235-4170-adf6-4770e08110fc\n",
      "Text: ```markdown # Contents  I    Fundamental Algorithms for NLP\n",
      "1 1    Introduction\n",
      "3 2    Regular Expressions, Text Normalization, Edit Distance\n",
      "4 2.1      Reg...\n",
      "Node ID: d13e82ca-e749-4635-89a0-c3cd14b1e920\n",
      "Text: ```markdown 4  CONTENTS  5.7       Regularization . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . .                    97 5.8\n",
      "Learning in Multinomial Logistic Regression . . . . . . . . . . . .\n",
      "98 5.9       Interpreting models . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . .                     99 5.10      Adv...\n",
      "Node ID: fafd52b2-7ca1-4333-9b43-4cce20a6e159\n",
      "Text: ```markdown # CONTENTS  9.4 Stacked and Bidirectional RNN\n",
      "architectures . . . . . . . . . . . . 195 9.5 The LSTM . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . 198 9.6 Summary: Common\n",
      "RNN NLP Architectures . . . . . . . . . . . 201 9.7 The Encoder-\n",
      "Decoder Model with RNNs . . . . . . . . . . . . . . 201 9.8 Attention\n",
      ". . . . . . . . ...\n",
      "Node ID: e3b1998a-ce54-4326-8864-344261cecfbf\n",
      "Text: ```markdown 6  CONTENTS  15 Chatbots & Dialogue Systems\n",
      "296 15.1     Properties of Human Conversation . . . . . . . . . . . .\n",
      ". . . . . 297 15.2     Chatbots . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . 300 15.3     GUS: Simple Frame-based Dialogue\n",
      "Systems ...\n",
      "Node ID: 0322c8d3-1b37-4565-92b3-57458b3b6c96\n",
      "Text: ```markdown # CONTENTS  19.5     Description Logics . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . 419 19.6     Summary . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . 425\n",
      "Bibliographical and Historical Notes . . . . . . . . . . . . . . . . .\n",
      ". . . 425 Exercises      . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . ...\n",
      "Node ID: d926600f-fe0a-45aa-8885-f7c11abeda18\n",
      "Text: ```markdown 8  CONTENTS  25.2     Available Sentiment and Affect\n",
      "Lexicons . . . . . . . . . . . . . . 499 25.3     Creating Affect\n",
      "Lexicons by Human Labeling . . . . . . . . . . . 500 25.4     Semi-\n",
      "supervised Induction of Affect Lexicons . . . . . . . . . . . 502 25.5\n",
      "Supervised Learning of Word Sentiment . . . . . . . . . . . . . . 505\n",
      "25.6...\n",
      "Node ID: 1c3794c3-6b2f-4177-a63b-e7c9eaca1fa0\n",
      "Text: The text provided does not contain any code or math equations to\n",
      "format. If you have specific content that includes code or equations,\n",
      "please share that, and I can help format it accordingly.\n",
      "Node ID: caaab354-150c-4fd1-9516-9804c07cb99a\n",
      "Text: It seems that there is no content available on the current page.\n",
      "If you have any specific text, code, or equations you'd like to share\n",
      "or inquire about, please provide that information, and I'll be happy\n",
      "to assist you!\n",
      "Node ID: 211d6bcb-b778-420b-a5d7-258f8bb23074\n",
      "Text: ```markdown # CHAPTER  ## Introduction  La dernire chose quon\n",
      "trouve en faisant un ouvrage est de savoir celle quil fautere. [The\n",
      "last thing you figure out in writing a book is what to put first.]\n",
      "Pascal ```\n",
      "Node ID: fb222b46-b259-427d-8a64-ee411b5908db\n",
      "Text: ```plaintext CHAPTER 2  REGULAR EXPRESSIONS, TEXT\n",
      "NORMALIZATION, EDIT DISTANCE  CHAPTER  Regular Expressions, Text\n",
      "Normalization, Edit Distance  User:  I am unhappy. ELIZA: DO YOU THINK\n",
      "COMING HERE WILL HELP YOU NOT TO BE UNHAPPY User:                I\n",
      "need some help, that much seems certain. ELIZA: WHAT WOULD IT MEAN TO\n",
      "YOU IF YOU GOT SOME HEL...\n",
      "Node ID: 927aae0f-5302-44d1-a0d7-09dd94d67bdc\n",
      "Text: ```markdown 2.1        REGULAR EXPRESSIONS  Some languages,\n",
      "like Japanese, dont have spaces between words, so word tokenization\n",
      "becomes more difficult.  **lemmatization**: Another part of text\n",
      "normalization is lemmatization, the task of determining that two words\n",
      "have the same root, despite their surface differences. For example,\n",
      "the words san...\n",
      "Node ID: c40e4439-0e86-42b1-8cc4-ea3a2a1ba873\n",
      "Text: ```markdown # CHAPTER 2  REGULAR EXPRESSIONS, TEXT\n",
      "NORMALIZATION, EDIT DISTANCE  ## Regex\n",
      "Example Patterns Matched - /woodchucks/\n",
      "interesting links to woodchucks and lemurs - /a/\n",
      "Mary Ann stopped by Monas - /!/                         ...\n",
      "Node ID: 9dbac338-d250-4f0a-8337-351a1c41829c\n",
      "Text: ```regex /woodchucks?/ ``` ```regex /colou?r/ ``` ```regex /a*/\n",
      "``` ```regex /aa*/ ``` ```regex /[ab]*/ ``` ```regex /[0-9][0-9]*/ ```\n",
      "```regex /[0-9]+/ ``` ```regex /baaa*!/ ``` ```regex /baa+!/ ```\n",
      "```regex /beg.n/ ``` ```regex /aardvark.*aardvark/ ```\n",
      "Node ID: 21ef6c2d-d7c8-40d8-a54b-24b327c9d713\n",
      "Text: ```regex /The/ ```  ```regex $ ```  ```regex /\\bthe\\b/ ```\n",
      "```regex /cat|dog/ ```  ```regex /gupp(y|ies)/ ```  ```regex /Column\n",
      "[0-9]+ */ ```\n",
      "Node ID: 5c757b65-1b81-40d5-89cc-36468883551a\n",
      "Text: ```regex /(Column [0-9]+ *)*/ ```  ```regex /the/ ```  ```regex\n",
      "/[tT]he/ ```  ```regex /\\b[tT]he\\b/ ```  ```regex /[a-zA-Z][tT]he[a-\n",
      "zA-Z]/ ```\n",
      "Node ID: 4fa8bf0d-2447-428e-a990-fc6fe3f59515\n",
      "Text: ```regex /(|[a-zA-Z])[tT]he([a-zA-Z]|$)/ ```  ```regex /{3}/\n",
      "```  ```regex /a\\.{24}z/ ```  ```regex \\d ```  ```regex \\D ```\n",
      "```regex \\w ```  ```regex \\W ```  ```regex \\s ```  ```regex \\S ```\n",
      "```regex {n,m} ```  ```regex {n,} ```  ```regex {,m} ```  ```regex *\n",
      "```  ```regex + ```  ```regex ? ```  ```regex {n} ```  ```regex {n,m}\n",
      "```  ```rege...\n",
      "Node ID: 6c076b50-1f41-4394-91ca-d70a6e4c52bf\n",
      "Text: ```regex /$[0-9]+/ ```  ```regex /$[0-9]+\\.[0-9][0-9]/ ```\n",
      "```regex /(|\\W)$[0-9]+(\\.[0-9][0-9])?\\b/ ```  ```regex\n",
      "/(|\\W)$[0-9]{0,3}(\\.[0-9][0-9])?\\b/ ```  ```regex\n",
      "/\\b[0-9]+(\\.[0-9]+)? *(GB|[Gg]igabytes?)\\b/ ```\n",
      "Node ID: 17707128-51be-44d3-9cdf-9df864feed57\n",
      "Text: ```python # Example of substitution in Python import re  #\n",
      "Substituting 'colour' with 'color' text = \"The colour of the sky is\n",
      "blue.\" result = re.sub(r'colour', 'color', text) print(result)  #\n",
      "Output: The color of the sky is blue.  # Putting angle brackets around\n",
      "integers text_with_numbers = \"There are 35 boxes.\"\n",
      "result_with_brackets = re.sub(r'...\n",
      "Node ID: 292b18a0-bdcd-44b9-a1ae-14a74c83620a\n",
      "Text: ```regex s/.* IM (depressed|sad) .*/I AM SORRY TO HEAR YOU ARE\n",
      "\\1/ s/.* I AM (depressed|sad) .*/WHY DO YOU THINK YOU ARE \\1/ s/.* all\n",
      ".*/IN WHAT WAY/ s/.* always .*/CAN YOU THINK OF A SPECIFIC EXAMPLE/\n",
      "```  ```regex /(?!Volcano)[A-Za-z]+/ ```  The Brown corpus is a\n",
      "million-word collection of samples from 500 written English texts from\n",
      "differen...\n",
      "Node ID: 168a82a0-a847-4b8d-804b-3e5c0ec20962\n",
      "Text: ```latex |V| = kN^\\beta \\quad (2.1) ```\n",
      "Node ID: bf58a0ee-ffdc-44ff-adeb-2c488e276e85\n",
      "Text: ```markdown | Corpus\n",
      "| Tokens = N       | Types = |V |         | |-------------------------\n",
      "-------------------------------------------|------------------|-------\n",
      "--|-----------| | Shakespeare\n",
      "| 884 thousand      | 31 thousand | | Bro...\n",
      "Node ID: 88c3cf92-7a06-4d89-a73d-9583700358df\n",
      "Text: ```markdown (2.2) Por primera vez veo a @username actually being\n",
      "hateful! it was beautiful:) [For the first time I get to see @username\n",
      "actually being hateful! it was beautiful:) ] (2.3) dost tha or ra-\n",
      "hega ... dont wory ... but dherya rakhe [he was and will remain a\n",
      "friend ... dont worry ... but have faith] ```  ### Text\n",
      "Normalization Befor...\n",
      "Node ID: 51f1a9a2-fe10-4be0-91be-6e6d8fd9b940\n",
      "Text: ```bash tr -sc 'A-Za-z' '\\n' < sh.txt ```  ```bash tr -sc\n",
      "'A-Za-z' '\\n' < sh.txt | sort | uniq -c ```  ```bash tr -sc 'A-Za-z'\n",
      "'\\n' < sh.txt | tr A-Z a-z | sort | uniq -c ```\n",
      "Node ID: 50f79a4a-1f41-4b2c-b2c8-08a55182899f\n",
      "Text: ```bash tr -sc 'A-Za-z' '\\n' < sh.txt | tr A-Z a-z | sort | uniq\n",
      "-c | sort -n -r ```\n",
      "Node ID: 03404cb6-6e48-477f-b8e4-c41759c69a10\n",
      "Text: ```python text = 'That U.S.A. poster-print costs $12.40...'\n",
      "pattern = r'''(?x)                 # set flag to allow verbose regexps\n",
      "(?:[A-Z]\\.)+                  # abbreviations, e.g. U.S.A. |\n",
      "\\w+?:(-\\w+)*                   # words with optional internal hyphens\n",
      "| \\$?\\d+(?:\\.\\d+)?%? # currency, percentages, e.g. $12.40, 82% |\n",
      "\\.\\.\\.              ...\n",
      "Node ID: e7594eb0-40ea-4b1a-89be-e910b1ce9e26\n",
      "Text: ```markdown 2.4.3 Byte-Pair Encoding for Tokenization  There is\n",
      "a third option to tokenizing text. Instead of defining tokens as words\n",
      "(whether delimited by spaces or more complex algorithms), or as\n",
      "characters (as in Chinese), we can use our data to automatically tell\n",
      "us what the tokens should be. This is especially useful in dealing\n",
      "with unknow...\n",
      "Node ID: 658266a1-2a82-4a9a-af12-1da3f233630c\n",
      "Text: ```markdown Most tokenization schemes have two parts: a token\n",
      "learner, and a token segmenter. The token learner takes a raw training\n",
      "corpus (sometimes roughly pre-separated into words, for example by\n",
      "whitespace) and induces a vocabulary, a set of tokens. The token\n",
      "segmenter takes a raw test sentence and segments it into the tokens in\n",
      "the vocabul...\n",
      "Node ID: f3a370ff-d6cf-423b-a093-fa69ab02f801\n",
      "Text: ```plaintext function BYTE-PAIR ENCODING(strings C, number of\n",
      "merges k) returns vocab V V  all unique characters in C\n",
      "# initial set of tokens is characters for i = 1 to k do\n",
      "# merge tokens k times tL, tR  Most frequent pair of adjacent tokens\n",
      "in C tNEW  tL + tR                               # mak...\n",
      "Node ID: b599d98d-2001-410f-b2fe-bd771f92486e\n",
      "Text: ```markdown 2.4  TEXT NORMALIZATION  Extraction about the US,\n",
      "we might want to see information from documents whether they mention\n",
      "the US or the USA.  **Case Folding** Case folding is another kind of\n",
      "normalization. Mapping everything to lower case means that Woodchuck\n",
      "and woodchuck are represented identically, which is very helpful for\n",
      "generali...\n",
      "Node ID: eca83a5d-148c-4264-9d64-af8314908b90\n",
      "Text: ```markdown The algorithm is based on series of rewrite rules\n",
      "run in series: the output of each pass is fed as input to the next\n",
      "pass. Here are some sample rules (more details can be found at\n",
      "https://tartarus.org/martin/PorterStemmer/):  ATIONAL  ATE (e.g.,\n",
      "relational  relate) ING              if the stem contains a vowel\n",
      "(e.g., motoring  mo...\n",
      "Node ID: 8fe8bf23-4aa5-4c83-9e1b-15c5309a9a71\n",
      "Text: ```markdown # Minimum Edit Distance  The minimum edit distance\n",
      "between two strings is defined as the minimum number of editing\n",
      "operations (operations like insertion, deletion, substitution) needed\n",
      "to transform one string into another.  For example, the gap between\n",
      "\"intention\" and \"execution\" is 5, which can be achieved through the\n",
      "following oper...\n",
      "Node ID: d340ae23-758d-41ec-8d09-9af338347919\n",
      "Text: ```latex D[i, j] = \\min \\left\\{ D[i - 1, j] + \\text{del-\n",
      "cost}(source[i]), D[i, j - 1] + \\text{ins-cost}(target[j]), D[i - 1, j\n",
      "- 1] + \\text{sub-cost}(source[i], target[j]) \\right\\} \\tag{2.8} ```\n",
      "Node ID: 52cfa648-a9d6-4960-8f0e-6f9a8ca6b42f\n",
      "Text: ```markdown If we assume the version of Levenshtein distance in\n",
      "which the insertions and deletions each have a cost of 1 (ins-cost()\n",
      "= del-cost() = 1), and substitutions have a cost of 2 (except\n",
      "substitution of identical letters have zero cost), the computation for\n",
      "\\( D[i, j] \\) becomes:  $$ D[i, j] = \\begin{cases} D[i - 1, j] + 1 &\n",
      "\\text{if }...\n",
      "Node ID: f92aaffe-6265-4ca9-96fb-ab42eb539b9c\n",
      "Text: ```plaintext 28   CHAPTER 2          REGULAR EXPRESSIONS, TEXT\n",
      "NORMALIZATION, EDIT DISTANCE  Src\\Tar         #       e       x\n",
      "e         c        u         t         i       o         n #       0\n",
      "1       2        3         4         5        6         7         8\n",
      "9 i      1       2       3        4         5         6      ...\n",
      "Node ID: 2c2be4d4-8ca9-4bc8-b15f-56ac908bb01a\n",
      "Text: ```markdown 2.6        SUMMARY  29  each other on the keyboard.\n",
      "The Viterbi algorithm is a probabilistic extension of minimum edit\n",
      "distance. Instead of computing the minimum edit distance between two\n",
      "strings, Viterbi computes the maximum probability alignment of one\n",
      "string with another. Well discuss this more in Chapter 8.  2.6\n",
      "Su...\n",
      "Node ID: 5291f902-da4d-4789-bbbc-2a2e83f2ebd9\n",
      "Text: ```markdown Exercises 2.1 Write regular expressions for the\n",
      "following languages. 1. the set of all alphabetic strings; 2. the set\n",
      "of all lower case alphabetic strings ending in a b; 3. the set of all\n",
      "strings from the alphabet a, b such that each a is immediately\n",
      "preceded by and immediately followed by a b;  2.2 Write regular\n",
      "expressions for the ...\n",
      "Node ID: 618e5880-41b2-452a-9f34-2aefe9be5a45\n",
      "Text: ```markdown CHAPTER  N-gram Language Models 3\n",
      "You are uniformly charming! cried he, with a smile of associating\n",
      "and now and then I bowed and they perceived a chaise and four to wish\n",
      "for. Random sentence generated from a Jane Austen trigram model\n",
      "Predicting is difficultespecially about the future, as the old quip\n",
      "goes. But how ...\n",
      "Node ID: d2cdd77a-c7ab-4e50-b977-24016fff94c9\n",
      "Text: ```markdown P(the|its water is so transparent that) =\n",
      "\\frac{C(its\\ water\\ is\\ so\\ transparent\\ that\\ the)}{C(its\\ water\\ is\\\n",
      "so\\ transparent\\ that)} \\tag{3.2} ```\n",
      "Node ID: 44cbb1b7-d209-4fd2-a0e5-c089d8271098\n",
      "Text: ```markdown P(X1...Xn) = P(X1)P(X2|X1)P(X3|X1:2) . . .\n",
      "P(Xn|X1:n1) P(Xk|X1:k1)n =\n",
      "(3.3)  P(w1:n) = P(w1)P(w2|w1)P(w3|w1:2) . . . P(wn|w1:n1)\n",
      "P(wk|w1:k1)n =\n",
      "(3.4) ```  $$ P(X1...Xn) = P(X1)P(X2|X1)P(X3|X1:2) \\ldots P(...\n",
      "Node ID: 4d6b9fa8-c59c-47b1-abfa-23aff2cb64d6\n",
      "Text: ```markdown When we use a bigram model to predict the\n",
      "conditional probability of the next word, we are thus making the\n",
      "following approximation:  $$ P(wn|w1:n1) \\approx P(wn|wn1) \\quad\n",
      "(3.7) $$  The assumption that the probability of a word depends only\n",
      "on the previous word is called a Markov assumption. Markov models are\n",
      "the class of probabili...\n",
      "Node ID: e9cf98c2-1206-4358-8647-cff337975f6a\n",
      "Text: Here are the calculations for some of the bigram probabilities\n",
      "from this corpus:  $$ P(I|) = \\frac{32}{48} = 0.67 \\quad P(Sam|) =\n",
      "\\frac{31}{48} = 0.33 \\quad P(am|I) = \\frac{32}{48} = 0.67 $$  $$\n",
      "P(|Sam) = \\frac{2}{4} = 0.51 \\quad P(Sam|am) = \\frac{2}{4} = 0.51\n",
      "\\quad P(do|I) = \\frac{3}{9} = 0.33 $$  For the general case of MLE\n",
      "n-gram parameter es...\n",
      "Node ID: eb7fb140-a464-426b-bea7-6d42697a0631\n",
      "Text: ```markdown P( i want english food ) =\n",
      "P(i|)P(want|i)P(english|want)P(food|english)P(|food) = 0.25  0.33 \n",
      "0.0011  0.5  0.68 = 0.000031 ```  $$ P( i want english food ) =\n",
      "P(i|)P(want|i)P(english|want)P(food|english)P(|food) = 0.25 \\times\n",
      "0.33 \\times 0.0011 \\times 0.5 \\times 0.68 = 0.000031 $$\n",
      "Node ID: c3935228-0c80-4b1c-a59b-72854f84e2ed\n",
      "Text: ```latex p_1 \\times p_2 \\times p_3 \\times p_4 = \\exp(\\log p_1 +\n",
      "\\log p_2 + \\log p_3 + \\log p_4) \\tag{3.13} ```\n",
      "Node ID: b304b6af-5351-4c81-b8fa-22317c0934b7\n",
      "Text: ```latex \\text{perplexity}(W) = P(w_1 w_2 \\ldots w_N)^{-1/N}\n",
      "\\tag{3.14} ```  ```latex \\text{perplexity}(W) = \\sqrt{\\prod_{i=1}^{N}\n",
      "P(w|w_1 \\ldots w_{i-1})} \\sqrt{N} \\tag{3.15} ```  ```latex\n",
      "\\text{perplexity}(W) = \\sqrt{\\prod_{i=1}^{N} P(w)} \\sqrt{N} \\tag{3.16}\n",
      "```  ```latex \\text{perplexity}(W) = \\sqrt{\\prod_{i=1}^{N}\n",
      "P(w|w_{i-1})} \\sqrt{N} \\tag...\n",
      "Node ID: 4b0fdc35-6206-4e70-a0f1-647d26c07b62\n",
      "Text: ```latex \\text{perplexity}(W) = P(w_1 w_2 \\ldots\n",
      "w_N)^{-\\frac{1}{N}} = (10^{-1})^{-\\frac{1}{N}} = \\frac{1}{10} = 10\n",
      "\\tag{3.18} ```  |                | Unigram | Bigram | Trigram |\n",
      "|----------------|---------|--------|---------| | Perplexity     | 962\n",
      "| 170    | 109     |\n",
      "Node ID: 49c58c16-d784-4afb-b45a-650763e22aff\n",
      "Text: ```markdown 3.3 Sampling sentences from a language model One\n",
      "important way to visualize what kind of knowledge a language model\n",
      "embodies is to sample from it. Sampling from a distribution means to\n",
      "choose random points according to their likelihood. Thus sampling from\n",
      "a language modelwhich represents a distribution over sentencesmeans\n",
      "to genera...\n",
      "Node ID: ebb178b9-8036-4509-9aec-792b66cc2e56\n",
      "Text: ```markdown Figure 3.4      Eight sentences randomly generated\n",
      "from four n-grams computed from Shakespeares works. All characters\n",
      "were mapped to lower-case and punctuation marks were treated as words.\n",
      "Output is hand-corrected for capitalization to improve readability.\n",
      "The longer the context on which we train the model, the more coherent\n",
      "the se...\n",
      "Node ID: 239a53d7-1375-49aa-b936-3efdbc2e840d\n",
      "Text: ```markdown Months the my and issue of year foreign new\n",
      "exchanges september 1 gram        were recession exchange new\n",
      "endorsed a acquire to six executives Last December through the way to\n",
      "preserve the Hudson corporation N. 2           B. E. C. Taylor would\n",
      "seem to complete the major central planners one gram        point five\n",
      "percent of U. S. E...\n",
      "Node ID: e426216d-0df2-47cc-8696-0034bb1773db\n",
      "Text: ```markdown 3.5        SMOOTHING  43  test set. Thus if some\n",
      "words have zero probability, we cant compute perplexity at all, since\n",
      "we cant divide by 0! What do we do about zeros? There are two\n",
      "solutions, depending on the kind of zero. For words whose n-gram\n",
      "probability is zero because they occur in a novel test set context,\n",
      "like the example o...\n",
      "Node ID: 787c5e32-ff06-44f1-b61f-ce03c8c4a24d\n",
      "Text: ```markdown $$ P(w) = \\frac{c_i}{N} $$ $$ P_{Laplace}(w) =\n",
      "\\frac{c_i + 1}{N + V} \\quad (3.21) $$ $$ c_i^* = (c_i + 1) \\frac{N}{N\n",
      "+ V} \\quad (3.22) $$ $$ d = \\frac{c^*}{c} $$ ```\n",
      "Node ID: 77afcfd9-3d66-479f-900a-a84e041a87bf\n",
      "Text: ```markdown $$ P(wn|wn1) = \\frac{C(wn1wn)}{C(wn1)} \\tag{3.23}\n",
      "$$  $$ P_{Laplace}(wn|wn1) = \\frac{\\sum C(wn1wn) + 1}{C(wn1) + V} =\n",
      "\\frac{C(wn1wn) + 1}{C(wn1) + V} \\tag{3.24} $$  $$ c^*(wn1wn) =\n",
      "\\frac{[C(wn1wn) + 1] \\times C(wn1)}{C(wn1) + V} \\tag{3.25} $$ ```\n",
      "Node ID: 558ad0d5-6c6e-4c09-9303-d42758d687bf\n",
      "Text: ```plaintext 46     CHAPTER 3           N-GRAM LANGUAGE MODELS\n",
      "i         want       to          eat         chinese       food\n",
      "lunch    spend i              3.8       527        0.64        6.4\n",
      "0.64          0.64       0.64     1.9 want           1.2       0.39\n",
      "238         0.78        2.7           2.7        2.3      0.78 ...\n",
      "Node ID: 5932dba4-db5f-4f2e-973e-53bb5b9691c3\n",
      "Text: ```latex \\hat{P}(w_n|w_{n-2}w_{n-1}) = \\lambda_1 P(w_n) +\n",
      "\\lambda_2 P(w_n|w_{n-1}) + \\lambda_3 P(w_n|w_{n-2}w_{n-1}) \\tag{3.27}\n",
      "```  ```latex \\sum \\lambda_i = 1 \\tag{3.28} ```  ```latex\n",
      "\\hat{P}(w_n|w_{n-2}w_{n-1}) = \\lambda_1(w_{n-2:n-1}) P(w_n) +\n",
      "\\lambda_2(w_{n-2:n-1}) P(w_n|w_{n-1}) + \\lambda_3(w_{n-2:n-1})\n",
      "P(w_n|w_{n-2}w_{n-1}) \\tag{3.29} ```...\n",
      "Node ID: 982f9371-cf5d-4041-91d2-40b4f0a6c5dd\n",
      "Text: ```markdown Good-Turing           Katz backoff is often combined\n",
      "with a smoothing method called Good-Turing. The combined Good-Turing\n",
      "backoff algorithm involves quite detailed computation for estimating\n",
      "the Good-Turing smoothing and the P and  values.  3.6         Huge\n",
      "Language Models and Stupid Backoff By using text from the web or other\n",
      "enor...\n",
      "Node ID: a9760869-4cee-4c31-abeb-b03b83bbab13\n",
      "Text: ```latex S(w_i|w_{i-N+1} : w_{i-1}) = \\begin{cases}\n",
      "\\text{count}(w_{i-N+1} : w_i) & \\text{if } \\text{count}(w_{i-N+1} :\n",
      "w_i) > 0 \\\\ \\lambda S(w|w_{i-N+2} : w_{i-1}) & \\text{otherwise}\n",
      "\\end{cases} ```  ```plaintext Bigram count in            Bigram count\n",
      "in training set         heldout set 0      0.0000270 1      0.448 2\n",
      "1.25 3      2.24 4  ...\n",
      "Node ID: 732bb4e3-779e-4d2e-bb3a-3313a70ac6ac\n",
      "Text: ```markdown P_{\\text{AbsoluteDiscounting}}(w|w_{i-1}) =\n",
      "C(w_{i-1}w_{i}) - d + \\lambda(w_{i-1})P(w) \\sum_{v}\n",
      "\\frac{C(w_{i-1}v)}{C(w_{i-1}v)} \\tag{3.32} ```  ```markdown d =\n",
      "\\frac{n_1}{n_1 + 2n_2} \\tag{3.33} ```  ```markdown\n",
      "P_{\\text{CONTINUATION}}(w) \\propto |\\{v : C(vw) > 0\\}| \\tag{3.34} ```\n",
      "```markdown P_{\\text{CONTINUATION}}(w) = \\frac{|\\{v :...\n",
      "Node ID: 92560fb7-5f63-4485-a64e-c00fb0b2c139\n",
      "Text: ```latex PCONTINUATION(w) \\propto |{v : C(vw) > 0}| ```\n",
      "```latex PCONTINUATION(w) = \\frac{\\sum|{v : C(vw) > 0}|}{|{w' :\n",
      "C(wi1w') > 0}|} ```  ```latex PKN(w|wi1) = \\frac{max(C(wi1w) - d,\n",
      "0) + \\lambda(wi1)PCONTINUATION(w)}{C(wi1)} ```  ```latex\n",
      "\\lambda(wi1) = \\frac{\\sum_v C(wi1v)}{|{w : C(wi1w) > 0}|d} ```\n",
      "```latex PKN(w|win+1:i1) = \\f...\n",
      "Node ID: d58e8dba-80e8-4d98-9eb0-119b558748b3\n",
      "Text: ```latex H(X) = - \\sum_{x \\in \\chi} p(x) \\log_2 p(x) \\tag{3.43}\n",
      "```  ```latex H(X) = -\\sum_{i=1}^{8} p(i) \\log p(i) = - \\left(\n",
      "\\frac{2}{1} \\log_2 \\frac{1}{2} - \\frac{4}{1} \\log_2 \\frac{4}{1} -\n",
      "\\frac{8}{1} \\log_2 \\frac{8}{1} - \\frac{16}{1} \\log_2 \\frac{16}{1} - 4\n",
      "\\left( \\frac{64}{1} \\log_2 \\frac{64}{1} \\right) \\right) = 2 \\text{\n",
      "bits} \\tag{3.44} ```\n",
      "Node ID: c1327803-5a80-4eb3-9447-567ab92af5fd\n",
      "Text: ```markdown What if the horses are equally likely? We saw above\n",
      "that if we used an equal-length binary code for the horse numbers,\n",
      "each horse took 3 bits to code, so the average was 3. Is the entropy\n",
      "the same? In this case each horse would have a probability of \\(\n",
      "\\frac{1}{8} \\). The entropy of the choice of horses is then  $$ H(X) =\n",
      "- \\sum_{i=1...\n",
      "Node ID: c768e321-f8d5-4241-972c-50b820381308\n",
      "Text: ```latex H(p, m) = \\lim_{n \\to \\infty} -\\frac{1}{n} \\sum_{w \\in\n",
      "L^1} p(w_1, \\ldots, w_n) \\log m(w_1, \\ldots, w_n) \\tag{3.50} ```\n",
      "```latex H(p, m) = \\lim_{n \\to \\infty} -\\frac{1}{n} \\log m(w_1 w_2\n",
      "\\ldots w_n) \\tag{3.51} ```  ```latex H(p) \\leq H(p, m) \\tag{3.52} ```\n",
      "```latex H(W) = -\\frac{1}{N} \\log P(w_1 w_2 \\ldots w_N) \\tag{3.53} ```\n",
      "Node ID: ea38b0fc-6d22-450e-807c-c4f443ee9e72\n",
      "Text: ```latex \\text{Perplexity}(W) = 2H(W) = P(w_1 w_2 \\ldots\n",
      "w_N)^{-\\frac{1}{N}} = \\sqrt{N} = \\sqrt{\\prod_{i=1}^{N} P(w|w_1 \\ldots\n",
      "w_{i-1})} \\sqrt{P(w_1 w_2 \\ldots w_N)} ```  ### Summary This chapter\n",
      "introduced language modeling and the n-gram, one of the most widely\n",
      "used tools in language processing. - Language models offer a way to\n",
      "assign a probab...\n",
      "Node ID: a9d654a2-b24d-4d91-b7fc-2c3c0505920e\n",
      "Text: ```markdown ## Exercises  3.1 Write out the equation for trigram\n",
      "probability estimation (modifying Eq. 3.11). Now write out all the\n",
      "non-zero trigram probabilities for the I am Sam corpus on page 34.\n",
      "3.2 Calculate the probability of the sentence i want chinese food.\n",
      "Give two probabilities, one using Fig. 3.2 and the useful\n",
      "probabilities just b...\n",
      "Node ID: 15ea572c-c114-4a54-b3f4-a7a40e41c2f2\n",
      "Text: ```markdown EXERCISES  57  1. I am Sam 2. Sam I am 3. I am Sam\n",
      "4. I do not like green eggs and Sam  Using a bigram language model\n",
      "with add-one smoothing, what is P(Sam | am)? Include  and  in your\n",
      "counts just like any other token.  3.5 Suppose we didnt use the end-\n",
      "symbol . Train an unsmoothed bigram grammar on the following training\n",
      "corpus with...\n",
      "Node ID: 728a4213-3ad4-452a-91a1-80e51a599f12\n",
      "Text: ```markdown # CHAPTER 4 - Naive Bayes and Sentiment\n",
      "Classification  Classification lies at the heart of both human and\n",
      "machine intelligence. Deciding what letter, word, or image has been\n",
      "presented to our senses, recognizing faces or voices, sorting mail,\n",
      "assigning grades to homeworks; these are all examples of assigning a\n",
      "category to an input. T...\n",
      "Node ID: b1da5e49-d1dd-4aa7-a3e9-ad7ddcef6255\n",
      "Text: ```markdown 4.1  NAIVE BAYES CLASSIFIERS  Finally, one of the\n",
      "oldest tasks in text classification is assigning a library subject\n",
      "category or topic label to a text. Deciding whether a research paper\n",
      "concerns epidemiology or instead, perhaps, embryology, is an important\n",
      "component of information retrieval. Various sets of subject categories\n",
      "exist,...\n",
      "Node ID: 6cd3c0b3-b900-4d4a-a6fb-7c1858972d8f\n",
      "Text: ```markdown c = argmaxP(c|d)\n",
      "(4.1) ```  ```markdown P(x|y) = P(y|x)P(x)P(y)\n",
      "(4.2) ```  ```markdown c = argmaxP(c|d) = argmaxP(d|c)P(c)\n",
      "(4.3) ```\n",
      "Node ID: ce6f8d37-4a8b-4830-921b-bcea0581816b\n",
      "Text: ```latex c = \\arg\\max_{c \\in C} P(c|d) = \\arg\\max_{c \\in C}\n",
      "P(d|c) P(c) \\tag{4.4} ```  ```latex c = \\arg\\max_{c \\in C} P(d|c)\n",
      "P(c) \\tag{4.5} ```  ```latex c = \\arg\\max_{c \\in C} P(f_1, f_2,\n",
      "\\ldots, f_n|c) P(c) \\tag{4.6} ```  ```latex P(f_1, f_2, \\ldots, f_n|c)\n",
      "= P(f_1|c) \\cdot P(f_2|c) \\cdots P(f_n|c) \\tag{4.7} ```  ```latex\n",
      "c_{NB} = \\arg\\max...\n",
      "Node ID: 974a9b07-1d3e-4b31-9fc2-b3da739ebf3e\n",
      "Text: ```latex c_{NB} = \\arg\\max_{c \\in C} \\left( \\log P(c) + \\sum_{i\n",
      "\\in \\text{positions}} \\log P(w|c) \\right) \\tag{4.10} ```  ```latex\n",
      "\\hat{P}(c) = \\frac{N_c}{N_{\\text{doc}}} \\tag{4.11} ```  ```latex\n",
      "\\hat{P}(w|c) = \\frac{\\sum_{w \\in V} \\text{count}(w, c)}{\\sum_{w \\in V}\n",
      "\\text{count}(w, c_i)} \\tag{4.12} ```  ```latex\n",
      "\\hat{P}(\\text{\"fantastic\"}|positi...\n",
      "Node ID: 8678a08a-f94e-4ede-9bf3-0a07984a0e1e\n",
      "Text: ```python function TRAIN_NAIVE_BAYS(D, C) returns log P(c) and\n",
      "log P(w|c) for each class c  C                         # Calculate\n",
      "P(c) terms Ndoc = number of documents in D Nc = number of documents\n",
      "from D in class c logprior[c]  log (Nc / N) V  vocabulary of D\n",
      "bigdoc[c]  append(d) for d  D with class c for each word w in V\n",
      "...\n",
      "Node ID: 4c77ee1a-c86d-4721-93c9-00af5e6e8bb9\n",
      "Text: ```latex P() = \\frac{5}{3}, \\quad P(+) = \\frac{5}{2} ```\n",
      "```latex P(predictable|) = \\frac{1 + 1}{14 + 20}, \\quad\n",
      "P(predictable|+) = \\frac{9 + 2}{0 + 20 + 1} ```  ```latex P(no|)\n",
      "= \\frac{1 + 1}{14 + 20}, \\quad P(no|+) = \\frac{9 + 2}{0 + 20 + 1}\n",
      "```  ```latex P(fun|) = \\frac{0 + 1}{1}, \\quad P(fun|+) = \\frac{9\n",
      "+ 2}{0 + 20 + 1} ```...\n",
      "Node ID: b3eab002-e6e3-49b4-92ac-2017a3e1e045\n",
      "Text: ```markdown A second important addition commonly made when doing\n",
      "text classification for sentiment is to deal with negation. Consider\n",
      "the difference between I really like this movie (positive) and I\n",
      "didnt like this movie (negative). The negation expressed by didnt\n",
      "completely alters the inferences we draw from the predicate like.\n",
      "Similarly, neg...\n",
      "Node ID: 75d2cfa3-7a8b-4366-b55b-801a33897095\n",
      "Text: ```markdown Finally, in some situations we might have\n",
      "insufficient labeled training data to train accurate naive Bayes\n",
      "classifiers using all words in the training set to estimate positive\n",
      "and negative sentiment. In such cases we can instead derive the\n",
      "positive sentiment and negative word features from sentiment lexicons,\n",
      "lists of words that are ...\n",
      "Node ID: 12bfa99c-ec6a-4342-a737-6665759ce52c\n",
      "Text: ```markdown P(s|c) = \\prod_{i \\in positions} P(w_i|c) \\tag{4.15}\n",
      "```  P(I love this fun film|+) = 0.1  0.1  0.01  0.05  0.1 =\n",
      "0.0000005  P(I love this fun film|) = 0.2  0.001  0.01  0.005 \n",
      "0.1 = 0.0000000010\n",
      "Node ID: 20941687-359b-4100-ba20-51fb0f672864\n",
      "Text: ```markdown P(s|pos) > P(s|neg) ```  $$ \\text{precision} =\n",
      "\\frac{tp}{tp + fp} $$  $$ \\text{accuracy} = \\frac{tp + fp + tn}{tp +\n",
      "tn} $$  $$ \\text{recall} = \\frac{tp}{tp + fn} $$\n",
      "Node ID: 5702777e-936e-4c44-a2f5-7c129f5fb5aa\n",
      "Text: ```markdown Precision = \\frac{true\\ positives}{true\\ positives +\n",
      "false\\ positives} ```  ```markdown Recall = \\frac{true\\\n",
      "positives}{true\\ positives + false\\ negatives} ```  ```markdown\n",
      "F_{\\beta} = \\frac{(\\beta^2 P + R^2)}{(\\beta^2 P + R)} ```  ```markdown\n",
      "F_1 = \\frac{2PR}{P + R} ```  ```markdown HarmonicMean(a_1, a_2, a_3,\n",
      "a_4, \\ldots, a_n) = \\f...\n",
      "Node ID: fff60a70-b7cd-47c6-af4f-981ee90b9012\n",
      "Text: ```markdown Harmonic mean is used because it is a conservative\n",
      "metric; the harmonic mean of two values is closer to the minimum of\n",
      "the two values than the arithmetic mean is. Thus it weighs the lower\n",
      "of the two numbers more heavily.  ### 4.7.1 Evaluating with more than\n",
      "two classes Up to now we have been describing text classification\n",
      "tasks with ...\n",
      "Node ID: da587423-5268-4d18-a5e1-b9bd044257bc\n",
      "Text: ```plaintext 4.9        STATISTICAL SIGNIFICANCE TESTING\n",
      "71  Class 1: Urgent                 Class 2: Normal\n",
      "Class 3: Spam                            Pooled true    true\n",
      "true    true                    true   true\n",
      "true    true urgent   not                   normal...\n",
      "Node ID: 5ada2593-7d5a-4972-905d-9bec14db6ff8\n",
      "Text: ```latex \\delta (x) = M(A, x) - M(B, x) \\tag{4.19} ```  ```latex\n",
      "H_0 : \\delta (x) \\leq 0 H_1 : \\delta (x) > 0 \\tag{4.20} ```  ```latex\n",
      "P(\\delta (X) \\geq \\delta (x) | H_0 \\text{ is true}) \\tag{4.21} ```\n",
      "Node ID: 15b435ce-61ac-4a8d-8d4f-ac939fc0c96e\n",
      "Text: ```markdown 4.9  STATISTICAL SIGNIFICANCE TESTING  A very small\n",
      "p-value means that the difference we observed is very unlikely under\n",
      "the null hypothesis, and we can reject the null hypothesis. What\n",
      "counts as very small? It is common to use values like .05 or .01 as\n",
      "the thresholds. A value of .01 means that if the p-value (the\n",
      "probability of obs...\n",
      "Node ID: 91b27739-f8c4-4541-9430-cdaa87ec407f\n",
      "Text: ```markdown 1             2          3           4          5\n",
      "6          7           8     9  10 A% B%  () x(1) x(2)            AB\n",
      "AB AB AB AB AB AB AB AB AB AB AB AB .60 AB AB AB AB AB B AB .70 A .50\n",
      ".60         .20 .00  x               AB AB AB AB AB AB AB AB AB AB .60\n",
      ".70 -.10 ...b) x( ```  The p-value is calculated as follows:  $$ ...\n",
      "Node ID: 9c4a6d38-2224-4d52-a839-e8732bb668e5\n",
      "Text: ```python function BOOTSTRAP(test set x, num of samples b)\n",
      "returns p-value(x) Calculate  (x) # how much better does algorithm A\n",
      "do than B on x s = 0 for i = 1 to b do for j = 1 to n do      # Draw a\n",
      "bootstrap sample x(i) of size n Select a member of x at random and add\n",
      "it to x(i) Calculate  (x(i)) # how much better does algorithm A do\n",
      "than B o...\n",
      "Node ID: 54611810-3724-4793-929e-0cd7909bf729\n",
      "Text: ```markdown 4.11            Summary This chapter introduced the\n",
      "naive Bayes model for classification and applied it to the text\n",
      "categorization task of sentiment analysis.  Many language processing\n",
      "tasks can be viewed as tasks of classification.  Text categorization,\n",
      "in which an entire text is assigned a class from a finite set,\n",
      "includes such t...\n",
      "Node ID: 8e4ab8fa-91cc-498b-9932-8362c929935a\n",
      "Text: ```markdown Exercises 4.1 Assume the following likelihoods for\n",
      "each word being part of a positive or negative movie review, and equal\n",
      "prior probabilities for each class. ```\n",
      "Node ID: e4930c9d-9862-4ce3-a774-0e45f784f692\n",
      "Text: ```plaintext pos     neg I          0.09 0.16 always 0.07 0.06\n",
      "like       0.29 0.06 foreign 0.04 0.15 films      0.08 0.11 ```  Given\n",
      "the following short movie reviews, each labeled with a genre, either\n",
      "comedy or action: 1. fun, couple, love, love         comedy 2. fast,\n",
      "furious, shoot        action 3. couple, fly, fast, fun, fun\n",
      "comedy 4...\n",
      "Node ID: 525a89ae-0c41-4cb7-9f21-a12eb99743f7\n",
      "Text: ```markdown # CHAPTER 5  ## Logistic Regression  And how do you\n",
      "know that these fine begonias are not of equal importance? Hercule\n",
      "Poirot, in Agatha Christies The Mysterious Affair at Styles\n",
      "Detective stories are as littered with clues as texts are with words.\n",
      "Yet for the poor reader, it can be challenging to know how to weigh\n",
      "the authors c...\n",
      "Node ID: de141860-4b90-4490-9606-0b84f4549c5d\n",
      "Text: ```latex \\hat{c} = \\arg\\max_{c \\in C} P(d|c) P(c) \\tag{5.1} ```\n",
      "The components of a probabilistic machine learning classifier include:\n",
      "1. A feature representation of the input, represented as a vector of\n",
      "features \\([x_1, x_2, \\ldots, x_n]\\). 2. A classification function\n",
      "that computes \\(\\hat{y}\\), the estimated class, via \\(p(y|x)\\). 3. An\n",
      "obje...\n",
      "Node ID: 8521a853-a7d1-414d-9ec4-e6f9977c3aa7\n",
      "Text: ```markdown z = \\sum_{i=1}^{n} w_i x_i + b  \\tag{5.2} ```\n",
      "```markdown z = w \\cdot x + b  \\tag{5.3} ```  ```markdown \\sigma(z) =\n",
      "\\frac{1}{1 + e^{-z}}  \\tag{5.4} ```\n",
      "Node ID: c4ba474d-cb4d-4d99-8ee1-0209fecc0c4d\n",
      "Text: ```latex P(y = 1) = \\sigma (w \\cdot x + b) = \\frac{1}{1 + \\exp\n",
      "(-(w \\cdot x + b))} ```  ```latex P(y = 0) = 1 - \\sigma (w \\cdot x +\n",
      "b) = 1 - \\frac{1}{1 + \\exp (-(w \\cdot x + b))} = \\frac{\\exp (-(w \\cdot\n",
      "x + b))}{1 + \\exp (-(w \\cdot x + b))} ```  ```latex 1 - \\sigma (x) =\n",
      "\\sigma (-x) ```  ```latex decision(x) = \\begin{cases} 1 & \\text{if }\n",
      "P(y = ...\n",
      "Node ID: f998b9f5-0e7b-4b5d-b7cc-4eeda82f5173\n",
      "Text: ```markdown p(+|x) = P(y = 1|x) = \\sigma (w \\cdot x + b) =\n",
      "\\sigma ([2.5, -5.0, -1.2, 0.5, 2.0, 0.7] \\cdot [3, 2, 1, 3, 0, 4.19] +\n",
      "0.1) = \\sigma (0.833) = 0.70 ```  ```markdown p(|x) = P(y = 0|x) = 1\n",
      "- \\sigma (w \\cdot x + b) = 0.30 ```\n",
      "Node ID: a897eed1-e501-4df8-b010-85e61faf7f06\n",
      "Text: ```markdown x1 = { 1 if Case(wi) = Lower 0 otherwise x2 = { 1\n",
      "if wi  AcronymDict 0 otherwise x3 = { 1 if wi = St. & Case(wi1) =\n",
      "Cap 0 otherwise ```  $$ \\mu_i = \\frac{1}{m} \\sum_{j=1}^{m} x_i(j) $$\n",
      "$$ \\sigma_i = \\sqrt{\\frac{1}{m} \\sum_{j=1}^{m} (x_i(j) - \\mu_i)^2} $$\n",
      "$$ x'_i = \\frac{x_i - \\mu_i}{\\sigma_i} \\tag{5.8} $$\n",
      "Node ID: f29d73e7-0ae1-47a0-b10f-aae8e722924c\n",
      "Text: ```latex x_i = \\frac{x_i - \\min(x)_i}{\\max(x) - \\min(x)_i}\n",
      "\\quad (5.9) ```  ```plaintext foreach x(i) in input [x(1), x(2), ...,\n",
      "x(m)] y(i) =  (w  x(i) + b)\n",
      "(5.10) ```  ```latex X = \\begin{bmatrix} x_1^{(1)} & x_2^{(1)} &\n",
      "\\ldots & x_f^{(1)} \\\\ x_1^{(2)} & x_2^{(2)} ...\n",
      "Node ID: 6fccfc95-1b31-4c52-8a4e-41983d87112e\n",
      "Text: ```markdown y = X w + b ```  $$ y = X w + b \\quad (m \\times 1)\n",
      "\\quad (m \\times f)(f \\times 1) \\quad (m \\times 1) \\quad (5.14) $$\n",
      "Node ID: 61422315-7e08-4069-8a47-1e7994a7ae9e\n",
      "Text: ```markdown ### 5.3.1 Softmax  The multinomial logistic\n",
      "classifier uses a generalization of the sigmoid, called the softmax\n",
      "function, to compute \\( p(y_k = 1|x) \\). The softmax function takes a\n",
      "vector \\( z = [z_1, z_2, \\ldots, z_K] \\) of \\( K \\) arbitrary values\n",
      "and maps them to a probability distribution, with each value in the\n",
      "range [0,1], and...\n",
      "Node ID: 28d8d2da-ad0b-493e-9fe5-8b7914b312d1\n",
      "Text: ```markdown 88  CHAPTER 5             LOGISTIC REGRESSION  If\n",
      "you work out the matrix arithmetic, you can see that the estimated\n",
      "score of the first output class 1 (before we take the softmax) will\n",
      "correctly turn out to be w1  x + b1. Fig. 5.3 shows an intuition of\n",
      "the role of the weight vector versus weight matrix in the computation\n",
      "of the ou...\n",
      "Node ID: 68d16745-79f5-40d5-86ae-cf218b481435\n",
      "Text: ```plaintext x5 = { 1 if !  doc 0 otherwise ```  $$\n",
      "\\text{loss} = \\text{cross-entropy loss} $$\n",
      "Node ID: c999ceb4-5320-4446-be75-75fcb1f80b8f\n",
      "Text: ```latex L(\\hat{y}, y) = \\text{How much } \\hat{y} \\text{ differs\n",
      "from the true } y ```  ```latex p(y|x) = \\hat{y}^y (1 - \\hat{y})^{1-y}\n",
      "```  ```latex \\log p(y|x) = \\log [\\hat{y}^y (1 - \\hat{y})^{1-y}] = y\n",
      "\\log \\hat{y} + (1 - y) \\log(1 - \\hat{y}) ```  ```latex L_{CE}(\\hat{y},\n",
      "y) = - \\log p(y|x) = - [y \\log \\hat{y} + (1 - y) \\log(1 - \\hat{y})]\n",
      "```...\n",
      "Node ID: 1d53e338-ef99-4dc9-8fda-c88403214cb5\n",
      "Text: ```latex LCE( , y) =y [y log  (w  x + b)+(1  y) log (1  \n",
      "(w  x + b))] ```  ```latex LCE( , y) =  [log (1   (w  x + b))]\n",
      "```  ```latex LCE( , y) =  log (.30) = 1.2 ```  ```latex \\hat{y} =\n",
      "\\arg\\min_{\\theta} \\frac{1}{m} \\sum_{i=1}^{m} L_{CE}(f(x^{(i)};\n",
      "\\theta), y^{(i)}) ```  ```latex \\text{Gradient Descent: } \\text{Find\n",
      "the direction...\n",
      "Node ID: 9f23e16b-fbe9-4feb-a962-418065a5c550\n",
      "Text: ```markdown wt+1 = wt   \\frac{d}{dw} L(f(x; w), y)\n",
      "(5.25) ```  $$ \\text{gradient descent update: } w_{t+1} = w_t - \\eta\n",
      "\\nabla L(f(x; w), y) $$\n"
     ]
    }
   ],
   "source": [
    "for node in page_nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "node_parser = MarkdownElementNodeParser(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo-0125\"), num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mobjects\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mget_content()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "objects[0].get_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump both indexed tables and page text into the vector index\n",
    "recursive_index = VectorStoreIndex(nodes=base_nodes + objects + page_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text does not contain any math equations. If you have a specific page with math equations, please share that, and I can help format them in LaTeX markdown.\n"
     ]
    }
   ],
   "source": [
    "print(page_nodes[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.flag_embedding_reranker import (\n",
    "    FlagEmbeddingReranker,\n",
    ")\n",
    "\n",
    "rerank = FlagEmbeddingReranker(model=\"BAAI/bge-reranker-large\", top_n=5)\n",
    "\n",
    "recursive_query_engine = recursive_index.as_query_engine(\n",
    "    similarity_top_k=5, node_postprocessors=[rerank], verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 250.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$\n",
      "P_{\\text{Add-k}}(w_n|w_{n-1}) = \\frac{C(w_{n-1}w_n) + k}{C(w_{n-1}) + kV}\n",
      "$$\n"
     ]
    }
   ],
   "source": [
    "query_template = \"\"\"\n",
    "What is equation of {subtopic}?\n",
    "Output in latex (between $$)\n",
    "\"\"\"\n",
    "query = query_template.format(subtopic=\"add-k smoothing\", course_title=\"NLP\")\n",
    "response = recursive_query_engine.query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \n",
       "P_{\\text{Add-k}}(w_n|w_{n-1}) = \\frac{C(w_{n-1}w_n) + k}{C(w_{n-1}) + kV}\n",
       "$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math\n",
    "\n",
    "# Extract the LaTeX equation from the response\n",
    "latex_equation = response.response.split('$$')[1]\n",
    "\n",
    "# Display the LaTeX equation\n",
    "display(Math(latex_equation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtopics = [\"What is Python?\", \"Basic Syntax\", \"Variables\", \"Data Types\", \"Operators\", \"Control Flow\", \"Functions\", \"Modules\", \"File I/O\", \"Error Handling\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "c:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a programming language used in Intro to Python Programming. \"What is Python?\" is a concept in Intro to Python Programming that can be associated with code examples.\n",
      "\n",
      "Example code:\n",
      "```python\n",
      "print(\"Python is a versatile programming language.\")\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 998.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Syntax in Intro to Python Programming includes topics such as operators, variables, if/else statements, lists, loops, and functions. Python is the language used in Intro to Python Programming. Basic Syntax is a concept in Intro to Python Programming that can be associated with code examples.\n",
      "\n",
      "Code Example:\n",
      "```python\n",
      "# Variables\n",
      "x = 5\n",
      "y = 10\n",
      "\n",
      "# If/Else Statement\n",
      "if x > y:\n",
      "    print(\"x is greater than y\")\n",
      "else:\n",
      "    print(\"y is greater than x\")\n",
      "\n",
      "# List\n",
      "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
      "\n",
      "# Loop\n",
      "for fruit in fruits:\n",
      "    print(fruit)\n",
      "\n",
      "# Function\n",
      "def greet(name):\n",
      "    print(\"Hello, \" + name)\n",
      "\n",
      "greet(\"Alice\")\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 500.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The contents for Variables are related to programming. Intro to Python Programming is related to programming. Variables is a concept in Intro to Python Programming that can be associated with code examples. \n",
      "\n",
      "Code Example:\n",
      "```python\n",
      "# Variables in Python\n",
      "x = 5\n",
      "y = \"Hello\"\n",
      "z = 3.14\n",
      "\n",
      "print(x)\n",
      "print(y)\n",
      "print(z)\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 1003.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The contents for Data Types in the provided context discuss how Python determines data types for variables based on the context, known as dynamic typing. This is in contrast to compiled languages like C++ or Fortran, where types are identified by the programmer and compiler before the program runs. Run-time typing in Python is convenient for rapid code development but requires more code testing for reliability, especially in larger programs.\n",
      "\n",
      "Intro to Python Programming is related to programming as it introduces learners to Python, a programming language known for its simplicity and readability.\n",
      "\n",
      "The language used in Intro to Python Programming is Python.\n",
      "\n",
      "Data Types is a concept in Intro to Python Programming that can be associated with code examples. \n",
      "\n",
      "Example:\n",
      "```python\n",
      "# Integer data type\n",
      "num = 10\n",
      "\n",
      "# Float data type\n",
      "pi = 3.14\n",
      "\n",
      "# String data type\n",
      "name = \"Alice\"\n",
      "\n",
      "# Boolean data type\n",
      "is_student = True\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 998.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operators in Python are symbols that perform operations on variables and values. They are an essential part of programming in Python. \n",
      "\n",
      "Yes, Intro to Python Programming is related to programming.\n",
      "\n",
      "The language used in Intro to Python Programming is Python.\n",
      "\n",
      "Operators is a concept in Intro to Python Programming that can be associated with code examples.\n",
      "\n",
      "Example:\n",
      "```python\n",
      "# Arithmetic operators\n",
      "a = 10\n",
      "b = 5\n",
      "\n",
      "# Addition\n",
      "print(a + b)\n",
      "\n",
      "# Subtraction\n",
      "print(a - b)\n",
      "\n",
      "# Multiplication\n",
      "print(a * b)\n",
      "\n",
      "# Division\n",
      "print(a / b)\n",
      "\n",
      "# Modulus\n",
      "print(a % b)\n",
      "\n",
      "# Exponentiation\n",
      "print(a ** b)\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 999.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Flow is a concept in Intro to Python Programming that can be associated with code examples. In Python, Control Flow includes if/else statements and loops. Here is a code example for an if/else statement in Python:\n",
      "\n",
      "```python\n",
      "x = 10\n",
      "\n",
      "if x > 5:\n",
      "    print(\"x is greater than 5\")\n",
      "else:\n",
      "    print(\"x is not greater than 5\")\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 1001.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions are a part of the tutorial outline for Intro to Python Programming. Python is the language used in Intro to Python Programming. Functions are a concept in Python that can be associated with code examples. \n",
      "\n",
      "Example code for Functions in Python:\n",
      "```python\n",
      "def greet(name):\n",
      "    return \"Hello, \" + name + \"!\"\n",
      "\n",
      "print(greet(\"Alice\"))\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules in Python are separate files that contain Python code. They consist of Python statements and definitions. Modules are used to organize Python code logically into reusable components. Below is an example of how a module named \"example_module.py\" can be created:\n",
      "\n",
      "```python\n",
      "# example_module.py\n",
      "\n",
      "def greet(name):\n",
      "    return \"Hello, \" + name\n",
      "\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "```\n",
      "\n",
      "In the context of the tutorial outline provided, \"Modules\" would be a concept in Intro to Python Programming that can be associated with code examples.\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3a937a1a-cb48-4397-9b12-49aed18f4826: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query \n",
      "Retrieve the contents for File I/O.\n",
      "Is Intro to Python Programming related to programming?\n",
      "What language is used in Intro to Python Programming?\n",
      "Is the File I/O a concept in Intro to Python Programming that can be associated with code examples?\n",
      "If YES, provide a code example to the File I/O in that language.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 499.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File I/O is a concept in Intro to Python Programming that is related to programming. The language used in Intro to Python Programming is Python. File I/O is a concept in Python that can be associated with code examples. \n",
      "\n",
      "An example of File I/O in Python:\n",
      "```python\n",
      "# Writing to a file\n",
      "with open('example.txt', 'w') as file:\n",
      "    file.write('Hello, this is an example of File I/O in Python.')\n",
      "\n",
      "# Reading from a file\n",
      "with open('example.txt', 'r') as file:\n",
      "    data = file.read()\n",
      "    print(data)\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 1000.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Handling is not explicitly mentioned in the provided tutorial outline. However, in programming languages like Python, Error Handling is a common concept that involves managing errors that may occur during the execution of a program. It allows the program to handle unexpected situations gracefully.\n",
      "\n",
      "Yes, Intro to Python Programming is related to programming.\n",
      "\n",
      "The language used in Intro to Python Programming is Python.\n",
      "\n",
      "Error Handling is a concept in Python programming that can be associated with code examples. \n",
      "\n",
      "Code example for Error Handling in Python:\n",
      "```python\n",
      "try:\n",
      "    # code block where an error may occur\n",
      "    result = 10 / 0\n",
      "except ZeroDivisionError:\n",
      "    print(\"Error: Division by zero!\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "course_title = \"Intro to Python Programming\"\n",
    "query_template = \"\"\"\n",
    "Retrieve the contents for {subtopic}.\n",
    "Is {course_title} related to programming?\n",
    "What language is used in {course_title}?\n",
    "Is the {subtopic} a concept in {course_title} that can be associated with code examples?\n",
    "If YES, provide a code example to the {subtopic} in that language.\n",
    "\"\"\"\n",
    "\n",
    "for subtopic in subtopics:\n",
    "    query = query_template.format(subtopic=subtopic, course_title=course_title)\n",
    "    response = recursive_query_engine.query(query)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The contents for While Loops include information on how while loops have a condition and a code block, the significance of indentation in while loops, and how the loop continues to run until the condition becomes false. The break keyword is mentioned as a way to stop a while loop running.\n",
      "\n",
      "Intro to Python Programming is related to programming.\n",
      "\n",
      "The language used in Intro to Python Programming is Python.\n",
      "\n",
      "Example:\n",
      "```python\n",
      "# Python code example for While Loop\n",
      "count = 0\n",
      "while count < 5:\n",
      "    print(\"Count is:\", count)\n",
      "    count += 1\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "    \"Topic 1: Introduction to Java\": [\n",
    "        \"Editors and Tools\",\n",
    "        \"Basic Syntax\",\n",
    "        \"Language Syntax Properties\",\n",
    "        \"Variables & Datatypes & Literals\",\n",
    "        \"Operators\",\n",
    "        \"Autoboxing and Unboxing\",\n",
    "        \"Enums\",\n",
    "        \"Arrays\",\n",
    "        \"Strings\",\n",
    "        \"Date and Time\"\n",
    "    ],\n",
    "    \"Topic 2: Control Flow\": [\n",
    "        \"Statements, Expressions & Blocks\",\n",
    "        \"Flow Control statements\",\n",
    "        \"Ternary Operator\",\n",
    "        \"Loops statements\",\n",
    "        \"Nested Loops statements\",\n",
    "        \"Loop Control Statements\"\n",
    "    ],\n",
    "    \"Topic 3: Object Oriented Programming\": [\n",
    "        \"Scope\",\n",
    "        \"Classes & Object\",\n",
    "        \"Methods\",\n",
    "        \"Constructors\",\n",
    "        \"Access Modifiers\",\n",
    "        \"this keyword\",\n",
    "        \"Passing by Value\",\n",
    "        \"Encapsulation\",\n",
    "        \"Inheritance\",\n",
    "        \"Abstraction\",\n",
    "        \"Interface\",\n",
    "        \"Polymorphism\"\n",
    "    ],\n",
    "    \"Topic 4: Data Structures\": [\n",
    "        \"Static & Dynamic Array\",\n",
    "        \"N-Dimensional Array\",\n",
    "        \"Basic Operations on Arrays\",\n",
    "        \"Basic operations on Linked List\",\n",
    "        \"Arrays & Linked List\",\n",
    "        \"Types of Linked List\",\n",
    "        \"Stacks & Queues\"\n",
    "    ],\n",
    "    \"Topic 5: Developing an API\": [\n",
    "        \"Design the API architecture\",\n",
    "        \"Develop the API\",\n",
    "        \"Test the API\",\n",
    "        \"Monitor the API and iterate on feedback\"\n",
    "    ],\n",
    "    \"Topic 6: Debugging Java Applications\": [\n",
    "        \"What is Debugging?\",\n",
    "        \"Examining the code\",\n",
    "        \"Setting breakpoints\",\n",
    "        \"Running the program in debug mode\",\n",
    "        \"Analyze the program state\",\n",
    "        \"Step through the program\",\n",
    "        \"Stopping the debugging session and rerun the program\"\n",
    "    ],\n",
    "    \"Topic 7: Exception Handling\": [\n",
    "        \"Exception keywords\",\n",
    "        \"Nested exceptions\",\n",
    "        \"Throwing exceptions\",\n",
    "        \"Exception propagation\",\n",
    "        \"Throws clause\",\n",
    "        \"Custom exceptions\",\n",
    "        \"Chaining exceptions\",\n",
    "        \"Exceptions with polymorphism\"\n",
    "    ],\n",
    "    \"Topic 8: File Operations\": [\n",
    "        \"File paths\",\n",
    "        \"File metadata\",\n",
    "        \"Creating regular and temporary files\",\n",
    "        \"The try-with-resources statement\",\n",
    "        \"Checking if a File or Directory exists\",\n",
    "        \"File access modes\",\n",
    "        \"Reading from and writing to files\"\n",
    "    ],\n",
    "    \"Topic 9: Using Generics\": [\n",
    "        \"Generic types\",\n",
    "        \"Bounded type parameters\",\n",
    "        \"Inheritance and subtypes\",\n",
    "        \"Type inference\",\n",
    "        \"Wildcards\",\n",
    "        \"Restrictions\"\n",
    "    ],\n",
    "    \"Topic 10: Multi-threading\": [\n",
    "        \"Life cycle of a thread\",\n",
    "        \"Synchronization\",\n",
    "        \"Issues with Multi-threading\",\n",
    "        \"Interrupting Threads\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the updated query format\n",
    "query_template = \"\"\"Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
    "\n",
    "### Instructions\n",
    "1. Retrieve information that specifically corresponds to {subtopic} with context of the broarder topic {topic}, matching the relevant chapters, sections, or locations in the vector store.\n",
    "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
    "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
    "3. Organize information concisely, in bullet points.\n",
    "\n",
    "**Output Format:**\n",
    "{{\n",
    "    \"subtopic\": \"{subtopic}\",\n",
    "    \"keypoints\": [\n",
    "        {{\n",
    "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
    "            \"bullets\": [\n",
    "                \"Bullet point 1: [Specific lecture content on Key Point 1]\",\n",
    "                \"Bullet point 2: [Another specific lecture content on Key Point 1]\"\n",
    "            ]\n",
    "        }},\n",
    "        {{\n",
    "            \"keypoint\": \"Key Point 2\",\n",
    "            \"bullets\": [\n",
    "                \"Bullet point 1: [Specific lecture content about Key Point 2]\",\n",
    "                \"Bullet point 2: [Another specific lecture content about Key Point 2]\"\n",
    "            ]\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "**Requirements:**\n",
    "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
    "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Editors and Tools, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Editors and Tools\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 73786703-303b-417d-92e0-538ac0e2a046: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Editors and Tools, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Editors and Tools\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 0d39df79-39cd-4ba7-9b0d-efc276652ee9: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Editors and Tools, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Editors and Tools\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 500.10it/s]\n",
      "c:\\Users\\dljh1\\anaconda3\\envs\\autogen02\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 1 - Editors and Tools***********\n",
      "{\n",
      "    \"subtopic\": \"Editors and Tools\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Console Class\",\n",
      "            \"bullets\": [\n",
      "                \"Console class is referenced in the context of IntelliJ IDEA.\",\n",
      "                \"It is utilized for interactive and multi-threaded Java applications.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"File I/O Classes\",\n",
      "            \"bullets\": [\n",
      "                \"Various File I/O classes like BufferedInputStream, BufferedOutputStream, FileInputStream, FileOutputStream, FileReader, and FileWriter are mentioned.\",\n",
      "                \"These classes are used for reading from and writing to files in Java.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Statements, Expressions & Blocks, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Statements, Expressions & Blocks\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 498.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 2 - Statements, Expressions & Blocks***********\n",
      "{\n",
      "    \"subtopic\": \"Statements, Expressions & Blocks\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Statements in Java\",\n",
      "            \"bullets\": [\n",
      "                \"Statements are the building blocks of Java programs, executing specific actions like variable assignments or method calls.\",\n",
      "                \"Common types of statements include declaration statements, control flow statements (if, else, switch), and loop statements (for, while).\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Expressions in Java\",\n",
      "            \"bullets\": [\n",
      "                \"Expressions in Java are combinations of variables, operators, and method calls that produce a single value.\",\n",
      "                \"They can be simple expressions like arithmetic operations or complex expressions involving method invocations and conditional operators.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Blocks in Java\",\n",
      "            \"bullets\": [\n",
      "                \"Blocks in Java are enclosed within curly braces {} and can contain a group of zero or more statements.\",\n",
      "                \"They are used to define the scope of variables, control flow structures, and are essential in defining methods, classes, and control structures.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Scope, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Scope\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 73786703-303b-417d-92e0-538ac0e2a046: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Scope, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Scope\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 317.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 3 - Scope***********\n",
      "{\n",
      "    \"subtopic\": \"Scope\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Object-Oriented Programming\",\n",
      "            \"bullets\": [\n",
      "                \"Object-Oriented Programming emphasizes the concept of classes and objects interacting with each other.\",\n",
      "                \"Visibility levels in Java classes, methods, and fields are controlled using private, protected, and public modifiers.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Cohesion\",\n",
      "            \"bullets\": [\n",
      "                \"Cohesion refers to the degree to which a component focuses on a single well-defined task.\",\n",
      "                \"Java packages like java.io exhibit relatively high cohesion due to containing I/O-related classes and interfaces.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Association\",\n",
      "            \"bullets\": [\n",
      "                \"Association represents the relationship between objects where one object can be linked to one or more other objects.\",\n",
      "                \"Different types of object associations include one-to-one, one-to-many, many-to-one, and many-to-many.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Aggregation\",\n",
      "            \"bullets\": [\n",
      "                \"Aggregation is a technique used to establish associations between objects.\",\n",
      "                \"It involves a connection where one object contains or is composed of other objects.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Static & Dynamic Array, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Static & Dynamic Array\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 500.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 4 - Static & Dynamic Array***********\n",
      "{\n",
      "    \"subtopic\": \"Static & Dynamic Array\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Static Array\",\n",
      "            \"bullets\": [\n",
      "                \"In Java, arrays are index-based with the first element at the 0th index, and they can only hold a fixed number of items.\",\n",
      "                \"Java arrays are dynamically created class objects that store related components in a continuous memory region.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Dynamic Array\",\n",
      "            \"bullets\": [\n",
      "                \"Java arrays can store primitive values or objects and can be single-dimensional or multidimensional.\",\n",
      "                \"Java arrays inherit the Object class and implement Serializable and Cloneable interfaces, allowing for flexibility in data storage.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Design the API architecture, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Design the API architecture\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 73786703-303b-417d-92e0-538ac0e2a046: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Design the API architecture, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Design the API architecture\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 25.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 5 - Design the API architecture***********\n",
      "{\n",
      "    \"subtopic\": \"Design the API architecture\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Association\",\n",
      "            \"bullets\": [\n",
      "                \"Association represents the link between items where one item can be connected to one or more objects.\",\n",
      "                \"There are four types of object associations: One to One, One to Many, Many to One, and Many to Many.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Aggregation\",\n",
      "            \"bullets\": [\n",
      "                \"Aggregation is a technique used to achieve Association, indicating a connection where one object contains another object.\",\n",
      "                \"It establishes a 'whole-part' relationship, allowing one object's existence without the other.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to What is Debugging?, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"What is Debugging?\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 333.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 6 - What is Debugging?***********\n",
      "{\n",
      "    \"subtopic\": \"What is Debugging?\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Debugging in Java\",\n",
      "            \"bullets\": [\n",
      "                \"Debugging is the process of identifying and fixing errors or bugs in a program to ensure it runs correctly.\",\n",
      "                \"It involves using tools like breakpoints, watches, and stepping through code to trace and resolve issues.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Debugging Tools\",\n",
      "            \"bullets\": [\n",
      "                \"Common debugging tools in Java include IDE debuggers like IntelliJ IDEA, which provide features for inspecting variables, evaluating expressions, and tracking program flow.\",\n",
      "                \"Tools like debug logs, stack traces, and exception handling are also essential for identifying and resolving errors.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3af49523-3bfa-44b9-960a-e4607c69562f: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Exception keywords, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Exception keywords\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Exception keywords, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Exception keywords\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 73786703-303b-417d-92e0-538ac0e2a046: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Exception keywords, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Exception keywords\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 166.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 7 - Exception keywords***********\n",
      "{\n",
      "    \"subtopic\": \"Exception keywords\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Java BuzzWords\",\n",
      "            \"bullets\": [\n",
      "                \"Java BuzzWords section briefly mentions exceptions in Java programming.\",\n",
      "                \"Exceptions are a fundamental concept in Java programming covered in the Java BuzzWords section.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"NO CONTEXT\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to File paths, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"File paths\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 73786703-303b-417d-92e0-538ac0e2a046: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to File paths, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"File paths\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 122.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 8 - File paths***********\n",
      "{\n",
      "    \"subtopic\": \"File paths\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"File Paths in Java Classes\",\n",
      "            \"bullets\": [\n",
      "                \"Java classes such as FileInputStream and FileOutputStream handle file paths for reading from and writing to files.\",\n",
      "                \"Classes like FileReader and FileWriter also manage file paths for reading and writing character files.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"File Paths in Java Packages\",\n",
      "            \"bullets\": [\n",
      "                \"Java packages like java.io contain classes that work with file paths for input and output operations.\",\n",
      "                \"Sub-packages within Java packages further categorize classes related to file paths, like the io package for Input/Output operations.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Generic types, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Generic types\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 9ad286a2-37b8-4f3b-ae4e-ed773e3229ad: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Generic types, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Generic types\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 250.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 9 - Generic types***********\n",
      "{\n",
      "    \"subtopic\": \"Generic types\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Java Classes and Concepts\",\n",
      "            \"bullets\": [\n",
      "                \"Generic types are not specifically mentioned in the Java Classes and Concepts table.\",\n",
      "                \"NO CONTEXT\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 3f7a1bd7-0eb2-44a1-9767-d5925c582181: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query Retrieve key information on the following topic from the vector store ONLY. Ensure all responses are grounded strictly in retrieved data.\n",
      "\n",
      "### Instructions\n",
      "1. Retrieve information that specifically corresponds to Life cycle of a thread, matching the relevant chapters, sections, or locations in the vector store.\n",
      "2. If no relevant information exists for the subtopic in the vector store, return the response \"NO CONTEXT\".\n",
      "3. Ensure that each response provides content grounded only in the vector store, without additional extrapolation.\n",
      "3. Organize information concisely, in bullet points.\n",
      "\n",
      "**Output Format:**\n",
      "{\n",
      "    \"subtopic\": \"Life cycle of a thread\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 1 [Specific section of the subtopic]\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content on Key Point 1]\",\n",
      "                \"Bullet point 2: [Another specific content on Key Point 1]\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Key Point 2\",\n",
      "            \"bullets\": [\n",
      "                \"Bullet point 1: [Specific content about Key Point 2]\",\n",
      "                \"Bullet point 2: [Another specific content about Key Point 2]\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Requirements:**\n",
      "- Ensure each bullet point provides relevant details **about the content of the keypoint** itself, not references to a source.\n",
      "- Provide no more than two sentences per bullet point, ensuring concise, detailed information directly on the keypoint topic, not whether it is covered in Chapter X.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|| 1/1 [00:00<00:00, 249.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********LlamaParse+ Recursive Retriever Query Engine Response for 10 - Life cycle of a thread***********\n",
      "{\n",
      "    \"subtopic\": \"Life cycle of a thread\",\n",
      "    \"keypoints\": [\n",
      "        {\n",
      "            \"keypoint\": \"Thread Life Cycle Overview\",\n",
      "            \"bullets\": [\n",
      "                \"Threads in Java have a life cycle that includes states like New, Runnable, Blocked, Waiting, Timed Waiting, and Terminated.\",\n",
      "                \"Each state represents a specific stage in the thread's execution process.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"keypoint\": \"Thread States\",\n",
      "            \"bullets\": [\n",
      "                \"New state is when a thread is created but not yet started. Runnable state means the thread is ready to run and waiting for the CPU.\",\n",
      "                \"Blocked state occurs when a thread is waiting for a monitor lock to enter a synchronized block.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "results = {\"topics\": []}  # Initialize results as a dictionary with a \"topics\" key\n",
    "\n",
    "# Run the query for each topic individually\n",
    "for idx, (topic_title, subtopics) in enumerate(topics.items()):\n",
    "    # Create a topic dictionary to hold subtopics for each main topic\n",
    "    topic_data = {\n",
    "        \"topic\": topic_title,\n",
    "        \"subtopics\": []\n",
    "    }\n",
    "    \n",
    "    for subtopic in subtopics:\n",
    "        # Format the query with the subtopic-specific information only\n",
    "        query = query_template.format(subtopic=subtopic, topic=topic_title)\n",
    "        \n",
    "        # Execute the query\n",
    "        response = recursive_query_engine.query(query)\n",
    "        \n",
    "        # Extract the JSON response and convert it to a dictionary\n",
    "        try:\n",
    "            json_data = eval(response.response)  # Convert response string to dictionary\n",
    "            \n",
    "            # Add subtopic data to the current topic's subtopics list\n",
    "            subtopic_data = {\n",
    "                \"subtopic\": json_data.get(\"subtopic\"),\n",
    "                \"keypoints\": json_data.get(\"keypoints\", [])\n",
    "            }\n",
    "            topic_data[\"subtopics\"].append(subtopic_data)\n",
    "            \n",
    "        except (SyntaxError, ValueError):\n",
    "            print(f\"Failed to parse response for {subtopic}\")\n",
    "        \n",
    "        # Print response for testing purposes\n",
    "        print(f\"\\n***********LlamaParse+ Recursive Retriever Query Engine Response for {idx+1} - {subtopic}***********\")\n",
    "        print(response.response)\n",
    "        \n",
    "        # Only run the first subtopic for testing purposes\n",
    "        break\n",
    "\n",
    "    # Append the completed topic data to the main topics list in results\n",
    "    results[\"topics\"].append(topic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********JSON MAPPING RESULTS***********\n",
      "Data has been written to ../output/rag_output.json\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n***********JSON MAPPING RESULTS***********\")\n",
    "# json_data = json.dumps(results_json, indent=4)\n",
    "\n",
    "# Specify the file path\n",
    "file_path = '../output/rag_output.json'\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=4)  # indent=4 adds pretty-print formatting\n",
    "\n",
    "print(f\"Data has been written to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
